# Coming From ZIO

---

## title: Coming From ZIOexcerpt: Key differences between Effect and ZIO explained, covering the representation of the environment, removal of `Has`, and the absence of predefined type aliases like `UIO`, `URIO`, `RIO`, `Task`, or `IO` in Effect.bottomNavigation: pagination

If you are coming to Effect from ZIO, there are a few differences to be aware of.

## Environment

In Effect, we represent the environment required to run an `Effect` workflow as a union of services:

```ts twoslash
import { Effect } from 'effect';

//                                                          v---------v---- `R` is a union of Console | Logger
type Http = Effect.Effect<Response, IOError | HttpError, Console | Logger>;

type Response = Record<string, string>;

interface IOError {
  readonly _tag: 'IOError';
}

interface HttpError {
  readonly _tag: 'HttpError';
}

interface Console {
  readonly log: (msg: string) => void;
}

interface Logger {
  readonly log: (msg: string) => void;
}
```

This may be confusing to folks coming from ZIO, where the environment is represented as an intersection of services:

```scala
type Http = ZIO[Console with Logger, IOError, Response]
```

## Rationale

The rationale for using a union to represent the environment required by an `Effect` workflow boils down to our desire to remove `Has` as a wrapper for services in the environment (similar to what was achieved in ZIO 2.0).

To be able to remove `Has` from Effect, we had to think a bit more structurally given that TypeScript is a structural type system. In TypeScript, if you have a type `A & B` where there is a structural conflict between `A` and `B`, the type `A & B` will reduce to `never`.

```ts twoslash
// @errors: 2322
export interface A {
  readonly prop: string;
}

export interface B {
  readonly prop: number;
}

const ab: A & B = {
  prop: '',
};
```

In previous versions of Effect, intersections were used for representing an environment with multiple services. The problem with using intersections (i.e. `A & B`) is that there could be multiple services in the environment that have functions and properties named in the same way. To remedy this, we wrapped services in the `Has` type (similar to ZIO 1.0), so you would have `Has<A> & Has<B>` in your environment.

In ZIO 2.0, the _contravariant_ `R` type parameter of the `ZIO` type (representing the environment) became fully phantom, thus allowing for removal of the `Has` type. This significantly improved the clarity of type signatures as well as removing another "stumbling block" for new users.

To facilitate removal of `Has` in Effect, we had to consider how types in the environment compose. By the rule of composition, contravariant parameters composed as an intersection (i.e. with `&`) are equivalent to covariant parameters composed together as a union (i.e. with `|`) for purposes of assignability. Based upon this fact, we decided to diverge from ZIO and make the `R` type parameter _covariant_ given `A | B` does not reduce to `never` if `A` and `B` have conflicts.

From our example above:

```ts twoslash
export interface A {
  readonly prop: string;
}

export interface B {
  readonly prop: number;
}

const ab: A | B = {
  prop: '',
};
```

Representing `R` as a covariant type parameter containing the union of services required by an `Effect` workflow allowed us to remove the requirement for `Has`.

## Type Aliases

In Effect, there are no predefined type aliases such as `UIO`, `URIO`, `RIO`, `Task`, or `IO` like in ZIO.

The reason for this is that type aliases are lost as soon as you compose them, which renders them somewhat useless unless you maintain **multiple** signatures for **every** function. In Effect, we have chosen not to go down this path. Instead, we utilize the `never` type to indicate unused types.

It's worth mentioning that the perception of type aliases being quicker to understand is often just an illusion. In Effect, the explicit notation `Effect<A>` clearly communicates that only type `A` is being used. On the other hand, when using a type alias like `RIO<R, A>`, questions arise about the type `E`. Is it `unknown`? `never`? Remembering such details becomes challenging.

# FAQ

---

## title: FAQexcerpt: Explore common questions about Effect, including type extraction, sync/async behavior, comparison with fp-ts, understanding flatMap, and the absence of ZIO-like type aliases. Learn about configuring layers and the flexibility of accepting arguments to influence service construction in layers.bottomNavigation: pagination

## Effect

**Q: Is it possible to extract the types from an Effect?**

A: By using the utility types `Effect.Effect.Context`, `Effect.Effect.Error`, and `Effect.Effect.Success`, we can extract the corresponding types from the `program` Effect. In this example, we extract the context type (`R`), the error type (`E`), and the success type (`A`).

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('Random')<
  Random,
  {
    readonly next: Effect.Effect<number>;
  }
>() {}

declare const program: Effect.Effect<number, string, Random>;

// type R = Random
type R = Effect.Effect.Context<typeof program>;

// type E = string
type E = Effect.Effect.Error<typeof program>;

// type A = number
type A = Effect.Effect.Success<typeof program>;
```

**Q: Is there a way to determine whether an Effect is synchronous or asynchronous in advance?**

A: No, there isn't a straightforward way to statically determine if an Effect is synchronous or asynchronous. We did explore this idea in earlier versions of Effect, but we decided against it for a few important reasons:

1. **Complexity:** Introducing this feature to track sync/async behavior in the type system would make Effect more complex to use and limit its composability.

2. **Safety Concerns:** We experimented with different approaches to track asynchronous Effects, but they all resulted in a worse developer experience without significantly improving safety. Even with fully synchronous types, we needed to support a `fromCallback` combinator to work with APIs using Continuation-Passing Style (CPS). However, at the type level, it's impossible to guarantee that such a function is always called immediately and not deferred.

In practice, it's important to note that you should typically only run Effects at the edges of your application. If your application is entirely based on Effect, it usually involves a single call to the `main` effect. In such cases, the best approach is to use `runPromise` or `runFork` for most executions. Synchronous execution is a special case and should be considered an edge case, used only when asynchronous execution is not possible. So, our recommendation is to use `runPromise` or `runFork` whenever you can and resort to `runSync` only when absolutely necessary.

**Q: I'm familiar with `flatMap` in JavaScript/TypeScript from its usage on the `Array` prototype. Why do I see it in modules provided by Effect?**

A: Many JavaScript / TypeScript engineers are familiar with the term `flatMap` due to it's [presence as a method on the `Array` prototype](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/flatMap). Therefore it may be confusing to see `flatMap` methods exported from many of the modules that Effect provides.

The `flatMap` operation can actually be used to describe a more generic data transformation. Let's consider for a moment a generic data type that we will call `F`. `F` will also be a container for elements, so we can further refine our representation of `F` to `F<A>` which states that `F` holds some information about some data of type `A`.

If we have an `F<A>` and we want to transform to an `F<B>`, we could use the `map` operation:

```ts
map: (<A, B>(fa: F<A>, f: (a: A) => B) => F<B>);
```

But what if we have some function that returns an `F<B>` instead of just `B`? We can't use `map` because we would end up with a `F<F<B>>` instead of an `F<B>`. What we really want is some operator that allows us to `map` the data and then `flatten` the result.

This exact situation describes a `flatMap` operation:

```ts
flatMap: (<A, B>(fa: F<A>, f: (a: A) => F<B>) => F<B>);
```

You can also see how this directly applies to `Array`'s `flatMap` if we replace our generic data type `F` with the concrete data type of `Array`:

```ts
flatMap: (<A, B>(fa: Array<A>, f: (a: A) => Array<B>) => Array<B>);
```

**Q: I can't seem to find any type aliases for Effect. Do any exist? I'm looking for something similar to ZIO's `UIO` / `URIO` / `RIO` / `Task` / `IO`. If not, have you considered adding them?**

A: In Effect, there are no predefined type aliases such as `UIO`, `URIO`, `RIO`, `Task`, or `IO` like in ZIO.

The reason for this is that type aliases are lost as soon as you compose them, which renders them somewhat useless unless you maintain **multiple** signatures for **every** function. In Effect, we have chosen not to go down this path. Instead, we utilize the `never` type to indicate unused types.

It's worth mentioning that the perception of type aliases being quicker to understand is often just an illusion. In Effect, the explicit notation `Effect<A>` clearly communicates that only type `A` is being used. On the other hand, when using a type alias like `RIO<R, A>`, questions arise about the type `E`. Is it `unknown`? `never`? Remembering such details becomes challenging.

## Comparison with fp-ts

**Q: What are the main differences between Effect and [fp-ts](https://github.com/gcanti/fp-ts)?**

A: The main differences between Effect and fp-ts are:

- Effect offers more flexible and powerful dependency management.
- Effect provides built-in services like `Clock`, `Random`, and `Tracer`, which fp-ts lacks.
- Effect includes dedicated testing tools like `TestClock`, while fp-ts does not offer specific testing utilities.
- Effect supports interruptions for canceling computations, whereas fp-ts does not have built-in interruption support.
- Effect has built-in tools to handle defects and unexpected failures, while fp-ts lacks specific defect management features.
- Effect leverages fiber-based concurrency for efficient and lightweight concurrent computations, which fp-ts does not provide.
- Effect includes built-in support for customizable retrying of computations, while fp-ts does not have this feature.
- Effect offers built-in logging, scheduling, caching, and more, which fp-ts does not provide.

For a more detailed comparison, you can refer to the [Effect vs fp-ts](fp-ts) documentation.

### Bundle Size Comparison Between Effect and fp-ts

**Q: I compared the bundle sizes of two simple programs using Effect and fp-ts. Why does Effect have a larger bundle size?**

A: It's natural to observe different bundle sizes because Effect and fp-ts are distinct systems designed for different purposes.
Effect's bundle size is larger due to its included fiber runtime, which is crucial for its functionality.
While the initial bundle size may seem large, the overhead amortizes as you use Effect.

**Q: Should I be concerned about the bundle size difference when choosing between Effect and fp-ts?**

A: Not necessarily. Consider the specific requirements and benefits of each library for your project.

# Glossary

---

## title: Glossaryexcerpt: Explore key concepts in Effect, such as context, dual APIs, distributed workflows, expected errors, fibers, interruption, local workflows, effect pipelines, schedules, services, tags, and unexpected errors. Understand their significance in managing dependencies, controlling concurrency, and handling errors within effectful computations.bottomNavigation: pagination

## Context

In `Effect`, context refers to a container that holds important contextual data required for the execution of effects. It's a conceptual construct that enables effects to access and utilize contextual data within their execution scope.

Think of context as a `Map<Tag, Impl>` that associates `Tag`s with their corresponding implementations. By providing the appropriate context to an effect, the effect gains access to the specific contextual data it needs. This allows the effect to perform operations that rely on that data.

Context plays a vital role in managing dependencies and facilitating the composition of effects in a modular and flexible manner. It ensures that effects have access to the necessary data they depend on, making it easier to organize and maintain code.

## Dual (API)

In the context of APIs, "dual" refers to a function that supports both the "data-first" and "data-last" variants.
It means that the API can be used interchangeably with either style, depending on the developer's preference.

One example of a dual API is the `andThen` function of the `Effect` data type.

In the "data-first" variant, the effect is passed as the first argument to `andThen`:

```ts twoslash
import { Effect } from 'effect';

Effect.andThen(Effect.succeed(1), (n) => n + 1);
```

while in the "data-last" variant, the effect is passed as the first argument to the `pipe` function, followed by the `andThen` function:

```ts twoslash
import { Effect, pipe } from 'effect';

pipe(
  Effect.succeed(1),
  Effect.andThen((n) => n + 1),
);

// or

Effect.succeed(1).pipe(Effect.andThen((n) => n + 1));
```

## Distributed workflow

Things that may execute across multiple execution boundaries.

## Expected Errors

Also referred to as _failures_, _typed errors_ or _recoverable errors_.

These are errors that developers anticipate and expect as part of normal program execution.
Expected errors are tracked at the type level by the `Effect` data type in the "Error" channel:

```ts
Effect<Value, Error, Context>;
```

## Fiber

A "fiber" is a small unit of work or a lightweight thread of execution. It represents a specific computation or an effectful operation in a program. Fibers are used to manage concurrency and asynchronous tasks.

Think of a fiber as a worker that performs a specific job. It can be started, paused, resumed, and even interrupted. Fibers are useful when we want to perform multiple tasks simultaneously or handle long-running operations without blocking the main program.

By using fibers, developers can control and coordinate the execution of tasks, allowing for efficient multitasking and responsiveness in their applications.

To summarize:

- An `Effect` is a higher-level concept that describes an effectful computation. It is lazy and immutable, meaning it represents a computation that may produce a value or fail but does not immediately execute.
- A fiber, on the other hand, represents the running execution of an `Effect`. It can be interrupted or awaited to retrieve its result. Think of it as a way to control and interact with the ongoing computation.

## Interruption

Interruption errors occur when the execution of a running fiber is deliberately interrupted.

## Local workflow

Things that execute within a single execution boundary.

## Pipeline (of Effects)

A "pipeline" refers to a series of sequential operations performed on `Effect` values to achieve a desired result.
When working with `Effect`, a pipeline typically consists of operations such as mapping, flat-mapping, filtering, and error handling, among others. Each operation in the pipeline takes an input `Effect` and produces an output `Effect`, which becomes the input for the next operation in the sequence.

## Schedule

A Schedule is an immutable value that defines a strategy for repeating or retrying an effectful operation.
Schedules can be composed and combined together to create more complex recurrence patterns.
This allows for flexible and customizable scheduling strategies.

## Service

A Service is an interface that defines a set of operations or functionality. Services encapsulate specific capabilities or behaviors that can be utilized by effects. By providing service implementations, we can enhance the capabilities of effects and enable them to interact with external systems, perform IO operations, or access shared resources. Services are usually associated with Tags, which allow effects to locate and access the corresponding service implementation during runtime.

## Tag

In Effect, a Tag is a unique marker that represents a specific value in a `Context`. It is used when you need to uniquely identify something in a "bag of type-safe things". Tags are similar to map keys but come with associated types. In the context of Effect, a Tag is often used to represent a specific service.

Tags serve as keys that allow Effect to locate and use the corresponding service implementation at runtime. They play a crucial role in managing dependencies in a type-safe manner and providing the required services for the smooth execution of your effects.

For examples of how to use Tags in creating a simple service, check out [Creating a Simple Service](../guides/context-management/services#creating-a-simple-service).

## Unexpected Errors

Also referred to as _defects_, _untyped errors_, or _unrecoverable errors_.

These are errors that occur unexpectedly and are not part of the intended program flow.

# Other

---

## title: Otherexcerpt: OtherbottomNavigation: childCards

# Either

---

## title: Eitherexcerpt: Explore the `Either` data type in Effect for representing exclusive values using `Left` and `Right`. Learn to create Eithers, use guards for checking types, and perform pattern matching. Discover operations like mapping over `Right` and `Left` values, and understand interoperability with the `Effect` type. Master the expressive and versatile features of `Either` for error handling and result representation in your applications.bottomNavigation: pagination

The `Either` data type represents two exclusive possible values: an `Either<R, L>` can be either a `Right` value or a `Left` value, where `R` represents the type of the `Right` value and `L` represents the type of the `Left` value.

## Understanding Either and Exit

- Either is primarily used as a **simple discriminated union** and is not recommended as the main result type for operations requiring detailed error information.

- [Exit](exit) is the preferred **result type** within Effect for capturing comprehensive details about failures.
  It encapsulates the outcomes of effectful computations, distinguishing between success and various failure modes, such as errors, defects and interruptions.

## Creating Eithers

You can create an `Either` using the `Either.right` and `Either.left` constructors.

- The `Either.right` function takes a value of type `R` and constructs a `Either<R, never>`:

  ```ts twoslash
  import { Either } from 'effect';

  const rightValue = Either.right(42);
  ```

- The `Either.left` function takes a value of type `L` and constructs a `Either<never, L>`:

  ```ts twoslash
  import { Either } from 'effect';

  const leftValue = Either.left('not a number');
  ```

## Guards

You can determine whether an `Either` is a `Left` or a `Right` by using the `Either.isLeft` and `Either.isRight` guards:

```ts twoslash
import { Either } from 'effect';

const foo = Either.right(42);

if (Either.isLeft(foo)) {
  console.log(`The left value is: ${foo.left}`);
} else {
  console.log(`The Right value is: ${foo.right}`);
}
// Output: "The Right value is: 42"
```

## Pattern Matching

The `Either.match` function allows you to handle different cases of an `Either` by providing separate callbacks for each case:

```ts twoslash
import { Either } from 'effect';

const foo = Either.right(42);

const message = Either.match(foo, {
  onLeft: (left) => `The left value is: ${left}`,
  onRight: (right) => `The Right value is: ${right}`,
});

console.log(message); // Output: "The Right value is: 42"
```

<Idea>
  Using `match` instead of `isLeft` or `isRight` can be more expressive and
  provide a clear way to handle both cases of an `Either`.
</Idea>

## Working with Either

Once you have an `Either`, there are several operations you can perform on it.

### Mapping over the Right Value

You can use the `Either.map` function to transform the `Right` value of an `Either`.
The `Either.map` function takes a transformation function that maps the `Right` value.

If the `Either` value is a `Left` value, the transformation function is **ignored**, and the `Left` value is returned unchanged.

**Example**

```ts twoslash
import { Either } from 'effect';

Either.map(Either.right(1), (n) => n + 1); // right(2)

Either.map(Either.left('not a number'), (n) => n + 1); // left("not a number")
```

### Mapping over the Left Value

You can use the `Either.mapLeft` function to transform the `Left` value of an Either. The `mapLeft` function takes a transformation function that maps the `Left`.

If the `Either` value is a `Right` value, the transformation function is **ignored**, and the `Right` value is returned unchanged.

**Example**

```ts twoslash
import { Either } from 'effect';

Either.mapLeft(Either.right(1), (s) => s + '!'); // right(1)

Either.mapLeft(Either.left('not a number'), (s) => s + '!'); // left("not a number!")
```

### Mapping over Both Values

You can use the `Either.mapBoth` function to transform both the `Left` and `Right` values of an `Either`. The `mapBoth` function takes two transformation functions: one for the `Left` value and one for the `Right` value.

**Example**

```ts twoslash
import { Either } from 'effect';

Either.mapBoth(Either.right(1), {
  onLeft: (s) => s + '!',
  onRight: (n) => n + 1,
}); // right(2)

Either.mapBoth(Either.left('not a number'), {
  onLeft: (s) => s + '!',
  onRight: (n) => n + 1,
}); // left("not a number!")
```

## Interop with Effect

The `Either` type is a subtype of the `Effect` type, which means that it can be seamlessly used with functions from the `Effect` module. These functions are primarily designed to work with `Effect` values, but they can also handle `Either` values and process them correctly.

In the context of `Effect`, the two members of the `Either` type are treated as follows:

- `Left<L>` is equivalent to `Effect<never, L>`
- `Right<R>` is equivalent to `Effect<R>`

To illustrate this interoperability, let's consider the following example:

```ts twoslash
import { Effect, Either } from 'effect';

const head = <A>(array: ReadonlyArray<A>): Either.Either<A, string> =>
  array.length > 0 ? Either.right(array[0]) : Either.left('empty array');

const foo = Effect.runSync(Effect.andThen(Effect.succeed([1, 2, 3]), head));
console.log(foo); // Output: 1

const bar = Effect.runSync(Effect.andThen(Effect.succeed([]), head)); // throws "empty array"
```

## Combining Two or More Eithers

The `Either.zipWith` function allows you to combine two `Either` values using a provided function. It creates a new `Either` that holds the combined value of both original `Either` values.

```ts twoslash
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.right('John');
const maybeAge: Either.Either<number, Error> = Either.right(25);

const person = Either.zipWith(maybeName, maybeAge, (name, age) => ({
  name: name.toUpperCase(),
  age,
}));

console.log(person);
/*
Output:
{ _id: 'Either', _tag: 'Right', right: { name: 'JOHN', age: 25 } }
*/
```

The `Either.zipWith` function takes three arguments:

- The first `Either` you want to combine
- The second `Either` you want to combine
- A function that takes two arguments, which are the values held by the two `Either`, and returns the combined value

It's important to note that if either of the two `Either` values is `Left`, the resulting `Either` will also be `Left`, containing the value of the first encountered `Left`:

```ts {4-6} twoslash
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.right('John');
const maybeAge: Either.Either<number, Error> = Either.left(
  new Error('Oh no!'),
);

const person = Either.zipWith(maybeName, maybeAge, (name, age) => ({
  name: name.toUpperCase(),
  age,
}));

console.log(person);
/*
Output:
{ _id: 'Either', _tag: 'Left', left: new Error("Oh no!") }
*/
```

If you need to combine two or more `Either`s without transforming the values they hold, you can use `Either.all`, which takes a collection of `Either`s and returns an `Either` with the same structure.

- If a tuple is provided, the returned `Either` will contain a tuple with the same length.
- If a struct is provided, the returned `Either` will contain a struct with the same keys.
- If an iterable is provided, the returned `Either` will contain an array.

```ts twoslash
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.right('John');
const maybeAge: Either.Either<number, Error> = Either.right(25);

const tuple = Either.all([maybeName, maybeAge]);

const struct = Either.all({ name: maybeName, age: maybeAge });
```

Note that if one or more `Either` is a `Left`, then the first encountered `Left` will be returned:

```ts
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.left(
  new Error('name not found'),
);
const maybeAge: Either.Either<number, Error> = Either.left(
  new Error('age not found'),
);

const tuple = Either.all([maybeName, maybeAge]);

console.log(tuple);
/*
Output:
{ _id: 'Either', _tag: 'Left', left: new Error("name not found") }
*/
```

## gen

Similar to [Effect.gen](../../guides/essentials/using-generators), there's also `Either.gen`, which provides a convenient syntax, akin to async/await, for writing code involving `Either` and using generators.

Let's revisit the previous example, this time using `Either.gen` instead of `Either.zipWith`:

```ts twoslash
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.right('John');
const maybeAge: Either.Either<number, Error> = Either.right(25);

const person = Either.gen(function* () {
  const name = (yield* maybeName).toUpperCase();
  const age = yield* maybeAge;
  return { name, age };
});

console.log(person);
/*
Output:
{ _id: 'Either', _tag: 'Right', right: { name: 'JOHN', age: 25 } }
*/
```

Once again, if either of the two `Either` values is `Left`, the resulting `Either` will also be `Left`:

```ts twoslash
import { Either } from 'effect';

const maybeName: Either.Either<string, Error> = Either.right('John');
const maybeAge: Either.Either<number, Error> = Either.left(
  new Error('Oh no!'),
);

const person = Either.gen(function* () {
  const name = (yield* maybeName).toUpperCase();
  const age = yield* maybeAge;
  return { name, age };
});

console.log(person);
/*
Output:
{ _id: 'Either', _tag: 'Left', left: new Error("Oh no!") }
*/
```

# Option

---

## title: Optionexcerpt: Master the versatile `Option` data type for handling optional values. Learn to create, model optional properties, and utilize guards. Discover powerful functions like `Option.map`, `Option.flatMap`, and explore seamless interop with nullable types and the Effect module. Also, delve into fallback strategies, working with nullable types, combining options, and much more.bottomNavigation: pagination

The `Option` data type is used to represent optional values. An `Option` can be either `Some`, which contains a value, or `None`, which indicates the absence of a value.

The `Option` type is versatile and can be applied in various scenarios, including:

- Using it for initial values
- Returning values from functions that are not defined for all possible inputs (referred to as "partial functions")
- Managing optional fields in data structures
- Handling optional function arguments

## Creating Options

### some

The `Option.some` constructor takes a value of type `A` and returns an `Option<A>` that holds that value:

```ts twoslash
import { Option } from 'effect';

const value = Option.some(1); // An Option holding the number 1
```

### none

On the other hand, the `Option.none` constructor returns an `Option<never>`, representing the absence of a value:

```ts twoslash
import { Option } from 'effect';

const noValue = Option.none(); // An Option holding no value
```

### liftPredicate

Sometimes you need to create an `Option` based on a predicate, such as checking if a value is positive.

Here's how you can do this explicitly using `Option.none` and `Option.some`

```ts twoslash
import { Option } from 'effect';

const isPositive = (n: number) => n > 0;

const parsePositive = (n: number): Option.Option<number> =>
  isPositive(n) ? Option.some(n) : Option.none();
```

The same result can be achieved more concisely using `Option.liftPredicate`

```ts twoslash
import { Option } from 'effect';

const isPositive = (n: number) => n > 0;

const parsePositive = Option.liftPredicate(isPositive);
```

## Modeling Optional Properties

Let's look at an example of a `User` model where the `"email"` property is optional and can have a value of type `string`.
To represent this, we can use the `Option<string>` type:

```ts {6} twoslash
import { Option } from 'effect';

interface User {
  readonly id: number;
  readonly username: string;
  readonly email: Option.Option<string>;
}
```

<Warning>
  Optionality only applies to the value of the property. The key `"email"`
  will always be present in the object, regardless of whether it has a value
  or not.
</Warning>

Now, let's see how we can create instances of `User` with and without an email:

```ts twoslash
import { Option } from 'effect';

interface User {
  readonly id: number;
  readonly username: string;
  readonly email: Option.Option<string>;
}

// ---cut---
const withEmail: User = {
  id: 1,
  username: 'john_doe',
  email: Option.some('john.doe@example.com'),
};

const withoutEmail: User = {
  id: 2,
  username: 'jane_doe',
  email: Option.none(),
};
```

## Guards

You can determine whether an `Option` is a `Some` or a `None` by using the `isSome` and `isNone` guards:

```ts twoslash
import { Option } from 'effect';

const foo = Option.some(1);

console.log(Option.isSome(foo)); // Output: true

if (Option.isNone(foo)) {
  console.log('Option is empty');
} else {
  console.log(`Option has a value: ${foo.value}`);
}
// Output: "Option has a value: 1"
```

## Matching

The `Option.match` function allows you to handle different cases of an `Option` value by providing separate actions for each case:

```ts twoslash
import { Option } from 'effect';

const foo = Option.some(1);

const result = Option.match(foo, {
  onNone: () => 'Option is empty',
  onSome: (value) => `Option has a value: ${value}`,
});

console.log(result); // Output: "Option has a value: 1"
```

<Idea>
  Using `match` instead of `isSome` or `isNone` can be more expressive and
  provide a clear way to handle both cases of an `Option`.
</Idea>

## Working with Option

### map

The `Option.map` function allows you to transform the value inside an `Option` without having to unwrap and wrap the underlying value. Let's see an example:

```ts twoslash
import { Option } from 'effect';

const maybeIncremented = Option.map(Option.some(1), (n) => n + 1); // some(2)
```

The convenient aspect of using `Option` is how it handles the absence of a value, represented by `None`:

```ts twoslash
import { Option } from 'effect';

const maybeIncremented = Option.map(Option.none(), (n) => n + 1); // none()
```

Despite having `None` as the input, we can still operate on the `Option` without encountering errors. The mapping function `(n) => n + 1` is not executed when the `Option` is `None`, and the result remains `none` representing the absence of a value.

### flatMap

The `Option.flatMap` function works similarly to `Option.map`, but with an additional feature. It allows us to sequence computations that depend on the absence or presence of a value in an `Option`.

Let's explore an example that involves a **nested** optional property. We have a `User` model with an optional `address` field of type `Option<Address>`:

```ts {7} twoslash
interface Address {
  readonly city: string;
  readonly street: Option.Option<string>;
}

// ---cut---
import { Option } from 'effect';

interface User {
  readonly id: number;
  readonly username: string;
  readonly email: Option.Option<string>;
  readonly address: Option.Option<Address>;
}
```

The `address` field itself contains a nested optional property called `street` of type `Option<string>`:

```ts {3} twoslash
import { Option } from 'effect';

// ---cut---
interface Address {
  readonly city: string;
  readonly street: Option.Option<string>;
}
```

We can use `Option.flatMap` to extract the `street` property from the `address` field.

```ts twoslash
import { Option } from 'effect';

interface Address {
  readonly city: string;
  readonly street: Option.Option<string>;
}

interface User {
  readonly id: number;
  readonly username: string;
  readonly email: Option.Option<string>;
  readonly address: Option.Option<Address>;
}

// ---cut---
const user: User = {
  id: 1,
  username: 'john_doe',
  email: Option.some('john.doe@example.com'),
  address: Option.some({
    city: 'New York',
    street: Option.some('123 Main St'),
  }),
};

const street = user.address.pipe(Option.flatMap((address) => address.street));
```

Here's how it works: if the `address` is `Some`, meaning it has a value, the mapping function `(addr) => addr.street` is applied to retrieve the `street` value. On the other hand, if the `address` is `None`, indicating the absence of a value, the mapping function is not executed, and the result is also `None`.

### filter

The `Option.filter` function is used to filter an `Option` using a predicate. If the predicate is not satisfied or the `Option` is `None`, it returns `None`.

Let's see an example where we refactor some code to a more idiomatic version:

Original Code

```ts twoslash
import { Option } from 'effect';

const removeEmptyString = (input: Option.Option<string>) => {
  if (Option.isSome(input) && input.value === '') {
    return Option.none();
  }
  return input;
};

console.log(removeEmptyString(Option.none())); // { _id: 'Option', _tag: 'None' }
console.log(removeEmptyString(Option.some(''))); // { _id: 'Option', _tag: 'None' }
console.log(removeEmptyString(Option.some('a'))); // { _id: 'Option', _tag: 'Some', value: 'a' }
```

Idiomatic Code

```ts twoslash
import { Option } from 'effect';

const removeEmptyString = (input: Option.Option<string>) =>
  Option.filter(input, (value) => value !== '');
```

## Getting the Value from an Option

To retrieve the value stored within an `Option`, you can use various functions provided by the `Option` module. Let's explore these functions:

- `getOrThrow`: It retrieves the wrapped value from an `Option`, or throws an error if the `Option` is a `None`. Here's an example:

  ```ts twoslash
  import { Option } from 'effect';

  Option.getOrThrow(Option.some(10)); // 10
  Option.getOrThrow(Option.none()); // throws getOrThrow called on a None
  ```

- `getOrNull` and `getOrUndefined`: These functions are useful when you want to work with code that doesn't use `Option`. They allow you to retrieve the value of an `Option` as `null` or `undefined`, respectively. Examples:

  ```ts twoslash
  import { Option } from 'effect';

  Option.getOrNull(Option.some(5)); // 5
  Option.getOrNull(Option.none()); // null

  Option.getOrUndefined(Option.some(5)); // 5
  Option.getOrUndefined(Option.none()); // undefined
  ```

- `getOrElse`: This function lets you provide a default value that will be returned if the `Option` is a `None`. Here's an example:

  ```ts twoslash
  import { Option } from 'effect';

  Option.getOrElse(Option.some(5), () => 0); // 5
  Option.getOrElse(Option.none(), () => 0); // 0
  ```

## Fallback

In certain situations, when a computation returns `None`, you may want to try an alternative computation that returns an `Option`. This is where the `Option.orElse` function comes in handy. It allows you to chain multiple computations together and continue with the next one if the previous one resulted in `None`. This can be useful for implementing retry logic, where you want to attempt a computation multiple times until you either succeed or exhaust all possible attempts.

```ts twoslash
import { Option } from 'effect';

// Simulating a computation that may or may not produce a result
const performComputation = (): Option.Option<number> =>
  Math.random() < 0.5 ? Option.some(10) : Option.none();

const performAlternativeComputation = (): Option.Option<number> =>
  Math.random() < 0.5 ? Option.some(20) : Option.none();

const result = performComputation().pipe(
  Option.orElse(() => performAlternativeComputation()),
);

Option.match(result, {
  onNone: () => console.log('Both computations resulted in None'),
  onSome: (value) => console.log('Computed value:', value), // At least one computation succeeded
});
```

Additionally, the `Option.firstSomeOf` function can be used to retrieve the first value that is `Some` within an iterable of `Option` values:

```ts twoslash
import { Option } from 'effect';

const first = Option.firstSomeOf([
  Option.none(),
  Option.some(2),
  Option.none(),
  Option.some(3),
]); // some(2)
```

## Interop with Nullable Types

When working with the `Option` data type, you may come across code that uses `undefined` or `null` to represent optional values. The `Option` data type provides several APIs to facilitate the interaction between `Option` and nullable types.

You can create an `Option` from a nullable value using the `fromNullable` API.

```ts twoslash
import { Option } from 'effect';

Option.fromNullable(null); // none()
Option.fromNullable(undefined); // none()
Option.fromNullable(1); // some(1)
```

Conversely, if you have a value of type `Option` and want to convert it to a nullable value, you have two options:

- Convert `None` to `null` using the `getOrNull` API.
- Convert `None` to `undefined` using the `getOrUndefined` API.

```ts twoslash
import { Option } from 'effect';

Option.getOrNull(Option.some(5)); // 5
Option.getOrNull(Option.none()); // null

Option.getOrUndefined(Option.some(5)); // 5
Option.getOrUndefined(Option.none()); // undefined
```

## Interop with Effect

The `Option` type is a subtype of the `Effect` type, which means that it can be seamlessly used with functions from the `Effect` module. These functions are primarily designed to work with `Effect` values, but they can also handle `Option` values and process them correctly.

In the context of `Effect`, the two members of the `Option` type are treated as follows:

- `None` is equivalent to `Effect<never, NoSuchElementException>`
- `Some<A>` is equivalent to `Effect<A>`

To illustrate this interoperability, let's consider the following example:

```ts twoslash
import { Effect, Option } from 'effect';

const head = <A>(as: ReadonlyArray<A>): Option.Option<A> =>
  as.length > 0 ? Option.some(as[0]) : Option.none();

console.log(
  Effect.runSync(Effect.succeed([1, 2, 3]).pipe(Effect.andThen(head))),
); // Output: 1

Effect.runSync(Effect.succeed([]).pipe(Effect.andThen(head))); // throws NoSuchElementException: undefined
```

## Combining Two or More Options

The `Option.zipWith` function allows you to combine two `Option` values using a provided function. It creates a new `Option` that holds the combined value of both original `Option` values.

```ts twoslash
import { Option } from 'effect';

const maybeName: Option.Option<string> = Option.some('John');
const maybeAge: Option.Option<number> = Option.some(25);

const person = Option.zipWith(maybeName, maybeAge, (name, age) => ({
  name: name.toUpperCase(),
  age,
}));

console.log(person);
/*
Output:
{ _id: 'Option', _tag: 'Some', value: { name: 'JOHN', age: 25 } }
*/
```

The `Option.zipWith` function takes three arguments:

- The first `Option` you want to combine
- The second `Option` you want to combine
- A function that takes two arguments, which are the values held by the two `Options`, and returns the combined value

It's important to note that if either of the two `Option` values is `None`, the resulting `Option` will also be `None`:

```ts {4} twoslash
import { Option } from 'effect';

const maybeName: Option.Option<string> = Option.some('John');
const maybeAge: Option.Option<number> = Option.none();

const person = Option.zipWith(maybeName, maybeAge, (name, age) => ({
  name: name.toUpperCase(),
  age,
}));

console.log(person);
/*
Output:
{ _id: 'Option', _tag: 'None' }
*/
```

If you need to combine two or more `Option`s without transforming the values they hold, you can use `Option.all`, which takes a collection of `Option`s and returns an `Option` with the same structure.

- If a tuple is provided, the returned `Option` will contain a tuple with the same length.
- If a struct is provided, the returned `Option` will contain a struct with the same keys.
- If an iterable is provided, the returned `Option` will contain an array.

```ts twoslash
import { Option } from 'effect';

const maybeName: Option.Option<string> = Option.some('John');
const maybeAge: Option.Option<number> = Option.some(25);

const tuple = Option.all([maybeName, maybeAge]);

const struct = Option.all({ name: maybeName, age: maybeAge });
```

## gen

Similar to [Effect.gen](../../guides/essentials/using-generators), there's also `Option.gen`, which provides a convenient syntax, akin to async/await, for writing code involving `Option` and using generators.

Let's revisit the previous example, this time using `Option.gen` instead of `Option.zipWith`:

```ts twoslash
import { Option } from 'effect';

const maybeName: Option.Option<string> = Option.some('John');
const maybeAge: Option.Option<number> = Option.some(25);

const person = Option.gen(function* () {
  const name = (yield* maybeName).toUpperCase();
  const age = yield* maybeAge;
  return { name, age };
});

console.log(person);
/*
Output:
{ _id: 'Option', _tag: 'Some', value: { name: 'JOHN', age: 25 } }
*/
```

Once again, if either of the two `Option` values is `None`, the resulting `Option` will also be `None`:

```ts twoslash
import { Option } from 'effect';

const maybeName: Option.Option<string> = Option.some('John');
const maybeAge: Option.Option<number> = Option.none();

const person = Option.gen(function* () {
  const name = (yield* maybeName).toUpperCase();
  const age = yield* maybeAge;
  return { name, age };
});

console.log(person);
/*
Output:
{ _id: 'Option', _tag: 'None' }
*/
```

## Comparing Option Values with Equivalence

You can compare `Option` values using the `Option.getEquivalence` function.
This function lets you define rules for comparing the contents of `Option` types by providing an `Equivalence` for the type of value they might contain.

**Example: Checking Equivalence of Optional Numbers**

Imagine you have optional numbers and you want to check if they are equivalent. Hereâ€™s how you can do it:

```ts twoslash
import { Equivalence, Option } from 'effect';

const myEquivalence = Option.getEquivalence(Equivalence.number);

console.log(myEquivalence(Option.some(1), Option.some(1))); // Output: true, because both options contain the number 1
console.log(myEquivalence(Option.some(1), Option.some(2))); // Output: false, because the numbers are different
console.log(myEquivalence(Option.some(1), Option.none())); // Output: false, because one is a number and the other is empty
```

## Sorting Option Values with Order

Sorting a collection of `Option` values can be done using the `Option.getOrder` function.
This function helps you sort `Option` values by providing a custom sorting rule for the type of value they might contain.

**Example: Sorting Optional Numbers**

Suppose you have a list of optional numbers and you want to sort them in ascending order, considering empty values as the lowest:

```ts twoslash
import { Array, Option, Order } from 'effect';

const items = [
  Option.some(1),
  Option.none(),
  Option.some(2),
];

const myOrder = Option.getOrder(Order.number);

console.log(Array.sort(myOrder)(items));
/*
Output:
[
  { _id: 'Option', _tag: 'None' },           // None appears first because it's considered the lowest
  { _id: 'Option', _tag: 'Some', value: 1 }, // Sorted in ascending order
  { _id: 'Option', _tag: 'Some', value: 2 }
]
*/
```

In this example, `Option.none()` is treated as the lowest value, allowing `Option.some(1)` and `Option.some(2)` to be sorted in ascending order based on their numerical value. This method ensures that all `Option` values are sorted logically according to their content, with empty values (`Option.none()`) being placed before non-empty values (`Option.some()`).

**Advanced Example: Sorting Optional Dates in Reverse Order**

Now, let's consider a more complex scenario where you have a list of objects containing optional dates, and you want to sort them in descending order, with any empty optional values placed at the end:

```ts
import { Array, Option, Order } from 'effect';

const items = [
  { data: Option.some(new Date(10)) },
  { data: Option.some(new Date(20)) },
  { data: Option.none() },
];

// Define the order to sort dates within Option values in reverse
const sorted = Array.sortWith(
  items,
  (item) => item.data,
  Order.reverse(Option.getOrder(Order.Date)),
);

console.log(sorted);
/*
Output:
[
  { data: { _id: 'Option', _tag: 'Some', value: '1970-01-01T00:00:00.020Z' } },
  { data: { _id: 'Option', _tag: 'Some', value: '1970-01-01T00:00:00.010Z' } },
  { data: { _id: 'Option', _tag: 'None' } } // None placed last
]
*/
```

# Cause

---

## title: Causeexcerpt: Explore the `Cause` data type in the `Effect` type, which stores comprehensive information about failures, including unexpected errors, stack traces, and fiber interruption causes. Learn how `Cause` ensures no failure information is lost, providing a complete story for precise error analysis and handling in your codebase. Discover various causes such as Empty, Fail, Die, Interrupt, Sequential, and Parallel, each representing different error scenarios within the `Effect` workflow.bottomNavigation: pagination

The [Effect&lt;A, E, R&gt;](../../guides/essentials/the-effect-type) type is polymorphic in values of type `E`, which means we can work with any error type we want. However, there is additional information related to failures that is not captured by the `E` value alone.

To preserve and provide comprehensive information about failures, Effect uses the `Cause<E>` data type. `Cause` is responsible for storing various details, such as:

- Unexpected errors or defects
- Stack and execution traces
- Causes of fiber interruptions

Effect is designed to be strict in preserving all the information related to a failure. It captures and stores the complete story of failure in the `Cause` data type. This ensures that no information about the failure is lost, allowing us to precisely determine what happened during the execution of our effects.

Although we don't typically work directly with `Cause` values, it is an underlying data type that represents errors occurring within an Effect workflow. It provides us with total access to all concurrent and sequential errors within our codebase. This gives us the ability to analyze and handle failures in a comprehensive manner whenever needed.

## Creating Causes

We can intentionally create effects with specific causes using the `Effect.failCause` constructor:

```ts twoslash
import { Cause, Effect } from 'effect';

// Create an effect that intentionally fails with an empty cause
const effect = Effect.failCause(Cause.empty);
```

To uncover the underlying cause of an effect, we can use the `Effect.cause` function:

```ts
Effect.cause(effect).pipe(
  Effect.andThen((cause) => ...)
)
```

## Cause Variations

There are several causes for various errors, in this section, we will describe each of these causes.

### Empty

The `Empty` cause represents a lack of errors.

### Fail

The `Fail` cause represents a `Cause` which failed with an expected error of type `E`.

### Die

The `Die` cause represents a `Cause` which failed as a result of a defect, or in other words, an unexpected error.

### Interrupt

The `Interrupt` cause represents failure due to `Fiber` interruption, which contains the `FiberId` of the interrupted `Fiber`.

### Sequential

The `Sequential` cause represents the composition of two causes which occurred
sequentially.

For example, if we perform Effect's analog of `try-finally` (i.e.
`Effect.ensuring`), and both the `try` and `finally` blocks fail, we have two
errors which occurred sequentially. In these cases, the errors can be
represented by the `Sequential` cause.

### Parallel

The `Parallel` cause represents the composition of two causes which occurred in parallel.

In Effect programs, it is possible that two operations may be performed in
parallel. In these cases, the `Effect` workflow can fail for more than one
reason. If both computations fail, then there are actually two errors which
occurred in parallel. In these cases, the errors can be represented by the
`Parallel` cause.

## Guards

To identify the type of a `Cause`, you can use specific guards provided by the `Cause` module:

- `Cause.isEmpty`
- `Cause.isFailType`
- `Cause.isDie`
- `Cause.isInterruptType`
- `Cause.isSequentialType`
- `Cause.isParallelType`

Let's see an example of how you can utilize these guards:

```ts twoslash
import { Cause } from 'effect';

const cause = Cause.fail(new Error('my message'));

if (Cause.isFailType(cause)) {
  console.log(cause.error.message); // Output: my message
}
```

By using these guards, you can effectively determine the nature of a `Cause`, enabling you to handle different error scenarios appropriately in your code. Whether it's an empty cause, failure, defect, interruption, sequential composition, or parallel composition, these guards provide a clear way to identify and manage various types of errors.

## Pattern Matching

In addition to using guards, you can handle different cases of a `Cause` using the `Cause.match` function. This function allows you to define separate callbacks for each possible case of a `Cause`.

Let's explore how you can use `Cause.match`:

```ts twoslash
import { Cause } from 'effect';

const cause = Cause.parallel(
  Cause.fail(new Error('my fail message')),
  Cause.die('my die message'),
);

console.log(
  Cause.match(cause, {
    onEmpty: '(empty)',
    onFail: (error) => `(error: ${error.message})`,
    onDie: (defect) => `(defect: ${defect})`,
    onInterrupt: (fiberId) => `(fiberId: ${fiberId})`,
    onSequential: (left, right) =>
      `(onSequential (left: ${left}) (right: ${right}))`,
    onParallel: (left, right) =>
      `(onParallel (left: ${left}) (right: ${right})`,
  }),
);
/*
Output:
(onParallel (left: (error: my fail message)) (right: (defect: my die message))
*/
```

## Pretty Printing

When working with errors in your code, it's crucial to have clear and readable error messages for effective debugging. The `Cause.pretty` function provides a convenient way to achieve this by generating nicely formatted error messages as strings.

Let's take a look at how you can use `Cause.pretty`:

```ts twoslash
import { Cause, FiberId } from 'effect';

console.log(Cause.pretty(Cause.empty)); // All fibers interrupted without errors.
console.log(Cause.pretty(Cause.fail(new Error('my fail message')))); // Error: my fail message
console.log(Cause.pretty(Cause.die('my die message'))); // Error: my die message
console.log(Cause.pretty(Cause.interrupt(FiberId.make(1, 0)))); // All fibers interrupted without errors.
console.log(
  Cause.pretty(Cause.sequential(Cause.fail('fail1'), Cause.fail('fail2'))),
);
/*
Output:
Error: fail1
Error: fail2
*/
```

## Retrieval of Failures and Defects

If you're specifically interested in obtaining a collection of failures or defects from a `Cause`, you can use the `Cause.failures` and `Cause.defects` functions respectively.

Let's see how you can utilize these functions:

```ts twoslash
import { Cause } from 'effect';

const cause = Cause.parallel(
  Cause.fail(new Error('my fail message 1')),
  Cause.sequential(
    Cause.die('my die message'),
    Cause.fail(new Error('my fail message 2')),
  ),
);

console.log(Cause.failures(cause));
/*
Output:
{
  _id: 'Chunk',
  values: [
    Error: my fail message 1 ...,
    Error: my fail message 2 ...
  ]
}
*/

console.log(Cause.defects(cause));
/*
Output:
{ _id: 'Chunk', values: [ 'my die message' ] }
*/
```

# Referenced Data types

---

## title: Referenced Data typesexcerpt: Referenced Data typescollapsible: truebottomNavigation: childCards

# Duration

---

## title: Durationexcerpt: Explore the `Duration` data type in Effect for representing non-negative spans of time. Learn to create durations with different units, including milliseconds, seconds, and minutes. Discover options for creating infinite durations and decoding values. Retrieve duration values in milliseconds or nanoseconds. Compare durations and perform arithmetic operations like addition and multiplication. Master the capabilities of the `Duration` module for efficient time handling in your applications.bottomNavigation: pagination

The `Duration` data type data type is used to represent specific non-negative spans of time. It is commonly used to represent time intervals or durations in various operations, such as timeouts, delays, or scheduling. The `Duration` type provides a convenient way to work with time units and perform calculations on durations.

## Creating Durations

The `Duration` module provides several constructors to create durations of different units. Here are some examples:

```ts twoslash
import { Duration } from 'effect';

const duration1 = Duration.millis(100); // Create a duration of 100 milliseconds
const duration2 = Duration.seconds(2); // Create a duration of 2 seconds
const duration3 = Duration.minutes(5); // Create a duration of 5 minutes
```

You can create durations using units such as nanoseconds, microsecond, milliseconds, seconds, minutes, hours, days, and weeks.

If you want to create an infinite duration, you can use `Duration.infinity`:

```ts twoslash
import { Duration } from 'effect';

console.log(String(Duration.infinity));
/*
Output:
{
  "_id": "Duration",
  "_tag": "Infinity"
}
*/
```

Another option for creating durations is using the `Duration.decode` helper:

- `number`s are treated as milliseconds
- `bigint`s are treated as nanoseconds
- strings must be formatted as `"${number} ${unit}"`

```ts twoslash
// @target: ES2020
import { Duration } from 'effect';

Duration.decode(10n); // same as Duration.nanos(10)
Duration.decode(100); // same as Duration.millis(100)
Duration.decode(Infinity); // same as Duration.infinity

Duration.decode('10 nanos'); // same as Duration.nanos(10)
Duration.decode('20 micros'); // same as Duration.micros(20)
Duration.decode('100 millis'); // same as Duration.millis(100)
Duration.decode('2 seconds'); // same as Duration.seconds(2)
Duration.decode('5 minutes'); // same as Duration.minutes(5)
Duration.decode('7 hours'); // same as Duration.hours(7)
Duration.decode('3 weeks'); // same as Duration.weeks(3)
```

## Getting the Duration Value

You can retrieve the value of a duration in milliseconds using the `toMillis` function:

```ts twoslash
import { Duration } from 'effect';

console.log(Duration.toMillis(Duration.seconds(30))); // Output: 30000
```

You can retrieve the value of a duration in nanoseconds using the `toNanos` function:

```ts twoslash
import { Duration } from 'effect';

console.log(Duration.toNanos(Duration.millis(100)));
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 100000000n
}
*/
```

Note that `toNanos` returns an `Option<bigint>` since the duration might be infinite. If you want a `bigint` as a return type, you can use `unsafeToNanos`. However, note that it will throw an error for infinite durations:

```ts twoslash
import { Duration } from 'effect';

console.log(Duration.unsafeToNanos(Duration.millis(100))); // Output: 100000000n
console.log(Duration.unsafeToNanos(Duration.infinity)); // throws "Cannot convert infinite duration to nanos"
```

## Comparing Durations

You can compare two durations using the following functions:

| **Function**           | **Description**                                                             |
| ---------------------- | --------------------------------------------------------------------------- |
| `lessThan`             | returns `true` if the first duration is less than the second                |
| `lessThanOrEqualTo`    | returns `true` if the first duration is less than or equal to the second    |
| `greaterThan`          | returns `true` if the first duration is greater than the second             |
| `greaterThanOrEqualTo` | returns `true` if the first duration is greater than or equal to the second |

```ts twoslash
import { Duration } from 'effect';

const duration1 = Duration.seconds(30);
const duration2 = Duration.minutes(1);

console.log(Duration.lessThan(duration1, duration2)); // Output: true
console.log(Duration.lessThanOrEqualTo(duration1, duration2)); // Output: true
console.log(Duration.greaterThan(duration1, duration2)); // Output: false
console.log(Duration.greaterThanOrEqualTo(duration1, duration2)); // Output: false
```

## Performing Arithmetic Operations

You can perform arithmetic operations on durations, such as addition and multiplication. Here are some examples:

```ts twoslash
import { Duration } from 'effect';

const duration1 = Duration.seconds(30);
const duration2 = Duration.minutes(1);

console.log(String(Duration.sum(duration1, duration2)));
/*
Output:
{
  "_id": "Duration",
  "_tag": "Millis",
  "millis": 90000
}
*/

console.log(String(Duration.times(duration1, 2))); // Output: Duration("60000 millis")
/*
Output:
{
  "_id": "Duration",
  "_tag": "Millis",
  "millis": 60000
}
*/
```

# Exit

---

## title: Exitexcerpt: Explore the `Exit` data type in Effect, representing the result of executing an `Effect` workflow. Learn about success and failure states, matching with `Exit.match`, and the conceptual relationship between `Exit` and `Either`. Understand how `Exit` is a subtype of `Effect` and its role in handling results and errors.bottomNavigation: pagination

An `Exit<A, E>` describes the result of executing an `Effect` workflow.

There are two possible values for an `Exit<A, E>`:

- `Exit.Success` contains a success value of type `A`.
- `Exit.Failure` contains a failure [Cause](cause) of type `E`.

## Matching

To handle the different outcomes of an `Exit`, we can use the `Exit.match` function:

```ts twoslash
import { Effect, Exit } from 'effect';

const simulatedSuccess = Effect.runSyncExit(Effect.succeed(1));

Exit.match(simulatedSuccess, {
  onFailure: (cause) =>
    console.error(`Exited with failure state: ${cause._tag}`),
  onSuccess: (value) => console.log(`Exited with success value: ${value}`),
});
// Output: "Exited with success value: 1"

const simulatedFailure = Effect.runSyncExit(Effect.fail('error'));

Exit.match(simulatedFailure, {
  onFailure: (cause) =>
    console.error(`Exited with failure state: ${cause._tag}`),
  onSuccess: (value) => console.log(`Exited with success value: ${value}`),
});
// Output: "Exited with failure state: Fail"
```

In this example, we first simulate a successful `Effect` execution using `Effect.runSyncExit` and `Effect.succeed`. We then handle the `Exit` using `Exit.match`, where the `onSuccess` callback prints the success value.

Next, we simulate a failure using `Effect.runSyncExit` and `Effect.fail`, and handle the `Exit` again using `Exit.match`, where the `onFailure` callback prints the failure state.

## Exit vs Either

An `Exit<A, E>` is conceptually an `Either<A, Cause<E>>`. However, it's important to note that [Cause](cause) encompasses more states than just the expected error type `E`. It also includes other states such as interruption and defects (unexpected errors), as well as the possibility of combining multiple `Cause` values together.

## Exit vs Effect

The `Exit` data type is a subtype of the `Effect` type, which means that an `Exit` is itself an `Effect`.
The reason for this is that a result can be considered as a _constant computation_.
Technically, `Effect.succeed` is an alias for `Exit.succeed`, and `Effect.fail` is an alias for `Exit.fail` (avoiding conversions between `Exit` and `Effect` is important for performance, as boxing and unboxing have a cost).

# Redacted

---

## title: Redactedexcerpt: RedactedbottomNavigation: pagination

The Redacted module provides functionality for handling sensitive information securely within your application.
By using the `Redacted` data type, you can ensure that sensitive values are not accidentally exposed in logs or error messages.

## make

This function creates a `Redacted<A>` instance from a given value `A`, securely hiding its content.

```ts twoslash
import { Redacted } from 'effect';

// Creating a redacted value
const API_KEY = Redacted.make('1234567890');

console.log(API_KEY); // Output: {}
console.log(String(API_KEY)); // Output: <redacted>
```

## value

Retrieves the original value from a `Redacted` instance. Use this function with caution, as it exposes the sensitive data.

```ts twoslash
import { Redacted } from 'effect';

const API_KEY = Redacted.make('1234567890');

console.log(Redacted.value(API_KEY)); // Output: "1234567890"
```

## unsafeWipe

Erases the underlying value of a `Redacted` instance, rendering it unusable. This function is intended to ensure that sensitive data does not remain in memory longer than necessary.

```ts twoslash
import { Redacted } from 'effect';

const API_KEY = Redacted.make('1234567890');

console.log(Redacted.value(API_KEY)); // Output: "1234567890"

Redacted.unsafeWipe(API_KEY);

console.log(Redacted.value(API_KEY)); // throws Error: Unable to get redacted value
```

## getEquivalence

Generates an equivalence relation for `Redacted<A>` values based on an equivalence relation for the underlying values `A`.
This function is useful for comparing `Redacted` instances without exposing their contents.

```ts twoslash
import { Equivalence, Redacted } from 'effect';

const API_KEY1 = Redacted.make('1234567890');
const API_KEY2 = Redacted.make('1-34567890');
const API_KEY3 = Redacted.make('1234567890');

const equivalence = Redacted.getEquivalence(Equivalence.string);

console.log(equivalence(API_KEY1, API_KEY2)); // Output: false
console.log(equivalence(API_KEY1, API_KEY3)); // Output: true
```

# Chunk

---

## title: Chunkexcerpt: Explore the benefits of using `Chunk`, an immutable and high-performance array-like data structure in JavaScript. Learn about its advantages, including immutability for concurrent programming and specialized operations for efficient array manipulations. Discover operations like creating, concatenating, dropping elements, comparing for equality, and converting to a `ReadonlyArray`.bottomNavigation: pagination

A `Chunk<A>` represents a chunk of values of type `A`.
Chunks are usually backed by arrays, but expose a purely functional, safe interface to the underlying elements, and they become lazy on operations that would be costly with arrays, such as repeated concatenation. Like lists and arrays, `Chunk` is an ordered collection.

<Warning>
  `Chunk` is purpose-built to amoritize the cost of repeated concatenation of
  arrays. Therefore, for use-cases that **do not** involve repeated
  concatenation of arrays, the overhead of `Chunk` will result in reduced
  performance.
</Warning>

## Why Chunk?

Let's explore the reasons behind using `Chunk`:

- **Immutability**: In JavaScript, there is no built-in immutable data type that can efficiently represent an array. While the `Array` type exists, it provides a mutable interface, which means it can be modified after creation. `Chunk`, on the other hand, is an immutable array-like data structure that ensures the data remains unchanged. Immutability is beneficial in various scenarios, especially when dealing with concurrent programming.

- **High Performance**: `Chunk` not only offers immutability but also delivers high performance. It provides specialized operations for common array manipulations, such as appending a single element or concatenating two `Chunk`s together. These specialized operations are significantly faster than performing the same operations on regular JavaScript arrays.

## Operations

### Creating

To create an empty `Chunk`, you can use the following code:

```ts twoslash
import { Chunk } from 'effect';

const emptyChunk = Chunk.empty();
```

If you want to create a `Chunk` with specific values, you can use the `Chunk.make(...values)` function:

```ts twoslash
import { Chunk } from 'effect';

const nonEmptyChunk = Chunk.make(1, 2, 3);
```

Alternatively, you can create a `Chunk` by providing a collection of values. There are multiple ways to achieve this:

- Creating a `Chunk` from a generic `Iterable`:

  ```ts twoslash
  import { Chunk, List } from 'effect';

  const fromArray = Chunk.fromIterable([1, 2, 3]);

  const fromList = Chunk.fromIterable(List.make(1, 2, 3));
  ```

- Creating a `Chunk` from an `Array`:

  ```ts twoslash
  import { Chunk } from 'effect';

  const fromUnsafeArray = Chunk.unsafeFromArray([1, 2, 3]);
  ```

`Chunk.fromIterable` makes a chunk by cloning the iterable, which can be an expensive process for large iterables or when making many Chunks. `unsafeFromArray` doesn't do any cloning which can have performance benefits, but this breaks the assumption that Chunk is immutable.

<Warning>
  It is important to note that using `unsafeFromArray` can potentially lead to
  unsafe or unexpected behavior if the input array is mutated after
  conversion. If you want to ensure safety, it is recommended to use
  `fromIterable`.
</Warning>

### Concatenating

You can concatenate two Chunks using the `appendAll` function:

```ts twoslash
import { Chunk } from 'effect';

const concatenatedChunk = Chunk.appendAll(
  Chunk.make(1, 2),
  Chunk.make('a', 'b'),
);

console.log(concatenatedChunk);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, "a", "b" ]
}
*/
```

### Dropping

To drop elements from the beginning of a `Chunk`, you can use the `drop` function:

```ts twoslash
import { Chunk } from 'effect';

const droppedChunk = Chunk.drop(Chunk.make(1, 2, 3, 4), 2); // Drops the first 2 elements from the Chunk
```

### Comparing

You can compare two `Chunk`s for equality using the `Equal.equals` function:

```ts twoslash
import { Chunk, Equal } from 'effect';

const chunk1 = Chunk.make(1, 2);
const chunk2 = Chunk.make(1, 2, 3);

const areEqual = Equal.equals(chunk1, chunk2);
```

### Converting

To convert a `Chunk` to a `ReadonlyArray`, you can use the `toReadonlyArray` function:

```ts twoslash
import { Chunk } from 'effect';

const readonlyArray = Chunk.toReadonlyArray(Chunk.make(1, 2, 3));
```

# Data

---

## title: Dataexcerpt: Explore the Data module in Effect, offering functionalities for defining data types, ensuring value equality, and working with case classes. Learn about the advantages of using `Data.struct`, `Data.tuple`, and `Data.array` for efficient value comparisons. Dive into the concept of case classes, including `case`, `tagged`, `Class`, and `TaggedClass`, providing automated implementations for data types. Discover how to create unions of case classes using `TaggedEnum` for streamlined handling of disjoint unions.bottomNavigation: pagination

The Data module offers a range of features that make it easier to create and manipulate data structures in your TypeScript applications.
It includes functionalities for **defining data types**, ensuring **equality** between data objects, and **hashing** data for efficient comparison.

The module offers APIs tailored for comparing **existing values** of your data types.
Alternatively, it provides mechanisms for defining **constructors** for your data types.

## Value Equality

If you need to compare **existing values** for equality without the need for explicit
implementations, consider using the Data module. It provides convenient APIs
that generate default implementations for [Equal](../trait/equal) and [Hash](../trait/hash), making equality
checks a breeze.

### struct

In this example, we use the `Data.struct` function to create structured data objects and check their equality using `Equal.equals`.

```ts twoslash
import { Data, Equal } from 'effect';

const alice = Data.struct({ name: 'Alice', age: 30 });

const bob = Data.struct({ name: 'Bob', age: 40 });

console.log(Equal.equals(alice, alice)); // Output: true
console.log(Equal.equals(alice, Data.struct({ name: 'Alice', age: 30 }))); // Output: true

console.log(Equal.equals(alice, { name: 'Alice', age: 30 })); // Output: false
console.log(Equal.equals(alice, bob)); // Output: false
```

The `Data` module simplifies the process by providing a default implementation for both [Equal](../trait/equal) and [Hash](../trait/hash),
allowing you to focus on comparing values without the need for explicit implementations.

### tuple

If you prefer to model your domain with tuples, the `Data.tuple` function has got you covered:

```ts twoslash
import { Data, Equal } from 'effect';

const alice = Data.tuple('Alice', 30);

const bob = Data.tuple('Bob', 40);

console.log(Equal.equals(alice, alice)); // Output: true
console.log(Equal.equals(alice, Data.tuple('Alice', 30))); // Output: true

console.log(Equal.equals(alice, ['Alice', 30])); // Output: false
console.log(Equal.equals(alice, bob)); // Output: false
```

### array

You can take it a step further and use arrays to compare multiple values:

```ts twoslash
import { Data, Equal } from 'effect';

const alice = Data.struct({ name: 'Alice', age: 30 });
const bob = Data.struct({ name: 'Bob', age: 40 });

const persons = Data.array([alice, bob]);

console.log(
  Equal.equals(
    persons,
    Data.array([
      Data.struct({ name: 'Alice', age: 30 }),
      Data.struct({ name: 'Bob', age: 40 }),
    ]),
  ),
); // Output: true
```

In this extended example, we create an array of person objects using the `Data.array` function.
We then compare this array with another array of person objects using `Equal.equals`,
and the result is `true` since the arrays contain structurally equal elements.

## Constructors

The module introduces a concept known as "Case classes", which automate various essential operations when defining data types.
These operations include generating **constructors**, handling **equality** checks, and managing **hashing**.

Case classes can be defined in two primary ways:

- as plain objects using `case` or `tagged`
- as TypeScript classes using `Class` or `TaggedClass`

### case

This helper automatically provides implementations for constructors, equality checks, and hashing for your data type.

```ts twoslash
import { Data, Equal } from 'effect';

interface Person {
  readonly name: string;
}

// Creating a constructor for `Person`
const Person = Data.case<Person>();

// Creating instances of Person
const mike1 = Person({ name: 'Mike' });
const mike2 = Person({ name: 'Mike' });
const john = Person({ name: 'John' });

// Checking equality
console.log(Equal.equals(mike1, mike2)); // Output: true
console.log(Equal.equals(mike1, john)); // Output: false
```

Here we create a constructor for `Person` using `Data.case`.
The resulting instances come with built-in equality checks, making it simple to compare them using `Equal.equals`.

### tagged

In certain situations, like when you're defining a data type that includes a tag field (commonly used in disjoint unions),
using the `case` approach can become repetitive and cumbersome.
This is because you're required to specify the tag every time you create an instance:

```ts twoslash
import { Data } from 'effect';

interface Person {
  readonly _tag: 'Person'; // the tag
  readonly name: string;
}

const Person = Data.case<Person>();

// It can be quite frustrating to repeat `_tag: 'Person'` every time...
const mike = Person({ _tag: 'Person', name: 'Mike' });
const john = Person({ _tag: 'Person', name: 'John' });
```

To make your life easier, the `tagged` helper simplifies this process by allowing you to define the tag only once. It follows the convention within the Effect ecosystem of naming the tag field with `"_tag"`:

```ts twoslash
import { Data } from 'effect';

interface Person {
  readonly _tag: 'Person'; // the tag
  readonly name: string;
}

const Person = Data.tagged<Person>('Person');

// Now, it's much more convenient...
const mike = Person({ name: 'Mike' });
const john = Person({ name: 'John' });

console.log(mike._tag); // Output: { name: 'Mike', _tag: 'Person' }
```

### Class

If you find it more comfortable to work with classes instead of plain objects, you have the option to use `Data.Class` instead of `case`.
This approach can be particularly useful in scenarios where you prefer a more class-oriented structure:

```ts twoslash
import { Data, Equal } from 'effect';

class Person extends Data.Class<{ name: string }> {}

// Creating instances of Person
const mike1 = new Person({ name: 'Mike' });
const mike2 = new Person({ name: 'Mike' });
const john = new Person({ name: 'John' });

// Checking equality
console.log(Equal.equals(mike1, mike2)); // Output: true
console.log(Equal.equals(mike1, john)); // Output: false
```

One advantage of using classes is that you can easily add custom getters and methods to the class definition, enhancing its functionality to suit your specific needs:

```ts twoslash
import { Data } from 'effect';

class Person extends Data.Class<{ name: string }> {
  get upperName() {
    return this.name.toUpperCase();
  }
}

const mike = new Person({ name: 'Mike' });

console.log(mike.upperName); // Output: MIKE
```

### TaggedClass

For those who prefer working with classes over plain objects, you can utilize `Data.TaggedClass` as an alternative to `tagged`.

```ts twoslash
import { Data, Equal } from 'effect';

class Person extends Data.TaggedClass('Person')<{ name: string }> {}

// Creating instances of Person
const mike1 = new Person({ name: 'Mike' });
const mike2 = new Person({ name: 'Mike' });
const john = new Person({ name: 'John' });

console.log(mike1); // Output: Person { name: 'Mike', _tag: 'Person' }

// Checking equality
console.log(Equal.equals(mike1, mike2)); // Output: true
console.log(Equal.equals(mike1, john)); // Output: false
```

One of the advantages of using tagged classes is that you can seamlessly incorporate custom getters and methods into the class definition, expanding its functionality as needed:

```ts twoslash
import { Data } from 'effect';

class Person extends Data.TaggedClass('Person')<{ name: string }> {
  get upperName() {
    return this.name.toUpperCase();
  }
}

const mike = new Person({ name: 'Mike' });

console.log(mike.upperName); // Output: MIKE
```

## Union of Tagged Structs

If you're looking to create a disjoint union of tagged structs, you can easily achieve this using `Data.TaggedEnum` and `Data.taggedEnum`.
This feature simplifies the process of defining and working with unions of plain objects.

### Definition

Let's walk through an example to see how this works:

```ts twoslash
import { Data, Equal } from 'effect';

// Define a union type using TaggedEnum
type RemoteData = Data.TaggedEnum<{
  Loading: {};
  Success: { readonly data: string };
  Failure: { readonly reason: string };
}>;

// Create constructors for specific error types
const { Loading, Success, Failure } = Data.taggedEnum<RemoteData>();

// Create instances of errors
const state1 = Loading();
const state2 = Success({ data: 'test' });
const state3 = Success({ data: 'test' });
const state4 = Failure({ reason: 'not found' });

// Checking equality
console.log(Equal.equals(state2, state3)); // Output: true
console.log(Equal.equals(state2, state4)); // Output: false

console.log(state1); // Output: { _tag: 'Loading' }
console.log(state2); // Output: { data: 'test', _tag: 'Success' }
console.log(state4); // Output: { reason: 'not found', _tag: 'Failure' }
```

In this example:

- We define a `RemoteData` union type with three states: `Loading`, `Success`, and `Failure`.
- We use `Data.taggedEnum` to create constructors for these states.
- We create instances of each state and check for equality using `Equal.equals`.

Note that it follows the convention within the Effect ecosystem of naming the tag field with `"_tag"`.

### Adding Generics

You can also create tagged unions with generics using `TaggedEnum.WithGenerics`. This allows for more flexible and reusable type definitions.

```ts twoslash
import { Data } from 'effect';

type RemoteData<Success, Failure> = Data.TaggedEnum<{
  Loading: {};
  Success: { data: Success };
  Failure: { reason: Failure };
}>;

interface RemoteDataDefinition extends Data.TaggedEnum.WithGenerics<2> {
  readonly taggedEnum: RemoteData<this['A'], this['B']>;
}

const { Loading, Failure, Success } = Data.taggedEnum<RemoteDataDefinition>();

const loading = Loading();

const failure = Failure({ reason: 'not found' });

const success = Success({ data: 1 });
```

### $is and $match

The `Data.taggedEnum` also provides `$is` and `$match` functions for type guards and pattern matching, respectively.

```ts twoslash
import { Data } from 'effect';

type RemoteData = Data.TaggedEnum<{
  Loading: {};
  Success: { readonly data: string };
  Failure: { readonly reason: string };
}>;

const { $is, $match, Loading, Success, Failure } = Data.taggedEnum<
  RemoteData
>();

// Create a type guard
const isLoading = $is('Loading');

console.log(isLoading(Loading())); // true
console.log(isLoading(Success({ data: 'test' }))); // false

// Create a matcher
const matcher = $match({
  Loading: () => 'this is a Loading',
  Success: ({ data }) => `this is a Success: ${data}`,
  Failure: ({ reason }) => `this is a Failre: ${reason}`,
});

console.log(matcher(Success({ data: 'test' }))); // "this is a Success: test"
```

## Errors

In Effect, errors play a crucial role, and defining and constructing them is made easier with two specialized constructors:

- `Error`
- `TaggedError`

### Error

With `Data.Error`, we can create an `Error` with additional fields beyond the usual `message`:

```ts twoslash
import { Data } from 'effect';

class NotFound extends Data.Error<{ message: string; file: string }> {}

const err = new NotFound({
  message: 'Cannot find this file',
  file: 'foo.txt',
});

console.log(err instanceof Error); // Output: true

console.log(err.file); // Output: foo.txt
console.log(err);
/*
Output:
Error: Cannot find this file
  ... stack trace ...
*/
```

Additionally, `NotFound` is "yieldable" as it is an `Effect`, so there's no need to use `Effect.fail`:

```ts twoslash
import { Data, Effect } from 'effect';

class NotFound extends Data.Error<{ message: string; file: string }> {}

const program = Effect.gen(function* () {
  yield* new NotFound({
    message: 'Cannot find this file',
    file: 'foo.txt',
  });
});
```

### TaggedError

In Effect, there's a special convention to add a `_tag` field to custom errors. This convention simplifies certain operations, such as error handling with APIs like `Effect.catchTag` or `Effect.catchTags`. Therefore, the `TaggedError` API simplifies the process of creating custom errors by automatically adding this type of tag without needing to specify it every time you create a new error:

```ts twoslash
import { Console, Data, Effect } from 'effect';

class NotFound extends Data.TaggedError('NotFound')<{
  message: string;
  file: string;
}> {}

const program = Effect.gen(function* () {
  yield* new NotFound({
    message: 'Cannot find this file',
    file: 'foo.txt',
  });
}).pipe(
  Effect.catchTag(
    'NotFound',
    (err) => Console.error(`${err.message} (${err.file})`),
  ),
);

Effect.runPromise(program);
// Output: Cannot find this file (foo.txt)
```

# Effect vs Promise

---

## title: Effect vs Promiseexcerpt: Explore the differences between `Promise` and `Effect` in TypeScript, covering type safety, creation, chaining, and concurrency. Learn how `Effect` enhances type tracking for errors and dependencies and provides powerful features like fiber-based concurrency and built-in capabilities for logging, scheduling, caching, and more.bottomNavigation: pagination

In this guide, we will explore the differences between `Promise` and `Effect`, two approaches to handling asynchronous operations in TypeScript. We'll discuss their type safety, creation, chaining, and concurrency, providing examples to help you understand their usage.

## Comparing Effects and Promises: Key Distinctions

- **Evaluation Strategy:** Promises are eagerly evaluated, whereas effects are lazily evaluated.
- **Execution Mode:** Promises are one-shot, executing once, while effects are multi-shot, repeatable.
- **Interruption Handling and Automatic Propagation:** Promises lack built-in interruption handling, posing challenges in managing interruptions, and don't automatically propagate interruptions, requiring manual abort controller management. In contrast, effects come with interruption handling capabilities and automatically compose interruption, simplifying management locally on smaller computations without the need for high-level orchestration.
- **Structured Concurrency:** Effects offer structured concurrency built-in, which is challenging to achieve with Promises.
- **Error Reporting (Type Safety):** Promises don't inherently provide detailed error reporting at the type level, whereas effects do, offering type-safe insight into error cases.
- **Runtime Behavior:** The Effect runtime aims to remain synchronous as long as possible, transitioning into asynchronous mode only when necessary due to computation requirements or main thread starvation.

## Type safety

Let's start by comparing the types of `Promise` and `Effect`. The type parameter `A` represents the resolved value of the operation:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts
Promise<A>;
```

</Tab>
<Tab>

```ts
Effect<A, Error, Context>;
```

</Tab>
</Tabs>

Here's what sets `Effect` apart:

- It allows you to track the types of errors statically through the type parameter `Error`. For more information about error management in `Effect`, see [Expected Errors](../guides/error-management/expected-errors).
- It allows you to track the types of required dependencies statically through the type parameter `Context`. For more information about context management in `Effect`, see [Managing Services](../guides/context-management/services).

## Creating

### Success

Let's compare creating a successful operation using `Promise` and `Effect`:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
export const success = Promise.resolve(2);
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

export const success = Effect.succeed(2);
```

</Tab>
</Tabs>

### Failure

Now, let's see how to handle failures with `Promise` and `Effect`:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
export const failure = Promise.reject('Uh oh!');
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

export const failure = Effect.fail('Uh oh!');
```

</Tab>
</Tabs>

### Constructor

Creating operations with custom logic:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
export const task = new Promise<number>((resolve, reject) => {
  setTimeout(() => {
    Math.random() > 0.5 ? resolve(2) : reject('Uh oh!');
  }, 300);
});
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

export const task = Effect.gen(function* () {
  yield* Effect.sleep('300 millis');
  return Math.random() > 0.5 ? 2 : yield* Effect.fail('Uh oh!');
});
```

</Tab>
</Tabs>

## Thenable

Mapping the result of an operation:

### map

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
export const mapped = Promise.resolve('Hello').then((s) => s.length);
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

export const mapped = Effect.succeed('Hello').pipe(
  Effect.map((s) => s.length),
  // or Effect.andThen((s) => s.length)
);
```

</Tab>
</Tabs>

### flatMap

Chaining multiple operations:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
export const flatMapped = Promise.resolve('Hello').then((s) =>
  Promise.resolve(s.length)
);
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

export const flatMapped = Effect.succeed('Hello').pipe(
  Effect.flatMap((s) => Effect.succeed(s.length)),
  // or Effect.andThen((s) => Effect.succeed(s.length))
);
```

</Tab>
</Tabs>

## Comparing Effect.gen with async/await

If you are familiar with `async`/`await`, you may notice that the flow of writing code is similar.

Let's compare the two approaches:

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
const increment = (x: number) => x + 1;

const divide = (a: number, b: number): Promise<number> =>
  b === 0
    ? Promise.reject(new Error('Cannot divide by zero'))
    : Promise.resolve(a / b);

const task1 = Promise.resolve(10);

const task2 = Promise.resolve(2);

const program = async function () {
  const a = await task1;
  const b = await task2;
  const n1 = await divide(a, b);
  const n2 = increment(n1);
  return `Result is: ${n2}`;
};

program().then(console.log); // Output: "Result is: 6"
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';
// ---cut---
const increment = (x: number) => x + 1;

const divide = (a: number, b: number): Effect.Effect<number, Error> =>
  b === 0
    ? Effect.fail(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);

const task1 = Effect.promise(() => Promise.resolve(10));

const task2 = Effect.promise(() => Promise.resolve(2));

export const program = Effect.gen(function* () {
  const a = yield* task1;
  const b = yield* task2;
  const n1 = yield* divide(a, b);
  const n2 = increment(n1);
  return `Result is: ${n2}`;
});

Effect.runPromise(program).then(console.log); // Output: "Result is: 6"
```

</Tab>
</Tabs>

It's important to note that although the code appears similar, the two programs are not identical. The purpose of comparing them side by side is just to highlight the resemblance in how they are written.

## Concurrency

### Promise.all()

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
const task1 = new Promise<number>((resolve, reject) => {
  console.log('Executing task1...');
  setTimeout(() => {
    console.log('task1 done');
    resolve(1);
  }, 100);
});

const task2 = new Promise<number>((resolve, reject) => {
  console.log('Executing task2...');
  setTimeout(() => {
    console.log('task2 done');
    reject('Uh oh!');
  }, 200);
});

const task3 = new Promise<number>((resolve, reject) => {
  console.log('Executing task3...');
  setTimeout(() => {
    console.log('task3 done');
    resolve(3);
  }, 300);
});

export const program = Promise.all([task1, task2, task3]);

program.then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
Uh oh!
task3 done
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('Executing task1...');
  yield* Effect.sleep('100 millis');
  console.log('task1 done');
  return 1;
});

const task2 = Effect.gen(function* () {
  console.log('Executing task2...');
  yield* Effect.sleep('200 millis');
  console.log('task2 done');
  return yield* Effect.fail('Uh oh!');
});

const task3 = Effect.gen(function* () {
  console.log('Executing task3...');
  yield* Effect.sleep('300 millis');
  console.log('task3 done');
  return 3;
});

export const program = Effect.all([task1, task2, task3], {
  concurrency: 'unbounded',
});

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
(FiberFailure) Error: Uh oh!
*/
```

</Tab>
</Tabs>

### Promise.allSettled()

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts
const task1 = new Promise<number>((resolve, reject) => {
  console.log('Executing task1...');
  setTimeout(() => {
    console.log('task1 done');
    resolve(1);
  }, 100);
});

const task2 = new Promise<number>((resolve, reject) => {
  console.log('Executing task2...');
  setTimeout(() => {
    console.log('task2 done');
    reject('Uh oh!');
  }, 200);
});

const task3 = new Promise<number>((resolve, reject) => {
  console.log('Executing task3...');
  setTimeout(() => {
    console.log('task3 done');
    resolve(3);
  }, 300);
});

export const program = Promise.allSettled([task1, task2, task3]);

program.then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
task3 done
[
  { status: 'fulfilled', value: 1 },
  { status: 'rejected', reason: 'Uh oh!' },
  { status: 'fulfilled', value: 3 }
]
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('Executing task1...');
  yield* Effect.sleep('100 millis');
  console.log('task1 done');
  return 1;
});

const task2 = Effect.gen(function* () {
  console.log('Executing task2...');
  yield* Effect.sleep('200 millis');
  console.log('task2 done');
  return yield* Effect.fail('Uh oh!');
});

const task3 = Effect.gen(function* () {
  console.log('Executing task3...');
  yield* Effect.sleep('300 millis');
  console.log('task3 done');
  return 3;
});

export const program = Effect.forEach(
  [task1, task2, task3],
  (task) => Effect.either(task), // or Effect.exit
  {
    concurrency: 'unbounded',
  },
);

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
task3 done
[
  {
    _id: "Either",
    _tag: "Right",
    right: 1
  }, {
    _id: "Either",
    _tag: "Left",
    left: "Uh oh!"
  }, {
    _id: "Either",
    _tag: "Right",
    right: 3
  }
]
*/
```

</Tab>
</Tabs>

### Promise.any()

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts
const task1 = new Promise<number>((resolve, reject) => {
  console.log('Executing task1...');
  setTimeout(() => {
    console.log('task1 done');
    reject('Something went wrong!');
  }, 100);
});

const task2 = new Promise<number>((resolve, reject) => {
  console.log('Executing task2...');
  setTimeout(() => {
    console.log('task2 done');
    resolve(2);
  }, 200);
});

const task3 = new Promise<number>((resolve, reject) => {
  console.log('Executing task3...');
  setTimeout(() => {
    console.log('task3 done');
    reject('Uh oh!');
  }, 300);
});

export const program = Promise.any([task1, task2, task3]);

program.then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
2
task3 done
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('Executing task1...');
  yield* Effect.sleep('100 millis');
  console.log('task1 done');
  return yield* Effect.fail('Something went wrong!');
});

const task2 = Effect.gen(function* () {
  console.log('Executing task2...');
  yield* Effect.sleep('200 millis');
  console.log('task2 done');
  return 2;
});

const task3 = Effect.gen(function* () {
  console.log('Executing task3...');
  yield* Effect.sleep('300 millis');
  console.log('task3 done');
  return yield* Effect.fail('Uh oh!');
});

export const program = Effect.raceAll([task1, task2, task3]);

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
task2 done
2
*/
```

</Tab>
</Tabs>

### Promise.race()

<Tabs items={['Promise', 'Effect']}>
<Tab>

```ts twoslash
const task1 = new Promise<number>((resolve, reject) => {
  console.log('Executing task1...');
  setTimeout(() => {
    console.log('task1 done');
    reject('Something went wrong!');
  }, 100);
});

const task2 = new Promise<number>((resolve, reject) => {
  console.log('Executing task2...');
  setTimeout(() => {
    console.log('task2 done');
    reject('Uh oh!');
  }, 200);
});

const task3 = new Promise<number>((resolve, reject) => {
  console.log('Executing task3...');
  setTimeout(() => {
    console.log('task3 done');
    resolve(3);
  }, 300);
});

export const program = Promise.race([task1, task2, task3]);

program.then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
Something went wrong!
task2 done
task3 done
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('Executing task1...');
  yield* Effect.sleep('100 millis');
  console.log('task1 done');
  return yield* Effect.fail('Something went wrong!');
});

const task2 = Effect.gen(function* () {
  console.log('Executing task2...');
  yield* Effect.sleep('200 millis');
  console.log('task2 done');
  return yield* Effect.fail('Uh oh!');
});

const task3 = Effect.gen(function* () {
  console.log('Executing task3...');
  yield* Effect.sleep('300 millis');
  console.log('task3 done');
  return 3;
});

export const program = Effect.raceAll(
  [task1, task2, task3].map(Effect.either),
); // or Effect.exit

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
Executing task1...
Executing task2...
Executing task3...
task1 done
{
  _id: "Either",
  _tag: "Left",
  left: "Something went wrong!"
}
*/
```

</Tab>
</Tabs>

## FAQ

**Question**. What is the equivalent of starting a promise without immediately waiting for it in Effects?

```ts {10,16} twoslash
const task = (delay: number, name: string) =>
  new Promise((resolve) =>
    setTimeout(() => {
      console.log(`${name} done`);
      return resolve(name);
    }, delay)
  );

export async function program() {
  const r0 = task(2_000, 'long running task');
  const r1 = await task(200, 'task 2');
  const r2 = await task(100, 'task 3');
  return {
    r1,
    r2,
    r0: await r0,
  };
}

program().then(console.log);
/*
Output:
task 2 done
task 3 done
long running task done
{ r1: 'task 2', r2: 'task 3', r0: 'long running promise' }
*/
```

**Answer:** You can achieve this by utilizing `Effect.fork` and `Fiber.join`.

```ts {11,17} twoslash
import { Effect, Fiber } from 'effect';

const task = (delay: number, name: string) =>
  Effect.gen(function* () {
    yield* Effect.sleep(delay);
    console.log(`${name} done`);
    return name;
  });

const program = Effect.gen(function* () {
  const r0 = yield* Effect.fork(task(2_000, 'long running task'));
  const r1 = yield* task(200, 'task 2');
  const r2 = yield* task(100, 'task 3');
  return {
    r1,
    r2,
    r0: yield* Fiber.join(r0),
  };
});

Effect.runPromise(program).then(console.log);
/*
Output:
task 2 done
task 3 done
long running task done
{ r1: 'task 2', r2: 'task 3', r0: 'long running promise' }
*/
```

# Myths

---

## title: Mythsexcerpt: Discuss common misconceptions about Effect.bottomNavigation: pagination

## Effect heavily relies on generators and generators are slow!

Effect's internals are not built on generators, we only use generators to provide an API which closely mimics async-await. Internally async-await uses the same mechanics as generators and they are equally performant. So if you don't have a problem with async-await you won't have a problem with Effect's generators.

Where generators and iterables are unacceptably slow is in transforming collections of data, for that try to use plain arrays as much as possible.

## Effect will make your code 500x slower!

Effect does perform 500x slower if you are comparing:

```ts
const result = 1 + 1;
```

to

```ts
const result = Effect.runSync(Effect.zipWith(
  Effect.succeed(1),
  Effect.succeed(1),
  (a, b) => a + b,
));
```

The reason is one operation is optimized by the JIT compiler to be a direct CPU instruction and the other isn't.

In reality you'd never use Effect in such cases, Effect is an app-level library to tame concurrency, error handling, and much more!

You'd use Effect to coordinate your thunks of code, and you can build your thunks of code in the best perfoming manner as you see fit while still controlling execution through Effect.

## Effect has a huge performance overhead!

Depends what you mean by performance, many times performance bottlenecks in JS are due to bad management of concurrency.

Thanks to structured concurrency and observability it becomes much easier to spot and optimize those issues.

There are apps in frontend running at 120fps that use Effect intensively, so most likely effect won't be your perf problem.

In regards of memory, it doesn't use much more memory than a normal program would, there are a few more allocations compared to non Effect code but usually this is no longer the case when the non Effect code does the same thing as the Effect code.

The advise would be start using it and monitor your code, optimise out of need not out of thought, optimizing too early is the root of all evils in software design.

## The bundle size is HUGE!

Effect's minimum cost is about 25k of gzipped code, that chunk contains the Effect Runtime and already includes almost all the functions that you'll need in a normal app-code scenario.

From that point on Effect is tree-shaking friendly so you'll only include what you use.

Also when using Effect your own code becomes shorter and terser, so the overall cost is amortized with usage, we have apps where adopting Effect in the majority of the codebase led to reduction of the final bundle.

## Effect is impossible to learn, there are so many functions and modules!

True, the full Effect ecosystem is quite large and some modules contain 1000s of functions, the reality is that you don't need to know them all to start being productive, you can safely start using Effect knowing just 10-20 functions and progressively discover the rest, just like you can start using TypeScript without knowing every single NPM package.

A short list of commonly used functions to begin are:

- Effect.succeed
- Effect.fail
- Effect.sync
- Effect.tryPromise
- Effect.gen
- Effect.runPromise
- Effect.catchTag
- Effect.catchAll
- Effect.acquireRelease
- Effect.acquireUseRelease
- Effect.provide
- Effect.provideService
- Effect.andThen
- Effect.map
- Effect.tap

A short list of commonly used modules:

- Effect
- Context
- Layer
- Option
- Either
- Array
- Match

## Effect is the same as RxJS and shares its problems

This is a sensitive topic, let's start by saying that RxJS is a great project and that it has helped millions of developers write reliable software and we all should be thankful to the developers who contributed to such an amazing project.

Discussing the scope of the projects, RxJS aims to make working with Observables easy and wants to provide reactive extensions to JS, Effect instead wants to make writing production-grade TypeScript easy. While the intersection is non-empty the projects have fundamentally different objectives and strategies.

Sometimes people refer to RxJS in bad light, and the reason isn't RxJS in itself but rather usage of RxJS in problem domains where RxJS wasn't thought to be used.

Namely the idea that "everything is a stream" is theoretically true but it leads to fundamental limitations on developer experience, the primary issue being that streams are multi-shot (emit potentially multiple elements, or zero) and mutable delimited continuations (JS Generators) are known to be only good to represent single-shot effects (that emit a single value).

In short it means that writing in imperative style (think of async/await) is practically impossible with stream primitives (practically because there would be the option of replaying the generator at every element and at every step, but this tends to be inefficient and the semantics of it are counter-intuitive, it would only work under the assumption that the full body is free of side-effects), forcing the developer to use declarative approaches such as pipe to represent all of their code.

Effect has a Stream module (which is pull-based instead of push-based in order to be memory constant), but the basic Effect type is single-shot and it is optimised to act as a smart & lazy Promise that enables imperative programming, so when using Effect you're not forced to use a declarative style for everything and you can program using a model which is similar to async-await.

The other big difference is that RxJS only cares about the happy-path with explicit types, it doesn't offer a way of typing errors and dependencies, Effect instead consider both errors and dependencies as explicitely typed and offers control-flow around those in a fully type-safe manner.

In short if you need reactive programming around Observables, use RxJS, if you need to write production-grade TypeScript that includes by default native telemetry, error handling, dependency injection, and more use Effect.

## Effect should be a language or Use a different language

Neither solve the issue of writing production grade software in TypeScript.

TypeScript is an amazing language to write full stack code with deep roots in the JS ecosystem and wide compatibility of tools, it is an industrial language adopted by many large scale companies.

The fact that something like Effect is possible within the language and the fact that the language supports things such as generators that allows for imperative programming with custom types such as Effect makes TypeScript a unique language.

In fact even in functional languages such as Scala the interop with effect systems is less optimal than it is in TypeScript, to the point that effect system authors have expressed wish for their language to support as much as TypeScript supports.

# Equal

---

## title: Equalexcerpt: The Equal module provides a solution for value-based equality checks, addressing issues with JavaScript's native reference-based equality operators. Developers can define custom equality checks, ensuring data integrity and promoting predictable behavior. To implement custom equality, developers can either implement the `Equal` interface or leverage the simpler solution offered by the [Data](../data-types/data) module, which automatically generates default implementations for both `Equal` and `Hash`. This excerpt also explores working with collections like `HashSet` and `HashMap` to handle value-based equality checks effectively.bottomNavigation: pagination

The Equal module provides a simple and convenient way to define and check for equality between two values in TypeScript.

Here are some key reasons why Effect exports an Equal module:

1. **Value-Based Equality**: JavaScript's native equality operators (`===` and `==`) check for equality by reference, meaning they compare objects based on their memory addresses rather than their content. This behavior can be problematic when you want to compare objects with the same values but different references. The Equal module offers a solution by allowing developers to define custom equality checks based on the values of objects.

2. **Custom Equality**: The Equal module enables developers to implement custom equality checks for their data types and classes. This is crucial when you have specific requirements for determining when two objects should be considered equal. By implementing the `Equal` interface, developers can define their own equality logic.

3. **Data Integrity**: In some applications, maintaining data integrity is crucial. The ability to perform value-based equality checks ensures that identical data is not duplicated within collections like sets or maps. This can lead to more efficient memory usage and more predictable behavior.

4. **Predictable Behavior**: The Equal module promotes more predictable behavior when comparing objects. By explicitly defining equality criteria, developers can avoid unexpected results that may occur with JavaScript's default reference-based equality checks.

## How to Perform Equality Checking in Effect

In Effect it's advisable to **stop using** JavaScript's `===` and `==` operators and instead rely on the `Equal.equals` function.
This function can work with any data type that implements the `Equal` trait.
Some examples of such data types include [Option](../data-types/option), [Either](../data-types/either), [HashSet](https://effect-ts.github.io/effect/effect/HashSet.ts.html), and [HashMap](https://effect-ts.github.io/effect/effect/HashMap.ts.html).

When you use `Equal.equals` and your objects do not implement the `Equal` trait, it defaults to using the `===` operator for object comparison:

```ts twoslash
import { Equal } from 'effect';

const a = { name: 'Alice', age: 30 };
const b = { name: 'Alice', age: 30 };

console.log(Equal.equals(a, b)); // Output: false
```

In this example, `a` and `b` are two separate objects with the same contents. However, `===` considers them different because they occupy different memory locations. This behavior can lead to unexpected results when you want to compare values based on their content.

However, you can configure your models to ensure that `Equal.equals` behaves consistently with your custom equality checks. There are two alternative approaches:

1. **Implementing the `Equal` Interface**: This method is useful when you need to define your custom equality check.

2. **Using the Data Module**: For simple value equality, the [Data](../data-types/data) module provides a more straightforward solution by automatically generating default implementations for `Equal`.

Let's delve into both solutions.

### Implementing the Equal Interface

To create custom equality behavior, you can implement the `Equal` interface in your models. This interface extends the `Hash` interface from the [Hash](hash) module.

Here's an example of implementing the `Equal` interface for a `Person` class:

```twoslash include Person
import { Equal, Hash } from "effect"

export class Person implements Equal.Equal {
  constructor(
    readonly id: number,  // Unique identifier for each person
    readonly name: string,
    readonly age: number
  ) {}

  // Defines equality based on id, name, and age
  [Equal.symbol](that: Equal.Equal): boolean {
    if (that instanceof Person) {
      return (
        Equal.equals(this.id, that.id) &&
        Equal.equals(this.name, that.name) &&
        Equal.equals(this.age, that.age)
      )
    }
    return false
  }

  // Generates a hash code based primarily on the unique id
  [Hash.symbol](): number {
    return Hash.hash(this.id)
  }
}
```

```ts filename="Person.ts" twoslash
// @include: Person
```

In the above code, we define a custom equality function `[Equal.symbol]` and a hash function `[Hash.symbol]` for the `Person` class. The `Hash` interface optimizes equality checks by comparing hash values instead of the objects themselves. When you use the `Equal.equals` function to compare two objects, it first checks if their hash values are equal. If not, it quickly determines that the objects are not equal, avoiding the need for a detailed property-by-property comparison.

Once you've implemented the `Equal` interface, you can utilize the `Equal.equals` function to check for equality using your custom logic. Here's an example using the `Person` class:

```ts twoslash
// @filename: Person.ts
// @include: Person

// @filename: index.ts
// ---cut---
import { Equal } from 'effect';
import { Person } from './Person';

const alice = new Person(1, 'Alice', 30);
console.log(Equal.equals(alice, new Person(1, 'Alice', 30))); // Output: true

const bob = new Person(2, 'Bob', 40);
console.log(Equal.equals(alice, bob)); // Output: false
```

In this code, the equality check returns `true` when comparing `alice` to a new `Person` object with identical property values and `false` when comparing `alice` to `bob` due to their differing property values.

### Simplifying Equality with the Data Module

Implementing both `Equal` and `Hash` can become cumbersome when all you need is straightforward value equality checks. Luckily, the [Data](../data-types/data) module provides a simpler solution. It offers APIs that automatically generate default implementations for both `Equal` and `Hash`.

Let's see how it works:

```ts twoslash
import { Data, Equal } from 'effect';

const alice = Data.struct({ name: 'Alice', age: 30 });

const bob = Data.struct({ name: 'Bob', age: 40 });

console.log(Equal.equals(alice, alice)); // Output: true
console.log(Equal.equals(alice, Data.struct({ name: 'Alice', age: 30 }))); // Output: true

console.log(Equal.equals(alice, { name: 'Alice', age: 30 })); // Output: false
console.log(Equal.equals(alice, bob)); // Output: false
```

In this example, we use the `Data.struct` function to create structured data objects and check their equality using `Equal.equals`. The [Data](../data-types/data) module simplifies the process by providing a default implementation for both `Equal` and `Hash`, allowing you to focus on comparing values without the need for explicit implementations.

The Data module isn't limited to just structs. It can handle various data types, including tuples, arrays, and records. If you're curious about how to leverage its full range of features, you can explore the [Data module documentation](../data-types/data).

## Working with Collections

JavaScript's built-in `Set` and `Map` can be a bit tricky when it comes to checking equality:

```ts twoslash
export const set = new Set();

set.add({ name: 'Alice', age: 30 });
set.add({ name: 'Alice', age: 30 });

console.log(set.size); // Output: 2
```

Even though the two elements in the set have the same values, the set contains two elements. Why? JavaScript's `Set` checks for equality by reference, not by values.

To perform value-based equality checks, you'll need to use the `Hash*` collection types available in the `effect` package. These collection types, such as [HashSet](https://effect-ts.github.io/effect/effect/HashSet.ts.html) and [HashMap](https://effect-ts.github.io/effect/effect/HashMap.ts.html), provide support for the `Equal` trait.

Let's take a closer look at how to use `HashSet` for value-based equality checks:

```ts twoslash
import { Data, HashSet } from 'effect';

const set = HashSet.empty().pipe(
  HashSet.add(Data.struct({ name: 'Alice', age: 30 })),
  HashSet.add(Data.struct({ name: 'Alice', age: 30 })),
);

console.log(HashSet.size(set)); // Output: 1
```

When you use the `HashSet`, it correctly handles value-based equality checks. In this example, even though you're adding two objects with the same values, the `HashSet` treats them as a single element.

**Note**: It's crucial to use elements that implement the `Equal` trait, either by implementing custom equality checks or by using the Data module. This ensures proper functionality when working with `HashSet`. Without this, you'll encounter the same behavior as the native `Set` data type:

```ts twoslash
import { HashSet } from 'effect';

const set = HashSet.empty().pipe(
  HashSet.add({ name: 'Alice', age: 30 }),
  HashSet.add({ name: 'Alice', age: 30 }),
);

console.log(HashSet.size(set)); // Output: 2
```

In this case, without using the Data module alongside `HashSet`, you'll experience the same behavior as the native `Set` data type. The set contains two elements because it checks for equality by reference, not by values.

When working with the `HashMap`, you have the advantage of comparing keys by their values instead of their references. This is particularly helpful in scenarios where you want to associate values with keys based on their content.

Let's explore this concept with a practical example:

```ts twoslash
import { Data, HashMap } from 'effect';

const map = HashMap.empty().pipe(
  HashMap.set(Data.struct({ name: 'Alice', age: 30 }), 1),
  HashMap.set(Data.struct({ name: 'Alice', age: 30 }), 2),
);

console.log(HashMap.size(map)); // Output: 1

console.log(HashMap.get(map, Data.struct({ name: 'Alice', age: 30 })));
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 2
}
*/
```

In this code snippet, we use the `HashMap` data structure to create a map where keys are objects created using `Data.struct`. These objects have the same values, which would typically result in multiple entries in a traditional JavaScript map.

However, with `HashMap`, the keys are compared by their values rather than their memory references. As a result, even though we add two objects with identical content as keys, the map correctly handles them as a single key-value pair.

To retrieve a value associated with a specific key, we can use `HashMap.get`. In this example, when we query the map with an object having the same values as the key, it returns the associated value, which is `2`.

# Traits

---

## title: Traitsexcerpt: Traitscollapsible: truebottomNavigation: childCards

# Hash

---

## title: Hashexcerpt: Hash trait documentationbottomNavigation: pagination

The `Hash` trait in Effect is closely tied to the [Equal](equal) trait and serves a supportive role in optimizing equality checks by providing a mechanism for hashing. Hashing is a crucial step in the efficient determination of equality between two values, particularly when used with data structures like hash tables.

## Role of Hash in Equality Checking

The main function of the `Hash` trait is to provide a quick and efficient way to determine if two values are definitely not equal, thereby complementing the [Equal](equal) trait. When two values implement the [Equal](equal) trait, their hash values (computed using the `Hash` trait) are compared first:

- **Different Hash Values**: If the hash values are different, it is guaranteed that the values themselves are different. This quick check allows the system to avoid a potentially expensive equality check.
- **Same Hash Values**: If the hash values are the same, it does not guarantee that the values are equal, only that they might be. In this case, a more thorough comparison using the [Equal](equal) trait is performed to determine actual equality.

This method dramatically speeds up the equality checking process, especially in collections where quick look-up and insertion times are crucial, such as in hash sets or hash maps.

## Practical Example and Explanation

Consider a scenario where you have a custom `Person` class, and you want to check if two instances are equal based on their properties.
By implementing both the `Equal` and `Hash` traits, you can efficiently manage these checks:

```ts twoslash
import { Equal, Hash } from 'effect';

class Person implements Equal.Equal {
  constructor(
    readonly id: number, // Unique identifier for each person
    readonly name: string,
    readonly age: number,
  ) {}

  // Defines equality based on id, name, and age
  [Equal.symbol](that: Equal.Equal): boolean {
    if (that instanceof Person) {
      return (
        Equal.equals(this.id, that.id) &&
        Equal.equals(this.name, that.name) &&
        Equal.equals(this.age, that.age)
      );
    }
    return false;
  }

  // Generates a hash code based primarily on the unique id
  [Hash.symbol](): number {
    return Hash.hash(this.id);
  }
}

const alice = new Person(1, 'Alice', 30);
console.log(Equal.equals(alice, new Person(1, 'Alice', 30))); // Output: true

const bob = new Person(2, 'Bob', 40);
console.log(Equal.equals(alice, bob)); // Output: false
```

In this code snippet:

- The `[Equal.symbol]` method determines equality by comparing the `id`, `name`, and `age` fields of `Person` instances. This approach ensures that the equality check is comprehensive and considers all relevant attributes.
- The `[Hash.symbol]` method computes a hash code using the `id` of the person. This value is used to quickly differentiate between instances in hashing operations, optimizing the performance of data structures that utilize hashing.
- The equality check returns `true` when comparing `alice` to a new `Person` object with identical property values and `false` when comparing `alice` to `bob` due to their differing property values.

# Effect vs fp-ts

---

## title: Effect vs fp-tsexcerpt: A detailed comparison of key features between the Effect and fp-ts libraries, including typed services, built-in services, error handling, pipeable APIs, dual APIs, testability, resource management, interruptions, defects, fiber-based concurrency, retry policies, logging, scheduling, caching, batching, metrics, tracing, configuration, immutable data structures, and stream processing.bottomNavigation: pagination

## FAQ

### Bundle Size Comparison Between Effect and fp-ts

**Q: I compared the bundle sizes of two simple programs using Effect and fp-ts. Why does Effect have a larger bundle size?**

A: It's natural to observe different bundle sizes because Effect and fp-ts are distinct systems designed for different purposes.
Effect's bundle size is larger due to its included fiber runtime, which is crucial for its functionality.
While the initial bundle size may seem large, the overhead amortizes as you use Effect.

**Q: Should I be concerned about the bundle size difference when choosing between Effect and fp-ts?**

A: Not necessarily. Consider the specific requirements and benefits of each library for your project.

## Comparison Table

The following table compares the features of the Effect and [fp-ts](https://github.com/gcanti/fp-ts) libraries.

| Feature                   | fp-ts | Effect |
| ------------------------- | ----- | ------ |
| Typed Services            | âŒ    | âœ…     |
| Built-in Services         | âŒ    | âœ…     |
| Typed errors              | âœ…    | âœ…     |
| Pipeable APIs             | âœ…    | âœ…     |
| Dual APIs                 | âŒ    | âœ…     |
| Testability               | âŒ    | âœ…     |
| Resource Management       | âŒ    | âœ…     |
| Interruptions             | âŒ    | âœ…     |
| Defects                   | âŒ    | âœ…     |
| Fiber-Based Concurrency   | âŒ    | âœ…     |
| Fiber Supervision         | âŒ    | âœ…     |
| Retry and Retry Policies  | âŒ    | âœ…     |
| Built-in Logging          | âŒ    | âœ…     |
| Built-in Scheduling       | âŒ    | âœ…     |
| Built-in Caching          | âŒ    | âœ…     |
| Built-in Batching         | âŒ    | âœ…     |
| Metrics                   | âŒ    | âœ…     |
| Tracing                   | âŒ    | âœ…     |
| Configuration             | âŒ    | âœ…     |
| Immutable Data Structures | âŒ    | âœ…     |
| Stream Processing         | âŒ    | âœ…     |

Here's an explanation of each feature:

### Typed Services

Both fp-ts and Effect libraries provide the ability to track requirements at the type level, allowing you to define and use services with specific types. In fp-ts, you can utilize the `Reader<R, E, A>` type, while in Effect, the `Effect<A, E, R>` type is available. It's important to note that in fp-ts, the `R` type parameter is contravariant, which means that there is no guarantee of avoiding conflicts, and the library offers only basic tools for dependency management.

On the other hand, in Effect, the `R` type parameter is covariant and all APIs have the ability to merge dependencies at the type level when multiple effects are involved. Effect also provides a range of specifically designed tools to simplify the management of dependencies, including `Tag`, `Context`, and `Layer`. These tools enhance the ease and flexibility of handling dependencies in your code, making it easier to compose and manage complex applications.

### Built-in Services

The Effect library has built-in services like `Clock`, `Random` and `Tracer`, while fp-ts does not provide any default services.

### Typed errors

Both libraries support typed errors, enabling you to define and handle errors with specific types. However, in Effect, all APIs have the ability to merge errors at the type-level when multiple effects are involved, and each effect can potentially fail with different types of errors.

This means that when combining multiple effects that can fail, the resulting type of the error will be a union of the individual error types. Effect provides utilities and type-level operations to handle and manage these merged error types effectively.

### Pipeable APIs

Both fp-ts and Effect libraries provide pipeable APIs, allowing you to compose and sequence operations in a functional and readable manner using the `pipe` function. However, Effect goes a step further and offers a `.pipe()` method on each data type, making it more convenient to work with pipelines without the need to explicitly import the `pipe` function every time.

### Dual APIs

Effect library provides dual APIs, allowing you to use the same API in different ways (e.g., "data-last" and "data-first" variants).

### Testability

The functional style of fp-ts generally promotes good testability of the code written using it, but the library itself does not provide dedicated tools specifically designed for the testing phase. On the other hand, Effect takes testability a step further by offering additional tools that are specifically tailored to simplify the testing process.

Effect provides a range of utilities that improve testability. For example, it offers the `TestClock` utility, which allows you to control the passage of time during tests. This is useful for testing time-dependent code. Additionally, Effect provides the `TestRandom` utility, which enables fully deterministic testing of code that involves randomness. This ensures consistent and predictable test results. Another helpful tool is `ConfigProvider.fromMap`, which makes it easy to define mock configurations for your application during testing.

### Resource Management

The Effect library provides built-in capabilities for resource management, while fp-ts has limited features in this area (mainly `bracket`) and they are less sophisticated.

In Effect, resource management refers to the ability to acquire and release resources, such as database connections, file handles, or network sockets, in a safe and controlled manner. The library offers comprehensive and refined mechanisms to handle resource acquisition and release, ensuring proper cleanup and preventing resource leaks.

### Interruptions

The Effect library supports interruptions, which means you can interrupt and cancel ongoing computations if needed. This feature gives you more control over the execution of your code and allows you to handle situations where you want to stop a computation before it completes.

In Effect, interruptions are useful in scenarios where you need to handle user cancellations, timeouts, or other external events that require stopping ongoing computations. You can explicitly request an interruption and the library will safely and efficiently halt the execution of the computation.

On the other hand, fp-ts does not have built-in support for interruptions. Once a computation starts in fp-ts, it will continue until it completes or encounters an error, without the ability to be interrupted midway.

### Defects

The Effect library provides mechanisms for handling defects and managing **unexpected** failures. In Effect, defects refer to unexpected errors or failures that can occur during the execution of a program.

With the Effect library, you have built-in tools and utilities to handle defects in a structured and reliable manner. It offers error handling capabilities that allow you to catch and handle exceptions, recover from failures, and gracefully handle unexpected scenarios.

On the other hand, fp-ts does not have built-in support specifically dedicated to managing defects. While you can handle errors using standard functional programming techniques in fp-ts, the Effect library provides a more comprehensive and streamlined approach to dealing with defects.

### Fiber-Based Concurrency

The Effect library leverages fiber-based concurrency, which enables lightweight and efficient concurrent computations. In simpler terms, fiber-based concurrency allows multiple tasks to run concurrently, making your code more responsive and efficient.

With fiber-based concurrency, the Effect library can handle concurrent operations in a way that is lightweight and doesn't block the execution of other tasks. This means that you can run multiple computations simultaneously, taking advantage of the available resources and maximizing performance.

On the other hand, fp-ts does not have built-in support for fiber-based concurrency. While fp-ts provides a rich set of functional programming features, it doesn't have the same level of support for concurrent computations as the Effect library.

### Fiber Supervision

Effect library provides supervision strategies for managing and monitoring fibers. fp-ts does not have built-in support for fiber supervision.

### Retry and Retry Policies

The Effect library includes built-in support for retrying computations with customizable retry policies. This feature is not available in fp-ts out of the box, and you would need to rely on external libraries to achieve similar functionality. However, it's important to note that the external libraries may not offer the same level of sophistication and fine-tuning as the built-in retry capabilities provided by the Effect library.

Retry functionality allows you to automatically retry a computation or action when it fails, based on a set of predefined rules or policies. This can be particularly useful in scenarios where you are working with unreliable or unpredictable resources, such as network requests or external services.

The Effect library provides a comprehensive set of retry policies that you can customize to fit your specific needs. These policies define the conditions for retrying a computation, such as the number of retries, the delay between retries, and the criteria for determining if a retry should be attempted.

By leveraging the built-in retry functionality in the Effect library, you can handle transient errors or temporary failures in a more robust and resilient manner. This can help improve the overall reliability and stability of your applications, especially in scenarios where you need to interact with external systems or services.

In contrast, fp-ts does not offer built-in support for retrying computations. If you require retry functionality in fp-ts, you would need to rely on external libraries, which may not provide the same level of sophistication and flexibility as the Effect library.

It's worth noting that the built-in retry capabilities of the Effect library are designed to work seamlessly with its other features, such as error handling and resource management. This integration allows for a more cohesive and comprehensive approach to handling failures and retries within your computations.

### Built-in Logging

The Effect library comes with built-in logging capabilities. This means that you can easily incorporate logging into your applications without the need for additional libraries or dependencies. In addition, the default logger provided by Effect can be replaced with a custom logger to suit your specific logging requirements.

Logging is an essential aspect of software development as it allows you to record and track important information during the execution of your code. It helps you monitor the behavior of your application, debug issues, and gather insights for analysis.

With the built-in logging capabilities of the Effect library, you can easily log messages, warnings, errors, or any other relevant information at various points in your code. This can be particularly useful for tracking the flow of execution, identifying potential issues, or capturing important events during the operation of your application.

On the other hand, fp-ts does not provide built-in logging capabilities. If you need logging functionality in fp-ts, you would need to rely on external libraries or implement your own logging solution from scratch. This can introduce additional complexity and dependencies into your codebase.

### Built-in Scheduling

The Effect library provides built-in scheduling capabilities, which allows you to manage the execution of computations over time. This feature is not available in fp-ts.

In many applications, it's common to have tasks or computations that need to be executed at specific intervals or scheduled for future execution. For example, you might want to perform periodic data updates, trigger notifications, or run background processes at specific times. This is where built-in scheduling comes in handy.

On the other hand, fp-ts does not have built-in scheduling capabilities. If you need to schedule tasks or manage timed computations in fp-ts, you would have to rely on external libraries or implement your own scheduling mechanisms, which can add complexity to your codebase.

### Built-in Caching

The Effect library provides built-in caching mechanisms, which enable you to cache the results of computations for improved performance. This feature is not available in fp-ts.

In many applications, computations can be time-consuming or resource-intensive, especially when dealing with complex operations or accessing remote resources. Caching is a technique used to store the results of computations so that they can be retrieved quickly without the need to recompute them every time.

With the built-in caching capabilities of the Effect library, you can easily cache the results of computations and reuse them when needed. This can significantly improve the performance of your application by avoiding redundant computations and reducing the load on external resources.

### Built-in Batching

The Effect library offers built-in batching capabilities, which enable you to combine multiple computations into a single batched computation. This feature is not available in fp-ts.

In many scenarios, you may need to perform multiple computations that share similar inputs or dependencies. Performing these computations individually can result in inefficiencies and increased overhead. Batching is a technique that allows you to group these computations together and execute them as a single batch, improving performance and reducing unnecessary processing.

### Metrics

The Effect library includes built-in support for collecting and reporting metrics related to computations and system behavior. It specifically supports [OpenTelemetry Metrics](https://opentelemetry.io/docs/specs/otel/metrics/). This feature is not available in fp-ts.

Metrics play a crucial role in understanding and monitoring the performance and behavior of your applications. They provide valuable insights into various aspects, such as response times, resource utilization, error rates, and more. By collecting and analyzing metrics, you can identify performance bottlenecks, optimize your code, and make informed decisions to improve your application's overall quality.

### Tracing

The Effect library has built-in tracing capabilities, which enable you to trace and debug the execution of your code and track the path of a request through an application. Additionally, Effect offers a dedicated [OpenTelemetry exporter](https://opentelemetry.io/docs/instrumentation/js/exporters/) for integrating with the OpenTelemetry observability framework. In contrast, fp-ts does not offer a similar tracing tool to enhance visibility into code execution.

### Configuration

The Effect library provides built-in support for managing and accessing configuration values within your computations. This feature is not available in fp-ts.

Configuration values are an essential aspect of software development. They allow you to customize the behavior of your applications without modifying the code. Examples of configuration values include database connection strings, API endpoints, feature flags, and various settings that can vary between environments or deployments.

With the Effect library's built-in support for configuration, you can easily manage and access these values within your computations. It provides convenient utilities and abstractions to load, validate, and access configuration values, ensuring that your application has the necessary settings it requires to function correctly.

By leveraging the built-in configuration support in the Effect library, you can:

- Load configuration values from various sources such as environment variables, configuration files, or remote configuration providers.
- Validate and ensure that the loaded configuration values adhere to the expected format and structure.
- Access the configuration values within your computations, allowing you to use them wherever necessary.

### Immutable Data Structures

The Effect library provides built-in support for immutable data structures such as `Chunk`, `HashSet`, and `HashMap`. These data structures ensure that once created, their values cannot be modified, promoting safer and more predictable code. In contrast, fp-ts does not have built-in support for such data structures and only provides modules that add additional APIs to standard data types like `Set` and `Map`.

Immutable data structures offer several benefits, including:

- Immutability: Immutable data structures cannot be changed after they are created. This property eliminates the risk of accidental modifications and enables safer concurrent programming.

- Predictability: With immutable data structures, you can rely on the fact that their values won't change unexpectedly. This predictability simplifies reasoning about code behavior and reduces bugs caused by mutable state.

- Sharing and Reusability: Immutable data structures can be safely shared between different parts of your program. Since they cannot be modified, you don't need to create defensive copies, resulting in more efficient memory usage and improved performance.

On the other hand, fp-ts does not have built-in support for these specific immutable data structures. Instead, it provides modules that extend the functionality of standard JavaScript data types like `Set` and `Map` with additional functional programming APIs. While these modules can be useful, they do not offer the same level of performance optimizations and specialized operations as the built-in immutable data structures provided by the Effect library.

### Stream Processing

The Effect ecosystem provides built-in support for stream processing, enabling you to work with streams of data. Stream processing is a powerful concept that allows you to efficiently process and transform continuous streams of data in a reactive and asynchronous manner. However, fp-ts does not have this feature built-in and relies on external libraries like RxJS to handle stream processing.

# API Reference

---

## title: API Referenceexcerpt: Explore the Effect library's API documentation, including core functionalities like effect, CLI, OpenTelemetry, platform, printer, and RPC. Delve into the schema package with getting started and API reference sections. Discover the typeclass module for comprehensive typeclass-related documentation.bottomNavigation: pagination

- [effect](https://effect-ts.github.io/effect/docs/effect)
- [@effect/cli](https://effect-ts.github.io/effect/docs/cli) ([Getting Started](https://github.com/Effect-TS/effect/blob/main/packages/cli/README.md))
- [@effect/opentelemetry](https://effect-ts.github.io/effect/docs/opentelemetry)
- [@effect/platform](https://effect-ts.github.io/effect/docs/platform) ([Getting Started](https://github.com/Effect-TS/effect/blob/main/packages/platform/README.md))
- [@effect/printer](https://effect-ts.github.io/effect/docs/printer) ([Getting Started](https://github.com/Effect-TS/effect/blob/main/packages/printer/README.md))
- [@effect/rpc](https://effect-ts.github.io/effect/docs/rpc)
- [@effect/schema](https://effect-ts.github.io/effect/docs/schema) ([Getting Started](https://github.com/Effect-TS/effect/blob/main/packages/schema/README.md))
- [@effect/typeclass](https://effect-ts.github.io/effect/docs/typeclass) ([Getting Started](https://github.com/Effect-TS/effect/blob/main/packages/typeclass/README.md))

# Equivalence

---

## title: Equivalenceexcerpt: Equivalence behaviour documentationbottomNavigation: pagination

**This page is a stub. Help us expand it by contributing!**

To contribute to the documentation, please join our Discord community at [the Docs channel](https://discord.com/channels/795981131316985866/848185224356691978) and let us know which part of the documentation you would like to contribute to. We appreciate your help in improving our library's documentation. Thank you!

# Higher-Kinded Types

---

## title: Higher-Kinded Typesexcerpt: Explore Higher-Kinded Types (HKTs) and their role in simplifying code and enhancing flexibility. Learn how to create generic structures for different data types, improving code organization and maintainability.bottomNavigation: pagination

Higher-Kinded Types (HKTs) might sound complex, but they are a valuable concept in programming that can simplify code and make it more flexible. In this article, we'll explore what HKTs are and why they are useful for developers, especially those who are just starting out.

## What Are Higher-Kinded Types?

At its core, a higher-kinded type is a type that abstracts over another type, which, in turn, abstracts over yet another type. In simpler terms, it allows us to create generic structures that can work with a wide range of data types. Think of it as a way to build reusable code that can adapt to different data structures.

### The Need for HKTs

To understand why HKTs are useful, let's consider a practical scenario. We often want to implement similar functionality across different data structures, like arrays, chunks, and options. Here are some functions as examples:

```ts twoslash
import { Chunk, Option } from 'effect';

declare const mapArray: <A, B>(self: Array<A>, f: (a: A) => B) => Array<B>;

declare const mapChunk: <A, B>(
  self: Chunk.Chunk<A>,
  f: (a: A) => B,
) => Chunk.Chunk<B>;

declare const mapOption: <A, B>(
  self: Option.Option<A>,
  f: (a: A) => B,
) => Option.Option<B>;
```

Notice that these functions share a lot of similarities; in fact, they are almost identical except for the data type they operate on (`Array`, `Chunk`, `Option`).

Now, imagine if we could define a common interface to describe this behavior. This would make our code more organized and easier to maintain. However, doing this in a straightforward way is not so obvious.

### The Ideal Solution

In an ideal world, we could create an interface like this:

```ts
interface Mappable<F<~>> {
  readonly map: <A, B>(self: F<A>, f: (a: A) => B) => F<B>
}
```

With this interface in place, we could do the following:

```ts
declare const mapArray: Mappable<Array>['map'];
declare const mapChunk: Mappable<Chunk>['map'];
declare const mapOption: Mappable<Option>['map'];
```

We could also define instances of this interface for different data types:

```ts
declare const ArrayMappable: Mappable<Array>;
declare const ChunkMappable: Mappable<Chunk>;
declare const OptionMappable: Mappable<Option>;
```

Additionally, we could create generic functions like `stringify`:

```ts
const stringify = <F>(T: Mappable<F>) => (self: F<number>): F<string> =>
  T.map(self, (n) => `number: ${n}`);
```

And use them like this:

```ts
const stringifiedArray: Array<string> = stringify(ArrayMappable)([0, 1, 2]);
```

### A Brief Terminology

Before we move on, let's clarify some terms:

- `F<~>` is known as a "higher-kinded type".
- The interface `Mappable<F<~>>` is referred to as a "type class".
- Values like `ArrayMappable` are "instances" of the `Mappable` type class.

Now, let's pause our dream scenario and acknowledge that `F<~>` is not valid TypeScript. However, we've grasped the concept of what we'd like to achieve.

In the following sections, we will delve into how HKTs are emulated in Effect. This process involves gradually constructing the essential components needed to work with higher-kinded types effectively.

## Type Lambdas

To work effectively with Higher-Kinded Types (HKTs), we need to first grasp the concept of "Type Lambdas." Type Lambdas are a way to define type-level functions in TypeScript, which are not natively supported by the language.

A Type Lambda, like `Target -> F<Target>`, essentially defines a function that operates on types and returns other types. Let's break down this concept:

```ts
Target -> Array<Target>
```

In this example, the Type Lambda maps the input type `Target` to the output type `Array<Target>`. It's like defining a rule that transforms one type into another.

Type Lambdas allow us to express Higher-Kinded Types directly without the need for complex type definitions.

### Implementing a Type Lambda

To implement a Type Lambda, we'll start by defining an interface that includes a `Target` field. Here's how it's done:

```twoslash include TypeLambda
export interface TypeLambda {
  readonly Target: unknown
}
```

```ts twoslash
// @include: TypeLambda
```

This simple interface sets the foundation for our Type Lambdas.

### Creating a Type Lambda

Let's create a specific Type Lambda for the `Array` data type:

```twoslash include ArrayTypeLambda
export interface ArrayTypeLambda extends TypeLambda {
  readonly type: Array<this["Target"]>
}
```

```ts twoslash
// @include: TypeLambda

// ---cut---
// @include: ArrayTypeLambda
```

Here, we extend the base `TypeLambda` interface to define an `ArrayTypeLambda`. This specific Type Lambda is tailored for working with arrays.

### Applying the Type Lambda

Now that we have our Type Lambda and its specialized version for arrays, we need a way to apply this type-level function to a concrete type `A`. We'll call this operator `Kind`:

```twoslash include Kind
export type Kind<F extends TypeLambda, Target> = F extends {
  readonly type: unknown
}
  ? // If F has a type property, it means it is a concrete type lambda (e.g., F = ArrayTypeLambda).
    // The intersection allows us to obtain the result of applying F to Target.
    (F & {
      readonly Target: Target
    })["type"]
  : // If F is generic, we must explicitly specify all of its type parameters
    // to ensure that none are omitted from type checking.
    {
      readonly F: F
      readonly Target: (_: Target) => Target // This enforces invariance.
    }
```

```ts twoslash
// @include: TypeLambda

// ---cut---
// @include: Kind
```

The `Kind` operator takes a Type Lambda `F` and a `Target` type. It ensures that `F` is a valid type lambda and then applies it to the `Target`. This allows us to obtain a type that represents the result of the Type Lambda operation.

Let's test our operator with some examples:

```ts twoslash
// @include: TypeLambda
// @include: Kind
// @include: ArrayTypeLambda

// ---cut---
// Applying ArrayTypeLambda to string
type Test1 = Kind<ArrayTypeLambda, string>;

// Applying ArrayTypeLambda to number
type Test2 = Kind<ArrayTypeLambda, number>;
```

Let's take a step further and define Type Lambdas for other data types, such as `Chunk` and `Option`:

```twoslash include ChunkTypeLambda
export interface ChunkTypeLambda extends TypeLambda {
  readonly type: Chunk.Chunk<this["Target"]>
}
```

```twoslash include OptionTypeLambda
export interface OptionTypeLambda extends TypeLambda {
  readonly type: Option.Option<this["Target"]>
}
```

```ts twoslash
// @include: TypeLambda
// @include: Kind

// ---cut---
import { Chunk, Option } from 'effect';

// @include: ChunkTypeLambda

// @include: OptionTypeLambda

type Test3 = Kind<ChunkTypeLambda, string>;

type Test4 = Kind<OptionTypeLambda, string>;
```

## Type Classes

We are now ready to define the `Mappable` type class, which we introduced earlier:

```twoslash include Mappable
export interface Mappable<F extends TypeLambda> {
  readonly map: <A, B>(self: Kind<F, A>, f: (a: A) => B) => Kind<F, B>
}
```

```ts twoslash
// @include: TypeLambda
// @include: Kind

// ---cut---
// @include: Mappable
```

In the code above, we define a `Mappable` type class. This type class provides a blueprint for creating functions that can map values from one type to another. It's a powerful tool for writing code that's both generic and flexible.

## Instances

To put our `Mappable` type class to use, we need to create instances for specific data types. These instances will allow us to perform mapping operations on those data types.

```twoslash include instances
import { Chunk, Option } from "effect"

export const MappableArray: Mappable<ArrayTypeLambda> = {
  map: (self, f) => self.map(f)
}

export const MappableChunk: Mappable<ChunkTypeLambda> = {
  map: Chunk.map
}

export const MappableOption: Mappable<OptionTypeLambda> = {
  map: Option.map
}
```

```ts twoslash
// @include: TypeLambda
// @include: Kind
// @include: ArrayTypeLambda
// @include: ChunkTypeLambda
// @include: OptionTypeLambda
// @include: Mappable

// ---cut---
// @include: instances
```

Here, we've created instances for `Array`, `Chunk`, and `Option` types. Each instance is equipped with a `map` function tailored to its respective data type.

Now, we can proceed to create our `stringify` function:

```twoslash include stringify
export const stringify =
  <F extends TypeLambda>(TC: Mappable<F>) =>
  (self: Kind<F, number>): Kind<F, string> =>
    TC.map(self, (n) => `number: ${n}`)
```

```ts twoslash
// @include: TypeLambda
// @include: Kind
// @include: Mappable

// ---cut---
// @include: stringify
```

To ensure that everything works as expected, let's run some tests:

```ts twoslash
// @include: TypeLambda
// @include: Kind
// @include: Mappable
// @include: ArrayTypeLambda
// @include: ChunkTypeLambda
// @include: OptionTypeLambda
// @include: instances
// @include: stringify

// ---cut---
const arrayTest = stringify(MappableArray)([1, 2, 3]);
console.log(arrayTest);
// [ 'number: 1', 'number: 2', 'number: 3' ]

const chunkTest = stringify(MappableChunk)(Chunk.fromIterable([1, 2, 3]));
console.log(chunkTest);
// { _id: 'Chunk', values: [ 'number: 1', 'number: 2', 'number: 3' ] }

const optionTest = stringify(MappableOption)(Option.some(1));
console.log(optionTest);
// { _id: 'Option', _tag: 'Some', value: 'number: 1' }
```

These tests demonstrate how our `Mappable` type class, `stringify` function, and type instances work together to consistently map values across different data types.

## Enhancements

In our current implementation, we've created a simplified version of what Effect provides. However, there is an important enhancement that we need to address. Specifically, we must accommodate more than one parameter, not just `Target`. For instance, certain data types, like `Either<A, E>` or `Effect<A, E, R>`, require two or more type parameters to function correctly.

In Effect, we have the capability to work with data types that can have up to four type parameters, each with distinct variance characteristics. These parameters are essential for defining the behavior and constraints of various data types within Effect. Let's take a closer look at these type parameters:

1. `In` (Contravariant): This type parameter is used for contravariant operations, which means that it accepts input types that are more general or broader than the original type.

2. `Out2` (Covariant): `Out2` represents a covariant type parameter. It allows for operations where the output type is more specific or narrower than the original type.

3. `Out1` (Covariant): Similar to `Out2`, `Out1` is a covariant type parameter, enabling operations that result in a more specific output type.

4. `Target` (Invariant): The `Target` type parameter remains invariant, meaning that it maintains the exact type as the original without any variation.

```twoslash include HKT
export interface TypeLambda {
  readonly In: unknown
  readonly Out2: unknown
  readonly Out1: unknown
  readonly Target: unknown
}

export type Kind<F extends TypeLambda, In, Out2, Out1, Target> = F extends {
  readonly type: unknown
}
  ? (F & {
      readonly In: In
      readonly Out2: Out2
      readonly Out1: Out1
      readonly Target: Target
    })["type"]
  : {
      readonly F: F
      readonly In: (_: In) => void // Contravariant
      readonly Out2: () => Out2 // Covariant
      readonly Out1: () => Out1 // Covariant
      readonly Target: (_: Target) => Target // Invariant
    }

export declare const URI: unique symbol

export interface TypeClass<F extends TypeLambda> {
  // To improve inference it is necessary to mention the F parameter inside it
  // otherwise it will be lost, we can do so by adding an optional property
  readonly [URI]?: F
}
```

```ts twoslash
// @include: HKT
```

Here's how to define a Type Lambda for the `Either` type:

```ts twoslash
// @filename: HKT.ts
// @include: HKT

// @filename: Either.ts
// ---cut---
import { TypeLambda } from './HKT';
import { Either } from 'effect';

export interface EitherTypeLambda extends TypeLambda {
  readonly type: Either.Either<this['Target'], this['Out1']>;
}
```

Please note that we are using the `Out1` parameter, which is covariant since the `E` type parameter of `Either<A, E>` is covariant.

And here's how to define the `Mappable` type class:

```ts twoslash
// @filename: HKT.ts
// @include: HKT

// @filename: Mappable.ts
// ---cut---
import { Kind, TypeClass, TypeLambda } from './HKT';

export interface Mappable<F extends TypeLambda> extends TypeClass<F> {
  readonly map: <R, O, E, A, B>(
    self: Kind<F, R, O, E, A>,
    f: (a: A) => B,
  ) => Kind<F, R, O, E, B>;
}
```

## Variance

You might be wondering about the purpose of the second branch of the conditional type in the `Kind` type.

This second branch serves to enforce something called "variance." To understand this concept, let's explore an example. Imagine we define a type class like this:

```twoslash include Zippable
import { Kind, TypeClass, TypeLambda } from "./HKT"

export interface Zippable<F extends TypeLambda> extends TypeClass<F> {
  readonly zip: <R1, O1, E1, A, R2, O2, E2, B>(
    first: Kind<F, R1, O1, E1, A>,
    second: Kind<F, R2, O2, E2, B>
  ) => Kind<F, R1 & R2, O1 | O2, E1 | E2, readonly [A, B]>
}
```

```ts twoslash
// @filename: HKT.ts
// @include: HKT

// @filename: Zippable.ts
// ---cut---
// @include: Zippable
```

Now, we derive a `pipe`-able version of `zip`:

```ts twoslash
// @filename: HKT.ts
// @include: HKT

// @filename: Zippable.ts
// @include: Zippable
// ---cut---
export const zip =
  <F extends TypeLambda>(Zippable: Zippable<F>) =>
  <R2, O2, E2, B>(that: Kind<F, R2, O2, E2, B>) =>
  <R1, O1, E1, A>(
    self: Kind<F, R1, O1, E1, A>,
  ): Kind<F, R1 & R2, O1 | O2, E1 | E2, readonly [A, B]> =>
    Zippable.zip(self, that);
```

However, let's assume that we make a mistake while typing the return type of `zip` by specifying `R1` instead of `R1 & R2`:

```diff
-  ): Kind<F, R1 & R2, O1 | O2, E1 | E2, readonly [A, B]> =>
+  ): Kind<F, R1, O1 | O2, E1 | E2, readonly [A, B]> =>
```

In this case, it will not type check, and you'll encounter the following error:

```
...
Types of property 'In' are incompatible.
  Type '(_: R1 & R2) => void' is not assignable to type '(_: R1) => void'.
    Types of parameters '_' and '_' are incompatible.
      Type 'R1' is not assignable to type 'R1 & R2'.ts(2322)
```

The second branch of the conditional type helps catch such type errors and ensures that the type parameters are correctly aligned, enforcing proper type checking.

Now, let's proceed to define an instance of `Zippable` for the `Either` type:

```ts twoslash
// @filename: HKT.ts
// @include: HKT

// @filename: Zippable.ts
// @include: Zippable

// @filename: Either.ts
// ---cut---
import { TypeLambda } from './HKT';
import { Either } from 'effect';
import { Zippable } from './Zippable';

export interface EitherTypeLambda extends TypeLambda {
  readonly type: Either.Either<this['Target'], this['Out1']>;
}

export const EitherZippable: Zippable<EitherTypeLambda> = {
  zip: (first, second) => {
    if (Either.isLeft(first)) {
      return Either.left(first.left);
    }
    if (Either.isLeft(second)) {
      return Either.left(second.left);
    }
    return Either.right([first.right, second.right]);
  },
};
```

If you hover over `EitherZippable.zip` you will notice that the return type is as follows:

```ts
Either<readonly [A, B], E1 | E2>;
```

This signifies that the system has correctly managed the covariance of the `E` type parameter by returning the union of possible errors: `E1 | E2`.

# Order

---

## title: Orderexcerpt: Explore the Order module in Effect, which provides a powerful interface for comparing and sorting values. Learn about built-in comparators for common data types, sorting arrays, deriving custom orders, combining orders, and additional useful functions for comparisons, finding minimum/maximum, clamping values, and checking value range.bottomNavigation: pagination

The Order module provides a way to compare values and determine their order.
It defines an interface `Order<A>` which represents a single function for comparing two values of type `A`.
The function returns `-1`, `0`, or `1`, indicating whether the first value is less than, equal to, or greater than the second value.

Here's the basic structure of an `Order`:

```ts
interface Order<A> {
  (first: A, second: A): -1 | 0 | 1;
}
```

## Using the Built-in Orders

The Order module comes with several built-in comparators for common data types:

- `string`: Used for comparing strings.
- `number`: Used for comparing numbers.
- `bigint`: Used for comparing big integers.
- `Date`: Used for comparing `Date`s.

Here's how you can use these comparators:

```ts twoslash
// @target: ES2020
import { Order } from 'effect';

console.log(Order.string('apple', 'banana'));
// Output: -1, as "apple" < "banana"
console.log(Order.number(1, 1));
// Output: 0, as 1 = 1
console.log(Order.bigint(2n, 1n));
// Output: 1, as 2n > 1n
```

## Sorting Arrays

Once you have your comparators, you can sort arrays. The Array module provides a handy function called `sort` that allows you to sort arrays without modifying the original array. Here's an example:

```ts twoslash
import { Array, Order } from 'effect';

const strings = ['b', 'a', 'd', 'c'];

const result = Array.sort(strings, Order.string);

console.log(strings);
console.log(result);
/*
Output:
[ 'b', 'a', 'd', 'c' ]
[ 'a', 'b', 'c', 'd' ]
*/
```

You can even use an `Order` as a comparator in JavaScript's native `Array.sort` method:

```ts twoslash
import { Order } from 'effect';

const strings = ['b', 'a', 'd', 'c'];

strings.sort(Order.string);

console.log(strings);
// Output: [ 'a', 'b', 'c', 'd' ]
```

Please note that when using `Array#sort`, you modify the original array. So, be cautious if you want to keep the original order. If you don't want to alter the original array, consider using `Array.sort` as shown earlier.

## Deriving Orders

Sometimes, when working with more complex data structures, you may need to create custom sorting rules.
The `Order` module allows you to do this by deriving a new `Order` from an existing one using the `Order.mapInput` function.

Imagine you have a list of `Person` objects, and you want to sort them by their names in ascending order.
To achieve this, you can create a custom `Order`.

Here's how you can do it:

```ts twoslash
import { Array, Order } from 'effect';

// Define the Person interface
interface Person {
  readonly name: string;
  readonly age: number;
}

// Create a custom sorting rule to sort Persons by their names in ascending order
const byName = Order.mapInput(Order.string, (person: Person) => person.name);
```

In this example, we first import the necessary modules and define the `Person` interface, representing our data structure.
Next, we create a custom sorting rule called `byName` using the `mapInput` function.

The `mapInput` function takes two arguments:

1. The existing sorting rule you want to use as a base (`Order.string` in this case, for comparing strings).
2. A function that extracts the value you want to use for sorting from your data structure (`person.name` in this case).

Once you have defined your custom sorting rule, you can apply it to sort a list of `Person` objects:

```ts twoslash
import { Array, Order } from 'effect';

interface Person {
  readonly name: string;
  readonly age: number;
}

const byName = Order.mapInput(Order.string, (person: Person) => person.name);

// ---cut---
const persons: ReadonlyArray<Person> = [
  { name: 'Charlie', age: 22 },
  { name: 'Alice', age: 25 },
  { name: 'Bob', age: 30 },
];

// Use your custom sorting rule to sort the persons array
const sortedPersons = Array.sort(persons, byName);

console.log(sortedPersons);
/*
Output:
[
  { name: 'Alice', age: 25 },
  { name: 'Bob', age: 30 },
  { name: 'Charlie', age: 22 }
]
*/
```

## Combining Orders

The Order module not only handles basic comparisons but also empowers you to create intricate sorting rules. This is especially valuable when you need to sort data based on multiple criteria or properties.

The `combine*` functions in the Order module enables you to merge two or more `Order` instances, resulting in a new `Order` that incorporates the combined sorting logic. Let's walk through an example to illustrate this concept.

Imagine you have a list of people, each represented by an object with a `name` and an `age`. You want to sort this list first by name and then, for individuals with the same name, by age.

Here's how you can achieve this using the Order module:

```ts twoslash
import { Array, Order } from 'effect';

// Define the structure of a person
interface Person {
  readonly name: string;
  readonly age: number;
}

// Create an Order to sort people by their names
const byName = Order.mapInput(Order.string, (person: Person) => person.name);

// Create an Order to sort people by their ages
const byAge = Order.mapInput(Order.number, (person: Person) => person.age);

// Combine the two Orders to create a complex sorting logic
const byNameAge = Order.combine(byName, byAge);

const result = Array.sort(
  [
    { name: 'Bob', age: 20 },
    { name: 'Alice', age: 18 },
    { name: 'Bob', age: 18 },
  ],
  byNameAge,
);

console.log(result);
/*
Output:
[
  { name: 'Alice', age: 18 }, <-- by name
  { name: 'Bob', age: 18 },   <-- by age
  { name: 'Bob', age: 20 }    <-- by age
]
*/
```

In the code above, we first create two separate `Order` instances: `byName` and `byAge`. These orders individually sort people by their names and ages, respectively.

Next, we use the `combine` function to merge these two orders into a single `byNameAge` order. This combined order first sorts people by name and then, for those with the same name, by age.

Finally, we apply this combined order to the array of people using `Array.sort`. The result is an array of people sorted according to the specified criteria.

## Additional Useful Functions

The Order module extends its functionality by providing additional functions for common operations. These functions make it easier to work with ordered values and perform various comparisons. Let's explore each of them:

### Reversing Order

The `Order.reverse` function does exactly what its name suggests; it reverses the order of comparison. If you have an `Order` that sorts values in ascending order, applying `reverse` will sort them in descending order.

```ts twoslash
import { Order } from 'effect';

const ascendingOrder = Order.number;
const descendingOrder = Order.reverse(ascendingOrder);

console.log(ascendingOrder(1, 3));
// Output: -1 (1 < 3 in ascending order)
console.log(descendingOrder(1, 3));
// Output: 1 (1 > 3 in descending order)
```

### Comparing Values

These functions allow you to perform simple comparisons between values:

- `lessThan`: Checks if one value is strictly less than another.
- `greaterThan`: Checks if one value is strictly greater than another.
- `lessThanOrEqualTo`: Checks if one value is less than or equal to another.
- `greaterThanOrEqualTo`: Checks if one value is greater than or equal to another.

```ts twoslash
import { Order } from 'effect';

console.log(Order.lessThan(Order.number)(1, 2));
// Output: true (1 < 2)
console.log(Order.greaterThan(Order.number)(5, 3));
// Output: true (5 > 3)
console.log(Order.lessThanOrEqualTo(Order.number)(2, 2));
// Output: true (2 <= 2)
console.log(Order.greaterThanOrEqualTo(Order.number)(4, 4));
// Output: true (4 >= 4)
```

### Finding Minimum and Maximum

The `min` and `max` functions return the minimum or maximum value between two values, considering the order. These functions are particularly useful when you want to determine the smallest or largest value among multiple options.

```ts twoslash
import { Order } from 'effect';

console.log(Order.min(Order.number)(3, 1));
// Output: 1 (1 is the minimum)
console.log(Order.max(Order.number)(5, 8));
// Output: 8 (8 is the maximum)
```

### Clamping Values

The `clamp` function ensures that a value stays within a specified range. It takes three arguments: the value you want to clamp, the minimum bound, and the maximum bound. If the value falls outside the range, it's adjusted to the nearest bound.

```ts twoslash
import { Order } from 'effect';

const clampedValue = Order.clamp(Order.number)(10, {
  minimum: 20,
  maximum: 30,
});

console.log(clampedValue);
// Output: 20 (10 is clamped to the nearest bound, which is 20)
```

### Checking Value Range

The `between` function checks if a value falls within a specified range, inclusively. It takes three arguments: the value you want to check, the minimum bound, and the maximum bound.

```ts twoslash
import { Order } from 'effect';

console.log(Order.between(Order.number)(15, { minimum: 10, maximum: 20 }));
// Output: true (15 is within the range [10, 20])
console.log(Order.between(Order.number)(5, { minimum: 10, maximum: 20 }));
// Output: false (5 is outside the range [10, 20])
```

# Behaviours

---

## title: Behavioursexcerpt: Behaviourscollapsible: truebottomNavigation: childCards

# What is Dependency Injection?

---

## title: What is Dependency Injection?excerpt: Understand the Dependency Injection design pattern in software development, fostering loose coupling by passing dependencies externally. Learn its benefits, illustration of problems, and solutions through decoupling the dependency graph and using service interfaces.bottomNavigation: pagination

Dependency injection is a design pattern used in software development that helps manage the dependencies between different components of an application. It allows developers to create loosely coupled code by passing dependencies to a class or function from an external source.

In simpler terms, instead of creating dependencies inside a component, dependency injection enables us to provide them from the outside, making code more flexible and easier to test and maintain. By using dependency injection, developers can easily swap out dependencies or change their behavior without modifying the component's code directly.

## Illustrating the Problem

Let's assume we have a `Mailer` service which depends upon the functionality provided by a `Logger` service.

```ts twoslash
export class Logger {
  log(message: string): void {
    console.log(message);
  }
}

export class Mailer {
  logger = new Logger();
  sendMail(address: string, message: string): void {
    this.logger.log(`Sending the message ${message} to ${address}`);
  }
}
```

In the code above, we directly construct a `Logger` within our `Mailer` service. This tight coupling between the `Logger` and `Mailer` services introduces several problems:

1. Developers using the `Mailer` service have no control over how the `Logger` is constructed
2. Alternate implementations of the `Logger` service (e.g. for testing) cannot be provided
3. Changes to the `Logger` service may necessitate changes to the `Mailer` service

However, by making use of dependency injection we can decouple our `Mailer` and `Logger` services and solve the problems outlined above.

## Decoupling the Dependency Graph

The first step to solving the problems outlined above is to decouple the construction of the `Mailer` and `Logger` services from one another.

```ts twoslash
export class Logger {
  log(message: string): void {
    console.log(message);
  }
}

export class Mailer {
  constructor(readonly logger: Logger) {}
  sendMail(address: string, message: string): void {
    this.logger.log(`Sending the message ${message} to ${address}`);
  }
}

const logger = new Logger();
const mailer = new Mailer(logger);
```

Now instead of constructing the `Logger` service within the `Mailer` service, we construct the `Logger` externally and pass it to the constructor of the `Mailer` service.

<Idea>
  This pattern of inverting control of a service to the user is commonly known
  in software engineering as [_Inversion of
  Control_](https://en.wikipedia.org/wiki/Inversion_of_control).
</Idea>

This gives the developer much more control over how the dependencies within their application are constructed and composed together into a dependency graph.

## Using Service Interfaces

Though we have improved the coupling between our `Mailer` and `Logger` services in the example above, there is still a problem with our code - we can only have a single implementation of our `Mailer` and `Logger` services.

But what if we want to provide a different implementation of `Logger` to the `Mailer` service when we are running our application's test suite?

We can take things a step further and allow for multiple implementations of our services by decoupling the _interface_ of our services from the _implementation_ of the service.

<Steps>
### Define the interface of our services

First, we define the _interface_, or _behavior_, that our services should expose:

```ts twoslash
export interface Logger {
  log(message: string): void;
}

export interface Mailer {
  sendMail(address: string, message: string): void;
}
```

### Create concrete service implementations

Then, we bind the actual implementation of these services to the interfaces we have defined:

```ts twoslash
export interface Logger {
  log(message: string): void;
}

export interface Mailer {
  sendMail(address: string, message: string): void;
}

// ---cut---
class ConsoleLogger implements Logger {
  log(message: string): void {
    console.log(message);
  }
}

class ConsoleMailer implements Mailer {
  constructor(readonly logger: Logger) {}
  sendMail(address: string, message: string): void {
    this.logger.log(`Sending the message ${message} to ${address}`);
  }
}

const logger = new ConsoleLogger();
const mailer = new ConsoleMailer(logger);
```

### Providing other service implementations

Now, as long as we adhere to the interface specified by our services, we can easily create alternate implementations.

For example, we can create mock implementations of the `Logger` and `Mailer` services to use in our tests which internally track all messages logged and sent by the services:

```ts twoslash
export interface Logger {
  log(message: string): void;
}

export interface Mailer {
  sendMail(address: string, message: string): void;
}

// ---cut---
class MockLogger implements Logger {
  readonly messages: Array<string> = [];
  log(message: string): void {
    this.messages.push(message);
  }
}

class MockMailer implements Mailer {
  readonly sentMail: Array<string> = [];
  constructor(readonly logger: Logger) {}
  sendMail(address: string, message: string): void {
    const email = `Sending the message ${message} to ${address}`;
    this.logger.log(email);
    this.sentMail.push(email);
  }
}

const mockLogger = new MockLogger();
const mockMailer = new MockMailer(mockLogger);
```

</Steps>

# Concepts

---

## title: Conceptsexcerpt: ConceptsbottomNavigation: childCards

# Immutability

---

## title: Immutabilityexcerpt: Explore the importance and benefits of immutability in programming, providing enhanced code reliability and maintainability. Learn key concepts and practices to incorporate immutability into your projects.bottomNavigation: pagination

<Stub />

# Integrations

---

## title: Integrationsexcerpt: IntegrationsbottomNavigation: childCards

# Express Integration

---

## title: Express IntegrationnavTitle: Expressexcerpt: Explore integrating Effect with Express, a popular Node.js web framework. Learn to create a simple Express server with "Hello World!" response and understand basic routing with Effect and Express. Follow the guide to set up, run, and breakdown the provided examples.bottomNavigation: pagination

In this guide, we'll explore how to integrate Effect with [Express](https://expressjs.com/), a popular web framework for Node.js.

## Hello World Example

Let's start with a simple example that creates an Express server responding with "Hello World!" for requests to the root URL (/).
This mirrors the classic ["Hello world example"](https://expressjs.com/en/starter/hello-world.html) found in the Express documentation.

### Setup Steps

1. Create a new directory for your project and navigate to it using your terminal:

   ```bash filename="Terminal"
   mkdir express-effect-integration
   cd express-effect-integration
   ```

2. Initialize your project with npm. This will create a `package.json` file:

   ```bash filename="Terminal"
   npm init -y
   ```

3. Install the necessary dependencies:

   ```bash filename="Terminal"
   npm install effect express
   ```

   Install the necessary dev dependencies:

   ```bash filename="Terminal"
   npm install typescript @types/express --save-dev
   ```

   Now, initialize TypeScript:

   ```bash filename="Terminal"
   npx tsc --init
   ```

4. Create a new file, for example, `hello-world.ts`, and add the following code:

   ```ts filename="hello-world.ts" twoslash
   import { Context, Effect, Layer, Runtime } from 'effect';
   import express from 'express';

   // Define Express as a service
   class Express extends Context.Tag('Express')<
     Express,
     ReturnType<typeof express>
   >() {}

   // Define the main route, IndexRouteLive, as a Layer
   const IndexRouteLive = Layer.effectDiscard(
     Effect.gen(function* () {
       const app = yield* Express;
       const runFork = Runtime.runFork(yield* Effect.runtime<never>());

       app.get('/', (_, res) => {
         runFork(Effect.sync(() => res.send('Hello World!')));
       });
     }),
   );

   // Server Setup
   const ServerLive = Layer.scopedDiscard(
     Effect.gen(function* () {
       const port = 3001;
       const app = yield* Express;
       yield* Effect.acquireRelease(
         Effect.sync(() =>
           app.listen(
             port,
             () => console.log(`Example app listening on port ${port}`),
           )
         ),
         (server) => Effect.sync(() => server.close()),
       );
     }),
   );

   // Setting Up Express
   const ExpressLive = Layer.sync(Express, () => express());

   // Combine the layers
   const AppLive = ServerLive.pipe(
     Layer.provide(IndexRouteLive),
     Layer.provide(ExpressLive),
   );

   // Run the program
   Effect.runFork(Layer.launch(AppLive));
   ```

5. Run your Express server. Here we are using [ts-node](https://github.com/TypeStrong/ts-node) to run the `hello-world.ts` file in the terminal:

   ```bash filename="Terminal"
   npx ts-node hello-world.ts
   ```

   Visit [http://localhost:3001](http://localhost:3001) in your web browser, and you should see "Hello World!".

### Code Breakdown

Here's a breakdown of what's happening:

- **Express Service**. We define an `Express` [service](../guides/context-management/services) to retrieve the Express app later on.

  ```ts
  // Define Express as a service
  class Express extends Context.Tag('Express')<
    Express,
    ReturnType<typeof express>
  >() {}
  ```

- **Main Route**. The main route, `IndexRouteLive`, is defined as a [Layer](../guides/context-management/layers).

  ```ts
  // Define the main route, IndexRouteLive, as a Layer
  const IndexRouteLive = Layer.effectDiscard(
    Effect.gen(function* () {
      const app = yield* Express;
      const runFork = Runtime.runFork(yield* Effect.runtime<never>());

      app.get('/', (_, res) => {
        runFork(Effect.sync(() => res.send('Hello World!')));
      });
    }),
  );
  ```

  We access the [runtime](../guides/runtime) (`Effect.runtime`), which can be used to execute tasks within our route (`runFork`).
  Since we don't need to produce any service in the output, we use `Layer.effectDiscard` to discard its output.

- **Server Setup**. The server is created in a layer (`ServerLive`) and mounted at the end of our program.

  ```ts
  // Server Setup
  const ServerLive = Layer.scopedDiscard(
    Effect.gen(function* () {
      const port = 3001;
      const app = yield* Express;
      yield* Effect.acquireRelease(
        Effect.sync(() =>
          app.listen(
            port,
            () => console.log(`Example app listening on port ${port}`),
          )
        ),
        (server) => Effect.sync(() => server.close()),
      );
    }),
  );
  ```

  We use [Effect.acquireRelease](../guides/resource-management/scope#defining-resources) to create the server, allowing automatic management of the [scope](../guides/resource-management/scope#scope).
  Again, as we don't need to produce any service in the output, we use `Layer.scopedDiscard` to discard its output.

- **Mounting**. Finally, we mount the server by adding our route

  ```ts {1}
  const AppLive = ServerLive.pipe(
    Layer.provide(IndexRouteLive),
    Layer.provide(ExpressLive),
  );
  ```

  and providing the necessary dependency to the Express app

  ```ts {0,5}
  const ExpressLive = Layer.sync(Express, () => express());

  // Combine the layers
  const AppLive = ServerLive.pipe(
    Layer.provide(IndexRouteLive),
    Layer.provide(ExpressLive),
  );
  ```

## Basic routing

In this example, we'll explore the basics of routing with Effect and Express. The goal is to create a simple web server with two routes: one that returns all todos and another that returns a todo by its ID.

```ts filename="basic-routing.ts"
import { Context, Effect, FiberSet, Layer } from 'effect';
import express from 'express';

//
// Express
//
// NB: this is an example of an integration to a third party lib, not the suggested way of integrating express
//

// Define Express as a service
class Express extends Context.Tag('Express')<
  Express,
  ReturnType<typeof express>
>() {}

const get = <A, E, R>(
  path: string,
  body: (
    req: express.Request,
    res: express.Response,
  ) => Effect.Effect<A, E, R>,
) =>
  Effect.gen(function* () {
    const app = yield* Express;
    const run = yield* FiberSet.makeRuntime<R>();
    app.get(path, (req, res) => run(body(req, res)));
  });

// Server Setup
const ServerLive = Layer.scopedDiscard(
  Effect.gen(function* () {
    const port = 3001;
    const app = yield* Express;
    yield* Effect.acquireRelease(
      Effect.sync(() =>
        app.listen(
          port,
          () => console.log(`Example app listening on port ${port}`),
        )
      ),
      (server) => Effect.sync(() => server.close()),
    );
  }),
);

// Setting Up Express
const ExpressLive = Layer.sync(Express, () => express());

//
// Domain
//

interface Todo {
  readonly id: number;
  readonly title: string;
  readonly completed: boolean;
}

// Define the repository as a service
class TodoRepository extends Context.Tag('TodoRepository')<
  TodoRepository,
  {
    readonly getTodos: Effect.Effect<Array<Todo>>;
    readonly getTodo: (id: number) => Effect.Effect<Todo | null>;
  }
>() {}

//
// App
//

// Define a main route that returns all Todos
const IndexRouteLive = Layer.scopedDiscard(
  Effect.gen(function* () {
    const repo = yield* TodoRepository;

    yield* get('/', (_, res) =>
      Effect.gen(function* () {
        const todos = yield* repo.getTodos;
        res.json(todos);
      }));
  }),
);

// Define a route that returns a Todo by its ID
const TodoByIdRouteLive = Layer.scopedDiscard(
  Effect.gen(function* () {
    const repo = yield* TodoRepository;

    yield* get('/todo/:id', (req, res) =>
      Effect.gen(function* () {
        const id = req.params.id;
        const todo = yield* repo.getTodo(Number(id));
        res.json(todo);
      }));
  }),
);

// Merge routes into a single layer
const RouterLive = Layer.mergeAll(IndexRouteLive, TodoByIdRouteLive);

// Combine all layers to create the final application layer
const AppLive = ServerLive.pipe(
  Layer.provide(RouterLive),
  Layer.provide(ExpressLive),
);

// Test Data for TodoRepository
const testData = [
  {
    id: 1,
    title: 'delectus aut autem',
    completed: false,
  },
  {
    id: 2,
    title: 'quis ut nam facilis et officia qui',
    completed: false,
  },
  {
    id: 3,
    title: 'fugiat veniam minus',
    completed: false,
  },
];

// Create a layer with test data
const TodoRepositoryTest = Layer.succeed(TodoRepository, {
  getTodos: Effect.succeed(testData),
  getTodo: (id) =>
    Effect.succeed(testData.find((todo) => todo.id === id) || null),
});

const Test = AppLive.pipe(Layer.provide(TodoRepositoryTest));

Effect.runFork(Layer.launch(Test));
```

# Quickstart

---

## title: Quickstartexcerpt: Learn how to set up a new Effect project from scratch in TypeScript, covering Node.js, Deno, Bun, and Vite + React environments. Follow step-by-step instructions for each platform to create a basic program using the Effect library.bottomNavigation: pagination

In this tutorial, we will guide you through the process of setting up a new Effect project from scratch using plain **TypeScript 5.4 or newer**.

<Tabs items={["Node.js", "Deno", "Bun", "Vite + React"]}>
<Tab>

Follow these steps to create a new Effect project for **Node.js**:

1. As a first step, create a project directory and navigate into it:

   ```bash filename="Terminal"
   mkdir hello-effect
   cd hello-effect
   ```

2. Next, initialize a TypeScript project using npm (make sure you have TypeScript 5.0 or newer):

   ```bash filename="Terminal"
   npm init -y
   npm install typescript --save-dev
   ```

   This creates a `package.json` file with an initial setup for your TypeScript project.

3. Now, initialize TypeScript:

   ```bash filename="Terminal"
   npx tsc --init
   ```

   When running this command, it will generate a `tsconfig.json` file that contains configuration options for TypeScript. One of the most important options to consider is the `strict` flag.

   Make sure to open the `tsconfig.json` file and verify that the value of the `strict` option is set to `true`.

   ```json filename="tsconfig.json"
   {
     "compilerOptions": {
       "strict": true
     }
   }
   ```

4. Then, install the necessary package as dependency:

   ```bash filename="Terminal"
   npm install effect
   ```

   This package will provide the foundational functionality for your Effect project.

Let's write and run a simple program to ensure that everything is set up correctly.

In your terminal, execute the following commands:

```bash filename="Terminal"
mkdir src
touch src/index.ts
```

Open the `index.ts` file and add the following code:

```ts filename="src/index.ts"
import { Console, Effect } from 'effect';

const program = Console.log('Hello, World!');

Effect.runSync(program);
```

Run the `index.ts` file. Here we are using [ts-node](https://github.com/TypeStrong/ts-node) to run the `index.ts` file in the terminal:

```bash filename="Terminal"
npx ts-node src/index.ts
```

You should see the message `"Hello, World!"` printed. This confirms that the program is working correctly.

</Tab>
<Tab>

Follow these steps to create a new Effect project for **Deno**:

1. As a first step, create a project directory and navigate into it:

   ```bash filename="Terminal"
   mkdir hello-effect
   cd hello-effect
   ```

2. Next, initialize Deno:

   ```bash filename="Terminal"
   deno init
   ```

Let's write and run a simple program to ensure that everything is set up correctly.

Open the `main.ts` file and replace the content with the following code:

```ts filename="main.ts"
import { Console, Effect } from 'npm:effect';

const program = Console.log('Hello, World!');

Effect.runSync(program);
```

Run the `main.ts` file:

```bash filename="Terminal"
deno run main.ts
```

You should see the message `"Hello, World!"` printed. This confirms that the program is working correctly.

</Tab>
<Tab>

Follow these steps to create a new Effect project for **Bun**:

1. As a first step, create a project directory and navigate into it:

   ```bash filename="Terminal"
   mkdir hello-effect
   cd hello-effect
   ```

2. Next, initialize Bun:

   ```bash filename="Terminal"
   bun init
   ```

   When running this command, it will generate a `tsconfig.json` file that contains configuration options for TypeScript. One of the most important options to consider is the `strict` flag.

   Make sure to open the `tsconfig.json` file and verify that the value of the `strict` option is set to `true`.

   ```json filename="tsconfig.json"
   {
     "compilerOptions": {
       "strict": true
     }
   }
   ```

3. Then, install the necessary package as dependency:

   ```bash filename="Terminal"
   bun add effect
   ```

   This package will provide the foundational functionality for your Effect project.

Let's write and run a simple program to ensure that everything is set up correctly.

Open the `index.ts` file and replace the content with the following code:

```ts filename="index.ts"
import { Console, Effect } from 'effect';

const program = Console.log('Hello, World!');

Effect.runSync(program);
```

Run the `index.ts` file:

```bash filename="Terminal"
bun index.ts
```

You should see the message `"Hello, World!"` printed. This confirms that the program is working correctly.

</Tab>
<Tab>

Follow these steps to create a new Effect project for **Vite + React**:

1. Scaffold your Vite project, open your terminal and run the following command:

   ```bash filename="Terminal"
   # npm 6.x
   npm create vite@latest hello-effect --template react-ts

   # npm 7+, extra double-dash is needed:
   npm create vite@latest hello-effect -- --template react-ts
   ```

   This command will create a new Vite project with React and TypeScript template.

2. Navigate into the newly created project directory and install the required packages:

   ```bash filename="Terminal"
   cd hello-effect
   npm install
   ```

   Once the packages are installed, open the `tsconfig.json` file and ensure that the value of the `strict` option is set to true.

   ```json filename="tsconfig.json"
   {
     "compilerOptions": {
       "strict": true
     }
   }
   ```

3. Then, install the necessary `effect` package as a dependency:

   ```bash filename="Terminal"
   npm install effect
   ```

   The `effect` package will provide the foundational functionality for your Effect project.

Now, let's write and run a simple program to ensure that everything is set up correctly.

Open the `src/App.tsx` file and replace its content with the following code:

```tsx {1,5,10-16,30}
import { useCallback, useMemo, useState } from 'react';
import reactLogo from './assets/react.svg';
import viteLogo from '/vite.svg';
import './App.css';
import { Effect } from 'effect';

function App() {
  const [count, setCount] = useState(0);

  // Effect<void>
  const task = useMemo(
    () => Effect.sync(() => setCount((current) => current + 1)),
    [setCount],
  );

  const increment = useCallback(() => Effect.runSync(task), [task]);

  return (
    <>
      <div>
        <a href='https://vitejs.dev' target='_blank'>
          <img src={viteLogo} className='logo' alt='Vite logo' />
        </a>
        <a href='https://react.dev' target='_blank'>
          <img src={reactLogo} className='logo react' alt='React logo' />
        </a>
      </div>
      <h1>Vite + React</h1>
      <div className='card'>
        <button onClick={increment}>count is {count}</button>
        <p>
          Edit <code>src/App.tsx</code> and save to test HMR
        </p>
      </div>
      <p className='read-the-docs'>
        Click on the Vite and React logos to learn more
      </p>
    </>
  );
}

export default App;
```

After making these changes, start the development server by running the following command:

```bash filename="Terminal"
npm run dev
```

Then, press **o** to open the application in your browser.

When you click the button, you should see the counter increment. This confirms that the program is working correctly.

</Tab>

</Tabs>

# Why Effect?

---

## title: Why Effect?excerpt: Effect presents a new way of thinking about programming in TypeScript, offering an ecosystem of tools to build better applications and libraries. Learn how to leverage the TypeScript type system to enhance reliability and maintainability.bottomNavigation: pagination

## Motivation

Programming is challenging. When we build libraries and apps, we look to many tools to handle the complexity and make our day-to-day more manageable. Effect presents a new way of thinking about programming in TypeScript.

Effect is an ecosystem of tools that help you build better applications and libraries. As a result, you will also learn more about the TypeScript language and how to use the type system to make your programs more reliable and easier to maintain.

In "typical" TypeScript, without Effect, we write code that assumes that a function is either successful or throws an exception. Take this trivial example of division:

```ts twoslash
const divide = (a: number, b: number): number => {
  if (b === 0) {
    throw new Error('Cannot divide by zero');
  }
  return a / b;
};
```

Based on the types, we have no idea that this function can throw an exception. We can only find out by reading the code. This may not seem like much of a problem when you only have one function in your codebase, but when you have hundreds or thousands, it really starts to add up. It's easy to forget that a function can throw an exception, and it's easy to forget to handle that exception.

Often, we will do the "easiest" thing and just wrap the function in a `try/catch` block. This is a good first step to prevent your program from crashing, but it doesn't make it any easier to manage or understand our complex application/library. We can do better.

One of the most important tools we have in TypeScript is the compiler. It is the first line of defense against bugs, domain errors, and general complexity.

## The Effect Pattern

While Effect is a vast ecosystem of many different tools, if it had to be reduced down to just one idea, it would be the following:

Effect's major unique insight is that we can use the type system to track _errors_ and _"context"_ (more on this later), not only _success_ values as shown in the divide example above.

Here's the same divide function from above, but with the Effect pattern:

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number, Error, never> =>
  b === 0
    ? Effect.fail(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);
```

Notice how looking at the type signature tells you exactly what success value(s) it returns (`number`), what error(s) it can throw (`Error`) and what context the function needs (`never`, as in, no context required here). This function no longer throws an exception, and you can cleanly pass on the error to the caller of this function.

Errors now become values, just like your success values. Effect gives us many functions to make managing errors and success values ergonomic.

Additionally, tracking context allows you to provide additional information to your functions without having to pass in everything as an argument. For example, you can swap out implementations of live external services with mocks during your tests without changing any core business logic. There are many other use cases for context as well.

## Effect's Ecosystem

It turns out that this unique insight, along with a lot of other tooling, has led to a rich ecosystem of libraries that make building complex applications in TypeScript a breeze. Things that used to seem impossible are now ordinary. Effect's ecosystem is growing rapidly, and you can find the growing list on Effect's [GitHub](https://github.com/Effect-TS).

## Don't Re-Invent the Wheel

Application code in TypeScript often solves the same problems over and over again. Interacting with external services, filesystems, databases, etc. are common problems for all application developers. Effect provides a rich ecosystem of libraries that provide standardized solutions to many of these problems. You can use these libraries to build your application, or you can use them to build your own libraries.

Managing challenges like error handling, debugging, tracing, async/promises, retries, streaming, concurrency, caching, resource management, and a lot more are made manageable with Effect. You don't have to re-invent the solutions to these problems, or install tons of dependencies. Effect, under one umbrella, solves many of the problems that you would usually install many different dependencies with different APIs to solve.

## Solving Practical Problems

Effect is heavily inspired by great work done in other languages, like Scala and Haskell. However, it's important to understand that Effect's goal is to be a practical toolkit, and it goes to great lengths to solve real, everyday problems that developers face when building applications and libraries in TypeScript.

## Enjoy Building and Learning

Learning Effect is a lot of fun. Many developers in the Effect ecosystem are using Effect to solve real problems in their day-to-day work, and also experiment with cutting edge ideas for pushing TypeScript to be the most useful language it can be.

You don't have to use all aspects of Effect at once, and can start with the pieces of the ecosystem that make the most sense for the problems you are solving. Effect is a toolkit, and you can pick and choose the pieces that make the most sense for your use case. However, as more and more of your codebase is using Effect, you will probably find yourself wanting to utilize more of the ecosystem!

Effect's concepts may be new to you, and might not completely make sense at first. This is totally normal. Take your time with reading the docs and try to understand the core concepts - this will really pay off later on as you get into the more advanced tooling in the Effect ecosystem. The Effect community is always happy to help you learn and grow. Feel free to hop into our [Discord](https://discord.gg/effect-ts) or discuss on [GitHub](https://github.com/Effect-TS)! We are open to feedback and contributions, and are always looking for ways to improve Effect.

# Welcome to Effect

---

## title: Welcome to EffectnavTitle: Introductionexcerpt: Effect is a powerful TypeScript library designed to help developers easily create complex, synchronous, and asynchronous programs.bottomNavigation: pagination

Welcome to the Effect documentation!

## What is Effect?

Effect is a powerful TypeScript library designed to help developers
easily create complex, synchronous, and asynchronous programs.

## Main Features

Some of the main Effect features include:

| **Feature**         | **Description**                                                                                                    |
| ------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **Concurrency**     | Achieve highly-scalable, ultra low-latency applications through Effect's fiber-based concurrency model.            |
| **Composability**   | Construct highly maintainable, readable, and flexible software through the use of small, reusable building blocks. |
| **Resource Safety** | Safely manage acquisition and release of resources, even when your program fails.                                  |
| **Type Safety**     | Leverage the TypeScript type system to the fullest with Effect's focus on type inference and type safety.          |
| **Error Handling**  | Handle errors in a structured and reliable manner using Effect's built-in error handling capabilities.             |
| **Asynchronicity**  | Write code that looks the same, whether it is synchronous or asynchronous.                                         |
| **Observability**   | With full tracing capabilities, you can easily debug and monitor the execution of your Effect program.             |

## How to Use These Docs

The documentation is structured in a sequential manner, starting from the basics and progressing to more advanced topics. This allows you to follow along step-by-step as you build your Effect application. However, you have the flexibility to read the documentation in any order or jump directly to the pages that are relevant to your specific use case.

To facilitate navigation within a page, you will find a table of contents on the right side of the screen. This allows you to easily jump between different sections of the page.

## Join our Community

If you have questions about anything related to Effect,
you're always welcome to ask our community on [Discord](https://discord.gg/effect-ts).

# Branded Types

---

## title: Branded Typesexcerpt: Explore the concept of branded types in TypeScript using the Brand module. Understand the "data-last" and "data-first" variants, and learn to create branded types with runtime validation (refined) and without checks (nominal). Discover how to use and combine branded types to enforce type safety in your code.bottomNavigation: pagination

In this guide, we will explore the concept of **branded types** in TypeScript and learn how to create and work with them using the Brand module.
Branded types are TypeScript types with an added type tag that helps prevent accidental usage of a value in the wrong context.
They allow us to create distinct types based on an existing underlying type, enabling type safety and better code organization.

## The Problem with TypeScript's Structural Typing

TypeScript's type system is structurally typed, meaning that two types are considered compatible if their members are compatible.
This can lead to situations where values of the same underlying type are used interchangeably, even when they represent different concepts or have different meanings.

Consider the following types:

```ts twoslash
type UserId = number;

type ProductId = number;
```

Here, `UserId` and `ProductId` are structurally identical as they are both based on `number`.
TypeScript will treat these as interchangeable, potentially causing bugs if they are mixed up in your application.

For example:

```ts twoslash
type UserId = number;

type ProductId = number;

const getUserById = (id: UserId) => {
  // Logic to retrieve user
};

const getProductById = (id: ProductId) => {
  // Logic to retrieve product
};

const id: UserId = 1;

getProductById(id); // No type error, but this is incorrect usage
```

In the example above, passing a `UserId` to `getProductById` should ideally throw a type error, but it doesn't due to structural compatibility.

## How Branded Types Help

Branded types allow you to create distinct types from the same underlying type by adding a unique type tag, enforcing proper usage at compile-time.

Branding is accomplished by adding a symbolic identifier that distinguishes one type from another at the type level.
This method ensures that types remain distinct without altering their runtime characteristics.

Let's start by introducing the `BrandTypeId` symbol:

```ts twoslash
const BrandTypeId: unique symbol = Symbol.for('effect/Brand');

type ProductId = number & {
  readonly [BrandTypeId]: {
    readonly ProductId: 'ProductId'; // unique identifier for ProductId
  };
};
```

This approach assigns a unique identifier as a brand to the `number` type, effectively differentiating `ProductId` from other numerical types.
The use of a symbol ensures that the branding field does not conflict with any existing properties of the `number` type.

Attempting to use a `UserId` in place of a `ProductId` now results in an error:

```ts twoslash
// @errors: 2345
const BrandTypeId: unique symbol = Symbol.for('effect/Brand');

type ProductId = number & {
  readonly [BrandTypeId]: {
    readonly ProductId: 'ProductId';
  };
};
// ---cut---
const getProductById = (id: ProductId) => {
  // Logic to retrieve product
};

type UserId = number;

const id: UserId = 1;

getProductById(id);
```

The error message clearly states that a `number` cannot be used in place of a `ProductId`.

TypeScript won't let us pass an instance of `number` to the function accepting `ProductId` because it's missing the brand field.

What if `UserId` also had its own brand?

```ts twoslash
// @errors: 2345
const BrandTypeId: unique symbol = Symbol.for('effect/Brand');

type ProductId = number & {
  readonly [BrandTypeId]: {
    readonly ProductId: 'ProductId'; // unique identifier for ProductId
  };
};

const getProductById = (id: ProductId) => {
  // Logic to retrieve product
};

type UserId = number & {
  readonly [BrandTypeId]: {
    readonly UserId: 'UserId'; // unique identifier for UserId
  };
};

declare const id: UserId;

getProductById(id);
```

The error is saying that though both types utilize a branding strategy, the distinct values associated with their branding fields (`"ProductId"` and `"UserId"`) prevent them from being interchangeable.

## Generalizing Branded Types

To enhance the versatility and reusability of branded types, they can be generalized using a standardized approach:

```ts twoslash
const BrandTypeId: unique symbol = Symbol.for('effect/Brand');

// Create a generic Brand interface using a unique identifier
interface Brand<in out ID extends string | symbol> {
  readonly [BrandTypeId]: {
    readonly [id in ID]: ID;
  };
}

// Define a ProductId type branded with a unique identifier
type ProductId = number & Brand<'ProductId'>;

// Define a UserId type branded similarly
type UserId = number & Brand<'UserId'>;
```

This design allows any type to be branded using a unique identifier, either a string or symbol.

Here's how you can utilize the `Brand` interface, which is readily available from the Brand module, eliminating the need to craft your own implementation:

```ts
import { Brand } from 'effect';

// Define a ProductId type branded with a unique identifier
type ProductId = number & Brand.Brand<'ProductId'>;

// Define a UserId type branded similarly
type UserId = number & Brand.Brand<'UserId'>;
```

However, creating instances of these types directly leads to an error because the type system expects the brand structure:

```ts twoslash
// @errors: 2322
const BrandTypeId: unique symbol = Symbol.for('effect/Brand');

interface Brand<in out K extends string | symbol> {
  readonly [BrandTypeId]: {
    readonly [k in K]: K;
  };
}

type ProductId = number & Brand<'ProductId'>;
// ---cut---
const id: ProductId = 1;
```

We need a way to create a value of type `ProductId` without directly assigning a number to it. This is where the Brand module comes in.

## Constructing Branded Types

The Brand module offers two core functions for constructing branded types: `nominal` and `refined`.

### nominal

The `nominal` function is designed for defining branded types that do not require runtime validations.
It simply adds a type tag to the underlying type, allowing us to distinguish between values of the same type but with different meanings.
Nominal branded types are useful when we only want to create distinct types for clarity and code organization purposes.

```ts twoslash
import { Brand } from 'effect';

type UserId = number & Brand.Brand<'UserId'>;

// Constructor for UserId
const UserId = Brand.nominal<UserId>();

const getUserById = (id: UserId) => {
  // Logic to retrieve user
};

type ProductId = number & Brand.Brand<'ProductId'>;

// Constructor for ProductId
const ProductId = Brand.nominal<ProductId>();

const getProductById = (id: ProductId) => {
  // Logic to retrieve product
};
```

Attempting to assign a non-`ProductId` value will result in a compile-time error:

```ts twoslash
// @errors: 2345
import { Brand } from 'effect';

type UserId = number & Brand.Brand<'UserId'>;

const UserId = Brand.nominal<UserId>();

const getUserById = (id: UserId) => {
  // Logic to retrieve user
};

type ProductId = number & Brand.Brand<'ProductId'>;

const ProductId = Brand.nominal<ProductId>();

const getProductById = (id: ProductId) => {
  // Logic to retrieve product
};
// ---cut---
// Correct usage
getProductById(ProductId(1));

// Incorrect, will result in an error
getProductById(1);

// Also incorrect, will result in an error
getProductById(UserId(1));
```

### refined

The `refined` function enables the creation of branded types that include data validation. It requires a refinement predicate to check the validity of input data against specific criteria.

When the input data does not meet the criteria, the function uses `Brand.error` to generate a `BrandErrors` data type. This provides detailed information about why the validation failed.

```ts twoslash
import { Brand } from 'effect';

// Define a branded type 'Int' to represent integer values
type Int = number & Brand.Brand<'Int'>;

// Define the constructor using 'refined' to enforce integer values
const Int = Brand.refined<Int>(
  // Validation to ensure the value is an integer
  (n) => Number.isInteger(n),
  // Provide an error if validation fails
  (n) => Brand.error(`Expected ${n} to be an integer`),
);
```

Usage example of the `Int` constructor:

```ts twoslash
import { Brand } from 'effect';

type Int = number & Brand.Brand<'Int'>;

const Int = Brand.refined<Int>(
  (n) => Number.isInteger(n), // Check if the value is an integer
  (n) => Brand.error(`Expected ${n} to be an integer`), // Error message if the value is not an integer
);

// ---cut---
// Create a valid Int value
const x: Int = Int(3);
console.log(x); // Output: 3

// Attempt to create an Int with an invalid value
const y: Int = Int(3.14); // throws [ { message: 'Expected 3.14 to be an integer' } ]
```

Attempting to assign a non-`Int` value will result in a compile-time error:

```ts twoslash
// @errors: 2322
import { Brand } from 'effect';

type Int = number & Brand.Brand<'Int'>;

const Int = Brand.refined<Int>(
  (n) => Number.isInteger(n),
  (n) => Brand.error(`Expected ${n} to be an integer`),
);

// ---cut---
// Correct usage
const good: Int = Int(3);

// Incorrect, will result in an error
const bad1: Int = 3;

// Also incorrect, will result in an error
const bad2: Int = 3.14;
```

## Combining Branded Types

In some scenarios, you may need to combine multiple branded types together. The Brand module provides the `all` API to facilitate this:

```ts twoslash
import { Brand } from 'effect';

type Int = number & Brand.Brand<'Int'>;

const Int = Brand.refined<Int>(
  (n) => Number.isInteger(n),
  (n) => Brand.error(`Expected ${n} to be an integer`),
);

type Positive = number & Brand.Brand<'Positive'>;

const Positive = Brand.refined<Positive>(
  (n) => n > 0,
  (n) => Brand.error(`Expected ${n} to be positive`),
);

// Combine the Int and Positive constructors into a new branded constructor PositiveInt
const PositiveInt = Brand.all(Int, Positive);

// Extract the branded type from the PositiveInt constructor
type PositiveInt = Brand.Brand.FromConstructor<typeof PositiveInt>;

// Usage example

// Valid positive integer
const good: PositiveInt = PositiveInt(10);

// throws [ { message: 'Expected -5 to be positive' } ]
const bad1: PositiveInt = PositiveInt(-5);

// throws [ { message: 'Expected 3.14 to be an integer' } ]
const bad2: PositiveInt = PositiveInt(3.14);
```

# Dual APIs

---

## title: Dual APIsexcerpt: Explore "data-last" and "data-first" variants of dual APIs in the Effect ecosystem, illustrated with the example of `Effect.map`. Learn how to choose between them based on your coding style and readability preferences.bottomNavigation: pagination

When you're working with APIs in the Effect ecosystem, you may come across two different ways to use the same API. These two ways are called the "data-last" and "data-first" variants.

<Info>
  From a technical perspective, these variants are implemented using two
  TypeScript overloads.
</Info>

When an API supports both variants, we call them "dual" APIs.

Let's explore these two variants using a concrete example of a dual API: `Effect.map`.

The `Effect.map` function is defined with two TypeScript overloads. The terms "data-last" and "data-first" refer to the position of the `self` argument (also known as the "data") in the signatures of the two overloads:

```ts
export declare const map: {
  // data-last
  <A, B>(f: (a: A) => B): <E, R>(self: Effect<A, E, R>) => Effect<B, E, R>;
  // data-first
  <A, E, R, B>(self: Effect<A, E, R>, f: (a: A) => B): Effect<B, E, R>;
};
```

## data-last

In the first overload, the `self` argument comes in the **last position**:

```ts
<A, B>(f: (a: A) => B): <E, R>(self: Effect<A, E, R>) => Effect<B, E, R>
```

This is the variant we have been using with `pipe`. You pass the `Effect` as the first argument to the `pipe` function, followed by a call to `Effect.andThen`:

```ts
const mappedEffect = pipe(effect, Effect.andThen(func));
```

This variant is useful when you need to chain multiple computations in a long pipeline. You can continue the pipeline by adding more computations after the initial transformation:

```ts
pipe(effect, Effect.andThen(func1), Effect.andThen(func2), ...)
```

## data-first

In the second overload, the `self` argument comes in the **first position**:

```ts
<A, E, R, B>(self: Effect<A, E, R>, f: (a: A) => B): Effect<B, E, R>
```

This variant doesn't require the `pipe` function. Instead, you can directly pass the `Effect` as the first argument to the `Effect.andThen` function:

```ts
const mappedEffect = Effect.andThen(effect, func);
```

This variant is convenient when you only need to perform a single operation on the `Effect`.

<Design>
  **Choosing Between the variants**. It's important to note that both
  overloads achieve the same result. They are simply two different ways of
  expressing the code. You can choose the overload that best fits your coding
  style and makes the code more readable for you and your team.
</Design>

# Simplifying Excessive Nesting

---

## title: Simplifying Excessive Nestingexcerpt: Learn how to simplify code with the `elapsed` function using different approaches. The guide demonstrates using plain pipe, the "do simulation," and the concise `Effect.gen` constructor to calculate and log the elapsed time for an effect's execution. Choose the method that fits your coding style and enhances code readability.bottomNavigation: pagination

Suppose you want to create a custom function `elapsed` that prints the elapsed time taken by an effect to execute.

## Using plain pipe

Initially, you may come up with code that uses the standard `pipe` [method](../essentials/pipeline#the-pipe-method), but this approach can lead to excessive nesting and result in verbose and hard-to-read code:

```ts twoslash
import { Console, Effect } from 'effect';

// Get the current timestamp
const now = Effect.sync(() => new Date().getTime());

// Prints the elapsed time occurred to `self` to execute
const elapsed = <R, E, A>(
  self: Effect.Effect<A, E, R>,
): Effect.Effect<A, E, R> =>
  now.pipe(
    Effect.andThen((startMillis) =>
      self.pipe(
        Effect.andThen((result) =>
          now.pipe(
            Effect.andThen((endMillis) => {
              // Calculate the elapsed time in milliseconds
              const elapsed = endMillis - startMillis;
              // Log the elapsed time
              return Console.log(`Elapsed: ${elapsed}`).pipe(
                Effect.map(() => result),
              );
            }),
          )
        ),
      )
    ),
  );

// Simulates a successful computation with a delay of 200 milliseconds
const task = Effect.succeed('some task').pipe(Effect.delay('200 millis'));

const program = elapsed(task);

Effect.runPromise(program).then(console.log);
/*
Output:
Elapsed: 204
some task
*/
```

To address this issue and make the code more manageable, there is a solution: the "do simulation."

## Using the "do simulation"

The "do simulation" in Effect allows you to write code in a more declarative style, similar to the "do notation" in other programming languages. It provides a way to define variables and perform operations on them using functions like `Effect.bind` and `Effect.let`.

Here's how the do simulation works:

1. Start the do simulation using the `Effect.Do` value:

   ```ts
   const program = Effect.Do.pipe(); /* ... rest of the code */
   ```

2. Within the do simulation scope, you can use the `Effect.bind` function to define variables and bind them to `Effect` values:

   ```ts
   Effect.bind('variableName', (scope) => effectValue);
   ```

- `variableName` is the name you choose for the variable you want to define. It must be unique within the scope.
- `effectValue` is the `Effect` value that you want to bind to the variable. It can be the result of a function call or any other valid `Effect` value.

3. You can accumulate multiple `Effect.bind` statements to define multiple variables within the scope:

   ```ts
   Effect.bind("variable1", () => effectValue1),
   Effect.bind("variable2", ({ variable1 }) => effectValue2),
   // ... additional bind statements
   ```

4. Inside the do simulation scope, you can also use the `Effect.let` function to define variables and bind them to simple values:

   ```ts
   Effect.let('variableName', (scope) => simpleValue);
   ```

- `variableName` is the name you give to the variable. Like before, it must be unique within the scope.
- `simpleValue` is the value you want to assign to the variable. It can be a simple value like a `number`, `string`, or `boolean`.

5. Regular Effect functions like `Effect.andThen`, `Effect.flatMap`, `Effect.tap`, and `Effect.map` can still be used within the do simulation. These functions will receive the accumulated variables as arguments within the scope:

   ```ts
   Effect.andThen(({ variable1, variable2 }) => {
     // Perform operations using variable1 and variable2
     // Return an `Effect` value as the result
   });
   ```

With the do simulation, you can rewrite the `elapsed` combinator like this:

```ts twoslash
import { Console, Effect } from 'effect';

// Get the current timestamp
const now = Effect.sync(() => new Date().getTime());

const elapsed = <R, E, A>(
  self: Effect.Effect<A, E, R>,
): Effect.Effect<A, E, R> =>
  Effect.Do.pipe(
    Effect.bind('startMillis', () => now),
    Effect.bind('result', () => self),
    Effect.bind('endMillis', () => now),
    Effect.let(
      'elapsed',
      ({ startMillis, endMillis }) => endMillis - startMillis, // Calculate the elapsed time in milliseconds
    ),
    Effect.tap(({ elapsed }) => Console.log(`Elapsed: ${elapsed}`)), // Log the elapsed time
    Effect.map(({ result }) => result),
  );

// Simulates a successful computation with a delay of 200 milliseconds
const task = Effect.succeed('some task').pipe(Effect.delay('200 millis'));

const program = elapsed(task);

Effect.runPromise(program).then(console.log);
/*
Output:
Elapsed: 204
some task
*/
```

In this solution, we use the do simulation to simplify the code. The `elapsed` function now starts with `Effect.Do` to enter the simulation scope.
Inside the scope, we use `Effect.bind` to define variables and bind them to the corresponding effects.

## Using `Effect.gen`

The most concise and convenient solution is to use the `Effect.gen` constructor, which allows you to work with [generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator) when dealing with effects. This approach leverages the native scope provided by the generator syntax, avoiding excessive nesting and leading to more concise code.

```ts twoslash
import { Effect } from 'effect';

// Get the current timestamp
const now = Effect.sync(() => new Date().getTime());

// Prints the elapsed time occurred to `self` to execute
const elapsed = <R, E, A>(
  self: Effect.Effect<A, E, R>,
): Effect.Effect<A, E, R> =>
  Effect.gen(function* () {
    const startMillis = yield* now;
    const result = yield* self;
    const endMillis = yield* now;
    // Calculate the elapsed time in milliseconds
    const elapsed = endMillis - startMillis;
    // Log the elapsed time
    console.log(`Elapsed: ${elapsed}`);
    return result;
  });

// Simulates a successful computation with a delay of 200 milliseconds
const task = Effect.succeed('some task').pipe(Effect.delay('200 millis'));

const program = elapsed(task);

Effect.runPromise(program).then(console.log);
/*
Output:
Elapsed: 204
some task
*/
```

In this solution, we switch to using [generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator) to simplify the code. The `elapsed` function now uses a generator function (`Effect.gen`) to define the flow of execution. Within the generator, we use `yield*` to invoke effects and bind their results to variables. This eliminates the nesting and provides a more readable and sequential code structure.

The generator style in Effect uses a more linear and sequential flow of execution, resembling traditional imperative programming languages. This makes the code easier to read and understand, especially for developers who are more familiar with imperative programming paradigms.

On the other hand, the pipe style can lead to excessive nesting, especially when dealing with complex effectful computations. This can make the code harder to follow and debug.

For more information on how to use generators in Effect, you can refer to the [Using Generators in Effect](../essentials/using-generators) guide.

# Code Style

---

## title: Code Styleexcerpt: Code Stylecollapsible: truebottomNavigation: childCards

# Guidelines

---

## title: Guidelinesexcerpt: GuidelinesbottomNavigation: pagination

## Using `runMain`

In Effect, `runMain` serves as the primary entry point for running an Effect application on Node:

```ts
import { Console, Effect, pipe, Schedule } from 'effect';
import { NodeRuntime } from '@effect/platform-node';

const program = pipe(
  Effect.addFinalizer(() => Console.log('Application is about to exit!')),
  Effect.andThen(Console.log('Application started!')),
  Effect.andThen(
    Effect.repeat(Console.log('still alive...'), {
      schedule: Schedule.spaced('1 second'),
    }),
  ),
  Effect.scoped,
);

// Effect.runFork(program) // no graceful teardown with CTRL+C

NodeRuntime.runMain(program); // graceful teardown with CTRL+C
```

The `runMain` function is responsible for finding all fibers and interrupting them. Internally, it adds an observer for the fiber by listening to `sigint` and interrupts all fibers.

It's important to note that teardown should be on the main effect. If you kill the fiber that runs the application/server, the teardown of everything will occur. This is precisely what `runMain` from the `platform-node` package does.

## Avoid Tacit usage

> Avoid tacit function calls like `map(f)` and using `flow`

In Effect, it's recommended not to use functions point-free, meaning avoiding tacit usage.

While you're free to use tacit functions if you prefer, it's important to know that it can cause issues. It's safer to use `(x) => fn(x)` instead.

Using functions tacitly, especially with optional parameters, can be unsafe. If a function has overloads, using it tacitly might erase all generics, leading to bugs. For example, check out this X thread: [link to thread](https://twitter.com/MichaelArnaldi/status/1670715270845935616).

TypeScript inference can also be compromised when using tacit functions, which can lead to unexpected errors. So, it's not just a matter of style; it's a protective measure to avoid mistakes.

Additionally, stack traces may not be as clear when tacit usage is involved. It's risky without much benefit, as TypeScript may not properly check arguments, especially with optional ones, leading to potential issues.

It's worth trying without tacit usage, especially when dealing with generic functions with overloads, as using them tacitly can result in losing the generics.

# Pattern Matching

---

## title: Pattern Matchingexcerpt: Explore the power of pattern matching in code, simplifying complex conditions into concise expressions. Learn about exhaustiveness checking and discover how to implement pattern matching in JavaScript using the `effect/Match` module. Dive into defining matchers, patterns, predicates, and transformations for enhanced code branching and readability.bottomNavigation: pagination

Pattern matching is a method that allows developers to handle intricate conditions within a single, concise expression. It simplifies code, making it more concise and easier to understand. Additionally, it includes a process called exhaustiveness checking, which helps to ensure that no possible case has been overlooked.

Originating from functional programming languages, pattern matching stands as a powerful technique for code branching. It often offers a more potent and less verbose solution compared to imperative alternatives such as if/else or switch statements, particularly when dealing with complex conditions.

Although not yet a native feature in JavaScript, there's an ongoing [tc39 proposal](https://github.com/tc39/proposal-pattern-matching) in its early stages to introduce pattern matching to JavaScript. However, this proposal is at stage 1 and might take several years to be implemented. Nonetheless, developers can implement pattern matching in their codebase. The `effect/Match` module provides a reliable, type-safe pattern matching implementation that is available for immediate use.

## Defining a Matcher

### type

Creating a `Matcher` involves using the `type` constructor function with a specified type. This sets the foundation for pattern matching against that particular type. Once the `Matcher` is established, developers can employ various combinators like `when`, `not`, and `tag` to define patterns that the `Matcher` will check against.

Here's a practical example:

```ts twoslash
import { Match } from 'effect';

const match = Match.type<{ a: number } | { b: string }>().pipe(
  Match.when({ a: Match.number }, (_) => _.a),
  Match.when({ b: Match.string }, (_) => _.b),
  Match.exhaustive,
);

console.log(match({ a: 0 })); // Output: 0
console.log(match({ b: 'hello' })); // Output: "hello"
```

Let's dissect what's happening:

- `Match.type<{ a: number } | { b: string }>()`: This creates a `Matcher` for objects that are either of type `{ a: number }` or `{ b: string }`.
- `Match.when({ a: Match.number }, (_) => _.a)`: This sets up a condition to match an object with a property `a` containing a number. If matched, it returns the value of property `a`.
- `Match.when({ b: Match.string }, (_) => _.b)`: This condition matches an object with a property `b` containing a string. If found, it returns the value of property `b`.
- `Match.exhaustive`: This function ensures that all possible cases are considered and matched, making sure that no other unaccounted cases exist. It helps to prevent overlooking any potential scenario.

Finally, the `match` function is applied to test two different objects, `{ a: 0 }` and `{ b: "hello" }`. As per the defined conditions within the `Matcher`, it correctly matches the objects and provides the expected output based on the defined conditions.

### value

In addition to defining a `Matcher` based on a specific type, developers can also create a `Matcher` directly from a value utilizing the `value` constructor function. This method allows matching patterns against the provided value.

Let's take a look at an example to better understand this process:

```ts twoslash
import { Match } from 'effect';

const result = Match.value({ name: 'John', age: 30 }).pipe(
  Match.when(
    { name: 'John' },
    (user) => `${user.name} is ${user.age} years old`,
  ),
  Match.orElse(() => 'Oh, not John'),
);

console.log(result); // Output: "John is 30 years old"
```

Here's a breakdown of what's happening:

- `Match.value({ name: "John", age: 30 })`: This initializes a `Matcher` using the provided value `{ name: "John", age: 30 }`.
- `Match.when({ name: "John" }, (user) => ...`: It establishes a condition to match the object having the property `name` set to "John". If the condition is met, it constructs a string indicating the name and age of the user.
- `Match.orElse(() => "Oh, not John")`: In the absence of a match with the name "John," this provides a default output.

## Patterns

### Predicates

Predicates allow the testing of values against specific conditions. It helps in creating rules or conditions for the data being evaluated.

```ts twoslash
import { Match } from 'effect';

const match = Match.type<{ age: number }>().pipe(
  Match.when({ age: (age) => age >= 5 }, (user) => `Age: ${user.age}`),
  Match.orElse((user) => `${user.age} is too young`),
);

console.log(match({ age: 5 })); // Output: "Age: 5"
console.log(match({ age: 4 })); // Output: "4 is too young"
```

### not

`not` allows for excluding a specific value while matching other conditions.

```ts twoslash
import { Match } from 'effect';

const match = Match.type<string | number>().pipe(
  Match.not('hi', (_) => 'a'),
  Match.orElse(() => 'b'),
);

console.log(match('hello')); // Output: "a"
console.log(match('hi')); // Output: "b"
```

### tag

The `tag` function enables pattern matching against the tag within a [Discriminated Union](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes-func.html#discriminated-unions).

```ts twoslash
import { Either, Match } from 'effect';

const match = Match.type<Either.Either<number, string>>().pipe(
  Match.tag('Right', (_) => _.right),
  Match.tag('Left', (_) => _.left),
  Match.exhaustive,
);

console.log(match(Either.right(123))); // Output: 123
console.log(match(Either.left('Oh no!'))); // Output: "Oh no!"
```

<Warning>
  Note that it only works with the convention within the Effect ecosystem of
  naming the tag field with `"_tag"`.
</Warning>

## Transforming a Matcher

### exhaustive

The `exhaustive` transformation serves as an endpoint within the matching process, ensuring all potential matches have been considered. It results in returning the match (for `Match.value`) or the evaluation function (for `Match.type`).

```ts twoslash
import { Either, Match } from 'effect';

const result = Match.value(Either.right(0)).pipe(
  Match.when({ _tag: 'Right' }, (_) => _.right),
  // @ts-expect-error
  Match.exhaustive, // TypeError! Type 'Left<never, number>' is not assignable to type 'never'
);
```

### orElse

The `orElse` transformation signifies the conclusion of the matching process, offering a fallback value when no specific patterns match. It returns the match (for `Match.value`) or the evaluation function (for `Match.type`).

```ts twoslash
import { Match } from 'effect';

const match = Match.type<string | number>().pipe(
  Match.when('hi', (_) => 'hello'),
  Match.orElse(() => 'I literally do not understand'),
);

console.log(match('hi')); // Output: "hello"
console.log(match('hello')); // Output: "I literally do not understand"
```

### option

The `option` transformation returns the result encapsulated within an [Option](../data-types/option). When the match succeeds, it represents the result as `Some`, and when there's no match, it signifies the absence of a value with `None`.

```ts twoslash
import { Either, Match } from 'effect';

const result = Match.value(Either.right(0)).pipe(
  Match.when({ _tag: 'Right' }, (_) => _.right),
  Match.option,
);

console.log(result); // Output: { _id: 'Option', _tag: 'Some', value: 0 }
```

### either

The `either` transformation might match a value, returning an [Either](../data-types/either) following the format `Either<MatchResult, NoMatchResult>`.

```ts twoslash
import { Match } from 'effect';

const match = Match.type<string>().pipe(
  Match.when('hi', (_) => _.length),
  Match.either,
);

console.log(match('hi')); // Output: { _id: 'Either', _tag: 'Right', right: 2 }
console.log(match('shigidigi')); // Output: { _id: 'Either', _tag: 'Left', left: 'shigidigi' }
```

# Running Effects

---

## title: Running Effectsexcerpt: Explore various "run" functions in the Effect module to execute effects. Learn about `runSync` for synchronous execution, `runSyncExit` for obtaining results as `Exit`, `runPromise` for executing with a Promise result, and `runPromiseExit` for Promise results with `Exit`. Understand their use cases and considerations. Check out a cheatsheet summarizing available functions for executing effects in different contexts.bottomNavigation: pagination

To execute an `Effect`, we can utilize a variety of "run" functions provided by the `Effect` module.

## runSync

The `Effect.runSync` function is used to execute an Effect synchronously, which means it runs immediately and returns the result.

```ts twoslash
import { Effect } from 'effect';

const program = Effect.sync(() => {
  console.log('Hello, World!');
  return 1;
});

const result = Effect.runSync(program);
// Output: Hello, World!

console.log(result);
// Output: 1
```

If you check the console, you will see the message `"Hello, World!"` printed.

<Warning>
  `Effect.runSync` will throw an error if your Effect fails or performs any
  asynchronous tasks. In the latter case, the execution will not proceed
  beyond that asynchronous task.
</Warning>

```ts twoslash
import { Effect } from 'effect';

Effect.runSync(Effect.fail('my error')); // throws

Effect.runSync(Effect.promise(() => Promise.resolve(1))); // throws
```

## runSyncExit

The `Effect.runSyncExit` function is used to execute an Effect synchronously, which means it runs immediately and returns the result as an [Exit](../../other/data-types/exit)
(a data type used to describe the result of executing an `Effect` workflow).

```ts twoslash
import { Effect } from 'effect';

const result1 = Effect.runSyncExit(Effect.succeed(1));
console.log(result1);
/*
Output:
{
  _id: "Exit",
  _tag: "Success",
  value: 1
}
*/

const result2 = Effect.runSyncExit(Effect.fail('my error'));
console.log(result2);
/*
Output:
{
  _id: "Exit",
  _tag: "Failure",
  cause: {
    _id: "Cause",
    _tag: "Fail",
    failure: "my error"
  }
}
*/
```

<Warning>
  `Effect.runSyncExit` will throw an error if your Effect performs any
  asynchronous tasks and the execution will not proceed beyond that
  asynchronous task.
</Warning>

```ts twoslash
import { Effect } from 'effect';

Effect.runSyncExit(Effect.promise(() => Promise.resolve(1))); // throws
```

## runPromise

The `Effect.runPromise` function is used to execute an Effect and obtain the result as a `Promise`.

```ts twoslash
import { Effect } from 'effect';

Effect.runPromise(Effect.succeed(1)).then(console.log); // Output: 1
```

<Warning>
  `Effect.runPromise` will reject with an error if your Effect fails
</Warning>

```ts twoslash
import { Effect } from 'effect';

Effect.runPromise(Effect.fail('my error')); // rejects
```

## runPromiseExit

The `Effect.runPromiseExit` function is used to execute an Effect and obtain the result as a `Promise` that resolves to an [Exit](../../other/data-types/exit)
(a data type used to describe the result of executing an `Effect` workflow).

```ts twoslash
import { Effect } from 'effect';

Effect.runPromiseExit(Effect.succeed(1)).then(console.log);
/*
Output:
{
  _id: "Exit",
  _tag: "Success",
  value: 1
}
*/

Effect.runPromiseExit(Effect.fail('my error')).then(console.log);
/*
Output:
{
  _id: "Exit",
  _tag: "Failure",
  cause: {
    _id: "Cause",
    _tag: "Fail",
    failure: "my error"
  }
}
*/
```

## runFork

The `Effect.runFork` function serves as a foundational building block for running effects. In fact, all other run functions are built upon it. Unless you have a specific need for a Promise or a synchronous operation, `Effect.runFork` is the recommended choice. It returns a fiber that you can observe or interrupt as needed.

```ts twoslash
import { Console, Effect, Fiber, Schedule } from 'effect';

const program = Effect.repeat(
  Console.log('running...'),
  Schedule.spaced('200 millis'),
);

const fiber = Effect.runFork(program);

setTimeout(() => {
  Effect.runFork(Fiber.interrupt(fiber));
}, 500);
```

In this example, the `program` continuously logs "running..." with each repetition spaced 200 milliseconds apart. You can learn more about repetitions and scheduling in our [Introduction to Scheduling](../scheduling/introduction) guide.

To stop the execution of the program, we use `Fiber.interrupt` on the fiber returned by `Effect.runFork`. This allows you to control the execution flow and terminate it when necessary.

For a deeper understanding of how fibers work and how to handle interruptions, check out our guides on [Fibers](../concurrency/fibers) and [Interruptions](../concurrency/interruption-model).

## Cheatsheet

<Design>
  The recommended approach is to design your program with the majority of its
  logic as Effects. It's advisable to use the `run*` functions closer to the
  "edge" of your program. This approach allows for greater flexibility in
  executing your program and building sophisticated Effects.
</Design>

The table provides a summary of the available `run*` functions, along with their input and output types, allowing you to choose the appropriate function based on your needs.

| **Name**         | **Given**      | **To**                |
| ---------------- | -------------- | --------------------- |
| `runSync`        | `Effect<A, E>` | `A`                   |
| `runSyncExit`    | `Effect<A, E>` | `Exit<A, E>`          |
| `runPromise`     | `Effect<A, E>` | `Promise<A>`          |
| `runPromiseExit` | `Effect<A, E>` | `Promise<Exit<A, E>>` |
| `runFork`        | `Effect<A, E>` | `RuntimeFiber<A, E>`  |

You can find the complete list of `run*` functions [here](https://effect-ts.github.io/effect/effect/Effect.ts.html#execution).

# Creating Effects

---

## title: Creating Effectsexcerpt: Learn various methods to create effects in the Effect ecosystem. Understand the drawbacks of throwing errors in traditional programming and explore constructors like `Effect.succeed` and `Effect.fail` for explicit success and failure handling. Dive into modeling synchronous effects with `Effect.sync` and `Effect.try`, and asynchronous effects with `Effect.promise` and `Effect.tryPromise`. Explore `Effect.async` for callback-based APIs and `Effect.suspend` for deferred effect evaluation. Check out a cheatsheet summarizing available constructors.bottomNavigation: pagination

Effect provides different ways to create effects, which are units of computation that encapsulate side effects.
In this guide, we will cover some of the common methods that you can use to create effects.

## Why Not Throw Errors?

In traditional programming, when an error occurs, it is often handled by throwing an exception:

```ts twoslash
const divide = (a: number, b: number): number => {
  if (b === 0) {
    throw new Error('Cannot divide by zero');
  }
  return a / b;
};
```

However, throwing errors can be problematic. The type signatures of functions do not indicate that they can throw exceptions, making it difficult to reason about potential errors.

To address this issue, Effect introduces dedicated constructors for creating effects that represent both success and failure: `Effect.succeed` and `Effect.fail`. These constructors allow you to explicitly handle success and failure cases while **leveraging the type system to track errors**.

### succeed

The `Effect.succeed` constructor in the Effect library is used to explicitly create an effect that is guaranteed to succeed. Here's how you can use it:

```ts twoslash
import { Effect } from 'effect';

const success = Effect.succeed(42);
```

In this example, `success` is an instance of `Effect<number, never, never>`. This means it's an effect that:

- Always succeeds, yielding a value of type `number`.
- Does not generate any errors (`never` indicates that no errors are expected).
- Requires no additional data or dependencies from the environment (`never` indicates no requirements).

### fail

When a computation might fail, it's essential to manage the failure explicitly. The `Effect.fail` constructor allows you to encapsulate an error within your program flow explicitly. This method is useful for representing known error states in a predictable and type-safe way. Here's a practical example to illustrate:

```ts twoslash
import { Effect } from 'effect';

// Creating an effect that represents a failure scenario
const failure = Effect.fail(
  new Error('Operation failed due to network error'),
);
```

The type of `failure` is `Effect<never, Error, never>`, which means

- It never produces a successful value (`never`).
- It fails with an error, specifically an `Error`.
- It does not depend on any external context to execute (`never`).

You're not limited to using only `Error` objects with `Effect.fail`. You can also use strings, numbers, or more complex objects depending on what fits best with your error handling strategy:

```ts twoslash
import { Effect } from 'effect';

const failure = Effect.fail('Something went wrong');
```

With `Effect.succeed` and `Effect.fail`, you can explicitly handle success and failure cases and the type system will ensure that errors are tracked and accounted for.

**Example: Rewriting a Division Function**

Let's see an example of rewriting the `divide` function using Effect to make the error handling explicit:

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number, Error> =>
  b === 0
    ? Effect.fail(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);
```

In this example, the `divide` function explicitly indicates that it can produce an effect that either fails with an `Error` or succeeds with a `number` value.
The type signature makes it clear how errors are handled and ensures that callers are aware of the possible outcomes.

**Example: Simulating a User Retrieval Operation**

Let's imagine another scenario where we use `Effect.succeed` and `Effect.fail` to model a simple user retrieval operation where the user data is hardcoded, which could be useful in testing scenarios or when mocking data:

```ts twoslash
import { Effect } from 'effect';

// Define a User type
interface User {
  readonly id: number;
  readonly name: string;
}

// A mocked function to simulate fetching a user from a database
const getUser = (userId: number): Effect.Effect<User, Error> => {
  // Normally, you would access a database or an API here, but we'll mock it
  const userDatabase: Record<number, User> = {
    1: { id: 1, name: 'John Doe' },
    2: { id: 2, name: 'Jane Smith' },
  };

  // Check if the user exists in our "database" and return appropriately
  const user = userDatabase[userId];
  if (user) {
    return Effect.succeed(user);
  } else {
    return Effect.fail(new Error('User not found'));
  }
};

// When executed, this will successfully return the user with id 1
const exampleUserEffect = getUser(1);
```

In this example `exampleUserEffect` can result in either a `User` object or an `Error`, depending on whether the user exists in the simulated database

To dive deeper into handling and managing errors effectively in your applications using Effect, you might want to explore the guide on [Error Management](../error-management/expected-errors). This guide provides detailed insights and strategies for robust error handling in TypeScript applications using Effect.

## Modeling Synchronous Effects

In JavaScript, you can delay the execution of synchronous computations using "thunks".

<Info>
  A "thunk" is a function that takes no arguments and may return some value.
</Info>

Thunks are useful for delaying the computation of a value until it is needed.

To model synchronous side effects, Effect provides the `Effect.sync` and `Effect.try` constructors, which accept a thunk.

### sync

When working with side effects that are synchronous â€” meaning they don't involve asynchronous operations like fetching data from the internet â€” you can use the `Effect.sync` function.
This function is ideal when you are certain these operations **won't produce any errors**.

**Example: Logging a Message**

```ts twoslash
import { Effect } from 'effect';

const log = (message: string) =>
  Effect.sync(() => {
    console.log(message); // side effect
  });

const program = log('Hello, World!');
```

In the above example, `Effect.sync` is used to defer the side-effect of writing to the console.

The `program` has the type `Effect<void, never, never>`, indicating that:

- It doesn't produce a return value (`void`).
- It's not expected to fail (`never` indicates no expected errors).
- It doesn't require any external dependencies or context (`never`).

Important Notes:

- **Execution**: The side effect (logging to the console) encapsulated within `program` won't occur until the effect is explicitly [run](running-effects). This allows you to define side effects at one point in your code and control when they are activated, improving manageability and predictability of side effects in larger applications.
- **Error Handling**: It's crucial that the function you pass to `Effect.sync` does not throw any errors. If you anticipate potential errors, consider using [try](#try) instead, which handles errors gracefully.

<Error>The thunk passed to `Effect.sync` should never throw errors.</Error>

**Handling Unexpected Errors**. Despite your best efforts to avoid errors in the function passed to `Effect.sync`, if an error does occur, it results in a "defect".
This defect is not a standard error but indicates a flaw in the logic that was expected to be error-free.
You can think of it similar to an unexpected crash in the program, which can be further managed or logged using tools like [Effect.catchAllDefect](../error-management/unexpected-errors#catchalldefect).
This feature ensures that even unexpected failures in your application are not lost and can be handled appropriately.

### try

In situations where you need to perform synchronous operations that might fail, such as parsing JSON, you can use the `Effect.try` constructor from the Effect library.
This constructor is designed to handle operations that could throw exceptions by capturing those exceptions and transforming them into manageable errors within the Effect framework.

**Example: Safe JSON Parsing**

Suppose you have a function that attempts to parse a JSON string. This operation can fail and throw an error if the input string is not properly formatted as JSON:

```ts twoslash
import { Effect } from 'effect';

const parse = (input: string) =>
  Effect.try(
    () => JSON.parse(input), // This might throw an error if input is not valid JSON
  );

const program = parse('');
```

In this example:

- `parse` is a function that creates an effect encapsulating the JSON parsing operation.
- If `JSON.parse(input)` throws an error due to invalid input, `Effect.try` catches this error and the effect represented by `program` will fail with an `UnknownException`. This ensures that errors are not silently ignored but are instead handled within the structured flow of effects.

**Customizing Error Handling**. You might want to transform the caught exception into a more specific error or perform additional operations when catching an error. `Effect.try` supports an overload that allows you to specify how caught exceptions should be transformed:

**Example: Custom Error Handling**

```ts {6} twoslash
import { Effect } from 'effect';

const parse = (input: string) =>
  Effect.try({
    try: () => JSON.parse(input), // JSON.parse may throw for bad input
    catch: (unknown) => new Error(`something went wrong ${unknown}`), // remap the error
  });

const program = parse('');
```

You can think of this as a similar pattern to the traditional try-catch block in JavaScript:

```ts
try {
  return JSON.parse(input);
} catch (unknown) {
  throw new Error(`something went wrong ${unknown}`);
}
```

## Modeling Asynchronous Effects

In traditional programming, we often use `Promise`s to handle asynchronous computations. However, dealing with errors in promises can be problematic. By default, `Promise<Value>` only provides the type `Value` for the resolved value, which means errors are not reflected in the type system. This limits the expressiveness and makes it challenging to handle and track errors effectively.

To overcome these limitations, Effect introduces dedicated constructors for creating effects that represent both success and failure in an asynchronous context: `Effect.promise` and `Effect.tryPromise`. These constructors allow you to explicitly handle success and failure cases while **leveraging the type system to track errors**.

### promise

This constructor is similar to a regular `Promise`, where you're confident that the asynchronous operation will **always succeed**.
It allows you to create an `Effect` that represents successful completion without considering potential errors. However, it's essential to ensure that the underlying Promise never rejects.

**Example: Delayed Message**

```ts twoslash
import { Effect } from 'effect';

const delay = (message: string) =>
  Effect.promise<string>(
    () =>
      new Promise((resolve) => {
        setTimeout(() => {
          resolve(message);
        }, 2000);
      }),
  );

const program = delay('Async operation completed successfully!');
```

The `program` value has the type `Effect<string, never, never>` and can be interpreted as an effect that:

- succeeds with a value of type `string`
- does not produce any expected error (`never`)
- does not require any context (`never`)

<Error>
  The `Promise` within the thunk passed to `Effect.promise` should never
  reject.
</Error>

**Handling Unexpected Errors**. If, despite precautions, the thunk passed to `Effect.promise` does reject, an `Effect` containing a ["defect"](../error-management/unexpected-errors) is created, similar to what happens when using the [Effect.die](../error-management/unexpected-errors#die-diemessage) function.

### tryPromise

Unlike `Effect.promise`, this constructor is suitable when the underlying `Promise` **might reject**.
It provides a way to catch errors and handle them appropriately.
By default if an error occurs, it will be caught and propagated to the error channel as as an `UnknownException`.

**Example: Fetching a TODO Item**

```ts twoslash
import { Effect } from 'effect';

const getTodo = (id: number) =>
  Effect.tryPromise(() =>
    fetch(`https://jsonplaceholder.typicode.com/todos/${id}`)
  );

const program = getTodo(1);
```

The `program` value has the type `Effect<Response, UnknownException, never>` and can be interpreted as an effect that:

- succeeds with a value of type `Response`
- might produce an error (`UnknownException`)
- does not require any context (`never`)

**Customizing Error Handling**. If you want more control over what gets propagated to the error channel, you can use an overload of `Effect.tryPromise` that takes a remapping function:

```ts {7} twoslash
import { Effect } from 'effect';

const getTodo = (id: number) =>
  Effect.tryPromise({
    try: () => fetch(`https://jsonplaceholder.typicode.com/todos/${id}`),
    // remap the error
    catch: (unknown) => new Error(`something went wrong ${unknown}`),
  });

const program = getTodo(1);
```

## From a callback

Sometimes you have to work with APIs that don't support `async/await` or `Promise` and instead use the callback style.
To handle callback-based APIs, Effect provides the `Effect.async` constructor.

**Example: Reading a File**

For example, let's wrap the `readFile` async API from the Node.js `fs` module with Effect (ensure you have `@types/node` installed):

```ts twoslash
// @types: node
import { Effect } from 'effect';
import * as NodeFS from 'node:fs';

const readFile = (filename: string) =>
  Effect.async<Buffer, Error>((resume) => {
    NodeFS.readFile(filename, (error, data) => {
      if (error) {
        resume(Effect.fail(error));
      } else {
        resume(Effect.succeed(data));
      }
    });
  });

const program = readFile('todos.txt');
```

In the above example, we manually annotate the types when calling `Effect.async` because TypeScript cannot infer the type parameters for a callback
based on the return value inside the callback body. Annotating the types ensures that the values provided to `resume` match the expected types.

<Idea>
  You can seamlessly mix synchronous and asynchronous code within the Effect
  framework. Everything becomes an Effect, enabling you to handle different
  types of side effects in a unified way.
</Idea>

## Suspended Effects

`Effect.suspend` is used to delay the creation of an effect.
It allows you to defer the evaluation of an effect until it is actually needed.
The `Effect.suspend` function takes a thunk that represents the effect, and it wraps it in a suspended effect.

```ts
const suspendedEffect = Effect.suspend(() => effect);
```

Let's explore some common scenarios where `Effect.suspend` proves useful:

1. **Lazy Evaluation**. When you want to defer the evaluation of an effect until it is required. This can be useful for optimizing the execution of effects, especially when they are not always needed or when their computation is expensive.

   Also, when effects with side effects or scoped captures are created, use `Effect.suspend` to re-execute on each invocation.

   ```ts twoslash
   import { Effect } from 'effect';

   let i = 0;

   const bad = Effect.succeed(i++);

   const good = Effect.suspend(() => Effect.succeed(i++));

   console.log(Effect.runSync(bad)); // Output: 0
   console.log(Effect.runSync(bad)); // Output: 0

   console.log(Effect.runSync(good)); // Output: 1
   console.log(Effect.runSync(good)); // Output: 2
   ```

   <Info>
     This example utilizes `Effect.runSync` to execute effects and display
     their results (refer to [Running Effects](./running-effects#runsync) for
     more details).
   </Info>

   In this example, `Effect.succeed(i++)` creates a new numeric value and consistently returns the same number. On the other hand, `Effect.suspend(() => Effect.succeed(i++))` generates a new number with each invocation.

2. **Handling Circular Dependencies**. `Effect.suspend` is helpful in managing circular dependencies between effects, where one effect depends on another, and vice versa.
   For example it's fairly common for `Effect.suspend` to be used in recursive functions to escape an eager call. For instance:

   ```ts twoslash
   import { Effect } from 'effect';

   const blowsUp = (n: number): Effect.Effect<number> =>
     n < 2
       ? Effect.succeed(1)
       : Effect.zipWith(blowsUp(n - 1), blowsUp(n - 2), (a, b) => a + b);

   // console.log(Effect.runSync(blowsUp(32))) // crash: JavaScript heap out of memory

   const allGood = (n: number): Effect.Effect<number> =>
     n < 2 ? Effect.succeed(1) : Effect.zipWith(
       Effect.suspend(() => allGood(n - 1)),
       Effect.suspend(() => allGood(n - 2)),
       (a, b) => a + b,
     );

   console.log(Effect.runSync(allGood(32))); // Output: 3524578
   ```

   <Info>
     This example utilizes `Effect.zipWith` to combine the results of two
     effects (refer to [Zipping](../control-flow#zipwith) for more details).
   </Info>

   The `blowsUp` function creates a recursive Fibonacci sequence without deferring execution. Each call to `blowsUp` triggers further immediate recursive calls, rapidly increasing the JavaScript call stack size.

   Conversely, `allGood` avoids stack overflow by using `Effect.suspend` to defer the recursive calls. This mechanism doesn't immediately execute the recursive effects but schedules them to be run later, thus keeping the call stack shallow and preventing a crash.

3. **Unifying Return Type**. In situations where TypeScript struggles to unify the returned effect type, `Effect.suspend` can be employed to resolve this issue. For example:

   ```ts twoslash
   import { Effect } from 'effect';

   const ugly = (a: number, b: number) =>
     b === 0
       ? Effect.fail(new Error('Cannot divide by zero'))
       : Effect.succeed(a / b);

   const nice = (a: number, b: number) =>
     Effect.suspend(() =>
       b === 0
         ? Effect.fail(new Error('Cannot divide by zero'))
         : Effect.succeed(a / b)
     );
   ```

## Cheatsheet

The table provides a summary of the available constructors, along with their input and output types, allowing you to choose the appropriate function based on your needs.

| **Function**            | **Given**                          | **To**                        |
| ----------------------- | ---------------------------------- | ----------------------------- |
| `succeed`               | `A`                                | `Effect<A>`                   |
| `fail`                  | `E`                                | `Effect<never, E>`            |
| `sync`                  | `() => A`                          | `Effect<A>`                   |
| `try`                   | `() => A`                          | `Effect<A, UnknownException>` |
| `try` (overload)        | `() => A`, `unknown => E`          | `Effect<A, E>`                |
| `promise`               | `() => Promise<A>`                 | `Effect<A>`                   |
| `tryPromise`            | `() => Promise<A>`                 | `Effect<A, UnknownException>` |
| `tryPromise` (overload) | `() => Promise<A>`, `unknown => E` | `Effect<A, E>`                |
| `async`                 | `(Effect<A, E> => void) => void`   | `Effect<A, E>`                |
| `suspend`               | `() => Effect<A, E, R>`            | `Effect<A, E, R>`             |

You can find the complete list of constructors [here](https://effect-ts.github.io/effect/effect/Effect.ts.html#constructors).

Now that we know how to create effects, it's time to learn how to run them.
Check out the next guide on [Running Effects](running-effects) to find out more.

# Building Pipelines

---

## title: Building Pipelinesexcerpt: Explore the power of Effect pipelines for composing and sequencing operations on values. Learn about key functions like `pipe`, `Effect.map`, `Effect.flatMap`, `Effect.andThen`, `Effect.tap`, and `Effect.all` for building modular and concise transformations. Understand the advantages of using functions over methods in the Effect ecosystem for tree shakeability and extensibility.bottomNavigation: pagination

Effect pipelines allow for the composition and sequencing of operations on values, enabling the transformation and manipulation of data in a concise and modular manner.

## Why Pipelines are Good for Structuring Your Application

Pipelines are an excellent way to structure your application and handle data transformations in a concise and modular manner. They offer several benefits:

1. **Readability**: Pipelines allow you to compose functions in a readable and sequential manner. You can clearly see the flow of data and the operations applied to it, making it easier to understand and maintain the code.

2. **Code Organization**: With pipelines, you can break down complex operations into smaller, manageable functions. Each function performs a specific task, making your code more modular and easier to reason about.

3. **Reusability**: Pipelines promote the reuse of functions. By breaking down operations into smaller functions, you can reuse them in different pipelines or contexts, improving code reuse and reducing duplication.

4. **Type Safety**: By leveraging the type system, pipelines help catch errors at compile-time. Functions in a pipeline have well-defined input and output types, ensuring that the data flows correctly through the pipeline and minimizing runtime errors.

Now, let's delve into how to define pipelines and explore some of the key components:

## pipe

The `pipe` function is a utility that allows us to compose functions in a readable and sequential manner. It takes the output of one function and passes it as the input to the next function in the pipeline. This enables us to build complex transformations by chaining multiple functions together.

The basic syntax of `pipe` is as follows:

```ts
import { pipe } from "effect"

const result = pipe(input, func1, func2, ..., funcN)
```

In this syntax, `input` is the initial value, and `func1`, `func2`, ..., `funcN` are the functions to be applied in sequence. The result of each function becomes the input for the next function, and the final result is returned.

Here's an illustration of how `pipe` works:

![Pipe](/images/mmd/pipeline.svg)

It's important to note that functions passed to `pipe` must have a **single argument** because they are only called with a single argument.

Let's see an example to better understand how `pipe` works:

```ts twoslash
import { pipe } from 'effect';

// Define simple arithmetic operations
const increment = (x: number) => x + 1;
const double = (x: number) => x * 2;
const subtractTen = (x: number) => x - 10;

// Sequentially apply these operations using `pipe`
const result = pipe(5, increment, double, subtractTen);

console.log(result); // Output: 2
```

In the above example, we start with an input value of `5`. The `increment` function adds `1` to the initial value, resulting in `6`. Then, the `double` function doubles the value, giving us `12`. Finally, the `subtractTen` function subtracts `10` from `12`, resulting in the final output of `2`.

The result is equivalent to `subtractTen(double(increment(5)))`, but using `pipe` makes the code more readable because the operations are sequenced from left to right, rather than nesting them inside out.

## Functions vs Methods

In the Effect ecosystem, libraries often expose functions rather than methods. This design choice is important for two key reasons: tree shakeability and extensibility.

### Tree Shakeability

Tree shakeability refers to the ability of a build system to eliminate unused code during the bundling process. Functions are tree shakeable, while methods are not.

When functions are used in the Effect ecosystem, only the functions that are actually imported and used in your application will be included in the final bundled code. Unused functions are automatically removed, resulting in a smaller bundle size and improved performance.

On the other hand, methods are attached to objects or prototypes, and they cannot be easily tree shaken. Even if you only use a subset of methods, all methods associated with an object or prototype will be included in the bundle, leading to unnecessary code bloat.

### Extensibility

Another important advantage of using functions in the Effect ecosystem is the ease of extensibility. With methods, extending the functionality of an existing API often requires modifying the prototype of the object, which can be complex and error-prone.

In contrast, with functions, extending the functionality is much simpler. You can define your own "extension methods" as plain old functions without the need to modify the prototypes of objects. This promotes cleaner and more modular code, and it also allows for better compatibility with other libraries and modules.

<Idea>
  The use of functions in the Effect ecosystem libraries is important for
  achieving **tree shakeability** and ensuring **extensibility**. Functions
  enable efficient bundling by eliminating unused code, and they provide a
  flexible and modular approach to extending the libraries' functionality.
</Idea>

Now let's explore some examples of APIs that can be used with the `pipe` function to build pipelines.

## map

The `Effect.map` function is used to transform the value inside an `Effect`.
It takes a function and applies it to the value contained within the `Effect`, creating a **new** `Effect` with the transformed value.

**Usage of Effect.map**

The syntax for `Effect.map` is as follows:

```ts
import { Effect, pipe } from 'effect';

const mappedEffect = pipe(myEffect, Effect.map(transformation));
// or
const mappedEffect = Effect.map(myEffect, transformation);
// or
const mappedEffect = myEffect.pipe(Effect.map(transformation));
```

In the code above, `transformation` is the function applied to the value, and `myEffect` is the `Effect` being transformed.

<Info>
  It's important to note that `Effect`s are immutable, meaning that when you
  use `Effect.map` on an `Effect`, it doesn't modify the original data type.
  Instead, it returns a new copy of the `Effect` with the transformed value.
</Info>

**Example**

Consider a program that adds a small service charge to a transaction:

```ts twoslash
import { Effect, pipe } from 'effect';

// Function to add a small service charge to a transaction amount
const addServiceCharge = (amount: number) => amount + 1;

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

// Apply service charge to the transaction amount
const finalAmount = pipe(fetchTransactionAmount, Effect.map(addServiceCharge));

Effect.runPromise(finalAmount).then(console.log); // Output: 101
```

## as

To map an `Effect` to a constant value, replacing the original value, use `Effect.as`:

```ts twoslash
import { Effect, pipe } from 'effect';

const program = pipe(Effect.succeed(5), Effect.as('new value'));

Effect.runPromise(program).then(console.log); // Output: "new value"
```

## flatMap

The `Effect.flatMap` function is used when you need to chain transformations that produce `Effect` instances. This is useful for asynchronous operations or computations that depend on the results of previous effects.

**Usage of Effect.flatMap**

The `Effect.flatMap` function enables you to sequence computations that result in new `Effect` values, "flattening" any nested `Effect` structures that arise.

The syntax for `Effect.flatMap` is as follows:

```ts
import { Effect, pipe } from 'effect';

const flatMappedEffect = pipe(myEffect, Effect.flatMap(transformation));
// or
const flatMappedEffect = Effect.flatMap(myEffect, transformation);
// or
const flatMappedEffect = myEffect.pipe(Effect.flatMap(transformation));
```

In the code above, `transformation` is the function that takes a value and returns an `Effect`, and `myEffect` is the initial `Effect` being transformed.

<Info>
  It's important to note that `Effect`s are immutable, meaning that when you
  use `Effect.flatMap` on an `Effect`, it doesn't modify the original data
  type. Instead, it returns a new copy of the `Effect` with the transformed
  value.
</Info>

**Example**

```ts twoslash
import { Effect, pipe } from 'effect';

// Function to apply a discount safely to a transaction amount
const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

const finalAmount = pipe(
  fetchTransactionAmount,
  Effect.flatMap((amount) => applyDiscount(amount, 5)),
);

Effect.runPromise(finalAmount).then(console.log); // Output: 95
```

**Ensuring All Effects Are Considered**

It's vital to ensure that all effects within `Effect.flatMap` contribute to the final computation.
Neglecting any effect can lead to unexpected behaviors or incorrect outcomes:

```ts {1}
Effect.flatMap((amount) => {
  Effect.sync(() => console.log(`Apply a discount to: ${amount}`)); // This effect is ignored
  return applyDiscount(amount, 5);
});
```

The `Effect.sync` above is ignored and does not influence the result of `applyDiscount(amount, 5)`.
To include effects properly and avoid errors, explicitly chain them using functions like `Effect.map`, `Effect.flatMap`, `Effect.andThen`, or `Effect.tap`.

**Further Information on `flatMap`**

Although many developers may recognize `flatMap` from its usage with arrays, in the `Effect` framework, it's utilized to manage and resolve nested `Effect` structures.
If your goal is to flatten nested arrays within an Effect (`Effect<Array<Array<A>>>`), this can be done using:

```ts twoslash
import { Array, Effect, pipe } from 'effect';

const flattened = pipe(
  Effect.succeed([
    [1, 2],
    [3, 4],
  ]),
  Effect.map((nested) => Array.flatten(nested)),
);
```

or using the standard `Array.prototype.flat()` method.

## andThen

Both the `Effect.map` and `Effect.flatMap` functions serve to transform an `Effect` into another `Effect` in two different scenarios.
In the first scenario, `Effect.map` is used when the transformation function does not return an `Effect`, while in the second scenario,
`Effect.flatMap` is used when the transformation function still returns an `Effect`.
However, since both scenarios involve transformations, the Effect module also exposes a convenient all-in-one solution to use: `Effect.andThen`.

The `Effect.andThen` function executes a sequence of two actions, typically two `Effect`s, where the second action can depend on the result of the first action.

```ts
import { Effect, pipe } from 'effect';

const transformedEffect = pipe(myEffect, Effect.andThen(anotherEffect));
// or
const transformedEffect = Effect.andThen(myEffect, anotherEffect);
// or
const transformedEffect = myEffect.pipe(Effect.andThen(anotherEffect));
```

The `anotherEffect` action can take various forms:

- a value
- a function returning a value (i.e. same functionality of `Effect.map`)
- a `Promise`
- a function returning a `Promise`
- an `Effect`
- a function returning an `Effect`(i.e. same functionality of `Effect.flatMap`)

**Example**

Let's see an example where we can compare the use of `Effect.andThen` instead of `Effect.map` and `Effect.flatMap`:

```ts
import { Effect, pipe } from 'effect';

// Function to apply a discount safely to a transaction amount
const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

// Using Effect.map, Effect.flatMap
const result1 = pipe(
  fetchTransactionAmount,
  Effect.map((amount) => amount * 2),
  Effect.flatMap((amount) => applyDiscount(amount, 5)),
);

Effect.runPromise(result1).then(console.log); // Output: 190

// Using Effect.andThen
const result2 = pipe(
  fetchTransactionAmount,
  Effect.andThen((amount) => amount * 2),
  Effect.andThen((amount) => applyDiscount(amount, 5)),
);

Effect.runPromise(result2).then(console.log); // Output: 190
```

## tap

The `Effect.tap` API has a similar signature to `Effect.flatMap`, but the result of the transformation function is **ignored**.
This means that the value returned by the previous computation will still be available for the next computation.

**Example**

```ts twoslash
import { Effect, pipe } from 'effect';

// Function to apply a discount safely to a transaction amount
const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

const finalAmount = pipe(
  fetchTransactionAmount,
  Effect.tap((amount) =>
    Effect.sync(() => console.log(`Apply a discount to: ${amount}`))
  ),
  // `amount` is still available!
  Effect.flatMap((amount) => applyDiscount(amount, 5)),
);

Effect.runPromise(finalAmount).then(console.log);
/*
Output:
Apply a discount to: 100
95
*/
```

Using `Effect.tap` allows us to execute side effects during the computation without altering the result.
This can be useful for logging, performing additional actions, or observing the intermediate values without interfering with the main computation flow.

## all

The `Effect.all` function is a powerful utility provided by Effect that allows you to combine multiple effects into a single effect that produces a tuple of results.

**Usage of Effect.all**

The syntax for `Effect.all` is as follows:

```ts
import { Effect } from "effect"

const combinedEffect = Effect.all([effect1, effect2, ...])
```

The `Effect.all` function will execute all these effects in **sequence** (to explore options for
managing concurrency and controlling how these effects are executed, you can
refer to the [Concurrency Options](../concurrency/concurrency-options)
documentation).

It will return a new effect that produces a tuple containing the results of each individual effect.
Keep in mind that the order of the results corresponds to the order of the original effects passed to `Effect.all`.

**Example**

```ts twoslash
import { Effect } from 'effect';

// Simulated function to read configuration from a file
const webConfig = Effect.promise(() =>
  Promise.resolve({ dbConnection: 'localhost', port: 8080 })
);

// Simulated function to test database connectivity
const checkDatabaseConnectivity = Effect.promise(() =>
  Promise.resolve('Connected to Database')
);

// Combine both effects to perform startup checks
const startupChecks = Effect.all([webConfig, checkDatabaseConnectivity]);

Effect.runPromise(startupChecks).then(([config, dbStatus]) => {
  console.log(
    `Configuration: ${JSON.stringify(config)}, DB Status: ${dbStatus}`,
  );
});
/*
Output:
Configuration: {"dbConnection":"localhost","port":8080}, DB Status: Connected to Database
*/
```

<Info>
  The `Effect.all` function not only combines tuples but also works with
  iterables, structs, and records. To explore the full potential of `all` head
  over to the [Introduction to Effect's Control Flow
  Operators](../control-flow#all) documentation.
</Info>

## Build your first pipeline

Now, let's combine `pipe`, `Effect.all` and `Effect.andThen` to build a pipeline that performs a series of transformations:

```ts twoslash
import { Effect, pipe } from 'effect';

// Function to add a small service charge to a transaction amount
const addServiceCharge = (amount: number) => amount + 1;

// Function to apply a discount safely to a transaction amount
const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

// Simulated asynchronous task to fetch a discount rate from a configuration file
const fetchDiscountRate = Effect.promise(() => Promise.resolve(5));

// Assembling the program using a pipeline of effects
const program = pipe(
  Effect.all([fetchTransactionAmount, fetchDiscountRate]),
  Effect.flatMap(([transactionAmount, discountRate]) =>
    applyDiscount(transactionAmount, discountRate)
  ),
  Effect.map(addServiceCharge),
  Effect.map((finalAmount) => `Final amount to charge: ${finalAmount}`),
);

// Execute the program and log the result
Effect.runPromise(program).then(console.log); // Output: "Final amount to charge: 96"
```

## The pipe method

Effect provides a `pipe` method that works similarly to the `pipe` method found in [rxjs](https://rxjs.dev/api/index/function/pipe). This method allows you to chain multiple operations together, making your code more concise and readable.

Here's how the `pipe` **method** works:

```ts
const result = effect.pipe(func1, func2, ..., funcN)
```

This is equivalent to using the `pipe` **function** like this:

```ts
const result = pipe(effect, func1, func2, ..., funcN)
```

The `pipe` method is available on all effects and many other data types, eliminating the need to import the `pipe` function from the `Function` module and saving you some keystrokes.

Let's rewrite the previous example using the `pipe` method:

```ts twoslash
import { Effect } from 'effect';

const addServiceCharge = (amount: number) => amount + 1;

const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

const fetchDiscountRate = Effect.promise(() => Promise.resolve(5));

// ---cut---
const program = Effect.all([fetchTransactionAmount, fetchDiscountRate]).pipe(
  Effect.flatMap(([transactionAmount, discountRate]) =>
    applyDiscount(transactionAmount, discountRate)
  ),
  Effect.map(addServiceCharge),
  Effect.map((finalAmount) => `Final amount to charge: ${finalAmount}`),
);
```

## Cheatsheet

Let's summarize the transformation functions we have seen so far:

| **Function** | **Input**                                 | **Output**                  |
| ------------ | ----------------------------------------- | --------------------------- |
| `map`        | `Effect<A, E, R>`, `A => B`               | `Effect<B, E, R>`           |
| `flatMap`    | `Effect<A, E, R>`, `A => Effect<B, E, R>` | `Effect<B, E, R>`           |
| `andThen`    | `Effect<A, E, R>`, \*                     | `Effect<B, E, R>`           |
| `tap`        | `Effect<A, E, R>`, `A => Effect<B, E, R>` | `Effect<A, E, R>`           |
| `all`        | `[Effect<A, E, R>, Effect<B, E, R>, ...]` | `Effect<[A, B, ...], E, R>` |

These functions are powerful tools for transforming and chaining `Effect` computations. They allow you to apply functions to values inside `Effect` and build complex pipelines of computations.

# The Effect Type

---

## title: The Effect Typeexcerpt: Explore the `Effect<Success, Error, Requirements>` type in the Effect ecosystem, representing an immutable, lazy description of a workflow or job. Understand its type parameters and conceptualize it as an effectful program. Learn how to interpret `Effect` values with the Effect Runtime System for effectful interactions with the external world.bottomNavigation: pagination

The `Effect<Success, Error, Requirements>` type represents an **immutable** value that **lazily** describes a workflow or job.

This type encapsulates the logic of a program, defining whether it succeeds, providing a value of type `Success`, or fails, resulting in an error of type `Error`. Additionally, the program requires a collection of contextual data `Context<Requirements>` to execute.

Conceptually, you can think of `Effect<Success, Error, Requirements>` as an effectful version of the following function type:

```ts
type Effect<Success, Error, Requirements> = (
  context: Context<Requirements>,
) => Error | Success;
```

However, effects are not actually functions. They can model synchronous, asynchronous, concurrent, and resourceful computations.

## Type Parameters

The `Effect` type has three type parameters with the following meanings:

- **Success**. Represents the type of value that an effect can succeed with when executed.
  If this type parameter is `void`, it means the effect produces no useful information, while if it is `never`, it means the effect runs forever (or until failure).
- **Error**. Represents the expected errors that can occur when executing an effect.
  If this type parameter is `never`, it means the effect cannot fail, because there are no values of type `never`.
- **Requirements**. Represents the contextual data required by the effect to be executed.
  This data is stored in a collection named `Context`.
  If this type parameter is `never`, it means the effect has no requirements and the `Context` collection is empty.

<Info>
  In the Effect ecosystem, you may often encounter the type parameters of
  `Effect` abbreviated as `A`, `E`, and `R` respectively. This is just
  shorthand for the success value of type **A**, **E**rror, and
  **R**equirements.
</Info>

`Effect` values are immutable, and all Effect functions produce new `Effect` values.

`Effect` values do not actually do anything, they are just values that model or describe effectful interactions.

An `Effect` can be interpreted by the Effect Runtime System into effectful interactions with the external world. Ideally, this occurs at a single entry point in our application where the effectful interactions are initiated, such as the starting point of your program's execution.

# Effect Essentials

---

## title: Effect Essentialsexcerpt: Effect Essentialscollapsible: truebottomNavigation: childCards

# Using Generators in Effect

---

## title: Using Generators in Effectexcerpt: Explore the syntax of using generators in Effect to write effectful code. Learn about the `Effect.gen` function. Compare `Effect.gen` with `async`/`await` for writing asynchronous code. Understand how generators enhance control flow, handle errors, and utilize short-circuiting in effectful programs. Discover passing references to `this` in generator functions.bottomNavigation: pagination

In the previous sections, we learned how to [create](./creating-effects) effects and [execute](./running-effects) them. Now, it's time to write our first simple program.

Effect offers a convenient syntax, similar to `async`/`await`, to write effectful code using [generators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator).

<Idea>
  The use of generators is an **optional feature** in Effect. If you find
  generators unfamiliar or prefer a different coding style, you can explore
  the documentation about [Building Pipelines](./pipeline) in Effect.
</Idea>

## Understanding Effect.gen

The `Effect.gen` utility simplifies the task of writing effectful code by utilizing JavaScript's generator functions. This method helps your code appear and behave more like traditional synchronous code, which enhances both readability and error management.

Let's explore a practical program that performs a series of data transformations commonly found in application logic:

```ts twoslash
import { Effect } from 'effect';

// Function to add a small service charge to a transaction amount
const addServiceCharge = (amount: number) => amount + 1;

// Function to apply a discount safely to a transaction amount
const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

// Simulated asynchronous task to fetch a transaction amount from a database
const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

// Simulated asynchronous task to fetch a discount rate from a configuration file
const fetchDiscountRate = Effect.promise(() => Promise.resolve(5));

// Assembling the program using a generator function
const program = Effect.gen(function* () {
  // Retrieve the transaction amount
  const transactionAmount = yield* fetchTransactionAmount;

  // Retrieve the discount rate
  const discountRate = yield* fetchDiscountRate;

  // Calculate discounted amount
  const discountedAmount = yield* applyDiscount(
    transactionAmount,
    discountRate,
  );

  // Apply service charge
  const finalAmount = addServiceCharge(discountedAmount);

  // Return the total amount after applying the charge
  return `Final amount to charge: ${finalAmount}`;
});

// Execute the program and log the result
Effect.runPromise(program).then(console.log); // Output: "Final amount to charge: 96"
```

Key steps to follow when using `Effect.gen`:

- Wrap your logic in `Effect.gen`
- Use `yield*` to handle effects
- Return the final result

<Warning>
  The generator API is only available when using the `downlevelIteration` flag
  or with a `target` of `"es2015"` or higher in your `tsconfig.json` file
</Warning>

## Comparing Effect.gen with async/await

If you are familiar with `async`/`await`, you may notice that the flow of writing code is similar.

Let's compare the two approaches:

<Tabs items={['Using Effect.gen', 'Using async / await']}>
<Tab>

```ts twoslash
import { Effect } from 'effect';
// ---cut---
const addServiceCharge = (amount: number) => amount + 1;

const applyDiscount = (
  total: number,
  discountRate: number,
): Effect.Effect<number, Error> =>
  discountRate === 0
    ? Effect.fail(new Error('Discount rate cannot be zero'))
    : Effect.succeed(total - (total * discountRate) / 100);

const fetchTransactionAmount = Effect.promise(() => Promise.resolve(100));

const fetchDiscountRate = Effect.promise(() => Promise.resolve(5));

export const program = Effect.gen(function* () {
  const transactionAmount = yield* fetchTransactionAmount;
  const discountRate = yield* fetchDiscountRate;
  const discountedAmount = yield* applyDiscount(
    transactionAmount,
    discountRate,
  );
  const finalAmount = addServiceCharge(discountedAmount);
  return `Final amount to charge: ${finalAmount}`;
});
```

</Tab>
  <Tab>

```ts twoslash
const addServiceCharge = (amount: number) => amount + 1;

const applyDiscount = (
  total: number,
  discountRate: number,
): Promise<number> =>
  discountRate === 0
    ? Promise.reject(new Error('Discount rate cannot be zero'))
    : Promise.resolve(total - (total * discountRate) / 100);

const fetchTransactionAmount = Promise.resolve(100);

const fetchDiscountRate = Promise.resolve(5);

export const program = async function () {
  const transactionAmount = await fetchTransactionAmount;
  const discountRate = await fetchDiscountRate;
  const discountedAmount = await applyDiscount(
    transactionAmount,
    discountRate,
  );
  const finalAmount = addServiceCharge(discountedAmount);
  return `Final amount to charge: ${finalAmount}`;
};
```

</Tab>
</Tabs>

It's important to note that although the code appears similar, the two programs are not identical. The purpose of comparing them side by side is just to highlight the resemblance in how they are written.

## Embracing Control Flow

One significant advantage of using `Effect.gen` in conjunction with generators is its capability to employ standard control flow constructs within the generator function. These constructs include `if`/`else`, `for`, `while`, and other branching and looping mechanisms, enhancing your ability to express complex control flow logic in your code.

```ts twoslash
import { Effect } from 'effect';

const calculateTax = (
  amount: number,
  taxRate: number,
): Effect.Effect<number, Error> =>
  taxRate > 0
    ? Effect.succeed((amount * taxRate) / 100)
    : Effect.fail(new Error('Invalid tax rate'));

const program = Effect.gen(function* () {
  let i = 1;

  while (true) {
    if (i === 10) {
      break; // Break the loop when counter reaches 10
    } else {
      if (i % 2 === 0) {
        // Calculate tax for even numbers
        console.log(yield* calculateTax(100, i));
      }
      i++;
      continue;
    }
  }
});

Effect.runPromise(program);
/*
Output:
2
4
6
8
*/
```

## Raising Errors

The `Effect.gen` API allows you to incorporate error handling directly into your program flow by yielding failed effects. This mechanism, achieved through `Effect.fail`, is demonstrated in the example below:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  console.log('Task1...');
  console.log('Task2...');
  // Introduce an error into the flow
  yield* Effect.fail('Something went wrong!');
});

Effect.runPromiseExit(program).then(console.log);
/*
Output:
Task1...
Task2...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Something went wrong!' }
}
*/
```

### The Role of Short-Circuiting

When working with the `Effect.gen` API, it's important to understand how it manages errors.
This API is designed to **short-circuit the execution** upon encountering the **first error**.

What does this mean for you as a developer? Well, let's say you have a chain of operations or a collection of effects to be executed in sequence. If any error occurs during the execution of one of these effects, the remaining computations will be skipped, and the error will be propagated to the final result.

In simpler terms, the short-circuiting behavior ensures that if something goes wrong at any step of your program it will immediately stop and return the error to let you know that something went wrong.

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  console.log('Task1...');
  console.log('Task2...');
  yield* Effect.fail('Something went wrong!');
  console.log("This won't be executed");
});

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
Task1...
Task2...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Something went wrong!' }
}
*/
```

<Info>
  If you want to dive deeper into effective error handling with Effect, you
  can explore the ["Error Management"](../error-management/two-error-types)
  section.
</Info>

## Passing this

In some cases, you might need to pass a reference to the current object (`this`) into the body of your generator function.
You can achieve this by utilizing an overload that accepts the reference as the first argument:

```ts twoslash
import { Effect } from 'effect';

class MyService {
  readonly local = 1;
  compute = Effect.gen(this, function* () {
    return yield* Effect.succeed(this.local + 1);
  });
}

console.log(Effect.runSync(new MyService().compute)); // Output: 2
```

# Importing Effect

---

## title: Importing Effectexcerpt: Start using Effect by installing the `effect` package and exploring module imports. Learn how to import the `Effect` module, understand namespace imports, and grasp the advantages of using functions over methods in the Effect ecosystem. Focus on essential functions to build a strong foundation for your journey with Effect.bottomNavigation: pagination

Welcome to Effect! If you're just getting started, you might feel overwhelmed by the variety of modules and functions that Effect offers.
However, rest assured that you don't need to worry about all of them right away.
In this guide, we will provide you with a simple orientation on how to import modules and functions and assure you that,
in most cases, installing the `effect` package is all you need to get started. Let's dive in!

## Installing Effect

To begin your journey with Effect, you first need to install the `effect` package. Open your terminal and run the following command:

<Tabs items={["npm", "pnpm", "yarn"]}>
<Tab>

```bash filename="Terminal"
npm install effect
```

</Tab>
<Tab>

```bash filename="Terminal"
pnpm add effect
```

</Tab>
<Tab>

```bash filename="Terminal"
yarn add effect
```

</Tab>
</Tabs>

By installing this single package, you gain access to the core functionality of Effect.

For more detailed installation instructions on other platforms like Deno or Bun, you can refer to the [Quickstart](../../quickstart) tutorial.
This will provide you with step-by-step guidance to set up Effect on different environments.

## Importing Modules and Functions

Once you have installed the `effect` package, you can start using its modules and functions in your projects.
Importing modules and functions is straightforward and follows the standard JavaScript/TypeScript import syntax.

To import a module or a function from the `effect` package, simply use the `import` statement at the top of your file. Here's how you can import the `Effect` module:

```ts
import { Effect } from 'effect';
```

Now, you have access to the `Effect` module, which is the heart of the Effect library. It provides various functions to create, compose, and manipulate effectful computations.

## Namespace imports

In addition to importing the `Effect` module with a named import, as shown previously:

```ts
import { Effect } from 'effect';
```

You can also import it using a namespace import like this:

```ts
import * as Effect from 'effect/Effect';
```

Both forms of import allow you to access the functionalities provided by the `Effect` module.

However an important consideration is **tree shaking**, which refers to a process that eliminates unused code during the bundling of your application.
Named imports may generate tree shaking issues when a bundler doesn't support deep scope analysis.

Here are some bundlers that support deep scope analysis and thus don't have issues with named imports:

- Rollup
- Webpack 5+

## Functions vs Methods

In the Effect ecosystem, libraries often expose functions rather than methods. This design choice is important for two key reasons: tree shakeability and extendibility.

### Tree Shakeability

Tree shakeability refers to the ability of a build system to eliminate unused code during the bundling process. Functions are tree shakeable, while methods are not.

When functions are used in the Effect ecosystem, only the functions that are actually imported and used in your application will be included in the final bundled code. Unused functions are automatically removed, resulting in a smaller bundle size and improved performance.

On the other hand, methods are attached to objects or prototypes, and they cannot be easily tree shaken. Even if you only use a subset of methods, all methods associated with an object or prototype will be included in the bundle, leading to unnecessary code bloat.

### Extendibility

Another important advantage of using functions in the Effect ecosystem is the ease of extendibility. With methods, extending the functionality of an existing API often requires modifying the prototype of the object, which can be complex and error-prone.

In contrast, with functions, extending the functionality is much simpler. You can define your own "extension methods" as plain old functions without the need to modify the prototypes of objects. This promotes cleaner and more modular code, and it also allows for better compatibility with other libraries and modules.

<Idea>
  The use of functions in the Effect ecosystem libraries is important for
  achieving **tree shakeability** and ensuring **extendibility**. Functions
  enable efficient bundling by eliminating unused code, and they provide a
  flexible and modular approach to extending the libraries' functionality.
</Idea>

## Commonly Used Functions

As you start your adventure with Effect, you don't need to dive into every function in the `effect` package right away. Instead, focus on some commonly used functions that will provide a solid foundation for your journey into the world of Effect.

In the upcoming guides, we will explore some of these essential functions, specifically those for creating and running `Effect`s and building pipelines.

But before we dive into those, let's start from the very heart of Effect: understanding the `Effect` type. This will lay the groundwork for your understanding of how Effect brings composability, type safety, and error handling into your applications.

So, let's take the first step and explore the fundamental concepts of the [The Effect Type](the-effect-type).

# Batching

---

## title: Batchingexcerpt: Effect is a powerful TypeScript library designed to help developers easily create complex, synchronous, and asynchronous programs.bottomNavigation: pagination

## Classic Approach to API Integration

In typical application development, when interacting with external APIs, databases, or other data sources, we often define functions that perform requests and handle their results or failures accordingly.

### Simple Model Setup

Here's a basic model that outlines the structure of our data and possible errors:

```twoslash include Model
export interface User {
  readonly _tag: "User"
  readonly id: number
  readonly name: string
  readonly email: string
}

export class GetUserError {
  readonly _tag = "GetUserError"
}

export interface Todo {
  readonly _tag: "Todo"
  readonly id: number
  readonly message: string
  readonly ownerId: number
}

export class GetTodosError {
  readonly _tag = "GetTodosError"
}

export class SendEmailError {
  readonly _tag = "SendEmailError"
}
```

```ts filename="Model.ts" twoslash
// @include: Model
```

<Idea>
  In a real world scenario we may want to use a more precise types instead of
  directly using primitives for identifiers (see [Branded
  Types](style/branded-types)). Additionally, you may want to include more
  detailed information in the errors.
</Idea>

### Defining API Functions

Let's define functions that interact with an external API, handling common operations such as fetching todos, retrieving user details, and sending emails.

```twoslash include API
import { Effect } from "effect"
import * as Model from "./Model"

// Fetches a list of todos from an external API
export const getTodos = Effect.tryPromise({
  try: () =>
    fetch("https://api.example.demo/todos").then(
      (res) => res.json() as Promise<Array<Model.Todo>>
    ),
  catch: () => new Model.GetTodosError()
})

// Retrieves a user by their ID from an external API
export const getUserById = (id: number) =>
  Effect.tryPromise({
    try: () =>
      fetch(`https://api.example.demo/getUserById?id=${id}`).then(
        (res) => res.json() as Promise<Model.User>
      ),
    catch: () => new Model.GetUserError()
  })

// Sends an email via an external API
export const sendEmail = (address: string, text: string) =>
  Effect.tryPromise({
    try: () =>
      fetch("https://api.example.demo/sendEmail", {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({ address, text })
      }).then((res) => res.json() as Promise<void>),
    catch: () => new Model.SendEmailError()
  })

// Sends an email to a user by fetching their details first
export const sendEmailToUser = (id: number, message: string) =>
  getUserById(id).pipe(
    Effect.andThen((user) => sendEmail(user.email, message))
  )

// Notifies the owner of a todo by sending them an email
export const notifyOwner = (todo: Model.Todo) =>
  getUserById(todo.ownerId).pipe(
    Effect.andThen((user) =>
      sendEmailToUser(user.id, `hey ${user.name} you got a todo!`)
    )
  )
```

```ts filename="API.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// ---cut---
// @include: API
```

<Idea>
  In a real-world scenario, you might not want to trust your APIs to always
  return the expected data - for this, you can use `@effect/schema` or similar
  alternatives such as `zod`.
</Idea>

While this approach is straightforward and readable, it may not be the most efficient. Repeated API calls, especially when many todos share the same owner, can significantly increase network overhead and slow down your application.

### Using the API Functions

While these functions are clear and easy to understand, their use may not be the most efficient. For example, notifying todo owners involves repeated API calls which can be optimized.

```ts filename="index.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as API from './API';

// Orchestrates operations on todos, notifying their owners
const program = Effect.gen(function* () {
  const todos = yield* API.getTodos;
  yield* Effect.forEach(todos, (todo) => API.notifyOwner(todo), {
    concurrency: 'unbounded',
  });
});
```

This implementation performs an API call for each todo to fetch the owner's details and send an email. If multiple todos have the same owner, this results in redundant API calls.

### Improving Efficiency with Batch Calls

To optimize, consider implementing batch API calls if your backend supports them. This reduces the number of HTTP requests by grouping multiple operations into a single request, thereby enhancing performance and reducing load.

**Next Steps:**

Refactor your API interactions to use batch processing where possible. This not only reduces server load but also streamlines the handling of data, keeping your code both efficient and clean.

## Batching

Batching API calls can drastically improve the performance of your application by reducing the number of HTTP requests.

Let's assume that `getUserById` and `sendEmail` can be batched. This means that we can send multiple requests in a single HTTP call, reducing the number of API requests and improving performance.

**Step-by-Step Guide to Batching**

1. **Structuring Requests:** We'll start by transforming our requests into structured data models. This involves detailing input parameters, expected outputs, and possible errors. Structuring requests this way not only helps in efficiently managing data but also in comparing different requests to understand if they refer to the same input parameters.

2. **Defining Resolvers:** Resolvers are designed to handle multiple requests simultaneously. By leveraging the ability to compare requests (ensuring they refer to the same input parameters), resolvers can execute several requests in one go, maximizing the utility of batching.

3. **Creating Queries:** Finally, we'll define queries that utilize these batch-resolvers to perform operations. This step ties together the structured requests and their corresponding resolvers into functional components of the application.

**Important Considerations**

It's crucial for the requests to be modeled in a way that allows them to be comparable. This means implementing comparability (using methods like [Equals.equals](../other/trait/equal)) to identify and batch identical requests effectively.

### Declaring Requests

Let's start by defining a structured model for the types of requests our data sources can handle. We'll design a model using the concept of a `Request` that a data source might support.

A `Request<Value, Error>` is a construct representing a request for a value of type `Value`, which might fail with an error of type `Error`.

```twoslash include Requests
import { Request } from "effect"
import * as Model from "./Model"

// Define a request to get multiple Todo items which might fail with a GetTodosError
export interface GetTodos
  extends Request.Request<Array<Model.Todo>, Model.GetTodosError> {
  readonly _tag: "GetTodos"
}

// Create a tagged constructor for GetTodos requests
export const GetTodos = Request.tagged<GetTodos>("GetTodos")

// Define a request to fetch a User by ID which might fail with a GetUserError
export interface GetUserById
  extends Request.Request<Model.User, Model.GetUserError> {
  readonly _tag: "GetUserById"
  readonly id: number
}

// Create a tagged constructor for GetUserById requests
export const GetUserById = Request.tagged<GetUserById>("GetUserById")

// Define a request to send an email which might fail with a SendEmailError
export interface SendEmail
  extends Request.Request<void, Model.SendEmailError> {
  readonly _tag: "SendEmail"
  readonly address: string
  readonly text: string
}

// Create a tagged constructor for SendEmail requests
export const SendEmail = Request.tagged<SendEmail>("SendEmail")

// Combine all requests into a union type for easier management
export type ApiRequest = GetTodos | GetUserById | SendEmail
```

```ts filename="Requests.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: Requests.ts
// ---cut---
// @include: Requests
```

Each request is defined with a specific data structure that extends from a generic `Request` type, ensuring that each request carries its unique data requirements along with a specific error type.

By using tagged constructors like `Request.tagged`, we can easily instantiate request objects that are recognizable and manageable throughout the application.

### Declaring Resolvers

After defining our requests, the next step is configuring how Effect resolves these requests using `RequestResolver`. A `RequestResolver<A, R>` requires an environment `R` and is capable of executing requests of type `A`.

In this section, we'll create individual resolvers for each type of request. The granularity of your resolvers can vary, but typically, they are divided based on the batching capabilities of the corresponding API calls.

```twoslash include Resolvers
import { Effect, RequestResolver, Request } from "effect"
import * as API from "./API"
import * as Model from "./Model"
import * as Requests from "./Requests"

// Assuming GetTodos cannot be batched, we create a standard resolver.
export const GetTodosResolver = RequestResolver.fromEffect(
  (request: Requests.GetTodos) => API.getTodos
)

// Assuming GetUserById can be batched, we create a batched resolver.
export const GetUserByIdResolver = RequestResolver.makeBatched(
  (requests: ReadonlyArray<Requests.GetUserById>) =>
    Effect.tryPromise({
      try: () =>
        fetch("https://api.example.demo/getUserByIdBatch", {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            users: requests.map(({ id }) => ({ id }))
          })
        }).then((res) => res.json()) as Promise<Array<Model.User>>,
      catch: () => new Model.GetUserError()
    }).pipe(
      Effect.andThen((users) =>
        Effect.forEach(requests, (request, index) =>
          Request.completeEffect(request, Effect.succeed(users[index]))
        )
      ),
      Effect.catchAll((error) =>
        Effect.forEach(requests, (request) =>
          Request.completeEffect(request, Effect.fail(error))
        )
      )
    )
)

// Assuming SendEmail can be batched, we create a batched resolver.
export const SendEmailResolver = RequestResolver.makeBatched(
  (requests: ReadonlyArray<Requests.SendEmail>) =>
    Effect.tryPromise({
      try: () =>
        fetch("https://api.example.demo/sendEmailBatch", {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            emails: requests.map(({ address, text }) => ({ address, text }))
          })
        }).then((res) => res.json() as Promise<void>),
      catch: () => new Model.SendEmailError()
    }).pipe(
      Effect.andThen(
        Effect.forEach(requests, (request) =>
          Request.completeEffect(request, Effect.void)
        )
      ),
      Effect.catchAll((error) =>
        Effect.forEach(requests, (request) =>
          Request.completeEffect(request, Effect.fail(error))
        )
      )
    )
)
```

```ts filename="Resolvers.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// ---cut---
// @include: Resolvers
```

<Info>
  Resolvers can also access the context like any other `Effect`, and there are
  many different ways to create resolvers. For further details, consider
  exploring the reference documentation for the
  [RequestResolver](https://effect-ts.github.io/effect/effect/RequestResolver.ts.html)
  module.
</Info>

In this configuration:

- **GetTodosResolver** handles the fetching of multiple Todo items. It's set up as a standard resolver since we assume it cannot be batched.
- **GetUserByIdResolver** and **SendEmailResolver** are configured as batched resolvers. This setup is based on the assumption that these requests can be processed in batches, enhancing performance and reducing the number of API calls.

### Defining Queries

Now that we've set up our resolvers, we're ready to tie all the pieces together to define our queries. This step will enable us to perform data operations effectively within our application.

```twoslash include Queries
import { Effect } from "effect"
import * as Model from "./Model"
import * as Requests from "./Requests"
import * as Resolvers from "./Resolvers"

// Defines a query to fetch all Todo items
export const getTodos: Effect.Effect<
  Array<Model.Todo>,
  Model.GetTodosError
> = Effect.request(Requests.GetTodos({}), Resolvers.GetTodosResolver)

// Defines a query to fetch a user by their ID
export const getUserById = (id: number) =>
  Effect.request(
    Requests.GetUserById({ id }),
    Resolvers.GetUserByIdResolver
  )

// Defines a query to send an email to a specific address
export const sendEmail = (address: string, text: string) =>
  Effect.request(
    Requests.SendEmail({ address, text }),
    Resolvers.SendEmailResolver
  )

// Composes getUserById and sendEmail to send an email to a specific user
export const sendEmailToUser = (id: number, message: string) =>
  getUserById(id).pipe(
    Effect.andThen((user) => sendEmail(user.email, message))
  )

// Uses getUserById to fetch the owner of a Todo and then sends them an email notification
export const notifyOwner = (todo: Model.Todo) =>
  getUserById(todo.ownerId).pipe(
    Effect.andThen((user) =>
      sendEmailToUser(user.id, `hey ${user.name} you got a todo!`)
    )
  )
```

```ts filename="Queries.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// ---cut---
// @include: Queries
```

By using the `Effect.request` function, we integrate the resolvers with the request model effectively. This approach ensures that each query is optimally resolved using the appropriate resolver.

Although the code structure looks similar to earlier examples, employing resolvers significantly enhances efficiency by optimizing how requests are handled and reducing unnecessary API calls.

```ts filename="index.ts" {7} twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// @include: Queries

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as Queries from './Queries';

const program = Effect.gen(function* () {
  const todos = yield* Queries.getTodos;
  yield* Effect.forEach(todos, (todo) => Queries.notifyOwner(todo), {
    batching: true,
  });
});
```

In the final setup, this program will execute only **3** queries to the APIs, regardless of the number of todos. This contrasts sharply with the traditional approach, which would potentially execute **1 + 2n** queries, where **n** is the number of todos. This represents a significant improvement in efficiency, especially for applications with a high volume of data interactions.

### Disabling Batching

Batching can be locally disabled using the `Effect.withRequestBatching` utility in the following way:

```ts filename="index.ts" {9} twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// @include: Queries

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as Queries from './Queries';

const program = Effect.gen(function* () {
  const todos = yield* Queries.getTodos;
  yield* Effect.forEach(todos, (todo) => Queries.notifyOwner(todo), {
    concurrency: 'unbounded',
  });
}).pipe(Effect.withRequestBatching(false));
```

### Resolvers with Context

In complex applications, resolvers often need access to shared services or configurations to handle requests effectively. However, maintaining the ability to batch requests while providing the necessary context can be challenging. Here, we'll explore how to manage context in resolvers to ensure that batching capabilities are not compromised.

When creating request resolvers, it's crucial to manage the context carefully. Providing too much context or providing varying services to resolvers can make them incompatible for batching. To prevent such issues, the context for the resolver used in `Effect.request` is explicitly set to `never`. This forces developers to clearly define how the context is accessed and used within resolvers.

Consider the following example where we set up an HTTP service that the resolvers can use to execute API calls:

```twoslash include ResolversWithContext
import { Effect, Context, RequestResolver } from "effect"
import * as Model from "./Model"
import * as Requests from "./Requests"

export class HttpService extends Context.Tag("HttpService")<
  HttpService,
  { fetch: typeof fetch }
>() {}

export const GetTodosResolver =
  // we create a normal resolver like we did before
  RequestResolver.fromEffect((request: Requests.GetTodos) =>
    Effect.andThen(HttpService, (http) =>
      Effect.tryPromise({
        try: () =>
          http
            .fetch("https://api.example.demo/todos")
            .then((res) => res.json() as Promise<Array<Model.Todo>>),
        catch: () => new Model.GetTodosError()
      })
    )
  ).pipe(
    // we list the tags that the resolver can access
    RequestResolver.contextFromServices(HttpService)
  )
```

```ts filename="ResolversWithContext.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: ResolversWithContext.ts
// ---cut---
// @include: ResolversWithContext
```

We can see now that the type of `GetTodosResolver` is no longer a `RequestResolver` but instead it is:

```ts
Effect<RequestResolver<GetTodos, never>, never, HttpService>;
```

which is an `Effect` that access the `HttpService` and returns a composed resolver that has the minimal context ready to use.

Once we have such `Effect` we can directly use it in our query definition:

```ts filename="QueriesWithContext.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: ResolversWithContext.ts
// @include: ResolversWithContext

// @filename: QueriesWithContext.ts
// ---cut---
import { Effect } from 'effect';
import * as Model from './Model';
import * as Requests from './Requests';
import * as ResolversWithContext from './ResolversWithContext';

export const getTodos = Effect.request(
  Requests.GetTodos({}),
  ResolversWithContext.GetTodosResolver,
);
```

We can see that the Effect correctly requires `HttpService` to be provided.

Alternatively you can create `RequestResolver`s as part of layers direcly accessing or closing over context from construction.

For example:

```ts filename="QueriesFromLayers.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: ResolversWithContext.ts
// @include: ResolversWithContext

// @filename: QueriesFromLayers.ts
// ---cut---
import { Context, Effect, Layer, RequestResolver } from 'effect';
import * as API from './API';
import * as Model from './Model';
import * as Requests from './Requests';
import * as ResolversWithContext from './ResolversWithContext';

export class TodosService extends Context.Tag('TodosService')<
  TodosService,
  {
    getTodos: Effect.Effect<Array<Model.Todo>, Model.GetTodosError>;
  }
>() {}

export const TodosServiceLive = Layer.effect(
  TodosService,
  Effect.gen(function* () {
    const http = yield* ResolversWithContext.HttpService;
    const resolver = RequestResolver.fromEffect(
      (request: Requests.GetTodos) =>
        Effect.tryPromise<Array<Model.Todo>, Model.GetTodosError>({
          try: () =>
            http
              .fetch('https://api.example.demo/todos')
              .then((res) => res.json()),
          catch: () => new Model.GetTodosError(),
        }),
    );
    return {
      getTodos: Effect.request(Requests.GetTodos({}), resolver),
    };
  }),
);

export const getTodos: Effect.Effect<
  Array<Model.Todo>,
  Model.GetTodosError,
  TodosService
> = Effect.andThen(TodosService, (service) => service.getTodos);
```

This way is probably the best for most of the cases given that layers are the natural primitive where to wire services together.

## Caching

While we have significantly optimized request batching, there's another area that can enhance our application's efficiency: caching. Without caching, even with optimized batch processing, the same requests could be executed multiple times, leading to unnecessary data fetching.

In the Effect library, caching is handled through built-in utilities that allow requests to be stored temporarily, preventing the need to re-fetch data that hasn't changed. This feature is crucial for reducing the load on both the server and the network, especially in applications that make frequent similar requests.

Here's how you can implement caching for the `getUserById` query:

```ts {9} filename="Queries.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// ---cut---
import { Effect } from 'effect';
import * as Requests from './Requests';
import * as Resolvers from './Resolvers';

export const getUserById = (id: number) =>
  Effect.request(
    Requests.GetUserById({ id }),
    Resolvers.GetUserByIdResolver,
  ).pipe(Effect.withRequestCaching(true));
```

## Final Program

Assuming you've wired everything up correctly:

```ts filename="index.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// @include: Queries

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import * as Queries from './Queries';

const program = Effect.gen(function* () {
  const todos = yield* Queries.getTodos;
  yield* Effect.forEach(todos, (todo) => Queries.notifyOwner(todo), {
    concurrency: 'unbounded',
  });
}).pipe(Effect.repeat(Schedule.fixed('10 seconds')));
```

With this program, the `getTodos` operation retrieves the todos for each user. Then, the `Effect.forEach` function is used to notify the owner of each todo concurrently, without waiting for the notifications to complete.

The `repeat` function is applied to the entire chain of operations, and it ensures that the program repeats every 10 seconds using a fixed schedule. This means that the entire process, including fetching todos and sending notifications, will be executed repeatedly with a 10-second interval.

The program incorporates a caching mechanism, which prevents the same `GetUserById` operation from being executed more than once within a span of 1 minute. This default caching behavior helps optimize the program's execution and reduces unnecessary requests to fetch user data.

Furthermore, the program is designed to send emails in batches, allowing for efficient processing and better utilization of resources.

## Customizing Request Caching

In real-world applications, effective caching strategies can significantly improve performance by reducing redundant data fetching. The Effect library provides flexible caching mechanisms that can be tailored for specific parts of your application or applied globally.

There may be scenarios where different parts of your application have unique caching requirementsâ€”some might benefit from a localized cache, while others might need a global cache setup. Letâ€™s explore how you can configure a custom cache to meet these varied needs.

### Creating a Custom Cache

Here's how you can create a custom cache and apply it to part of your application. This example demonstrates setting up a cache that repeats a task every 10 seconds, caching requests with specific parameters like capacity and TTL (time-to-live).

```ts filename="index.ts" twoslash
// @filename: Model.ts
// @include: Model

// @filename: API.ts
// @include: API

// @filename: Requests.ts
// @include: Requests

// @filename: Resolvers.ts
// @include: Resolvers

// @filename: Queries.ts
// @include: Queries

// @filename: index.ts
// ---cut---
import { Effect, Layer, Request, Schedule } from 'effect';
import * as Queries from './Queries';

const program = Effect.gen(function* () {
  const todos = yield* Queries.getTodos;
  yield* Effect.forEach(todos, (todo) => Queries.notifyOwner(todo), {
    concurrency: 'unbounded',
  });
}).pipe(
  Effect.repeat(Schedule.fixed('10 seconds')),
  Effect.provide(
    Layer.setRequestCache(
      Request.makeCache({ capacity: 256, timeToLive: '60 minutes' }),
    ),
  ),
);
```

### Direct Cache Application

You can also construct a cache using `Request.makeCache` and apply it directly to a specific program using `Effect.withRequestCache`. This method ensures that all requests originating from the specified program are managed through the custom cache, provided that caching is enabled.

# Ref

---

## title: Refexcerpt: Learn how to leverage Effect's `Ref` data type for efficient state management in your programs. Understand the importance of managing state in dynamic applications and the challenges posed by traditional approaches. Dive into the powerful capabilities of `Ref`, a mutable reference that provides a controlled way to handle mutable state and ensure safe updates in a concurrent environment. Explore practical examples, from simple counters to complex scenarios involving shared state and concurrent interactions. Enhance your programming skills by mastering the effective use of `Ref` for state management in your Effect programs.bottomNavigation: pagination

When we write programs, it is common to need to keep track of some form of state during the execution of the program. State refers to any data that can change as the program runs. For example, in a counter application, the count value changes as the user increments or decrements it. Similarly, in a banking application, the account balance changes as deposits and withdrawals are made. State management is crucial to building interactive and dynamic applications.

In traditional imperative programming, one common way to store state is using variables. However, this approach can introduce bugs, especially when the state is shared between multiple components or functions. As the program becomes more complex, managing shared state can become challenging.

To overcome these issues, Effect introduces a powerful data type called `Ref`, which represents a mutable reference. With `Ref`, we can share state between different parts of our program without relying on mutable variables directly. Instead, `Ref` provides a controlled way to handle mutable state and safely update it in a concurrent environment.

Effect's `Ref` data type enables communication between different fibers in your program. This capability is crucial in concurrent programming, where multiple tasks may need to access and update shared state simultaneously.

In this guide, we will explore how to use the `Ref` data type to manage state in your programs effectively. We will cover simple examples like counting, as well as more complex scenarios where state is shared between different parts of the program. Additionally, we will show how to use `Ref` in a concurrent environment, allowing multiple tasks to interact with shared state safely.

Let's dive in and see how we can leverage `Ref` for effective state management in your Effect programs.

## Using Ref

Let's explore how to use the `Ref` data type with a simple example of a counter:

```twoslash include Counter
import { Effect, Ref } from "effect"

export class Counter {
  inc: Effect.Effect<void>
  dec: Effect.Effect<void>
  get: Effect.Effect<number>

  constructor(private value: Ref.Ref<number>) {
    this.inc = Ref.update(this.value, (n) => n + 1)
    this.dec = Ref.update(this.value, (n) => n - 1)
    this.get = Ref.get(this.value)
  }
}

export const make = Effect.andThen(Ref.make(0), (value) => new Counter(value))
```

```ts filename="Counter.ts" twoslash
// @include: Counter
```

Here is the usage example of the `Counter`:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: Counter.ts
// @include: Counter

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as Counter from './Counter';

const program = Effect.gen(function* () {
  const counter = yield* Counter.make;
  yield* counter.inc;
  yield* counter.inc;
  yield* counter.dec;
  yield* counter.inc;
  const value = yield* counter.get;
  console.log(`This counter has a value of ${value}.`);
});

Effect.runPromise(program);
/*
Output:
This counter has a value of 2.
*/
```

</Tab>
<Tab>

```ts twoslash
// @filename: Counter.ts
// @include: Counter

// @filename: index.ts
// ---cut---
import { Console, Effect } from 'effect';
import * as Counter from './Counter';

const program = Counter.make.pipe(
  Effect.andThen((counter) =>
    counter.inc.pipe(
      Effect.andThen(counter.inc),
      Effect.andThen(counter.dec),
      Effect.andThen(counter.inc),
      Effect.andThen(counter.get),
      Effect.andThen((value) =>
        Console.log(`This counter has a value of ${value}.`)
      ),
    )
  ),
);

Effect.runPromise(program);
/*
This counter has a value of 2.
*/
```

</Tab>
</Tabs>

<Info>
  All the operations on the `Ref` data type are effectful. So when we are
  reading from or writing to a `Ref`, we are performing an effectful
  operation.
</Info>

## Using Ref in a Concurrent Environment

We can use this counter in a concurrent environment, such as counting the number of requests in a RESTful API.
For this example, let's update the counter concurrently:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: Counter.ts
// @include: Counter

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as Counter from './Counter';

const program = Effect.gen(function* () {
  const counter = yield* Counter.make;

  const logCounter = <R, E, A>(
    label: string,
    effect: Effect.Effect<A, E, R>,
  ) =>
    Effect.gen(function* () {
      const value = yield* counter.get;
      yield* Effect.log(`${label} get: ${value}`);
      return yield* effect;
    });

  yield* logCounter('task 1', counter.inc).pipe(
    Effect.zip(logCounter('task 2', counter.inc), { concurrent: true }),
    Effect.zip(logCounter('task 3', counter.dec), { concurrent: true }),
    Effect.zip(logCounter('task 4', counter.inc), { concurrent: true }),
  );
  const value = yield* counter.get;
  yield* Effect.log(`This counter has a value of ${value}.`);
});

Effect.runPromise(program);
/*
Output:
... fiber=#2 message="task 4 get: 0"
... fiber=#4 message="task 3 get: 1"
... fiber=#5 message="task 1 get: 0"
... fiber=#5 message="task 2 get: 1"
... fiber=#0 message="This counter has a value of 2."
*/
```

</Tab>
<Tab>

```ts twoslash
// @filename: Counter.ts
// @include: Counter

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import * as Counter from './Counter';

const program = Counter.make.pipe(
  Effect.andThen((counter) => {
    const logCounter = <R, E, A>(
      label: string,
      effect: Effect.Effect<A, E, R>,
    ) =>
      counter.get.pipe(
        Effect.andThen((value) => Effect.log(`${label} get: ${value}`)),
        Effect.andThen(effect),
      );

    return logCounter('task 1', counter.inc).pipe(
      Effect.zip(logCounter('task 2', counter.inc), { concurrent: true }),
      Effect.zip(logCounter('task 3', counter.dec), { concurrent: true }),
      Effect.zip(logCounter('task 4', counter.inc), { concurrent: true }),
      Effect.andThen(counter.get),
      Effect.andThen((value) =>
        Effect.log(`This counter has a value of ${value}.`)
      ),
    );
  }),
);

Effect.runPromise(program);
/*
Output:
... fiber=#2 message="task 4 get: 0"
... fiber=#4 message="task 3 get: 1"
... fiber=#5 message="task 1 get: 0"
... fiber=#5 message="task 2 get: 1"
... fiber=#0 message="This counter has a value of 2."
*/
```

</Tab>
</Tabs>

## Using Ref as a Service

You can also pass a `Ref` as a [service](../context-management/services) to share state between different parts of your program. Let's see how this works:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Context, Effect, Ref } from 'effect';

// Create a Tag for our state
class MyState extends Context.Tag('MyState')<MyState, Ref.Ref<number>>() {}

// Subprogram 1: Increment the state value twice
const subprogram1 = Effect.gen(function* () {
  const state = yield* MyState;
  yield* Ref.update(state, (n) => n + 1);
  yield* Ref.update(state, (n) => n + 1);
});

// Subprogram 2: Decrement the state value and then increment it
const subprogram2 = Effect.gen(function* () {
  const state = yield* MyState;
  yield* Ref.update(state, (n) => n - 1);
  yield* Ref.update(state, (n) => n + 1);
});

// Subprogram 3: Read and log the current value of the state
const subprogram3 = Effect.gen(function* () {
  const state = yield* MyState;
  const value = yield* Ref.get(state);
  console.log(`MyState has a value of ${value}.`);
});

// Compose subprograms 1, 2, and 3 to create the main program
const program = Effect.gen(function* () {
  yield* subprogram1;
  yield* subprogram2;
  yield* subprogram3;
});

// Create a Ref instance with an initial value of 0
const initialState = Ref.make(0);

// Provide the Ref as a service
const runnable = Effect.provideServiceEffect(program, MyState, initialState);

// Run the program and observe the output
Effect.runPromise(runnable);
/*
Output:
MyState has a value of 2.
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Context, Effect, Ref } from 'effect';

// Create a Tag for our state
class MyState extends Context.Tag('MyState')<MyState, Ref.Ref<number>>() {}

// Subprogram 1: Increment the state value twice
const subprogram1 = MyState.pipe(
  Effect.tap((state) => Ref.update(state, (n) => n + 1)),
  Effect.andThen((state) => Ref.update(state, (n) => n + 1)),
);

// Subprogram 2: Decrement the state value and then increment it
const subprogram2 = MyState.pipe(
  Effect.tap((state) => Ref.update(state, (n) => n - 1)),
  Effect.andThen((state) => Ref.update(state, (n) => n + 1)),
);

// Subprogram 3: Read and log the current value of the state
const subprogram3 = MyState.pipe(
  Effect.andThen((state) => Ref.get(state)),
  Effect.andThen((value) => Console.log(`MyState has a value of ${value}.`)),
);

// Compose subprograms 1, 2, and 3 to create the main program
const program = subprogram1.pipe(
  Effect.andThen(subprogram2),
  Effect.andThen(subprogram3),
);

// Create a Ref instance with an initial value of 0
const initialState = Ref.make(0);

// Provide the Ref as a service
const runnable = Effect.provideServiceEffect(program, MyState, initialState);

// Run the program and observe the output
Effect.runPromise(runnable);
/*
Output:
MyState has a value of 2.
*/
```

</Tab>
</Tabs>

Note that we use `Effect.provideServiceEffect` instead of `Effect.provideService` to provide an actual implementation of the `MyState` service because all the operations on the `Ref` data type are effectful, including the creation `Ref.make(0)`.

## Sharing state between Fibers

Let's consider an example where we want to read names from user input until the user enters the command `"q"` to exit.

First, let's introduce a `readLine` utility to read user input (ensure you have `@types/node` installed):

```twoslash include ReadLine
// @types: node
import { Effect } from "effect"
import * as NodeReadLine from "node:readline"

export const readLine = (
  message: string
): Effect.Effect<string> =>
  Effect.promise(
    () =>
      new Promise((resolve) => {
        const rl = NodeReadLine.createInterface({
          input: process.stdin,
          output: process.stdout
        })
        rl.question(message, (answer) => {
          rl.close()
          resolve(answer)
        })
      })
  )
```

```ts filename="ReadLine.ts" twoslash
// @include: ReadLine
```

Now, let's take a look at the main program:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: ReadLine.ts
// @include: ReadLine

// @filename: index.ts
// ---cut---
import { Chunk, Effect, Ref } from 'effect';
import * as ReadLine from './ReadLine';

const getNames = Effect.gen(function* () {
  const ref = yield* Ref.make(Chunk.empty<string>());
  while (true) {
    const name = yield* ReadLine.readLine(
      'Please enter a name or `q` to exit: ',
    );
    if (name === 'q') {
      break;
    }
    yield* Ref.update(ref, (state) => Chunk.append(state, name));
  }
  return yield* Ref.get(ref);
});

Effect.runPromise(getNames).then(console.log);
/*
Output:
Please enter a name or `q` to exit: Alice
Please enter a name or `q` to exit: Bob
Please enter a name or `q` to exit: q
{
  _id: "Chunk",
  values: [ "Alice", "Bob" ]
}
*/
```

</Tab>
<Tab>

```ts twoslash
// @filename: ReadLine.ts
// @include: ReadLine

// @filename: index.ts
// ---cut---
import { Chunk, Effect, Ref } from 'effect';
import * as ReadLine from './ReadLine';

const getNames = Ref.make(Chunk.empty<string>()).pipe(
  Effect.andThen((ref) =>
    ReadLine.readLine('Please enter a name or `q` to exit: ').pipe(
      Effect.repeat({
        while: (name) => {
          if (name === 'q') {
            return Effect.succeed(false);
          } else {
            return ref.pipe(
              Ref.update((state) => Chunk.append(state, name)),
              Effect.as(true),
            );
          }
        },
      }),
      Effect.andThen(Ref.get(ref)),
    )
  ),
);

Effect.runPromise(getNames).then(console.log);
/*
Output:
Please enter a name or `q` to exit: Alice
Please enter a name or `q` to exit: Bob
Please enter a name or `q` to exit: q
{
  _id: "Chunk",
  values: [ "Alice", "Bob" ]
}
*/
```

</Tab>
</Tabs>

Now that we have learned how to use the `Ref` data type, we can use it to manage the state concurrently. For example, assume while we are reading from the console, we have another fiber that is trying to update the state from a different source:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: ReadLine.ts
// @include: ReadLine

// @filename: index.ts
// ---cut---
import { Chunk, Effect, Fiber, Ref } from 'effect';
import * as ReadLine from './ReadLine';

const getNames = Effect.gen(function* () {
  const ref = yield* Ref.make(Chunk.empty<string>());
  const fiber1 = yield* Effect.fork(
    Effect.gen(function* () {
      while (true) {
        const name = yield* ReadLine.readLine(
          'Please enter a name or `q` to exit: ',
        );
        if (name === 'q') {
          break;
        }
        yield* Ref.update(ref, (state) => Chunk.append(state, name));
      }
    }),
  );
  const fiber2 = yield* Effect.fork(
    Effect.gen(function* () {
      for (const name of ['John', 'Jane', 'Joe', 'Tom']) {
        yield* Ref.update(ref, (state) => Chunk.append(state, name));
        yield* Effect.sleep('1 second');
      }
    }),
  );
  yield* Fiber.join(fiber1);
  yield* Fiber.join(fiber2);
  return yield* Ref.get(ref);
});

Effect.runPromise(getNames).then(console.log);
/*
Output:
Please enter a name or `q` to exit: Alice
Please enter a name or `q` to exit: Bob
Please enter a name or `q` to exit: q
{
  _id: "Chunk",
  values: [ ... ]
}
*/
```

</Tab>
<Tab>

```ts twoslash
// @filename: ReadLine.ts
// @include: ReadLine

// @filename: index.ts
// ---cut---
import { Chunk, Effect, Fiber, Ref } from 'effect';
import * as ReadLine from './ReadLine';

const getNames = Ref.make(Chunk.empty<string>()).pipe(
  Effect.andThen((ref) => {
    const fiber1 = ReadLine.readLine(
      'Please enter a name or `q` to exit: ',
    ).pipe(
      Effect.repeat({
        while: (name) => {
          if (name === 'q') {
            return Effect.succeed(false);
          } else {
            return ref.pipe(
              Ref.update((state) => Chunk.append(state, name)),
              Effect.as(true),
            );
          }
        },
      }),
      Effect.fork,
    );
    const fiber2 = Effect.fork(
      Effect.forEach(
        ['John', 'Jane', 'Joe', 'Tom'],
        (name) =>
          ref.pipe(
            Ref.update((state) => Chunk.append(state, name)),
            Effect.andThen(Effect.sleep('1 second')),
          ),
        { concurrency: 'unbounded', discard: true },
      ),
    );
    return Effect.all([fiber1, fiber2]).pipe(
      Effect.andThen(([f1, f2]) =>
        Fiber.join(f1).pipe(Effect.andThen(Fiber.join(f2)))
      ),
      Effect.andThen(Ref.get(ref)),
    );
  }),
);

Effect.runPromise(getNames).then(console.log);
/*
Output:
Please enter a name or `q` to exit: Alice
Please enter a name or `q` to exit: Bob
Please enter a name or `q` to exit: q
{
  _id: "Chunk",
  values: [ ... ]
}
*/
```

</Tab>
</Tabs>

# State Management

---

## title: State Managementexcerpt: State Managementcollapsible: truebottomNavigation: childCards

# SynchronizedRef

---

## title: SynchronizedRefexcerpt: Discover the power of `SynchronizedRef` in Effect, a mutable reference enabling the atomic and effectful update of shared state. Building on the foundation of `Ref`, `SynchronizedRef` introduces the unique `updateEffect` function, allowing execution of effectful operations to modify the shared state. Dive into practical examples demonstrating the distinct capabilities of `SynchronizedRef`, such as parallel updates with consistent sequencing and real-world scenarios involving API requests and state updates. Elevate your understanding of concurrent state management with this advanced feature in Effect programming.bottomNavigation: pagination

`SynchronizedRef<A>` serves as a **mutable reference** to a value of type `A`. With it, we can store **immutable** data and perform updates **atomically and effectfully**.

<Info>
  Most of the operations for `SynchronizedRef` are similar to those of `Ref`.
  If you're not already familiar with `Ref`, it's recommended to read about
  [the Ref concept](ref) first.
</Info>

The distinctive function in `SynchronizedRef` is `updateEffect`. This function takes an **effectful operation** and executes it to modify the shared state. This is the key feature setting `SynchronizedRef` apart from `Ref`.

```ts twoslash
import { Effect, SynchronizedRef } from 'effect';

const program = Effect.gen(function* () {
  const ref = yield* SynchronizedRef.make('current');
  // Simulating an effectful update operation
  const updateEffect = Effect.succeed('update');
  yield* SynchronizedRef.updateEffect(ref, () => updateEffect);
  const value = yield* SynchronizedRef.get(ref);
  return value;
});

Effect.runPromise(program).then(console.log);
/*
Output:
update
*/
```

In real-world applications, there are scenarios where we need to execute an effect (e.g., querying a database) and then update the shared state accordingly. This is where `SynchronizedRef` shines, allowing us to update shared state in an actor-model fashion. We have a shared mutable state, but for each distinct command or message, we want to execute our effect and update the state.

We can pass an effectful program into every single update. All of these updates will be performed in parallel, but the results will be sequenced in such a way that they only affect the state at different times, resulting in a consistent state at the end.

In the following example, we send a `getAge` request for each user, updating the state accordingly:

```ts twoslash
import { Effect, SynchronizedRef } from 'effect';

// Simulate API
const getAge = (userId: number) => Effect.succeed({ userId, age: userId * 10 });

const users = [1, 2, 3, 4];

const meanAge = Effect.gen(function* () {
  const ref = yield* SynchronizedRef.make(0);

  const log = <R, E, A>(label: string, effect: Effect.Effect<A, E, R>) =>
    Effect.gen(function* () {
      const value = yield* SynchronizedRef.get(ref);
      yield* Effect.log(`${label} get: ${value}`);
      return yield* effect;
    });

  const task = (id: number) =>
    log(
      `task ${id}`,
      SynchronizedRef.updateEffect(ref, (sumOfAges) =>
        Effect.gen(function* () {
          const user = yield* getAge(id);
          return sumOfAges + user.age;
        })),
    );

  yield* task(1).pipe(
    Effect.zip(task(2), { concurrent: true }),
    Effect.zip(task(3), { concurrent: true }),
    Effect.zip(task(4), { concurrent: true }),
  );

  const value = yield* SynchronizedRef.get(ref);
  return value / users.length;
});

Effect.runPromise(meanAge).then(console.log);
/*
Output:
... fiber=#1 message="task 4 get: 0"
... fiber=#2 message="task 3 get: 40"
... fiber=#3 message="task 1 get: 70"
... fiber=#4 message="task 2 get: 80"
25
*/
```

# Repetition

---

## title: Repetitionexcerpt: Discover the significance of repetition in effect-driven software development with functions like `repeat` and `repeatOrElse`. Explore repeat policies, which enable you to execute effects multiple times according to specific criteria. Learn the syntax and examples of `repeat` and `repeatOrElse` for effective handling of repeated actions, including optional fallback strategies for errors.bottomNavigation: pagination

Repetition is a common requirement when working with effects in software development. It allows us to perform an effect multiple times according to a specific repetition policy.

## repeat

The `repeat` function returns a new effect that repeats the given effect according to a specified schedule or until the first failure. The scheduled recurrences are in addition to the initial execution, so `Effect.repeat(action, Schedule.once)` executes `action` once initially, and if it succeeds, repeats it an additional time.

**Success Example**

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const action = Console.log('success');

const policy = Schedule.addDelay(Schedule.recurs(2), () => '100 millis');

const program = Effect.repeat(action, policy);

Effect.runPromise(program).then((n) => console.log(`repetitions: ${n}`));
/*
Output:
success
success
success
repetitions: 2
*/
```

**Failure Example**

```ts twoslash
import { Effect, Schedule } from 'effect';

let count = 0;

// Define an async effect that simulates an action with possible failures
const action = Effect.async<string, string>((resume) => {
  if (count > 1) {
    console.log('failure');
    resume(Effect.fail('Uh oh!'));
  } else {
    count++;
    console.log('success');
    resume(Effect.succeed('yay!'));
  }
});

const policy = Schedule.addDelay(Schedule.recurs(2), () => '100 millis');

const program = Effect.repeat(action, policy);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
success
success
failure
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Uh oh!' }
}
*/
```

### Skipping the First Occurrence

If you want to skip the first occurrence of a repeat, you can use `Effect.schedule`:

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const action = Console.log('success');

const policy = Schedule.addDelay(Schedule.recurs(2), () => '100 millis');

const program = Effect.schedule(action, policy);

Effect.runPromise(program).then((n) => console.log(`repetitions: ${n}`));
/*
Output:
success
success
repetitions: 2
*/
```

## repeatN

The `repeatN` function returns a new effect that repeats the specified effect a given number of times or until the first failure. The repeats are in addition to the initial execution, so `Effect.repeatN(action, 1)` executes `action` once initially and then repeats it one additional time if it succeeds.

```ts twoslash
import { Console, Effect } from 'effect';

const action = Console.log('success');

const program = Effect.repeatN(action, 2);

Effect.runPromise(program);
/*
Output:
success
success
success
*/
```

## repeatOrElse

The `repeatOrElse` function returns a new effect that repeats the specified effect according to the given schedule or until the first failure. When a failure occurs, the failure value and schedule output are passed to a specified handler. Scheduled recurrences are in addition to the initial execution, so `Effect.repeat(action, Schedule.once)` executes `action` once initially and then repeats it an additional time if it succeeds.

```ts twoslash
import { Effect, Schedule } from 'effect';

let count = 0;

// Define an async effect that simulates an action with possible failures
const action = Effect.async<string, string>((resume) => {
  if (count > 1) {
    console.log('failure');
    resume(Effect.fail('Uh oh!'));
  } else {
    count++;
    console.log('success');
    resume(Effect.succeed('yay!'));
  }
});

const policy = Schedule.addDelay(
  Schedule.recurs(2), // Repeat for a maximum of 2 times
  () => '100 millis', // Add a delay of 100 milliseconds between repetitions
);

const program = Effect.repeatOrElse(action, policy, () =>
  Effect.sync(() => {
    console.log('orElse');
    return count - 1;
  }));

Effect.runPromise(program).then((n) => console.log(`repetitions: ${n}`));
/*
Output:
success
success
failure
orElse
repetitions: 1
*/
```

# Scheduling

---

## title: Schedulingexcerpt: Schedulingcollapsible: truebottomNavigation: childCards

# Schedule Combinators

---

## title: Schedule Combinatorsexcerpt: Explore the power of combining schedules in Effect to create sophisticated recurring patterns. Learn about key combinators such as `Union`, `Intersection`, and `Sequencing`. Witness the impact of `Jittering` on scheduling by introducing randomness to delays. Understand how to `Filter` inputs or outputs and modify delays with precision. Leverage `Tapping` to effectfully process each schedule input/output, providing insights into the execution flow. Elevate your understanding of schedules for efficient and flexible handling of effectful operations.bottomNavigation: pagination

Schedules define stateful, possibly effectful, recurring schedules of events, and compose in a variety of ways. Combinators allow us to take schedules and combine them together to get other schedules.

To demonstrate the functionality of different schedules, we will be working with the following helper:

```twoslash include Delay
import { Effect, Schedule, TestClock, Fiber, TestContext } from "effect"

let start = 0
let i = 0

export const log = <A, Out>(
  action: Effect.Effect<A>,
  schedule: Schedule.Schedule<Out, void>
) => {
  Effect.gen(function* () {
    const fiber: Fiber.RuntimeFiber<[Out, number]> = yield* Effect.gen(
      function* () {
        yield* action
        const now = yield* TestClock.currentTimeMillis
        console.log(
          i === 0
            ? `delay: ${now - start}`
            : i === 10
              ? "..."
              : `#${i} delay: ${now - start}`
        )
        i++
        start = now
      }
    ).pipe(
      Effect.repeat(schedule.pipe(Schedule.intersect(Schedule.recurs(10)))),
      Effect.fork
    )
    yield* TestClock.adjust(Infinity)
    yield* Fiber.join(fiber)
  }).pipe(Effect.provide(TestContext.TestContext), Effect.runPromise)
}
```

```ts
declare const log: <A, Out>(
  action: Effect.Effect<A>,
  schedule: Schedule.Schedule<Out, void>,
) => void;
```

<br/>
<details>
  <summary>Click to see the implementation</summary>

```ts filename="Delay.ts" twoslash
// @include: Delay
```

</details>

The `log` helper logs the time delay between each execution. We will use this helper to showcase the behavior of various built-in schedules.

<Warning>
The `log` helper accelerates time using [TestClock](../testing/testclock), which means it simulates the passing of time that would normally occur in a real-world application.
</Warning>

## Composition

Schedules compose in the following primary ways:

- **Union**. This performs the union of the intervals of two schedules.
- **Intersection**. This performs the intersection of the intervals of two schedules.
- **Sequencing**. This concatenates the intervals of one schedule onto another.

### Union

Combines two schedules through union, by recurring if either schedule wants to recur, using the minimum of the two delays between recurrences.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.union(
  Schedule.exponential('100 millis'),
  Schedule.spaced('1 second'),
);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 100  < exponential
#2 delay: 200
#3 delay: 400
#4 delay: 800
#5 delay: 1000 < spaced
#6 delay: 1000
#7 delay: 1000
#8 delay: 1000
#9 delay: 1000
...
*/
```

When we use the combined schedule with `Effect.repeat`, we observe that the effect is executed repeatedly based on the minimum delay between the two schedules. In this case, the delay alternates between the exponential schedule (increasing delay) and the spaced schedule (constant delay).

### Intersection

Combines two schedules through the intersection, by recurring only if both schedules want to recur, using the maximum of the two delays between recurrences.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.intersect(
  Schedule.exponential('10 millis'),
  Schedule.recurs(5),
);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 10  < exponential
#2 delay: 20
#3 delay: 40
#4 delay: 80
#5 delay: 160
(end)         < recurs
*/
```

When we use the combined schedule with `Effect.repeat`, we observe that the effect is executed repeatedly only if both schedules want it to recur. The delay between recurrences is determined by the maximum delay between the two schedules. In this case, the delay follows the progression of the exponential schedule until the maximum number of recurrences specified by the recursive schedule is reached.

### Sequencing

Combines two schedules sequentially, by following the first policy until it ends, and then following the second policy.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.andThen(
  Schedule.recurs(5),
  Schedule.spaced('1 second'),
);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 0    < recurs
#2 delay: 0
#3 delay: 0
#4 delay: 0
#5 delay: 0
#6 delay: 1000 < spaced
#7 delay: 1000
#8 delay: 1000
#9 delay: 1000
...
*/
```

When we use the combined schedule with `Effect.repeat`, we observe that the effect follows the policy of the first schedule (recurs) until it completes the specified number of recurrences. After that, it switches to the policy of the second schedule (spaced) and continues repeating the effect with the fixed delay between recurrences.

## Jittering

A `jittered` is a combinator that takes one schedule and returns another schedule of the same type except for the delay which is applied randomly

When a resource is out of service due to overload or contention, retrying and backing off doesn't help us. If all failed API calls are backed off to the same point of time, they cause another overload or contention. Jitter adds some amount of randomness to the delay of the schedule. This helps us to avoid ending up accidentally synchronizing and taking the service down by accident.

[Research](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/) shows that `Schedule.jittered(0.0, 1.0)` is very suitable for retrying.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.jittered(Schedule.exponential('10 millis'));
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 9.006765
#2 delay: 20.549507999999996
#3 delay: 45.86659000000001
#4 delay: 77.055037
#5 delay: 178.06722299999998
#6 delay: 376.056965
#7 delay: 728.732785
#8 delay: 1178.174953
#9 delay: 2331.4659370000004
...
*/
```

In this example, we use the `jittered` combinator to apply jitter to an exponential schedule. The exponential schedule increases the delay between each repetition exponentially. By adding jitter to the schedule, the delays become randomly adjusted within a certain range.

## Filtering

We can filter inputs or outputs of a schedule with `whileInput` and `whileOutput`.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.whileOutput(Schedule.recurs(5), (n) => n <= 2);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 0 < recurs
#2 delay: 0
#3 delay: 0
(end)       < whileOutput
*/
```

In this example, we create a schedule using `Schedule.recurs(5)` to repeat a certain action up to 5 times. However, we apply the `whileOutput` combinator with a predicate that filters out outputs greater than 2. As a result, the schedule stops producing outputs once the value exceeds 2, and the repetition ends.

## Modifying

Modifies the delay of a schedule.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.modifyDelay(
  Schedule.spaced('1 second'),
  (_) => '100 millis',
);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 100 < modifyDelay
#2 delay: 100
#3 delay: 100
#4 delay: 100
#5 delay: 100
#6 delay: 100
#7 delay: 100
#8 delay: 100
#9 delay: 100
...
*/
```

## Tapping

Whenever we need to effectfully process each schedule input/output, we can use `tapInput` and `tapOutput`.

We can use these two functions for logging purposes:

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Console, Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.tapOutput(
  Schedule.recurs(2),
  (n) => Console.log(`repeating ${n}`),
);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
repeating 0
#1 delay: 0
repeating 1
#2 delay: 0
repeating 2
*/
```

# Examples

---

## title: Examplesexcerpt: Practical Examples of Using SchedulebottomNavigation: pagination

## Making API Calls and Handling Timeouts

For our API calls to third-party services, we have a few requirements.
We want to ensure that if the entire function takes more than `4` seconds to execute, it's interrupted.
Additionally, we'll set up the system to retry the API call a maximum of `2` times.

**Solution**

```ts twoslash
import { NodeRuntime } from '@effect/platform-node';
import { Console, Effect } from 'effect';

const getJson = (url: string) =>
  Effect.tryPromise(() =>
    fetch(url).then((res) => {
      if (!res.ok) {
        console.log('error');
        throw new Error(res.statusText);
      }
      console.log('ok');
      return res.json() as unknown;
    })
  );

const program = (url: string) =>
  getJson(url).pipe(
    Effect.retry({ times: 2 }),
    Effect.timeout('4 seconds'),
    Effect.catchAll(Console.error),
  );

// testing the happy path
NodeRuntime.runMain(program('https://dummyjson.com/products/1?delay=1000'));
/*
Output:
ok
*/

// testing the timeout
// NodeRuntime.runMain(program("https://dummyjson.com/products/1?delay=5000"))
/*
Output:
TimeoutException
*/

// testing API errors
// NodeRuntime.runMain(
//   program("https://dummyjson.com/auth/products/1?delay=500")
// )
/*
Output:
error
error
error
UnknownException: Forbidden
*/
```

## Implementing Conditional Retries

We want to implement a mechanism to retry an API call only if it encounters certain types of errors.

**Solution**

```ts twoslash
import { NodeRuntime } from '@effect/platform-node';
import { Console, Effect } from 'effect';

class Err extends Error {
  constructor(
    message: string,
    readonly status: number,
  ) {
    super(message);
  }
}

const getJson = (url: string) =>
  Effect.tryPromise({
    try: () =>
      fetch(url).then((res) => {
        if (!res.ok) {
          console.log(res.status);
          throw new Err(res.statusText, res.status);
        }
        return res.json() as unknown;
      }),
    catch: (e) => e as Err,
  });

const program = (url: string) =>
  getJson(url).pipe(
    // Retry if the error is a 403
    Effect.retry({ while: (err) => err.status === 403 }),
    Effect.catchAll(Console.error),
  );

// testing 403
NodeRuntime.runMain(
  program('https://dummyjson.com/auth/products/1?delay=1000'),
);
/*
Output:
403
403
403
403
...
*/

// testing 404
// NodeRuntime.runMain(program("https://dummyjson.com/-"))
/*
Output:
404
Err [Error]: Not Found
*/
```

## Running Scheduled Effects Until Completion

We can use schedules to run an effect periodically until another long-running effect completes. This can be useful for tasks like polling or periodic logging.

**Solution**

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const longRunningEffect = Console.log('done').pipe(Effect.delay('5 seconds'));

const action = Console.log('action...');

const schedule = Schedule.fixed('1.5 seconds');

const program = Effect.race(
  Effect.repeat(action, schedule),
  longRunningEffect,
);

Effect.runPromise(program);
/*
Output:
action...
action...
action...
action...
done
*/
```

# Built-in Schedules

---

## title: Built-in Schedulesexcerpt: Unlock the power of scheduling in Effect with built-in schedules. Dive into various schedules like `forever`, `once`, and `recurs`, each offering unique recurrence patterns. Witness the behavior of `spaced` and `fixed` schedules, understanding how they space repetitions at specific intervals. Delve into advanced schedules like `exponential` and `fibonacci`, providing controlled recurrence with increasing delays. Master the art of scheduling for precise and efficient execution of effectful operations.bottomNavigation: pagination

To demonstrate the functionality of different schedules, we will be working with the following helper:

```twoslash include Delay
import { Effect, Schedule, TestClock, Fiber, TestContext } from "effect"

let start = 0
let i = 0

export const log = <A, Out>(
  action: Effect.Effect<A>,
  schedule: Schedule.Schedule<Out, void>
) => {
  Effect.gen(function* () {
    const fiber: Fiber.RuntimeFiber<[Out, number]> = yield* Effect.gen(
      function* () {
        yield* action
        const now = yield* TestClock.currentTimeMillis
        console.log(
          i === 0
            ? `delay: ${now - start}`
            : i === 10
              ? "..."
              : `#${i} delay: ${now - start}`
        )
        i++
        start = now
      }
    ).pipe(
      Effect.repeat(schedule.pipe(Schedule.intersect(Schedule.recurs(10)))),
      Effect.fork
    )
    yield* TestClock.adjust(Infinity)
    yield* Fiber.join(fiber)
  }).pipe(Effect.provide(TestContext.TestContext), Effect.runPromise)
}
```

```ts
declare const log: <A, Out>(
  action: Effect.Effect<A>,
  schedule: Schedule.Schedule<Out, void>,
) => void;
```

<br/>
<details>
  <summary>Click to see the implementation</summary>

```ts filename="Delay.ts" twoslash
// @include: Delay
```

</details>

The `log` helper logs the time delay between each execution. We will use this helper to showcase the behavior of various built-in schedules.

<Warning>
The `log` helper accelerates time using [TestClock](../testing/testclock), which means it simulates the passing of time that would normally occur in a real-world application.
</Warning>

## forever

A schedule that always recurs and produces number of recurrence at each run.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.forever;
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 0 < forever
#2 delay: 0
#3 delay: 0
#4 delay: 0
#5 delay: 0
#6 delay: 0
#7 delay: 0
#8 delay: 0
#9 delay: 0
...
*/
```

## once

A schedule that recurs one time.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.once;
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 0 < once
*/
```

## recurs

A schedule that only recurs the specified number of times.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.recurs(5);
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 0 < recurs
#2 delay: 0
#3 delay: 0
#4 delay: 0
#5 delay: 0
*/
```

## Recurring at specific intervals

In the context of scheduling, two commonly used schedules are `spaced` and `fixed`. While they both involve recurring at specific intervals, they have a fundamental difference in how they determine the timing of repetitions.

The `spaced` schedule creates a recurring pattern where each repetition is spaced apart by a specified duration. This means that there is a delay between the completion of one repetition and the start of the next. The duration between repetitions remains constant, providing a consistent spacing pattern.

On the other hand, the `fixed` schedule recurs on a fixed interval, regardless of the duration of the actions or the completion time of previous repetitions. It operates independently of the execution time, ensuring a regular recurrence at the specified interval.

### spaced

A schedule that recurs continuously, each repetition spaced the specified duration from the last run.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.spaced('200 millis');
const action = Effect.delay(Effect.void, '100 millis');
log(action, schedule);
/*
Output:
delay: 100
#1 delay: 300 < spaced
#2 delay: 300
#3 delay: 300
#4 delay: 300
#5 delay: 300
#6 delay: 300
#7 delay: 300
#8 delay: 300
#9 delay: 300
...
*/
```

The first delay is approximately 100 milliseconds, as the initial execution is not affected by the schedule. Subsequent delays are approximately 200 milliseconds apart, demonstrating the effect of the `spaced` schedule.

### fixed

A schedule that recurs on a fixed interval. Returns the number of repetitions of the schedule so far.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.fixed('200 millis');
const action = Effect.delay(Effect.void, '100 millis');
log(action, schedule);
/*
Output:
delay: 100
#1 delay: 300 < fixed
#2 delay: 200
#3 delay: 200
#4 delay: 200
#5 delay: 200
#6 delay: 200
#7 delay: 200
#8 delay: 200
#9 delay: 200
...
*/
```

The first delay is approximately 100 milliseconds, as the initial execution is not affected by the schedule. Subsequent delays are consistently around 200 milliseconds apart, demonstrating the effect of the `fixed` schedule.

## exponential

A schedule that recurs using exponential backoff

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.exponential('10 millis');
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 10 < exponential
#2 delay: 20
#3 delay: 40
#4 delay: 80
#5 delay: 160
#6 delay: 320
#7 delay: 640
#8 delay: 1280
#9 delay: 2560
...
*/
```

## fibonacci

A schedule that always recurs, increasing delays by summing the preceding two delays (similar to the fibonacci sequence). Returns the current duration between recurrences.

```ts twoslash
// @filename: Delay.ts
// @include: Delay

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { log } from './Delay';

const schedule = Schedule.fibonacci('10 millis');
const action = Effect.void;
log(action, schedule);
/*
Output:
delay: 0
#1 delay: 10 < fibonacci
#2 delay: 10
#3 delay: 20
#4 delay: 30
#5 delay: 50
#6 delay: 80
#7 delay: 130
#8 delay: 210
#9 delay: 340
...
*/
```

# Introduction to Scheduling

---

## title: Introduction to Schedulingexcerpt: Explore the fundamental concepts of scheduling in Effect using `Schedule<Out, In, Context>`. These immutable values define recurring patterns for executing effects based on input values and internal state. Learn about the composability of schedules, allowing you to create sophisticated recurrence patterns by combining and modifying existing schedules.bottomNavigation: pagination

Scheduling is an important concept in Effect that allows you to define recurring effectful operations. It involves the use of `Schedule<Out, In, Context>`, which is an **immutable value** that describes a scheduled pattern for executing effects.

A `Schedule` operates by consuming values of type `In` (such as errors in the case of `retry`, or values in the case of `repeat`) and producing values of type `Out`. It determines when to halt or continue the execution based on input values and its internal state.

The inclusion of a `Context` parameter allows the schedule to leverage additional services or resources as needed.

Schedules are defined as a collection of intervals spread out over time. Each interval represents a window during which the recurrence of an effect is possible.

## Retrying and Repetition

In the realm of scheduling, there are two related concepts: [Retrying](../error-management/retrying) and [Repetition](repetition). While they share the same underlying idea, they differ in their focus. Retrying aims to handle failures by executing an effect again, while repetition focuses on executing an effect repeatedly to achieve a desired outcome.

When using schedules for retrying or repetition, each interval's starting boundary determines when the effect will be executed again. For example, in retrying, if an error occurs, the schedule defines when the effect should be retried.

## Composability of Schedules

Schedules are composable, meaning you can combine simple schedules to create more complex recurrence patterns. Operators like `union` or `intersect` allow you to build sophisticated schedules by combining and modifying existing ones. This flexibility enables you to tailor the scheduling behavior to meet specific requirements.

# Default Services

---

## title: Default Servicesexcerpt: Explore the default services in Effect - Clock, Console, Random, ConfigProvider, and Tracer. Learn how Effect automatically provides live versions of these services, eliminating the need for explicit implementations in your programs.bottomNavigation: pagination

Effect comes equipped with five pre-built services:

```ts
type DefaultServices = Clock | Console | Random | ConfigProvider | Tracer;
```

When we employ these services, there's no need to explicitly provide their implementations. Effect automatically supplies live versions of these services to our effects, sparing us from manual setup.

```ts twoslash
import { Clock, Console, Effect } from 'effect';

const program = Effect.gen(function* () {
  const now = yield* Clock.currentTimeMillis;
  yield* Console.log(`Application started at ${new Date(now)}`);
});
```

As you can observe, even if our program utilizes both `Clock` and `Console`, the `Requirements` parameter, representing the services required for the effect to execute, remains set to `never`.
Effect takes care of handling these services seamlessly for us.

# Requirements Management

---

## title: Requirements Managementexcerpt: Requirements Managementcollapsible: truebottomNavigation: childCards

# Managing Layers

---

## title: Managing Layersexcerpt: Learn how to use Layers to control the construction of service dependencies and manage the "dependency graph" of your program more effectively.bottomNavigation: pagination

In the previous sections, you learned how to create effects which depend on some service to be provided in order to execute, as well as how to provide that service to an Effect.

However, what if we have a service within our effect program that has dependencies on other services in order to be built? We want to avoid leaking these implementation details into the service interface.

To represent the "dependency graph" of our program and manage these dependencies more effectively, we can utilize a powerful abstraction called **Layer**.

Layers act as **constructors** for creating services, allowing us to manage dependencies during construction rather than at the service level. This approach helps to keep our service interfaces clean and focused.

| **Concept** | **Description**                                                                                                           |
| ----------- | ------------------------------------------------------------------------------------------------------------------------- |
| **Service** | A reusable component providing specific functionality, used across different parts of an application.                     |
| **Tag**     | A unique identifier representing a **service**, allowing Effect to locate and use it.                                     |
| **Context** | A collection storing services, functioning like a map with **tags** as keys and **services** as values.                   |
| **Layer**   | An abstraction for constructing **services**, managing dependencies during construction rather than at the service level. |

In this guide, we will cover the following topics:

- Using Layers to control the construction of services.
- Building a dependency graph with Layers.
- Providing a Layer to an effect.

## Designing the Dependency Graph

Let's imagine that we are building a web application! We could imagine that the dependency graph for an application where we need to manage configuration, logging, and database access might look something like this:

- The `Config` service provides application configuration.
- The `Logger` service depends on the `Config` service.
- The `Database` service depends on both the `Config` and `Logger` services.

Our goal is to build the `Database` service along with its direct and indirect dependencies. This means we need to ensure that the `Config` service is available for both `Logger` and `Database`, and then provide these dependencies to the `Database` service.

Now let's take our dependency graph and translate it into code.

## Creating Layers

We will use Layers to construct the `Database` service instead of providing a service implementation directly as we did in the [Managing Services](services) guide. Layers are a way of separating implementation details from the service itself.

<Idea>
  When a service has its own requirements, it's best to separate
  implementation details into layers. Layers act as **constructors** for
  creating the service, allowing us to handle dependencies at the construction
  level rather than the service level.
</Idea>

A `Layer<RequirementsOut, Error, RequirementsIn>` represents a blueprint for constructing a `RequirementsOut`.
It takes a value of type `RequirementsIn` as input and may potentially produce an error of type `Error` during the construction process.

In our case, the `RequirementsOut` type represents the service we want to construct, while `RequirementsIn` represents the dependencies required for construction.

<Info>
  For simplicity, let's assume that we won't encounter any errors during the
  value construction (meaning `Error = never`).
</Info>

Now, let's determine how many layers we need to implement our dependency graph:

| **Layer**      | **Dependencies**                                           | **Type**                                   |
| -------------- | ---------------------------------------------------------- | ------------------------------------------ |
| `ConfigLive`   | The `Config` service does not depend on any other services | `Layer<Config>`                            |
| `LoggerLive`   | The `Logger` service depends on the `Config` service       | `Layer<Logger, never, Config>`             |
| `DatabaseLive` | The `Database` service depends on `Config` and `Logger`    | `Layer<Database, never, Config \| Logger>` |

<Idea>
  A common convention when naming the `Layer` for a particular service is to
  add a `Live` suffix for the "live" implementation and a `Test` suffix for
  the "test" implementation. For example, for a `Database` service, the
  `DatabaseLive` would be the layer you provide in your application and the
  `DatabaseTest` would be the layer you provide in your tests.
</Idea>

When a service has multiple dependencies, they are represented as a **union type**. In our case, the `Database` service depends on both the `Config` and `Logger` services. Therefore, the type for the `DatabaseLive` layer will be `Layer<Database, never, Config | Logger>`.

### Config

The `Config` service does not depend on any other services, so `ConfigLive` will be the simplest layer to implement. Just like in the [Managing Services](services) guide, we must create a `Tag` for the service. And because the service has no dependencies, we can create the layer directly using `Layer.succeed`:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

// Create a tag for the Config service
class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

const ConfigLive = Layer.succeed(
  Config,
  Config.of({
    getConfig: Effect.succeed({
      logLevel: 'INFO',
      connection: 'mysql://username:password@hostname:port/database_name',
    }),
  }),
);
```

Looking at the type of `ConfigLive` we can observe:

- `RequirementsOut` is `Config`, indicating that constructing the layer will produce a `Config` service
- `Error` is `never`, indicating that layer construction cannot fail
- `RequirementsIn` is `never`, indicating that the layer has no dependencies

Note that, to construct `ConfigLive`, we used the `Config.of`
constructor. However, this is merely a helper to ensure correct type inference
for the implementation. It's possible to skip this helper and construct the
implementation directly as a simple object:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

// ---cut---
const ConfigLive = Layer.succeed(Config, {
  getConfig: Effect.succeed({
    logLevel: 'INFO',
    connection: 'mysql://username:password@hostname:port/database_name',
  }),
});
```

### Logger

Now we can move on to the implementation of the `Logger` service, which depends on the `Config` service to retrieve some configuration.

Just like we did in the [Managing Services](services#using-the-service) guide, we can map over the `Config` tag to "extract" the service from the context.

Given that using the `Config` tag is an effectful operation, we use `Layer.effect` to create a `Layer` from the resulting `Effect`.

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

// ---cut---
class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

const LoggerLive = Layer.effect(
  Logger,
  Effect.gen(function* () {
    const config = yield* Config;
    return {
      log: (message) =>
        Effect.gen(function* () {
          const { logLevel } = yield* config.getConfig;
          console.log(`[${logLevel}] ${message}`);
        }),
    };
  }),
);
```

Looking at the type of `LoggerLive` we can observe:

- `RequirementsOut` is `Logger`
- `Error` is `never`, indicating that layer construction cannot fail
- `RequirementsIn` is `Config`, indicating that the layer has a requirement

### Database

Finally, we can use our `Config` and `Logger` services to implement the `Database` service.

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

// ---cut---
class Database extends Context.Tag('Database')<
  Database,
  { readonly query: (sql: string) => Effect.Effect<unknown> }
>() {}

const DatabaseLive = Layer.effect(
  Database,
  Effect.gen(function* () {
    const config = yield* Config;
    const logger = yield* Logger;
    return {
      query: (sql: string) =>
        Effect.gen(function* () {
          yield* logger.log(`Executing query: ${sql}`);
          const { connection } = yield* config.getConfig;
          return { result: `Results from ${connection}` };
        }),
    };
  }),
);
```

Looking at the type of `DatabaseLive` we can observe that the `RequirementsIn` type is `Config | Logger`, i.e., the `Database` service requires both `Config` and `Logger` services.

## Combining Layers

Layers can be combined in two primary ways: merging and composing.

### Merging Layers

Layers can be combined through merging using the `Layer.merge` combinator:

```ts
Layer.merge(layer1, layer2);
```

When we merge two layers, the resulting layer:

- requires all the services that both of them require.
- produces all services that both of them produce.

For example, in our web application above, we can merge our `ConfigLive` and `LoggerLive` layers into a single `AppConfigLive` layer, which retains the requirements of both layers (`never | Config = Config`) and the outputs of both layers (`Config | Logger`):

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

const ConfigLive = Layer.succeed(
  Config,
  Config.of({
    getConfig: Effect.succeed({
      logLevel: 'INFO',
      connection: 'mysql://username:password@hostname:port/database_name',
    }),
  }),
);

class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

const LoggerLive = Layer.effect(
  Logger,
  Effect.gen(function* () {
    const config = yield* Config;
    return {
      log: (message) =>
        Effect.gen(function* () {
          const { logLevel } = yield* config.getConfig;
          console.log(`[${logLevel}] ${message}`);
        }),
    };
  }),
);

// ---cut---
const AppConfigLive = Layer.merge(ConfigLive, LoggerLive);
```

### Composing Layers

Layers can be composed using the `Layer.provide` function:

```ts twoslash
import { Layer } from 'effect';

declare const inner: Layer.Layer<'OutInner', never, 'InInner'>;
declare const outer: Layer.Layer<'InInner', never, 'InOuter'>;

const composition = inner.pipe(Layer.provide(outer));
```

Sequential composition of layers implies that the output of one layer (`outer`) is supplied as the input for the inner layer (`inner`),
resulting in a single layer with the requirements of the first layer and the output of the second.

Now we can compose the `AppConfigLive` layer with the `DatabaseLive` layer:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

const ConfigLive = Layer.succeed(
  Config,
  Config.of({
    getConfig: Effect.succeed({
      logLevel: 'INFO',
      connection: 'mysql://username:password@hostname:port/database_name',
    }),
  }),
);

class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

const LoggerLive = Layer.effect(
  Logger,
  Effect.gen(function* () {
    const config = yield* Config;
    return {
      log: (message) =>
        Effect.gen(function* () {
          const { logLevel } = yield* config.getConfig;
          console.log(`[${logLevel}] ${message}`);
        }),
    };
  }),
);

class Database extends Context.Tag('Database')<
  Database,
  { readonly query: (sql: string) => Effect.Effect<unknown> }
>() {}

const DatabaseLive = Layer.effect(
  Database,
  Effect.gen(function* () {
    const config = yield* Config;
    const logger = yield* Logger;
    return {
      query: (sql: string) =>
        Effect.gen(function* () {
          yield* logger.log(`Executing query: ${sql}`);
          const { connection } = yield* config.getConfig;
          return { result: `Results from ${connection}` };
        }),
    };
  }),
);

// ---cut---
const AppConfigLive = Layer.merge(ConfigLive, LoggerLive);

const MainLive = DatabaseLive.pipe(
  // provides the config and logger to the database
  Layer.provide(AppConfigLive),
  // provides the config to AppConfigLive
  Layer.provide(ConfigLive),
);
```

### Merging and Composing Layers

Let's say we want our `MainLive` layer to return both the `Config` and `Database` services. We can achieve this with `Layer.provideMerge`:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

const ConfigLive = Layer.succeed(
  Config,
  Config.of({
    getConfig: Effect.succeed({
      logLevel: 'INFO',
      connection: 'mysql://username:password@hostname:port/database_name',
    }),
  }),
);

class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

const LoggerLive = Layer.effect(
  Logger,
  Effect.gen(function* () {
    const config = yield* Config;
    return {
      log: (message) =>
        Effect.gen(function* () {
          const { logLevel } = yield* config.getConfig;
          console.log(`[${logLevel}] ${message}`);
        }),
    };
  }),
);

class Database extends Context.Tag('Database')<
  Database,
  { readonly query: (sql: string) => Effect.Effect<unknown> }
>() {}

const DatabaseLive = Layer.effect(
  Database,
  Effect.gen(function* () {
    const config = yield* Config;
    const logger = yield* Logger;
    return {
      query: (sql: string) =>
        Effect.gen(function* () {
          yield* logger.log(`Executing query: ${sql}`);
          const { connection } = yield* config.getConfig;
          return { result: `Results from ${connection}` };
        }),
    };
  }),
);

// ---cut---
const AppConfigLive = Layer.merge(ConfigLive, LoggerLive);

const MainLive = DatabaseLive.pipe(
  Layer.provide(AppConfigLive),
  Layer.provideMerge(ConfigLive),
);
```

## Providing a Layer to an Effect

Now that we have assembled the fully resolved `MainLive` for our application,
we can provide it to our program to satisfy the program's requirements using `Effect.provide`:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class Config extends Context.Tag('Config')<
  Config,
  {
    readonly getConfig: Effect.Effect<{
      readonly logLevel: string;
      readonly connection: string;
    }>;
  }
>() {}

const ConfigLive = Layer.succeed(
  Config,
  Config.of({
    getConfig: Effect.succeed({
      logLevel: 'INFO',
      connection: 'mysql://username:password@hostname:port/database_name',
    }),
  }),
);

class Logger extends Context.Tag('Logger')<
  Logger,
  { readonly log: (message: string) => Effect.Effect<void> }
>() {}

const LoggerLive = Layer.effect(
  Logger,
  Effect.gen(function* () {
    const config = yield* Config;
    return {
      log: (message) =>
        Effect.gen(function* () {
          const { logLevel } = yield* config.getConfig;
          console.log(`[${logLevel}] ${message}`);
        }),
    };
  }),
);

class Database extends Context.Tag('Database')<
  Database,
  { readonly query: (sql: string) => Effect.Effect<unknown> }
>() {}

const DatabaseLive = Layer.effect(
  Database,
  Effect.gen(function* () {
    const config = yield* Config;
    const logger = yield* Logger;
    return {
      query: (sql: string) =>
        Effect.gen(function* () {
          yield* logger.log(`Executing query: ${sql}`);
          const { connection } = yield* config.getConfig;
          return { result: `Results from ${connection}` };
        }),
    };
  }),
);

const AppConfigLive = Layer.merge(ConfigLive, LoggerLive);

const MainLive = DatabaseLive.pipe(
  Layer.provide(AppConfigLive),
  Layer.provide(ConfigLive),
);

// ---cut---
const program = Effect.gen(function* () {
  const database = yield* Database;
  const result = yield* database.query('SELECT * FROM users');
  return yield* Effect.succeed(result);
});

const runnable = Effect.provide(program, MainLive);

Effect.runPromise(runnable).then(console.log);
/*
Output:
[INFO] Executing query: SELECT * FROM users
{
  result: 'Results from mysql://username:password@hostname:port/database_name'
}
*/
```

# Layer Memoization

---

## title: Layer Memoizationexcerpt: Understand the power of layer memoization in Effect. Discover how layers can be efficiently created once and reused in the dependency graph, optimizing performance. Explore global and local memoization strategies, and learn to manually memoize layers for precise control in your Effect applications.bottomNavigation: pagination

Layer memoization allows a layer to be created once and used multiple times in the dependency graph. If we use the same layer twice, for example

```ts
Layer.merge(Layer.provide(b, a), Layer.provide(c, a));
```

then the `a` layer will be allocated only once.

## Memoization When Providing Globally

One important feature of an Effect application is that layers are shared by default. This means that if the same layer is used twice, and if we provide the layer globally, the layer will only be allocated a single time. For every layer in our dependency graph, there is only one instance of it that is shared between all the layers that depend on it.

For example, assume we have the three services `A`, `B`, and `C`. The implementation of both `B` and `C` is dependent on the `A` service:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class A extends Context.Tag('A')<A, { readonly a: number }>() {}

class B extends Context.Tag('B')<B, { readonly b: string }>() {}

class C extends Context.Tag('C')<C, { readonly c: boolean }>() {}

const a = Layer.effect(
  A,
  Effect.succeed({ a: 5 }).pipe(Effect.tap(() => Effect.log('initialized'))),
);

const b = Layer.effect(
  B,
  Effect.gen(function* () {
    const { a } = yield* A;
    return { b: String(a) };
  }),
);

const c = Layer.effect(
  C,
  Effect.gen(function* () {
    const { a } = yield* A;
    return { c: a > 0 };
  }),
);

const program = Effect.gen(function* () {
  yield* B;
  yield* C;
});

const runnable = Effect.provide(
  program,
  Layer.merge(Layer.provide(b, a), Layer.provide(c, a)),
);

Effect.runPromise(runnable);
/*
Output:
timestamp=... level=INFO fiber=#2 message=initialized
*/
```

Although both `b` and `c` layers require the `a` layer, the `a` layer is instantiated only once. It is shared with both `b` and `c`.

## Acquiring a Fresh Version

If we don't want to share a module, we should create a fresh, non-shared version of it through `Layer.fresh`.

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class A extends Context.Tag('A')<A, { readonly a: number }>() {}

class B extends Context.Tag('B')<B, { readonly b: string }>() {}

class C extends Context.Tag('C')<C, { readonly c: boolean }>() {}

const a = Layer.effect(
  A,
  Effect.succeed({ a: 5 }).pipe(Effect.tap(() => Effect.log('initialized'))),
);

const b = Layer.effect(
  B,
  Effect.gen(function* () {
    const { a } = yield* A;
    return { b: String(a) };
  }),
);

const c = Layer.effect(
  C,
  Effect.gen(function* () {
    const { a } = yield* A;
    return { c: a > 0 };
  }),
);

const program = Effect.gen(function* () {
  yield* B;
  yield* C;
});

// ---cut---
const runnable = Effect.provide(
  program,
  Layer.merge(
    Layer.provide(b, Layer.fresh(a)),
    Layer.provide(c, Layer.fresh(a)),
  ),
);

Effect.runPromise(runnable);
/*
Output:
timestamp=... level=INFO fiber=#2 message=initialized
timestamp=... level=INFO fiber=#3 message=initialized
*/
```

## No Memoization When Providing Locally

If we don't provide a layer globally but instead provide them locally, that layer doesn't support memoization by default.

In the following example, we provided the `a` layer two times locally, and Effect doesn't memoize the construction of the `a` layer. So, it will be initialized two times:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class A extends Context.Tag('A')<A, { readonly a: number }>() {}

const a = Layer.effect(
  A,
  Effect.succeed({ a: 5 }).pipe(Effect.tap(() => Effect.log('initialized'))),
);

const program = Effect.gen(function* () {
  yield* Effect.provide(A, a);
  yield* Effect.provide(A, a);
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=initialized
timestamp=... level=INFO fiber=#0 message=initialized
*/
```

## Manual Memoization

We can memoize the `a` layer manually using the `Layer.memoize` operator. It will return a scoped effect that, if evaluated, will return the lazily computed result of this layer:

```ts twoslash
import { Context, Effect, Layer } from 'effect';

class A extends Context.Tag('A')<A, { readonly a: number }>() {}

const a = Layer.effect(
  A,
  Effect.succeed({ a: 5 }).pipe(Effect.tap(() => Effect.log('initialized'))),
);

const program = Effect.scoped(
  Layer.memoize(a).pipe(
    Effect.andThen((memoized) =>
      Effect.gen(function* () {
        yield* Effect.provide(A, memoized);
        yield* Effect.provide(A, memoized);
      })
    ),
  ),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=initialized
*/
```

# Managing Services

---

## title: Managing Servicesexcerpt: Understand the concept of services in Effect programming, reusable components designed to provide specific capabilities across an application. Learn how to manage services with effects, create service interfaces, and provide service implementations. Explore the use of optional services for added flexibility in handling scenarios where a service may or may not be available.bottomNavigation: pagination

In the context of programming, a **service** refers to a reusable component or functionality that can be used by different parts of an application.
Services are designed to provide specific capabilities and can be shared across multiple modules or components.

Services often encapsulate common tasks or operations that are needed by different parts of an application.
They can handle complex operations, interact with external systems or APIs, manage data, or perform other specialized tasks.

Services are typically designed to be modular and decoupled from the rest of the application.
This allows them to be easily maintained, tested, and replaced without affecting the overall functionality of the application.

## Overview

When diving into services and their integration in application development, it helps to start from the basic principles of function management and dependency handling without relying on advanced constructs. Imagine having to manually pass a service around to every function that needs it:

```ts
const processData = (data: Data, databaseService: DatabaseService) => {
  // Operations using the database service
};
```

This approach becomes cumbersome and unmanageable as your application grows, with services needing to be passed through multiple layers of functions.

To streamline this, you might consider using an environment object that bundles various services:

```ts
type Context = {
  databaseService: DatabaseService;
  loggingService: LoggingService;
};

const processData = (data: Data, context: Context) => {
  // Using multiple services from the context
};
```

However, this introduces a new complexity: you must ensure that the environment is correctly set up with all necessary services before it's used, which can lead to tightly coupled code and makes functional composition and testing more difficult.

The Effect library simplifies managing these dependencies by leveraging the type system.
Instead of manually passing services or environment objects around, Effect allows you to declare service dependencies directly in the function's type signature using the `Requirements` parameter in the `Effect<Success, Error, Requirements>` type.

- **Dependency Declaration**: You specify what services a function needs directly in its type, pushing the complexity of dependency management into the type system.
- **Service Provision**: `Effect.provideService` is used to make a service implementation available to the functions that need it. By providing services at the start, you ensure that all parts of your application have consistent access to the required services, thus maintaining a clean and decoupled architecture.

This method abstracts the manual handling of services and dependencies, allowing developers to focus on business logic while the compiler ensures that all dependencies are correctly managed.
This approach not only simplifies code but also enhances its maintainability and scalability.

Let's explore how services are managed in Effect, step by step. You'll learn the essentials:

1. **Creating a Service**: Define a service with its unique functionality and interface.
2. **Using the Service**: Access and utilize the service within your applicationâ€™s functions.
3. **Providing a Service Implementation**: Supply an actual implementation of the service to fulfill the declared requirements.

## Managing Services with Effects

Up to this point, our examples with the Effect framework have dealt with effects that operate independently of external services. This means the `Requirements` parameter in our `Effect<Success, Error, Requirements>` type signature has been set to `never`, indicating no dependencies.

However, real-world applications often need effects that rely on specific services to function correctly. These services are managed and accessed through a construct known as `Context`.

Context serves as a repository or container for all services an effect may require. It acts like a store that maintains these services, allowing various parts of your application to access and use them as needed.

The services stored within the Context are directly reflected in the `Requirements` parameter of the `Effect` type.
Each service within the Context is identified by a unique "tag," which is essentially a unique identifier for the service. When an effect needs to use a specific service, the service's tag is included in the `Requirements` type parameter.

### Creating a Service

Let's start by creating a service for generating random numbers.

To create a new service, you need two things:

- A unique identifier.
- A type describing the possible operations of the service.

Let's define our first service:

- We'll use the string `"MyRandomService"` as the unique identifier.
- The service type will have a single operation called `next` that returns a random number.

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}
```

The exported `Random` value is known as a **tag** in Effect. It acts as a representation of the service and allows Effect to locate and use this service at runtime.

The service will be stored in a collection called `Context`, which can be thought of as a `Map` where the keys are tags and the values are services: `Context = Map<Tag, Service>`.

<Info>
You need to specify an identifier (in this case, the string `"MyRandomService"`) to make the tag global. This ensures that two tags with the same identifier refer to the same instance.

Using a unique identifier is particularly useful in scenarios where live reloads can occur, as it helps preserve the instance across reloads. It ensures there is no duplication of instances (although it shouldn't happen, some bundlers and frameworks can behave unpredictably)

</Info>

**Summary**

In the Effect, understanding services, tags, and context is essential for managing requirements and building modular applications.

| **Concept** | **Description**                                                                                        |
| ----------- | ------------------------------------------------------------------------------------------------------ |
| **Service** | A reusable component providing specific functionality, used across different parts of an application.  |
| **Tag**     | A unique identifier representing a **service**, allowing Effect to locate and use it.                  |
| **Context** | A collection storing service, functioning like a map with **tags** as keys and **services** as values. |

### Using the Service

Now that we have our service tag defined, let's see how we can use it by building a simple program.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Effect.gen(function* () {
  const random = yield* Random;
  const randomNumber = yield* random.next;
  console.log(`random number: ${randomNumber}`);
});
```

In the code above, we can observe that we are able to yield the `Random` tag as if it were an `Effect` itself.
This allows us to access the `next` operation of the service.

</Tab>
<Tab>

```ts twoslash
import { Console, Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Random.pipe(
  Effect.andThen((random) => random.next),
  Effect.andThen((randomNumber) =>
    Console.log(`random number: ${randomNumber}`)
  ),
);
```

In the code above, we can observe that we are able to flat-map over the `Random` Tag as if it were an Effect itself.
This allows us to access the `next` operation of the service within the `Effect.andThen` callback.
We then use the `Console.log` utility to log the generated random number.

</Tab>
</Tabs>

It's worth noting that the type of the `program` variable includes `Random` in the `Requirements` type parameter: `Effect<void, never, Random>`.

This indicates that our program requires the `Random` service to be provided in order to execute successfully.

If we attempt to execute the effect without providing the necessary service we will encounter a type-checking error:

```ts twoslash
// @errors: 2345
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Effect.gen(function* () {
  const random = yield* Random;
  const randomNumber = yield* random.next;
  console.log(`random number: ${randomNumber}`);
});

// ---cut---
Effect.runSync(program);
```

To resolve this error and successfully execute the program, we need to provide an actual implementation of the `Random` service.

In the next section, we will explore how to implement and provide the `Random` service to our program, enabling us to run it successfully.

### Providing a Service Implementation

In order to provide an actual implementation of the `Random` service, we can utilize the `Effect.provideService` function.

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Effect.gen(function* () {
  const random = yield* Random;
  const randomNumber = yield* random.next;
  console.log(`random number: ${randomNumber}`);
});

// ---cut---
const runnable = Effect.provideService(program, Random, {
  next: Effect.sync(() => Math.random()),
});

Effect.runPromise(runnable);
/*
Output:
random number: 0.8241872233134417
*/
```

In the code snippet above, we call the `program` that we defined earlier and provide it with an implementation of the `Random` service.
We use the `Effect.provideService` function to associate the `Random` tag with its implementation, an object with a `next` operation that generates a random number.

Notice that the `Requirements` type parameter of the `runnable` effect is now `never`. This indicates that the effect no longer requires any service to be provided. With the implementation of the `Random` service in place, we are able to run the program without any further requirements.

### Extracting the Service Type

To retrieve the service type from a tag, use the `Context.Tag.Service` utility type:

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

type RandomShape = Context.Tag.Service<Random>;
/*
This is equivalent to:
type RandomShape = {
    readonly next: Effect.Effect<number>;
}
*/
```

## Using Multiple Services

When we require the usage of more than one service, the process remains similar to what we've learned in defining a service, repeated for each service needed. Let's examine an example where we need two services, namely `Random` and `Logger`:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Context, Effect } from 'effect';

// Create a tag for the 'Random' service
class Random extends Context.Tag('MyRandomService')<
  Random,
  {
    readonly next: Effect.Effect<number>;
  }
>() {}

// Create a tag for the 'Logger' service
class Logger extends Context.Tag('MyLoggerService')<
  Logger,
  {
    readonly log: (message: string) => Effect.Effect<void>;
  }
>() {}

const program = Effect.gen(function* () {
  // Acquire instances of the 'Random' and 'Logger' services
  const random = yield* Random;
  const logger = yield* Logger;

  // Generate a random number using the 'Random' service
  const randomNumber = yield* random.next;

  // Log the random number using the 'Logger' service
  return yield* logger.log(String(randomNumber));
});
```

</Tab>
<Tab>

```ts twoslash
import { Context, Effect } from 'effect';

// Create a tag for the 'Random' service
class Random extends Context.Tag('MyRandomService')<
  Random,
  {
    readonly next: Effect.Effect<number>;
  }
>() {}

// Create a tag for the 'Logger' service
class Logger extends Context.Tag('MyLoggerService')<
  Logger,
  {
    readonly log: (message: string) => Effect.Effect<void>;
  }
>() {}

const program =
  // Acquire instances of the 'Random' and 'Logger' services
  Effect.all([Random, Logger]).pipe(
    Effect.andThen(([random, logger]) =>
      // Generate a random number using the 'Random' service
      random.next.pipe(
        Effect.andThen((randomNumber) =>
          // Log the random number using the 'Logger' service
          logger.log(String(randomNumber))
        ),
      )
    ),
  );
```

</Tab>
</Tabs>

The `program` effect now has a `Requirements` type parameter of `Random | Logger`, indicating that it requires both the `Random` and `Logger` services to be provided.

To execute the `program`, we need to provide implementations for both services:

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  {
    readonly next: Effect.Effect<number>;
  }
>() {}

class Logger extends Context.Tag('MyLoggerService')<
  Logger,
  {
    readonly log: (message: string) => Effect.Effect<void>;
  }
>() {}

const program = Effect.gen(function* () {
  const random = yield* Random;
  const logger = yield* Logger;
  const randomNumber = yield* random.next;
  return yield* logger.log(String(randomNumber));
});

// ---cut---
// Provide service implementations for 'Random' and 'Logger'
const runnable1 = program.pipe(
  Effect.provideService(Random, {
    next: Effect.sync(() => Math.random()),
  }),
  Effect.provideService(Logger, {
    log: (message) => Effect.sync(() => console.log(message)),
  }),
);
```

Alternatively, instead of calling `provideService` multiple times, we can combine the service implementations into a single `Context` and then provide the entire context using the `Effect.provide` function:

```ts twoslash
import { Context, Effect } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  {
    readonly next: Effect.Effect<number>;
  }
>() {}

class Logger extends Context.Tag('MyLoggerService')<
  Logger,
  {
    readonly log: (message: string) => Effect.Effect<void>;
  }
>() {}

const program = Effect.gen(function* () {
  const random = yield* Random;
  const logger = yield* Logger;
  const randomNumber = yield* random.next;
  return yield* logger.log(String(randomNumber));
});

// ---cut---
// Combine service implementations into a single 'Context'
const context = Context.empty().pipe(
  Context.add(Random, { next: Effect.sync(() => Math.random()) }),
  Context.add(Logger, {
    log: (message) => Effect.sync(() => console.log(message)),
  }),
);

// Provide the entire context to the 'program'
const runnable2 = Effect.provide(program, context);
```

By providing the necessary implementations for each service, we ensure that the runnable effect can access and utilize both services when it is executed.

## Optional Services

There are situations where we may want to access a service implementation only if it is available.
In such cases, we can use the `Effect.serviceOption` function to handle this scenario.

The `Effect.serviceOption` function returns an implementation that is available only if it is actually provided before executing this effect.
To represent this optionality it returns an [Option](../../other/data-types/option) of the implementation.

Let's take a look at an example that demonstrates the usage of optional services:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

To determine what action to take, we can use the `Option.isNone` function provided by the Option module. This function allows us to check if the service is available or not by returning `true` when the service is not available.

```ts twoslash
import { Context, Effect, Option } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Effect.gen(function* () {
  const maybeRandom = yield* Effect.serviceOption(Random);
  const randomNumber = Option.isNone(maybeRandom)
    // the service is not available, return a default value
    ? -1
    // the service is available
    : yield* maybeRandom.value.next;
  console.log(randomNumber);
});
```

</Tab>
<Tab>

To determine if we can use the service, we can use the `Option.match` function provided by the `Option` module. This function allows us to perform different actions based on whether the service is available or not. It takes two callbacks as arguments: one for the case when the service is not available, and another for the case when it is available.

```ts twoslash
import { Console, Context, Effect, Option } from 'effect';

class Random extends Context.Tag('MyRandomService')<
  Random,
  { readonly next: Effect.Effect<number> }
>() {}

const program = Effect.serviceOption(Random).pipe(
  Effect.andThen((maybeRandom) =>
    Option.match(maybeRandom, {
      // the service is not available, return a default value
      onNone: () => Effect.succeed(-1),
      // the service is available
      onSome: (random) => random.next,
    })
  ),
  Effect.andThen((randomNumber) => Console.log(`${randomNumber}`)),
);
```

</Tab>
</Tabs>

In the code above, we can observe that the `Requirements` type parameter of the `program` effect is `never`, even though we are working with a service. This allows us to access something from the context only if it is actually provided before executing this effect.

When we run the `program` effect without providing the `Random` service:

```ts
Effect.runPromise(program).then(console.log);
// Output: -1
```

We see that the log message contains `-1`, which is the default value we provided when the service was not available.

However, if we provide the `Random` service implementation:

```ts
Effect.runPromise(
  Effect.provideService(program, Random, {
    next: Effect.sync(() => Math.random()),
  }),
).then(console.log);
// Output: 0.9957979486841035
```

We can observe that the log message now contains a random number generated by the `next` operation of the `Random` service.

# Streaming

---

## title: Streamingexcerpt: Streamingcollapsible: truebottomNavigation: childCards

# Sinks

---

## title: Sinksexcerpt: Sinkscollapsible: truebottomNavigation: childCards

# Leftovers

---

## title: Leftoversexcerpt: Explore handling unconsumed elements with sinks. Learn to collect or ignore leftovers using `Sink.collectLeftover` and `Sink.ignoreLeftover`. Efficiently manage and process remaining elements from upstream sources in data streams.bottomNavigation: pagination

In this section, we'll explore how to deal with elements that may be left unconsumed by sinks. Sinks can consume varying numbers of elements from their upstream, and we'll learn how to collect or ignore any leftovers.

## Collecting Leftovers

When a sink consumes elements from an upstream source, it may not use all of them. These unconsumed elements are referred to as "leftovers." To collect these leftovers, we can use `Sink.collectLeftover`. It returns a tuple containing the result of the previous sink operation and any leftover elements:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.run(Sink.take<number>(3).pipe(Sink.collectLeftover)),
);

Effect.runPromise(s1).then(console.log);
/*
Output:
[
  {
    _id: "Chunk",
    values: [ 1, 2, 3 ]
  }, {
    _id: "Chunk",
    values: [ 4, 5 ]
  }
]
*/

const s2 = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.run(Sink.head<number>().pipe(Sink.collectLeftover)),
);

Effect.runPromise(s2).then(console.log);
/*
Output:
[
  {
    _id: "Option",
    _tag: "Some",
    value: 1
  }, {
    _id: "Chunk",
    values: [ 2, 3, 4, 5 ]
  }
]
*/
```

## Ignoring Leftovers

When leftover elements are not needed, they can be ignored using `Sink.ignoreLeftover`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.run(
    Sink.take<number>(3).pipe(Sink.ignoreLeftover).pipe(Sink.collectLeftover),
  ),
);

Effect.runPromise(s1).then(console.log);
/*
Output:
[
  {
    _id: "Chunk",
    values: [ 1, 2, 3 ]
  }, {
    _id: "Chunk",
    values: []
  }
]
*/
```

# Creating Sinks

---

## title: Creating Sinksexcerpt: Learn how to construct powerful sinks for processing stream elements. Explore common constructors like `head`, `last`, `count`, `sum`, `take`, `drain`, `timed`, `forEach`, and discover how to create sinks from success and failure. Dive into collecting strategies using `collectAll`, `collectAllToSet`, `collectAllToMap`, `collectAllN`, `collectAllWhile`, `collectAllToSetN`, `collectAllToMapN`, folding techniques with `foldLeft`, `fold`, `foldWeighted`, `foldUntil`, and more.bottomNavigation: pagination

In the world of streams, sinks are used to consume and process the elements of a stream. Here, we will introduce some common sink constructors that allow you to create sinks for specific tasks.

## Common Constructors

### head

The `head` sink creates a sink that captures the first element of a stream. If the stream is empty, it returns `None`.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.head()));

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 1
}
*/
```

### last

The `last` sink consumes all elements of a stream and returns the last element of the stream.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.last()));

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 4
}
*/
```

### count

The `count` sink consumes all elements of the stream and counts the number of elements fed to it.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.count));

Effect.runPromise(effect).then(console.log);
/*
Output:
4
*/
```

### sum

The `sum` sink consumes all elements of the stream and sums incoming numeric values.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.sum));

Effect.runPromise(effect).then(console.log);
/*
Output:
10
*/
```

### take

The `take` sink takes the specified number of values from the stream and results in a [Chunk](../../../other/data-types/chunk) data type.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.take(3)));

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3 ]
}
*/
```

### drain

The `drain` sink ignores its inputs, effectively discarding them.

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.drain));

Effect.runPromise(effect).then(console.log);
/*
Output:
undefined
*/
```

### timed

The `timed` sink executes the stream and measures its execution time, providing the duration.

```ts twoslash
import { Effect, Schedule, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(
  Stream.schedule(Schedule.spaced('100 millis')),
  Stream.run(Sink.timed),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Duration",
  _tag: "Millis",
  millis: 523
}
*/
```

### forEach

The `forEach` sink executes the provided effectful function for every element fed to it.

```ts twoslash
import { Console, Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(
  Stream.run(Sink.forEach(Console.log)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
1
2
3
4
undefined
*/
```

## From Success and Failure

In the realm of data streams, similar to crafting streams to hold and manipulate data, we can also create sinks using the `Sink.fail` and `Sink.succeed` functions.

### Succeeding Sink

Let's start with a sink that doesn't consume any elements from its upstream but instead succeeds with a numeric value:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.succeed(0)));

Effect.runPromise(effect).then(console.log);
/*
Output:
0
*/
```

### Failing Sink

Now, consider a sink that also doesn't consume any elements from its upstream but deliberately fails, generating an error message of type `string`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.fail('fail!')));

Effect.runPromiseExit(effect).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'fail!' }
}
*/
```

## Collecting

### Collecting All Elements

To gather all the elements from a data stream into a [Chunk](../../../other/data-types/chunk), you can employ the `Sink.collectAll()` function:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(Stream.run(Sink.collectAll()));

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4 ]
}
*/
```

### Collecting into a HashSet

If you want to accumulate the elements into a `HashSet`, you can use `Sink.collectAllToSet()`. This function ensures that each element appears only once in the resulting set:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 2, 3, 4, 4).pipe(
  Stream.run(Sink.collectAllToSet()),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "HashSet",
  values: [ 1, 2, 3, 4 ]
}
*/
```

### Collecting into a HashMap

For more advanced collection needs, you can use `Sink.collectAllToMap()`. This function allows you to accumulate and merge elements into a `HashMap<K, A>` using a specified merge function. In the following example, we determine map keys with `(n) => n % 3` and merge elements with the same key using `(a, b) => a + b`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 3, 2, 3, 1, 5, 1).pipe(
  Stream.run(
    Sink.collectAllToMap(
      (n) => n % 3,
      (a, b) => a + b,
    ),
  ),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "HashMap",
  values: [
    [ 0, 6 ], [ 1, 3 ], [ 2, 7 ]
  ]
}
*/
```

### Collecting a Specified Number

If you only want to collect a specific number of elements from a stream into a [Chunk](../../../other/data-types/chunk), you can use `Sink.collectAllN(n)`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.run(Sink.collectAllN(3)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3 ]
}
*/
```

### Collecting While Meeting a Condition

To accumulate elements as long as they satisfy a specific condition, you can use `Sink.collectAllWhile(predicate)`. This function will keep gathering elements until the predicate returns `false`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 0, 4, 0, 6, 7).pipe(
  Stream.run(Sink.collectAllWhile((n) => n !== 0)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2 ]
}
*/
```

### Collecting into HashSets of a Specific Size

For more controlled collection into sets with a maximum size of `n`, you can utilize `Sink.collectAllToSetN(n)`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 2, 3, 4, 4).pipe(
  Stream.run(Sink.collectAllToSetN(3)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "HashSet",
  values: [ 1, 2, 3 ]
}
*/
```

### Collecting into HashMaps with Limited Keys

If you need to accumulate elements into maps with a maximum of `n` keys, you can employ `Sink.collectAllToMapN(n, keyFunction, mergeFunction)`:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 3, 2, 3, 1, 5, 1).pipe(
  Stream.run(
    Sink.collectAllToMapN(
      3,
      (n) => n,
      (a, b) => a + b,
    ),
  ),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
{
  _id: "HashMap",
  values: [
    [ 1, 2 ], [ 2, 2 ], [ 3, 6 ]
  ]
}
*/
```

## Folding

### Folding Left

Imagine you have a stream of numbers, and you want to reduce them into a single value by applying an operation to each element sequentially. You can achieve this using the `Sink.foldLeft` function:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4).pipe(
  Stream.run(Sink.foldLeft(0, (a, b) => a + b)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
10
*/
```

### Folding with Termination

In some cases, you may want to fold elements in a stream but stop the folding process when a certain condition is met. This is called "short-circuiting." You can achieve this using the `Sink.fold` function, which allows you to specify a termination predicate:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.iterate(0, (n) => n + 1).pipe(
  Stream.run(
    Sink.fold(
      0,
      (sum) => sum <= 10,
      (a, b) => a + b,
    ),
  ),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
15
*/
```

### Folding with Weighted Elements

Sometimes, you may want to fold elements based on their weight or cost, accumulating them until a certain maximum cost is reached. You can do this using `Sink.foldWeighted`. In the following example, we group elements based on a weight of 1, restarting the folding process when the total weight reaches 3:

```ts twoslash
import { Chunk, Effect, Sink, Stream } from 'effect';

const stream = Stream.make(3, 2, 4, 1, 5, 6, 2, 1, 3, 5, 6).pipe(
  Stream.transduce(
    Sink.foldWeighted({
      initial: Chunk.empty<number>(),
      maxCost: 3,
      cost: () => 1,
      body: (acc, el) => Chunk.append(acc, el),
    }),
  ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    {
      _id: "Chunk",
      values: [ 3, 2, 4 ]
    }, {
      _id: "Chunk",
      values: [ 1, 5, 6 ]
    }, {
      _id: "Chunk",
      values: [ 2, 1, 3 ]
    }, {
      _id: "Chunk",
      values: [ 5, 6 ]
    }
  ]
}
*/
```

### Folding Until a Limit

If you want to fold elements up to a specific limit, you can use `Sink.foldUntil`. In the following example, we fold elements until we have accumulated 3 of them:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3, 4, 5, 6, 7, 8, 9, 10).pipe(
  Stream.run(Sink.foldUntil(0, 3, (a, b) => a + b)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
6
*/
```

# Sink Operations

---

## title: Sink Operationsexcerpt: Explore sink operations to transform or filter their behavior. Learn to adapt sinks for different input types using `Sink.mapInput`. Discover how `Sink.dimap` allows complete conversion between input and output types. Utilize `Sink.filterInput` to selectively process elements based on specific conditions.bottomNavigation: pagination

In the previous sections, we learned how to create and use sinks. Now, let's explore some operations you can perform on sinks to transform or filter their behavior.

## Changing the Input

Sometimes, you have a sink that works perfectly with one type of input, but you want to use it with a different type. This is where `Sink.mapInput` comes in handy. While `Sink.map` modifies the output of a function, `Sink.mapInput` modifies the input. It allows you to adapt your sink to work with a different input.

Imagine you have a `Sink.sum` that calculates the sum of incoming numeric values. However, your stream contains strings, not numbers. You can use `mapInput` to convert your strings into numbers and make `Sink.sum` compatible with your stream:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const numericSum = Sink.sum;

const stringSum = numericSum.pipe(
  Sink.mapInput((s: string) => Number.parseFloat(s)),
);

Effect.runPromise(
  Stream.make('1', '2', '3', '4', '5').pipe(Stream.run(stringSum)),
).then(console.log);
/*
Output:
15
*/
```

## Transforming Both Input and Output

If you need to change both the input and output of a sink, you can use `Sink.dimap`. It's an extended version of `mapInput` that lets you transform both types. This can be useful when you need to perform a complete conversion between your input and output types:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

// Convert its input to integers, do the computation and then convert them back to a string
const sumSink = Sink.sum.pipe(
  Sink.dimap({
    onInput: (s: string) => Number.parseFloat(s),
    onDone: (n) => String(n),
  }),
);

Effect.runPromise(
  Stream.make('1', '2', '3', '4', '5').pipe(Stream.run(sumSink)),
).then(console.log);
/*
Output:
15 <-- as string
*/
```

## Filtering Input

Sinks offer a way to filter incoming elements using `Sink.filterInput`. This allows you to collect or process only the elements that meet a specific condition. In the following example, we collect elements in chunks of three and filter out the negative numbers:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const stream = Stream.make(1, -2, 0, 1, 3, -3, 4, 2, 0, 1, -3, 1, 1, 6).pipe(
  Stream.transduce(
    Sink.collectAllN<number>(3).pipe(Sink.filterInput((n) => n > 0)),
  ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    {
      _id: "Chunk",
      values: [ 1, 1, 3 ]
    }, {
      _id: "Chunk",
      values: [ 4, 2, 1 ]
    }, {
      _id: "Chunk",
      values: [ 1, 1, 6 ]
    }, {
      _id: "Chunk",
      values: []
    }
  ]
}
*/
```

# Introduction to Sinks

---

## title: Introduction to Sinksexcerpt: Explore the role of `Sink<A, In, L, E, R>` in stream processing. Learn how a `Sink` consumes elements, handles errors, produces values, and manages leftover elements. Use it seamlessly with `Stream.run` for efficient stream processing.bottomNavigation: pagination

In the world of streams, a `Sink<A, In, L, E, R>` plays a crucial role. It's like a specialized function designed to consume elements generated by a `Stream`. Here's a breakdown of what a `Sink` does:

- It can consume a varying number of `In` elements, which might be zero, one, or more.
- It has the potential to encounter errors of type `E`.
- Ultimately, it produces a value of type `A`.
- Additionally, it can return a remainder of type `L`, which represents any leftover elements.

To use a `Sink` for processing a stream, you simply pass it to the `Stream.run` function:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const stream = Stream.make(1, 2, 3); // Define a stream with numbers 1, 2, and 3

const sink = Sink.sum; // Choose a sink that sums up numbers

const sum = Stream.run(stream, sink); // Run the stream through the sink

Effect.runPromise(sum).then(console.log);
/*
Output:
6
*/
```

# Parallel Operators

---

## title: Parallel Operatorsexcerpt: Explore parallel operations like `Sink.zip` for combining results and `Sink.race` for racing concurrent sinks. Learn how to run multiple sinks concurrently, combining or selecting the first to complete. Enhance task performance by executing operations simultaneously.bottomNavigation: pagination

In this section, we'll explore parallel operations that allow you to run multiple sinks concurrently. These operations can be quite useful when you need to perform tasks simultaneously.

## Parallel Zipping: Combining Results

When you want to run two sinks concurrently and combine their results, you can use `Sink.zip`. This operation runs both sinks concurrently and combines their outcomes into a tuple:

```ts twoslash
import { Console, Effect, Schedule, Sink, Stream } from 'effect';

const s1 = Sink.forEach((s: string) => Console.log(`sink 1: ${s}`)).pipe(
  Sink.as(1),
);

const s2 = Sink.forEach((s: string) => Console.log(`sink 2: ${s}`)).pipe(
  Sink.as(2),
);

const sink = s1.pipe(Sink.zip(s2, { concurrent: true }));

Effect.runPromise(
  Stream.make('1', '2', '3', '4', '5').pipe(
    Stream.schedule(Schedule.spaced('10 millis')),
    Stream.run(sink),
  ),
).then(console.log);
/*
Output:
sink 1: 1
sink 2: 1
sink 1: 2
sink 2: 2
sink 1: 3
sink 2: 3
sink 1: 4
sink 2: 4
sink 1: 5
sink 2: 5
[ 1, 2 ]
*/
```

## Racing: First One Wins

Another useful operation is `Sink.race`, which lets you race multiple sinks concurrently. The sink that completes first will provide the result for your program:

```ts twoslash
import { Console, Effect, Schedule, Sink, Stream } from 'effect';

const s1 = Sink.forEach((s: string) => Console.log(`sink 1: ${s}`)).pipe(
  Sink.as(1),
);

const s2 = Sink.forEach((s: string) => Console.log(`sink 2: ${s}`)).pipe(
  Sink.as(2),
);

const sink = s1.pipe(Sink.race(s2));

Effect.runPromise(
  Stream.make('1', '2', '3', '4', '5').pipe(
    Stream.schedule(Schedule.spaced('10 millis')),
    Stream.run(sink),
  ),
).then(console.log);
/*
Output:
sink 1: 1
sink 2: 1
sink 1: 2
sink 2: 2
sink 1: 3
sink 2: 3
sink 1: 4
sink 2: 4
sink 1: 5
sink 2: 5
1
*/
```

# Consuming Streams

---

## title: Consuming Streamsexcerpt: Consume streams effectively using methods like `runCollect` to gather elements into a single `Chunk`, `runForEach` to process elements with a callback, `fold` for performing operations, and `Sink` for specialized consumption. Learn key techniques for working with streams in your applications.bottomNavigation: pagination

When working with streams, it's essential to understand how to consume the data they produce.
In this guide, we'll walk through several common methods for consuming streams.

## Using `runCollect`

To gather all the elements from a stream into a single `Chunk`, you can use the `Stream.runCollect` function.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3, 4, 5);

const collectedData = Stream.runCollect(stream);

Effect.runPromise(collectedData).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4, 5 ]
}
*/
```

## Using `runForEach`

Another way to consume elements of a stream is by using `Stream.runForEach`. It takes a callback function that receives each element of the stream. Here's an example:

```ts twoslash
import { Console, Effect, Stream } from 'effect';

const effect = Stream.make(1, 2, 3).pipe(
  Stream.runForEach((n) => Console.log(n)),
);

Effect.runPromise(effect).then(console.log);
/*
Output:
1
2
3
undefined
*/
```

In this example, we use `Stream.runForEach` to log each element to the console.

## Using a Fold Operation

The `Stream.fold` function is another way to consume a stream by performing a fold operation over the stream of values and returning an effect containing the result. Here are a couple of examples:

```ts twoslash
import { Effect, Stream } from 'effect';

const e1 = Stream.make(1, 2, 3, 4, 5).pipe(Stream.runFold(0, (a, b) => a + b));

Effect.runPromise(e1).then(console.log); // Output: 15

const e2 = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.runFoldWhile(
    0,
    (n) => n <= 3,
    (a, b) => a + b,
  ),
);

Effect.runPromise(e2).then(console.log); // Output: 6
```

In the first example (`e1`), we use `Stream.runFold` to calculate the sum of all elements. In the second example (`e2`), we use `Stream.runFoldWhile` to calculate the sum but only until a certain condition is met.

## Using a Sink

To consume a stream using a Sink, you can pass the `Sink` to the `Stream.run` function. Here's an example:

```ts twoslash
import { Effect, Sink, Stream } from 'effect';

const effect = Stream.make(1, 2, 3).pipe(Stream.run(Sink.sum));

Effect.runPromise(effect).then(console.log); // Output: 6
```

In this example, we use a `Sink` to calculate the sum of the elements in the stream.

# Error Handling in Streams

---

## title: Error Handling in StreamsnavTitle: Error Handlingexcerpt: Effectively handle errors in streams using functions like `orElse` for seamless recovery, `catchAll` for advanced error handling, and `retry` to handle temporary failures. Learn to refine errors, set timeouts with various operators, and gracefully recover from defects, ensuring robust stream processing in your applications.bottomNavigation: pagination

## Recovering from Failure

When working with streams that may encounter errors, it's crucial to know how to handle these errors gracefully. The `Stream.orElse` function is a powerful tool for recovering from failures and switching to an alternative stream in case of an error.

Here's a practical example:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.fail('Oh! Error!')),
  Stream.concat(Stream.make(4, 5)),
);

const s2 = Stream.make('a', 'b', 'c');

const stream = Stream.orElse(s1, () => s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, "a", "b", "c" ]
}
*/
```

In this example, `s1` encounters an error, but instead of terminating the stream, we gracefully switch to `s2` using `Stream.orElse`. This ensures that we can continue processing data even if one stream fails.

There's also a variant called `Stream.orElseEither` that uses the [Either](../../../other/data-types/either) data type to distinguish elements from the two streams based on success or failure:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.fail('Oh! Error!')),
  Stream.concat(Stream.make(4, 5)),
);

const s2 = Stream.make('a', 'b', 'c');

const stream = Stream.orElseEither(s1, () => s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    {
      _id: "Either",
      _tag: "Left",
      left: 1
    }, {
      _id: "Either",
      _tag: "Left",
      left: 2
    }, {
      _id: "Either",
      _tag: "Left",
      left: 3
    }, {
      _id: "Either",
      _tag: "Right",
      right: "a"
    }, {
      _id: "Either",
      _tag: "Right",
      right: "b"
    }, {
      _id: "Either",
      _tag: "Right",
      right: "c"
    }
  ]
}
*/
```

The `Stream.catchAll` function provides advanced error handling capabilities compared to `Stream.orElse`. With `Stream.catchAll`, you can make decisions based on both the type and value of the encountered failure.

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.fail('Uh Oh!' as const)),
  Stream.concat(Stream.make(4, 5)),
  Stream.concat(Stream.fail('Ouch' as const)),
);

const s2 = Stream.make('a', 'b', 'c');

const s3 = Stream.make(true, false, false);

const stream = Stream.catchAll(
  s1,
  (error): Stream.Stream<string | boolean> => {
    switch (error) {
      case 'Uh Oh!':
        return s2;
      case 'Ouch':
        return s3;
    }
  },
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, "a", "b", "c" ]
}
*/
```

In this example, we have a stream, `s1`, which may encounter two different types of errors. Instead of a straightforward switch to an alternative stream, as done with `Stream.orElse`, we employ `Stream.catchAll` to precisely determine how to handle each type of error. This level of control over error recovery enables you to choose different streams or actions based on the specific error conditions.

## Recovering from Defects

When working with streams, it's essential to be prepared for various failure scenarios, including defects that might occur during stream processing. To address this, the `Stream.catchAllCause` function provides a robust solution. It enables you to gracefully handle and recover from any type of failure that may arise.

Here's an example to illustrate its usage:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.dieMessage('Boom!')),
  Stream.concat(Stream.make(4, 5)),
);

const s2 = Stream.make('a', 'b', 'c');

const stream = Stream.catchAllCause(s1, () => s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, "a", "b", "c" ]
}
*/
```

In this example, `s1` may encounter a defect, but instead of crashing the application, we use `Stream.catchAllCause` to gracefully switch to an alternative stream, `s2`. This ensures that your application remains robust and continues processing data even in the face of unexpected issues.

## Recovery from Some Errors

In stream processing, there may be situations where you need to recover from specific types of failures. The `Stream.catchSome` and `Stream.catchSomeCause` functions come to the rescue, allowing you to handle and mitigate errors selectively.

If you want to recover from a particular error, you can use `Stream.catchSome`:

```ts twoslash
import { Effect, Option, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.fail('Oh! Error!')),
  Stream.concat(Stream.make(4, 5)),
);

const s2 = Stream.make('a', 'b', 'c');

const stream = Stream.catchSome(s1, (error) => {
  if (error === 'Oh! Error!') {
    return Option.some(s2);
  }
  return Option.none();
});

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, "a", "b", "c" ]
}
*/
```

To recover from a specific cause, you can use the `Stream.catchSomeCause` function:

```ts twoslash
import { Cause, Effect, Option, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.dieMessage('Oh! Error!')),
  Stream.concat(Stream.make(4, 5)),
);

const s2 = Stream.make('a', 'b', 'c');

const stream = Stream.catchSomeCause(s1, (cause) => {
  if (Cause.isDie(cause)) {
    return Option.some(s2);
  }
  return Option.none();
});

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, "a", "b", "c" ]
}
*/
```

## Recovering to Effect

In stream processing, it's crucial to handle errors gracefully and perform cleanup tasks when needed. The `Stream.onError` function allows us to do just that. If our stream encounters an error, we can specify a cleanup task to be executed.

```ts twoslash
import { Console, Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.dieMessage('Oh! Boom!')),
  Stream.concat(Stream.make(4, 5)),
  Stream.onError(() =>
    Console.log(
      'Stream application closed! We are doing some cleanup jobs.',
    ).pipe(Effect.orDie)
  ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
Stream application closed! We are doing some cleanup jobs.
error: RuntimeException: Oh! Boom!
*/
```

## Retry a Failing Stream

Sometimes, streams may encounter failures that are temporary or recoverable. In such cases, the `Stream.retry` operator comes in handy. It allows you to specify a retry schedule, and the stream will be retried according to that schedule.

Here's an example to illustrate how it works:

```ts twoslash
// @types: node
import { Effect, Schedule, Stream } from 'effect';
import * as NodeReadLine from 'node:readline';

const stream = Stream.make(1, 2, 3).pipe(
  Stream.concat(
    Stream.fromEffect(
      Effect.gen(function* () {
        const s = yield* readLine('Enter a number: ');
        const n = parseInt(s);
        if (Number.isNaN(n)) {
          return yield* Effect.fail('NaN');
        }
        return n;
      }),
    ).pipe(Stream.retry(Schedule.exponential('1 second'))),
  ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
Enter a number: a
Enter a number: b
Enter a number: c
Enter a number: 4
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4 ]
}
*/

const readLine = (message: string): Effect.Effect<string> =>
  Effect.promise(
    () =>
      new Promise((resolve) => {
        const rl = NodeReadLine.createInterface({
          input: process.stdin,
          output: process.stdout,
        });
        rl.question(message, (answer) => {
          rl.close();
          resolve(answer);
        });
      }),
  );
```

In this example, the stream asks the user to input a number, but if an invalid value is entered (e.g., "a," "b," "c"), it fails with "NaN." However, we use `Stream.retry` with an exponential backoff schedule, which means it will retry after a delay of increasing duration. This allows us to handle temporary errors and eventually collect valid input.

## Refining Errors

When working with streams, there might be situations where you want to selectively keep certain errors and terminate the stream with the remaining errors. You can achieve this using the `Stream.refineOrDie` function.

Here's an example to illustrate how it works:

```ts twoslash
import { Option, Stream } from 'effect';

const stream = Stream.fail(new Error());

const res = Stream.refineOrDie(stream, (error) => {
  if (error instanceof SyntaxError) {
    return Option.some(error);
  }
  return Option.none();
});
```

In this example, `stream` initially fails with a generic `Error`. However, we use `Stream.refineOrDie` to filter and keep only errors of type `SyntaxError`. Any other errors will be terminated, while `SyntaxErrors` will be retained in `refinedStream`.

## Timing Out

When working with streams, there are scenarios where you may want to handle timeouts, such as terminating a stream if it doesn't produce a value within a certain duration. In this section, we'll explore how to manage timeouts using various operators.

### timeout

The `Stream.timeout` operator allows you to set a timeout on a stream. If the stream does not produce a value within the specified duration, it terminates.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.fromEffect(Effect.never).pipe(
  Stream.timeout('2 seconds'),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
{
  _id: "Chunk",
  values: []
}
*/
```

### timeoutFail

The `Stream.timeoutFail` operator combines a timeout with a custom failure message. If the stream times out, it fails with the specified error message.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.fromEffect(Effect.never).pipe(
  Stream.timeoutFail(() => 'timeout', '2 seconds'),
);

Effect.runPromiseExit(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'timeout' }
}
*/
```

### timeoutFailCause

Similar to `Stream.timeoutFail`, `Stream.timeoutFailCause` combines a timeout with a custom failure cause. If the stream times out, it fails with the specified cause.

```ts twoslash
import { Cause, Effect, Stream } from 'effect';

const stream = Stream.fromEffect(Effect.never).pipe(
  Stream.timeoutFailCause(() => Cause.die('timeout'), '2 seconds'),
);

Effect.runPromiseExit(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Die', defect: 'timeout' }
}
*/
```

### timeoutTo

The `Stream.timeoutTo` operator allows you to switch to another stream if the first stream does not produce a value within the specified duration.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.fromEffect(Effect.never).pipe(
  Stream.timeoutTo('2 seconds', Stream.make(1, 2, 3)),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
{
  _id: "Chunk",
  values: [ 1, 2, 3 ]
}
*/
```

# Streams

---

## title: Streamsexcerpt: Streamscollapsible: truebottomNavigation: childCards

# Creating Streams

---

## title: Creating Streamsexcerpt: Explore diverse methods for crafting `Stream`s in Effect, tailored to your specific needs. Learn about common constructors like `make`, `empty`, `unit`, `range`, `iterate`, and `scoped`. Discover how to generate streams from success and failure using `succeed` and `fail` functions, and construct streams from chunks, effects, asynchronous callbacks, iterables, repetitions, unfolding, pagination, queues, pub/sub, and schedules. Dive into practical examples and gain insights into the nuances of each method, enabling you to harness the full power of Effect's streaming capabilities.bottomNavigation: pagination

In this section, we'll explore various methods for creating Effect `Stream`s. These methods will help you generate streams tailored to your needs.

## Common Constructors

### make

You can create a pure stream by using the `Stream.make` constructor. This constructor accepts a variable list of values as its arguments.

```ts twoslash
import { Stream } from 'effect';

const stream = Stream.make(1, 2, 3);
```

### empty

Sometimes, you may require a stream that doesn't produce any values. In such cases, you can use `Stream.empty`. This constructor creates a stream that remains empty.

```ts twoslash
import { Stream } from 'effect';

const stream = Stream.empty;
```

### void

If you need a stream that contains a single `void` value, you can use `Stream.void`. This constructor is handy when you want to represent a stream with a single event or signal.

```ts twoslash
import { Stream } from 'effect';

const stream = Stream.void;
```

### range

To create a stream of integers within a specified range `[min, max]` (including both endpoints, `min` and `max`), you can use `Stream.range`. This is particularly useful for generating a stream of sequential numbers.

```ts twoslash
import { Stream } from 'effect';

// Creating a stream of numbers from 1 to 5
const stream = Stream.range(1, 5); // Produces 1, 2, 3, 4, 5
```

### iterate

With `Stream.iterate`, you can generate a stream by applying a function iteratively to an initial value. The initial value becomes the first element produced by the stream, followed by subsequent values produced by `f(init)`, `f(f(init))`, and so on.

```ts twoslash
import { Stream } from 'effect';

// Creating a stream of incrementing numbers
const stream = Stream.iterate(1, (n) => n + 1); // Produces 1, 2, 3, ...
```

### scoped

`Stream.scoped` is used to create a single-valued stream from a scoped resource. It can be handy when dealing with resources that require explicit acquisition, usage, and release.

```ts twoslash
import { Console, Effect, Stream } from 'effect';

// Creating a single-valued stream from a scoped resource
const stream = Stream.scoped(
  Effect.acquireUseRelease(
    Console.log('acquire'),
    () => Console.log('use'),
    () => Console.log('release'),
  ),
);
```

## From Success and Failure

Much like the `Effect` data type, you can generate a `Stream` using the `fail` and `succeed` functions:

```ts twoslash
import { Stream } from 'effect';

// Creating a stream that can emit errors
const streamWithError: Stream.Stream<never, string> = Stream.fail('Uh oh!');

// Creating a stream that emits a numeric value
const streamWithNumber: Stream.Stream<number> = Stream.succeed(5);
```

## From Chunks

You can construct a stream from a `Chunk` like this:

```ts twoslash
import { Chunk, Stream } from 'effect';

// Creating a stream with values from a single Chunk
const stream = Stream.fromChunk(Chunk.make(1, 2, 3));
```

Moreover, you can create a stream from multiple `Chunk`s as well:

```ts twoslash
import { Chunk, Stream } from 'effect';

// Creating a stream with values from multiple Chunks
const stream = Stream.fromChunks(Chunk.make(1, 2, 3), Chunk.make(4, 5, 6));
```

## From Effect

You can generate a stream from an Effect workflow by employing the `Stream.fromEffect` constructor. For instance, consider the following stream, which generates a single random number:

```ts twoslash
import { Random, Stream } from 'effect';

const stream = Stream.fromEffect(Random.nextInt);
```

This method allows you to seamlessly transform the output of an Effect into a stream, providing a straightforward way to work with asynchronous operations within your streams.

## From Asynchronous Callback

Imagine you have an asynchronous function that relies on callbacks. If you want to capture the results emitted by those callbacks as a stream, you can use the `Stream.async` function. This function is designed to adapt functions that invoke their callbacks multiple times and emit the results as a stream.

Let's break down how to use it in the following example:

```ts twoslash
import { Chunk, Effect, Option, Stream, StreamEmit } from 'effect';

const events = [1, 2, 3, 4];

const stream = Stream.async(
  (emit: StreamEmit.Emit<never, never, number, void>) => {
    events.forEach((n) => {
      setTimeout(() => {
        if (n === 3) {
          emit(Effect.fail(Option.none())); // Terminate the stream
        } else {
          emit(Effect.succeed(Chunk.of(n))); // Add the current item to the stream
        }
      }, 100 * n);
    });
  },
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2 ]
}
*/
```

The `StreamEmit.Emit<R, E, A, void>` type represents an asynchronous callback that can be called multiple times. This callback takes a value of type `Effect<Chunk<A>, Option<E>, R>`. Here's what each of the possible outcomes means:

- When the value provided to the callback results in a `Chunk<A>` upon success, it signifies that the specified elements should be emitted as part of the stream.

- If the value passed to the callback results in a failure with `Some<E>`, it indicates the termination of the stream with the specified error.

- When the value passed to the callback results in a failure with `None`, it serves as a signal for the end of the stream, essentially terminating it.

To put it simply, this type allows you to specify how your asynchronous callback interacts with the stream, determining when to emit elements, when to terminate with an error, or when to signal the end of the stream.

## From Iterables

### fromIterable

You can create a pure stream from an `Iterable` of values using the `Stream.fromIterable` constructor. It's a straightforward way to convert a collection of values into a stream.

```ts twoslash
import { Stream } from 'effect';

const numbers = [1, 2, 3];

const stream = Stream.fromIterable(numbers);
```

### fromIterableEffect

When you have an effect that produces a value of type `Iterable`, you can employ the `Stream.fromIterableEffect` constructor to generate a stream from that effect.

For instance, let's say you have a database operation that retrieves a list of users. Since this operation involves effects, you can utilize `Stream.fromIterableEffect` to convert the result into a `Stream`:

```ts twoslash
import { Context, Effect, Stream } from 'effect';

interface User {}

class Database extends Context.Tag('Database')<
  Database,
  { readonly getUsers: Effect.Effect<Array<User>> }
>() {}

const getUsers = Database.pipe(Effect.andThen((_) => _.getUsers));

const users = Stream.fromIterableEffect(getUsers);
```

This enables you to work seamlessly with effects and convert their results into streams for further processing.

### fromAsyncIterable

Async iterables are another type of data source that can be converted into a stream. With the `Stream.fromAsyncIterable` constructor, you can work with asynchronous data sources and handle potential errors gracefully.

```ts twoslash
import { Stream } from 'effect';

const myAsyncIterable = async function* () {
  yield 1;
  yield 2;
};

const stream = Stream.fromAsyncIterable(
  myAsyncIterable(),
  (e) => new Error(String(e)), // Error Handling
);
```

In this code, we define an async iterable and then create a stream named `stream` from it. Additionally, we provide an error handler function to manage any potential errors that may occur during the conversion.

## From Repetition

### Repeating a Single Value

You can create a stream that endlessly repeats a specific value using the `Stream.repeatValue` constructor:

```ts twoslash
import { Stream } from 'effect';

const repeatZero = Stream.repeatValue(0);
```

### Repeating a Stream's Content

`Stream.repeat` allows you to create a stream that repeats a specified stream's content according to a schedule. This can be useful for generating recurring events or values.

```ts twoslash
import { Schedule, Stream } from 'effect';

// Creating a stream that repeats a value indefinitely
const repeatingStream = Stream.repeat(Stream.succeed(1), Schedule.forever);
```

### Repeating an Effect's Result

Imagine you have an effectful API call, and you want to use the result of that call to create a stream. You can achieve this by creating a stream from the effect and repeating it indefinitely.

Here's an example of generating a stream of random numbers:

```ts twoslash
import { Random, Stream } from 'effect';

const randomNumbers = Stream.repeatEffect(Random.nextInt);
```

### Repeating an Effect with Termination

You can repeatedly evaluate a given effect and terminate the stream based on specific conditions.

In this example, we're draining an `Iterator` to create a stream from it:

```ts twoslash
import { Effect, Option, Stream } from 'effect';

const drainIterator = <A>(it: Iterator<A>): Stream.Stream<A> =>
  Stream.repeatEffectOption(
    Effect.sync(() => it.next()).pipe(
      Effect.andThen((res) => {
        if (res.done) {
          return Effect.fail(Option.none());
        }
        return Effect.succeed(res.value);
      }),
    ),
  );
```

### Generating Ticks

You can create a stream that emits `void` values at specified intervals using the `Stream.tick` constructor. This is useful for creating periodic events.

```ts twoslash
import { Stream } from 'effect';

const stream = Stream.tick('2 seconds');
```

## From Unfolding/Pagination

In functional programming, the concept of `unfold` can be thought of as the counterpart to `fold`.

With `fold`, we process a data structure and produce a return value. For example, we can take an `Array<number>` and calculate the sum of its elements.

On the other hand, `unfold` represents an operation where we start with an initial value and generate a recursive data structure, adding one element at a time using a specified state function. For example, we can create a sequence of natural numbers starting from `1` and using the `increment` function as the state function.

### Unfold

#### unfold

The Stream module includes an `unfold` function defined as follows:

```ts
declare const unfold: <S, A>(
  initialState: S,
  step: (s: S) => Option.Option<readonly [A, S]>,
) => Stream<A>;
```

Here's how it works:

- **initialState**. This is the initial state value.
- **step**. The state function `step` takes the current state `s` as input. If the result of this function is `None`, the stream ends. If it's `Some<[A, S]>`, the next element in the stream is `A`, and the state `S` is updated for the next step process.

For example, let's create a stream of natural numbers using `Stream.unfold`:

```ts twoslash
import { Option, Stream } from 'effect';

const nats = Stream.unfold(1, (n) => Option.some([n, n + 1]));
```

#### unfoldEffect

Sometimes, we may need to perform effectful state transformations during the unfolding operation. This is where `Stream.unfoldEffect` comes in handy. It allows us to work with effects while generating streams.

Here's an example of creating an infinite stream of random `1` and `-1` values using `Stream.unfoldEffect`:

```ts twoslash
import { Effect, Option, Random, Stream } from 'effect';

const ints = Stream.unfoldEffect(1, (n) =>
  Random.nextBoolean.pipe(
    Effect.map((b) => (b ? Option.some([n, -n]) : Option.some([n, n]))),
  ));
```

#### Additional Variants

There are also similar operations like `Stream.unfoldChunk` and `Stream.unfoldChunkEffect` tailored for working with `Chunk` data types.

### Pagination

#### paginate

`Stream.paginate` is similar to `Stream.unfold` but allows emitting values one step further.

For example, the following stream emits `0, 1, 2, 3` elements:

```ts twoslash
import { Option, Stream } from 'effect';

const stream = Stream.paginate(0, (n) => [
  n,
  n < 3 ? Option.some(n + 1) : Option.none(),
]);
```

Here's how it works:

- We start with an initial value of `0`.
- The provided function takes the current value `n` and returns a tuple. The first element of the tuple is the value to emit (`n`), and the second element determines whether to continue (`Option.some(n + 1)`) or stop (`Option.none()`).

#### Additional Variants

There are also similar operations like `Stream.paginateChunk` and `Stream.paginateChunkEffect` tailored for working with `Chunk` data types.

### Unfolding vs. Pagination

You might wonder about the difference between the `unfold` and `paginate` combinators and when to use one over the other. Let's explore this by diving into an example.

Imagine we have a paginated API that provides a substantial amount of data in a paginated manner. When we make a request to this API, it returns a `ResultPage` object containing the results for the current page and a flag indicating whether it's the last page or if there's more data to retrieve on the next page. Here's a simplified representation of our API:

```twoslash include domain
import { Chunk, Effect } from "effect"

export type RawData = string

export class PageResult {
  constructor(
    readonly results: Chunk.Chunk<RawData>,
    readonly isLast: boolean
  ) {}
}

const pageSize = 2

export const listPaginated = (
  pageNumber: number
): Effect.Effect<PageResult, Error> => {
  return Effect.succeed(
    new PageResult(
      Chunk.map(
        Chunk.range(1, pageSize),
        (index) => `Result ${pageNumber}-${index}`
      ),
      pageNumber === 2 // Return 3 pages
    )
  )
}
```

```ts filename="domain.ts" twoslash
// @include: domain
```

Our goal is to convert this paginated API into a stream of `RowData` events. For our initial attempt, we might think that using the `Stream.unfold` operation is the way to go:

```ts filename="firstAttempt.ts" twoslash
// @filename: domain.ts
// @include: domain

// @filename: firstAttempt.ts
// ---cut---
import { Effect, Option, Stream } from 'effect';
import { listPaginated, RawData } from './domain';

const firstAttempt: Stream.Stream<RawData, Error> = Stream.unfoldChunkEffect(
  0,
  (pageNumber) =>
    listPaginated(pageNumber).pipe(
      Effect.map((page) => {
        if (page.isLast) {
          return Option.none();
        }
        return Option.some([page.results, pageNumber + 1] as const);
      }),
    ),
);

Effect.runPromise(Stream.runCollect(firstAttempt)).then(console.log);
/*
{
  _id: "Chunk",
  values: [ "Result 0-1", "Result 0-2", "Result 1-1", "Result 1-2" ]
}
*/
```

However, this approach has a drawback, it doesn't include the results from the last page. To work around this, we perform an extra API call to include those missing results:

```ts filename="secondAttempt.ts" twoslash
// @filename: domain.ts
// @include: domain

// @filename: firstAttempt.ts
// ---cut---
import { Effect, Option, Stream } from 'effect';
import { listPaginated, RawData } from './domain';

const secondAttempt: Stream.Stream<RawData, Error> = Stream.unfoldChunkEffect(
  Option.some(0),
  (pageNumber) =>
    Option.match(pageNumber, {
      // We already hit the last page
      onNone: () => Effect.succeed(Option.none()),
      // We did not hit the last page yet
      onSome: (pageNumber) =>
        listPaginated(pageNumber).pipe(
          Effect.map((page) =>
            Option.some([
              page.results,
              page.isLast ? Option.none() : Option.some(pageNumber + 1),
            ])
          ),
        ),
    }),
);

Effect.runPromise(Stream.runCollect(secondAttempt)).then(console.log);
/*
{
  _id: "Chunk",
  values: [ "Result 0-1", "Result 0-2", "Result 1-1", "Result 1-2", "Result 2-1", "Result 2-2" ]
}
*/
```

While this approach works, it's clear that `Stream.unfold` isn't the most friendly option for retrieving data from paginated APIs. It requires additional workarounds to include the results from the last page.

This is where `Stream.paginate` comes to the rescue. It provides a more ergonomic way to convert a paginated API into an Effect stream. Let's rewrite our solution using `Stream.paginate`:

```ts filename="finalAttempt.ts" twoslash
// @filename: domain.ts
// @include: domain

// @filename: finalAttempt.ts
// ---cut---
import { Effect, Option, Stream } from 'effect';
import { listPaginated, RawData } from './domain';

const finalAttempt: Stream.Stream<RawData, Error> = Stream.paginateChunkEffect(
  0,
  (pageNumber) =>
    listPaginated(pageNumber).pipe(
      Effect.andThen((page) => {
        return [
          page.results,
          page.isLast ? Option.none<number>() : Option.some(pageNumber + 1),
        ];
      }),
    ),
);

Effect.runPromise(Stream.runCollect(finalAttempt)).then(console.log);
/*
{
  _id: "Chunk",
  values: [ "Result 0-1", "Result 0-2", "Result 1-1", "Result 1-2", "Result 2-1", "Result 2-2" ]
}
*/
```

## From Queue and PubSub

In Effect, there are two essential asynchronous messaging data types: [Queue](../../concurrency/queue) and [PubSub](../../concurrency/pubsub). You can easily transform these data types into `Stream`s by utilizing `Stream.fromQueue` and `Stream.fromPubSub`, respectively.

## From Schedule

We can create a stream from a `Schedule` that does not require any further input. The stream will emit an element for each value output from the schedule, continuing for as long as the schedule continues:

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

// Emits values every 1 second for a total of 10 emissions
const schedule = Schedule.spaced('1 second').pipe(
  Schedule.compose(Schedule.recurs(10)),
);

const stream = Stream.fromSchedule(schedule);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]
}
*/
```

# Operations

---

## title: Operationsexcerpt: In this section, explore essential stream operations, including tapping, taking elements, exploring streams as an alternative to async iterables, mapping, filtering, scanning, draining, detecting changes, zipping, grouping, concatenation, merging, interleaving, interspersing, broadcasting, buffering, and debouncing.bottomNavigation: pagination

In this section, we'll explore some essential operations you can perform on streams. These operations allow you to manipulate and interact with stream elements in various ways.

## Tapping

Tapping is an operation that involves running an effect on each emission of the stream. It allows you to observe each element, perform some effectful operation, and discard the result of this observation. Importantly, the `Stream.tap` operation does not alter the elements of the stream, and it does not affect the return type of the stream.

For instance, you can use `Stream.tap` to print each element of a stream:

```ts twoslash
import { Console, Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3).pipe(
  Stream.tap((n) => Console.log(`before mapping: ${n}`)),
  Stream.map((n) => n * 2),
  Stream.tap((n) => Console.log(`after mapping: ${n}`)),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
before mapping: 1
after mapping: 2
before mapping: 2
after mapping: 4
before mapping: 3
after mapping: 6
{
  _id: "Chunk",
  values: [ 2, 4, 6 ]
}
*/
```

## Taking Elements

Another essential operation is taking elements, which allows you to extract a specific number of elements from a stream. Here are several ways to achieve this:

- `take`. To extract a fixed number of elements.
- `takeWhile`. To extract elements until a certain condition is met.
- `takeUntil`. To extract elements until a specific condition is met.
- `takeRight`. To extract a specified number of elements from the end.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.iterate(0, (n) => n + 1);

// Using `take` to extract a fixed number of elements:
const s1 = Stream.take(stream, 5);
Effect.runPromise(Stream.runCollect(s1)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 2, 3, 4 ]
}
*/

// Using `takeWhile` to extract elements until a certain condition is met:
const s2 = Stream.takeWhile(stream, (n) => n < 5);
Effect.runPromise(Stream.runCollect(s2)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 2, 3, 4 ]
}
*/

// Using `takeUntil` to extract elements until a specific condition is met:
const s3 = Stream.takeUntil(stream, (n) => n === 5);
Effect.runPromise(Stream.runCollect(s3)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 2, 3, 4, 5 ]
}
*/

// Using `takeRight` to extract a specified number of elements from the end:
const s4 = Stream.takeRight(s3, 3);
Effect.runPromise(Stream.runCollect(s4)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 3, 4, 5 ]
}
*/
```

### Exploring Streams as an Alternative to Async Iterables

When working with asynchronous data sources, like async iterables, you often need to consume data in a loop until a certain condition is met. This tutorial introduces how you can achieve similar behavior using Streams in a beginner-friendly manner.

In async iterables, data consumption can continue in a loop until a break or return statement is encountered. To replicate this behavior with Streams, you have a couple of options:

1. **Stream.takeUntil:** This function allows you to take elements from a stream until a specified condition evaluates to true. It's akin to breaking out of a loop in async iterables when a certain condition is met.

2. **Stream.toPull:** The `Stream.toPull` function is another way to replicate looping through async iterables. It returns an effect that repeatedly pulls data chunks from the stream. This effect can fail with `None` when the stream is finished or with `Some` error if it fails.

Let's take a closer look at the second option, `Stream.toPull`.

```ts twoslash
import { Effect, Stream } from 'effect';

// Simulate a chunked stream
const stream = Stream.fromIterable([1, 2, 3, 4, 5]).pipe(Stream.rechunk(2));

const program = Effect.gen(function* () {
  // Create an effect to get data chunks from the stream
  const getChunk = yield* Stream.toPull(stream);

  // Continuously fetch and process chunks
  while (true) {
    const chunk = yield* getChunk;
    console.log(chunk);
  }
});

Effect.runPromise(Effect.scoped(program)).then(console.log, console.error);
/*
Output:
{ _id: 'Chunk', values: [ 1, 2 ] }
{ _id: 'Chunk', values: [ 3, 4 ] }
{ _id: 'Chunk', values: [ 5 ] }
(FiberFailure) {
  "_id": "Option",
  "_tag": "None"
}
*/
```

In this example, we're using `Stream.toPull` to repeatedly pull data chunks from the `stream`. The code enters a loop and continues to fetch and display chunks until there's no more data left to process.

## Mapping

In this section, we'll explore how to transform elements within a stream using the `Stream.map` family of operations. These operations allow you to apply a function to each element of the stream, producing a new stream with the transformed values.

### Basic Mapping

The `Stream.map` operation applies a given function to all elements of the stream, creating another stream with the transformed values. Let's illustrate this with an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3).pipe(Stream.map((n) => n + 1));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 2, 3, 4 ]
}
*/
```

### Effectful Mapping

If your transformation involves effects, you can use `Stream.mapEffect` instead. It allows you to apply an effectful function to each element of the stream, producing a new stream with effectful results:

```ts twoslash
import { Effect, Random, Stream } from 'effect';

const stream = Stream.make(10, 20, 30).pipe(
  Stream.mapEffect((n) => Random.nextIntBetween(0, n)),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 6, 13, 5 ]
}
*/
```

You can evaluate effects concurrently using the `concurrency` option. It allows you to specify the number of concurrent running effects. The results are emitted downstream in the original order.

Let's write a simple page downloader that fetches URLs concurrently:

```ts twoslash
import { Effect, Stream } from 'effect';

const getUrls = Effect.succeed(['url0', 'url1', 'url2']);

const fetchUrl = (url: string) =>
  Effect.succeed([
    `Resource 0-${url}`,
    `Resource 1-${url}`,
    `Resource 2-${url}`,
  ]);

const stream = Stream.fromIterableEffect(getUrls).pipe(
  Stream.mapEffect(fetchUrl, { concurrency: 4 }),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ "Resource 0-url0", "Resource 1-url0", "Resource 2-url0" ], [ "Resource 0-url1", "Resource 1-url1",
      "Resource 2-url1" ], [ "Resource 0-url2", "Resource 1-url2", "Resource 2-url2" ]
  ]
}
*/
```

### Stateful Mapping

The `Stream.mapAccum` operation is similar to `Stream.map`, but it transforms elements statefully and allows you to map and accumulate in a single operation. Let's see how you can use it to calculate the running total of an input stream:

```ts twoslash
import { Effect, Stream } from 'effect';

const runningTotal = (stream: Stream.Stream<number>): Stream.Stream<number> =>
  stream.pipe(Stream.mapAccum(0, (s, a) => [s + a, s + a]));

// input:  0, 1, 2, 3, 4, 5
Effect.runPromise(Stream.runCollect(runningTotal(Stream.range(0, 6)))).then(
  console.log,
);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 3, 6, 10, 15 ]
}
*/
```

### Mapping and Flattening

The `Stream.mapConcat` operation is akin to `Stream.map`, but it takes things a step further. It maps each element to zero or more elements of type `Iterable` and then flattens the entire stream. Let's illustrate this with an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const numbers = Stream.make('1-2-3', '4-5', '6').pipe(
  Stream.mapConcat((s) => s.split('-')),
  Stream.map((s) => parseInt(s)),
);

Effect.runPromise(Stream.runCollect(numbers)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4, 5, 6 ]
}
*/
```

In this example, we take a stream of strings like `"1-2-3"` and split them into individual numbers, resulting in a flattened stream of integers.

### Mapping to a Constant Value

The `Stream.as` method allows you to map the success values of a stream to a specified constant value. This can be handy when you want to transform elements into a uniform value. Here's an example where we map all elements to the `null` value:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.range(1, 5).pipe(Stream.as(null));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ null, null, null, null ]
}
*/
```

In this case, regardless of the original values in the stream, we've mapped them all to `null`.

## Filtering

The `Stream.filter` operation is like a sieve that lets through elements that meet a specified condition. Think of it as a way to sift through a stream and keep only the elements that satisfy the given criteria. Here's an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.range(1, 11).pipe(Stream.filter((n) => n % 2 === 0));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 2, 4, 6, 8, 10 ]
}
*/
```

In this example, we start with a stream of numbers from 1 to 10 and use `Stream.filter` to retain only the even numbers (those that satisfy the condition `n % 2 === 0`). The result is a filtered stream containing the even numbers from the original stream.

## Scanning

In this section, we'll explore the concept of stream scanning. Scans are similar to folds, but they provide a historical perspective. Like folds, scans also involve a binary operator and an initial value. However, what makes scans unique is that they emit every intermediate result as part of the stream.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.range(1, 6).pipe(Stream.scan(0, (a, b) => a + b));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 0, 1, 3, 6, 10, 15 ]
}
*/
```

In this example, we have a stream of numbers from 1 to 5, and we use `Stream.scan` to perform a cumulative addition starting from an initial value of 0. The result is a stream that emits the accumulated sum at each step: 0, 1, 3, 6, 10, and 15.

Streams scans provide a way to keep a historical record of your stream transformations, which can be invaluable for various applications.

Additionally, if you only need the final result of the scan, you can use `Stream.runFold`:

```ts twoslash
import { Effect, Stream } from 'effect';

const fold = Stream.range(1, 6).pipe(Stream.runFold(0, (a, b) => a + b));

Effect.runPromise(fold).then(console.log); // Output: 15
```

In this case, `Stream.runFold` gives you the final accumulated value, which is 15 in this example.

## Draining

In this section, we'll explore the concept of stream draining. Imagine you have a stream filled with effectful operations, but you're not interested in the values they produce; instead, you want to execute these effects and discard the results. This is where the `Stream.drain` function comes into play.

Let's go through a few examples:

**Example 1: Discarding Values**

```ts twoslash
import { Effect, Stream } from 'effect';

// We create a stream and immediately drain it.
const s1 = Stream.range(1, 6).pipe(Stream.drain);

Effect.runPromise(Stream.runCollect(s1)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: []
}
*/
```

In this example, we have a stream with values from 1 to 5, but we use `Stream.drain` to discard these values. As a result, the output stream is empty.

**Example 2: Executing Random Effects**

```ts twoslash
import { Effect, Random, Stream } from 'effect';

const s2 = Stream.repeatEffect(
  Effect.gen(function* () {
    const nextInt = yield* Random.nextInt;
    const number = Math.abs(nextInt % 10);
    console.log(`random number: ${number}`);
    return number;
  }),
).pipe(Stream.take(3));

Effect.runPromise(Stream.runCollect(s2)).then(console.log);
/*
Output:
random number: 4
random number: 2
random number: 7
{
  _id: "Chunk",
  values: [ 4, 2, 7 ]
}
*/

const s3 = Stream.drain(s2);

Effect.runPromise(Stream.runCollect(s3)).then(console.log);
/*
random number: 1
random number: 6
random number: 0
Output:
{
  _id: "Chunk",
  values: []
}
*/
```

In this example, we create a stream with random effects and collect the values of these effects initially. Later, we use `Stream.drain` to execute the same effects without collecting the values. This demonstrates how you can use draining to trigger effectful operations when you're not interested in the emitted values.

Stream draining can be particularly useful when you need to perform certain actions or cleanup tasks in your application without affecting the main stream of data.

## Detecting Changes in a Stream

In this section, we'll explore the `Stream.changes` operation, which allows you to detect and emit elements that are different from their preceding elements within the stream.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 1, 1, 2, 2, 3, 4).pipe(Stream.changes);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4 ]
}
*/
```

## Zipping

Zipping is a process of combining two or more streams to create a new stream by pairing elements from the input streams. We can achieve this using the `Stream.zip` and `Stream.zipWith` operators. Let's dive into some examples:

```ts twoslash
import { Effect, Stream } from 'effect';

// We create two streams and zip them together.
const s1 = Stream.zip(
  Stream.make(1, 2, 3, 4, 5, 6),
  Stream.make('a', 'b', 'c'),
);

Effect.runPromise(Stream.runCollect(s1)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 1, "a" ], [ 2, "b" ], [ 3, "c" ]
  ]
}
*/

// We create two streams and zip them with custom logic.
const s2 = Stream.zipWith(
  Stream.make(1, 2, 3, 4, 5, 6),
  Stream.make('a', 'b', 'c'),
  (n, s) => [n - s.length, s],
);

Effect.runPromise(Stream.runCollect(s2)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 0, "a" ], [ 1, "b" ], [ 2, "c" ]
  ]
}
*/
```

The new stream will end when one of the streams ends.

### Handling Stream Endings

When one of the input streams ends before the other, you might need to zip with default values. The `Stream.zipAll` and `Stream.zipAllWith` operations allow you to specify default values for both sides to handle such scenarios. Let's see an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.zipAll(Stream.make(1, 2, 3, 4, 5, 6), {
  other: Stream.make('a', 'b', 'c'),
  defaultSelf: 0,
  defaultOther: 'x',
});

Effect.runPromise(Stream.runCollect(s1)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 1, "a" ], [ 2, "b" ], [ 3, "c" ], [ 4, "x" ], [ 5, "x" ], [ 6, "x" ]
  ]
}
*/

const s2 = Stream.zipAllWith(Stream.make(1, 2, 3, 4, 5, 6), {
  other: Stream.make('a', 'b', 'c'),
  onSelf: (n) => [n, 'x'],
  onOther: (s) => [0, s],
  onBoth: (n, s) => [n - s.length, s],
});

Effect.runPromise(Stream.runCollect(s2)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 0, "a" ], [ 1, "b" ], [ 2, "c" ], [ 4, "x" ], [ 5, "x" ], [ 6, "x" ]
  ]
}
*/
```

This allows you to handle zipping when one stream completes earlier than the other.

### Zipping Streams at Different Rates

Sometimes, you might have two streams producing elements at different speeds. If you don't want to wait for the slower one when zipping elements, you can use `Stream.zipLatest` or `Stream.zipLatestWith`. These operations combine elements in a way that when a value is emitted by either of the two streams, it is combined with the latest value from the other stream to produce a result. Here's an example:

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.schedule(Schedule.spaced('1 second')),
);

const s2 = Stream.make('a', 'b', 'c', 'd').pipe(
  Stream.schedule(Schedule.spaced('500 millis')),
);

const stream = Stream.zipLatest(s1, s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 1, "a" ], [ 1, "b" ], [ 2, "b" ], [ 2, "c" ], [ 2, "d" ], [ 3, "d" ]
  ]
}
*/
```

Here, `Stream.zipLatest` combines elements from both streams without waiting for the slower one, resulting in a more responsive output.

### Pairing with Previous and Next Elements

- `zipWithPrevious`: This operator pairs each element of a stream with its previous element.

- `zipWithNext`: It pairs each element of a stream with its next element.

- `zipWithPreviousAndNext`: This operator pairs each element with both its previous and next elements.

Here's an example illustrating these operations:

```ts twoslash
import { Stream } from 'effect';

const stream = Stream.make(1, 2, 3, 4);

const s1 = Stream.zipWithPrevious(stream);

const s2 = Stream.zipWithNext(stream);

const s3 = Stream.zipWithPreviousAndNext(stream);
```

### Indexing Stream Elements

Another handy operator is `Stream.zipWithIndex`, which indexes each element of a stream by pairing it with its respective index. This is especially useful when you need to keep track of the position of elements within the stream.

Here's an example of indexing elements in a stream:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make('Mary', 'James', 'Robert', 'Patricia');

const indexedStream = Stream.zipWithIndex(stream);

Effect.runPromise(Stream.runCollect(indexedStream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ "Mary", 0 ], [ "James", 1 ], [ "Robert", 2 ], [ "Patricia", 3 ]
  ]
}
*/
```

## Cartesian Product of Streams

The Stream module introduces a powerful feature: the ability to compute the _Cartesian Product_ of two streams. This operation allows you to generate combinations of elements from two separate streams. Let's explore this concept further:

Imagine you have two sets of items, and you want to generate all possible pairs by taking one item from each set. This process is known as finding the Cartesian Product of the sets. In the context of streams, it means creating combinations of elements from two streams.

To achieve this, the Stream module provides the `Stream.cross` operator, along with its variants. These operators take two streams and generate a new stream containing all possible combinations of elements from the original streams.

Here's a practical example:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3);
const s2 = Stream.make('a', 'b');

const product = Stream.cross(s1, s2);

Effect.runPromise(Stream.runCollect(product)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 1, "a" ], [ 1, "b" ], [ 2, "a" ], [ 2, "b" ], [ 3, "a" ], [ 3, "b" ]
  ]
}
*/
```

It's important to note that the right-hand side stream (`s2` in this case) will be iterated multiple times, once for each element in the left-hand side stream (`s1`). This means that if the right-hand side stream involves expensive or side-effectful operations, they will be executed multiple times.

## Partitioning

Partitioning a stream means dividing it into two separate streams based on a specified condition. The Stream module provides two helpful functions for achieving this: `Stream.partition` and `Stream.partitionEither`. Let's explore how these functions work and when to use them.

### partition

The `Stream.partition` function takes a predicate as input and splits the original stream into two substreams: one containing elements that satisfy the predicate (evaluate to `true`), and the other containing elements that do not (evaluate to `false`). Additionally, these substreams are wrapped within a `Scope` type.

Here's an example where we partition a stream of numbers into even and odd numbers:

```ts twoslash
import { Effect, Stream } from 'effect';

const partition = Stream.range(1, 10).pipe(
  Stream.partition((n) => n % 2 === 0, { bufferSize: 5 }),
);

Effect.runPromise(
  Effect.scoped(
    Effect.gen(function* () {
      const [evens, odds] = yield* partition;
      console.log(yield* Stream.runCollect(evens));
      console.log(yield* Stream.runCollect(odds));
    }),
  ),
);
/*
Output:
{
  _id: "Chunk",
  values: [ 2, 4, 6, 8 ]
}
{
  _id: "Chunk",
  values: [ 1, 3, 5, 7, 9 ]
}
*/
```

In this example, we use the `Stream.partition` function with a predicate to split the stream into even and odd numbers. The `bufferSize` option controls how much the faster stream can advance beyond the slower one.

### partitionEither

Sometimes, you may need to partition a stream using an effectful predicate. For such cases, the `Stream.partitionEither` function is available. This function accepts an effectful predicate and divides the stream into two substreams based on the result of the predicate: elements that yield `Either.left` values go to one substream, while elements yielding `Either.right` values go to the other.

Here's an example where we use `Stream.partitionEither` to partition a stream of numbers based on an effectful condition:

```ts twoslash
import { Effect, Either, Stream } from 'effect';

const partition = Stream.range(1, 10).pipe(
  Stream.partitionEither(
    (n) => Effect.succeed(n < 5 ? Either.left(n * 2) : Either.right(n)),
    { bufferSize: 5 },
  ),
);

Effect.runPromise(
  Effect.scoped(
    Effect.gen(function* () {
      const [evens, odds] = yield* partition;
      console.log(yield* Stream.runCollect(evens));
      console.log(yield* Stream.runCollect(odds));
    }),
  ),
);
/*
Output:
{
  _id: "Chunk",
  values: [ 2, 4, 6, 8 ]
}
{
  _id: "Chunk",
  values: [ 5, 6, 7, 8, 9 ]
}
*/
```

In this case, the `Stream.partitionEither` function splits the stream into two substreams: one containing values that are less than 5 (doubled using `Either.left`), and the other containing values greater than or equal to 5 (using `Either.right`).

## GroupBy

When working with streams of data, you may often need to group elements based on certain criteria. The Stream module provides two functions for achieving this: `groupByKey` and `groupBy`. Let's explore how these functions work and when to use them.

### groupByKey

The `Stream.groupByKey` function allows you to partition a stream by a simple function of type `(a: A) => K`, where `A` represents the type of elements in your stream, and `K` represents the keys by which the stream should be partitioned.
This function is not effectful, it simply groups elements by applying the provided function.

The `Stream.groupByKey` function returns a new data type called `GroupBy`.
This `GroupBy` type represents a grouped stream.
To work with the groups, you can use the `GroupBy.evaluate` function, which takes a function of type `(key: K, stream: Stream<V, E>) => Stream.Stream<...>`. This function runs across all groups and merges them in a non-deterministic fashion.

In the example below, we use `groupByKey` to group exam results by the tens place of their scores and count the number of results in each group:

```ts twoslash
import { Chunk, Effect, GroupBy, Stream } from 'effect';

class Exam {
  constructor(
    readonly person: string,
    readonly score: number,
  ) {}
}

const examResults = [
  new Exam('Alex', 64),
  new Exam('Michael', 97),
  new Exam('Bill', 77),
  new Exam('John', 78),
  new Exam('Bobby', 71),
];

const groupByKeyResult = Stream.fromIterable(examResults).pipe(
  Stream.groupByKey((exam) => Math.floor(exam.score / 10) * 10),
);

const stream = GroupBy.evaluate(
  groupByKeyResult,
  (key, stream) =>
    Stream.fromEffect(
      Stream.runCollect(stream).pipe(
        Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const),
      ),
    ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ 60, 1 ], [ 90, 1 ], [ 70, 3 ]
  ]
}
*/
```

In this example, we partition the exam results into groups based on the tens place of their scores (e.g., 60, 90, 70). The `groupByKey` function is ideal for simple, non-effectful partitioning.

### groupBy

In more complex scenarios where partitioning involves effects, you can turn to the `Stream.groupBy` function. This function takes an effectful partitioning function and generates a `GroupBy` data type, representing a grouped stream. You can then use `GroupBy.evaluate` in a similar fashion as before to process the groups.

In the following example, we group names by their first character and count the number of names in each group. Note that the partitioning operation itself is simulated as effectful:

```ts twoslash
import { Chunk, Effect, GroupBy, Stream } from 'effect';

const groupByKeyResult = Stream.fromIterable([
  'Mary',
  'James',
  'Robert',
  'Patricia',
  'John',
  'Jennifer',
  'Rebecca',
  'Peter',
]).pipe(
  Stream.groupBy((name) => Effect.succeed([name.substring(0, 1), name])),
);

const stream = GroupBy.evaluate(
  groupByKeyResult,
  (key, stream) =>
    Stream.fromEffect(
      Stream.runCollect(stream).pipe(
        Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const),
      ),
    ),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    [ "M", 1 ], [ "J", 3 ], [ "R", 2 ], [ "P", 2 ]
  ]
}
*/
```

## Grouping

When working with streams, you may encounter situations where you need to group elements in a more structured manner. The Stream module provides two helpful functions for achieving this: `grouped` and `groupedWithin`. In this section, we'll explore how these functions work and when to use them.

### grouped

The `Stream.grouped` function is perfect for partitioning stream results into chunks of a specified size. It's especially useful when you want to work with data in smaller, more manageable pieces.

Here's an example that demonstrates the use of `Stream.grouped`:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.range(0, 8).pipe(Stream.grouped(3));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    {
      _id: "Chunk",
      values: [ 0, 1, 2 ]
    }, {
      _id: "Chunk",
      values: [ 3, 4, 5 ]
    }, {
      _id: "Chunk",
      values: [ 6, 7 ]
    }
  ]
}
*/
```

In this example, we take a stream of numbers from 0 to 9 and use `Stream.grouped(3)` to divide it into chunks of size 3.

### groupedWithin

The `Stream.groupedWithin` function provides more flexibility by allowing you to group events based on time intervals or chunk size, whichever condition is satisfied first. This is particularly useful when you want to group data based on time constraints.

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

const stream = Stream.range(0, 10).pipe(
  Stream.repeat(Schedule.spaced('1 second')),
  Stream.groupedWithin(18, '1.5 seconds'),
  Stream.take(3),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [
    {
      _id: "Chunk",
      values: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7 ]
    }, {
      _id: "Chunk",
      values: [ 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]
    }, {
      _id: "Chunk",
      values: [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7 ]
    }
  ]
}
*/
```

In this example, we use `Stream.groupedWithin(18, "1.5 seconds")` to create chunks of data. The grouping operation occurs either when 18 elements are reached or when 1.5 seconds have passed since the last chunk was created. This is particularly useful when dealing with time-sensitive data or when you want to control the chunk size dynamically.

## Concatenation

In stream processing, there are scenarios where you may want to combine the contents of multiple streams. The Stream module provides several operators for achieving this, including `Stream.concat`, `Stream.concatAll`, and `Stream.flatMap`. Let's explore these operators and understand how to use them effectively.

### Simple Concatenation

The `Stream.concat` operator is a straightforward way to concatenate two streams. It returns a new stream that emits elements from the left-hand stream followed by elements from the right-hand stream. This is useful when you want to combine two streams in a sequential manner.

Here's an example of using `Stream.concat`:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3);
const s2 = Stream.make(4, 5);

const stream = Stream.concat(s1, s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4, 5 ]
}
*/
```

### Concatenating Multiple Streams

Sometimes you may have multiple streams that you want to concatenate together. Instead of manually chaining `Stream.concat` operations, you can use `Stream.concatAll` to concatenate a `Chunk` of streams.

Here's an example:

```ts twoslash
import { Chunk, Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3);
const s2 = Stream.make(4, 5);
const s3 = Stream.make(6, 7, 8);

const stream = Stream.concatAll(Chunk.make(s1, s2, s3));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4, 5, 6, 7, 8 ]
}
*/
```

### Advanced Concatenation with flatMap

The `Stream.flatMap` operator allows you to create a stream whose elements are generated by applying a function of type `(a: A) => Stream<...>` to each output of the source stream. It concatenates all of the results.

Here's an example of using `Stream.flatMap`:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3).pipe(
  Stream.flatMap((a) => Stream.repeatValue(a).pipe(Stream.take(4))),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3 ]
}
*/
```

If we need to do the `flatMap` concurrently, we can use the `concurrency` option, and also if the order of concatenation is not important for us, we can use the `switch` option.

## Merging

Sometimes we need to interleave the emission of two streams and create another stream. In these cases, we can't use the `Stream.concat` operation because the concat operation waits for the first stream to finish and then consumes the second stream. So we need a way of picking elements from different sources. Effect Stream's merge operations does this for us. Let's discuss some variants of this operation:

### merge

The `Stream.merge` operation allows us to pick elements from different source streams and merge them into a single stream. Unlike `Stream.concat`, which waits for the first stream to finish before moving to the second, `Stream.merge` interleaves elements from both streams as they become available.

Here's an example:

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.schedule(Schedule.spaced('100 millis')),
);
const s2 = Stream.make(4, 5, 6).pipe(
  Stream.schedule(Schedule.spaced('200 millis')),
);

const stream = Stream.merge(s1, s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 4, 2, 3, 5, 6 ]
}
*/
```

### Termination Strategy

When merging two streams, we should consider their termination strategy. Each stream has its own lifetime, some may finish quickly, while others may continue indefinitely. By default, when using `Stream.merge`, the resulting stream terminates only when both specified streams terminate.

However, you can define the termination strategy to align with your requirements. Stream offers four different termination strategies using the `haltStrategy` option:

- `"left"`. The resulting stream will terminate when the left-hand side stream terminates.
- `"right"`. The resulting stream will terminate when the right-hand side stream finishes.
- `"both"`. The resulting stream will terminate when both streams finish.
- `"either"`. The resulting stream will terminate when one of the streams finishes.

Here's an example of specifying a termination strategy:

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

const s1 = Stream.range(1, 6).pipe(
  Stream.schedule(Schedule.spaced('100 millis')),
);
const s2 = Stream.repeatValue(0).pipe(
  Stream.schedule(Schedule.spaced('200 millis')),
);

const stream = Stream.merge(s1, s2, { haltStrategy: 'left' });

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 0, 2, 3, 0, 4, 5 ]
}
*/
```

In this example, we use `haltStrategy: "left"` to make the resulting stream terminate when the left-hand stream (`s1`) finishes.

### mergeWith

In some cases, we not only want to merge two streams but also transform and unify their elements into new types. This is where `Stream.mergeWith` comes into play. It allows us to specify transformation functions for both source streams.

Here's an example:

```ts twoslash
import { Effect, Schedule, Stream } from 'effect';

const s1 = Stream.make('1', '2', '3').pipe(
  Stream.schedule(Schedule.spaced('100 millis')),
);
const s2 = Stream.make(4.1, 5.3, 6.2).pipe(
  Stream.schedule(Schedule.spaced('200 millis')),
);

const stream = Stream.mergeWith(s1, s2, {
  onSelf: (s) => parseInt(s),
  onOther: (n) => Math.floor(n),
});

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 4, 2, 3, 5, 6 ]
}
*/
```

In this example, we use `Stream.mergeWith` to merge `s1` and `s2` while converting string elements from `s1` to integers and rounding decimal elements from `s2`.

## Interleaving

The `Stream.interleave` operator allows us to pull one element at a time from each of two streams, creating a new interleaved stream. Once one of the streams is exhausted, the remaining values from the other stream are pulled.

Here's an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 2, 3);
const s2 = Stream.make(4, 5, 6);

const stream = Stream.interleave(s1, s2);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 4, 2, 5, 3, 6 ]
}
*/
```

For more advanced interleaving logic, `Stream.interleaveWith` provides additional flexibility. It allows you to specify the interleaving logic using a third stream of `boolean` values. When the boolean stream emits `true`, it chooses elements from the left-hand stream; otherwise, it selects elements from the right-hand stream.

Here's an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const s1 = Stream.make(1, 3, 5, 7, 9);
const s2 = Stream.make(2, 4, 6, 8, 10);

const booleanStream = Stream.make(true, false, false).pipe(Stream.forever);

const stream = Stream.interleaveWith(s1, s2, booleanStream);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 2, 4, 3, 6, 8, 5, 10, 7, 9 ]
}
*/
```

In this example, `booleanStream` decides which source stream to choose for interleaving. When `true`, it picks elements from `s1`, and when `false`, it selects elements from `s2`.

## Interspersing

Interspersing is a technique that allows you to add separators in a stream. This can be especially useful when you want to format or structure the data in your streams.

### intersperse

The `Stream.intersperse` operator lets you intersperse a delimiter element between the elements of a stream. This delimiter can be any value you choose. It's added between each pair of elements in the original stream.

Here's an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3, 4, 5).pipe(Stream.intersperse(0));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 1, 0, 2, 0, 3, 0, 4, 0, 5 ]
}
*/
```

In this example, we have a stream `stream` with numbers from 1 to 5, and we use `Stream.intersperse(0)` to add zeros between them.

### intersperseAffixes

For more advanced interspersing needs, `Stream.intersperseAffixes` provides greater control. It allows you to specify different affixes for the start, middle, and end of your stream. These affixes can be strings or any other values you want.

Here's an example:

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.intersperseAffixes({
    start: '[',
    middle: '-',
    end: ']',
  }),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ "[", 1, "-", 2, "-", 3, "-", 4, "-", 5, "]" ]
}
*/
```

In this example, we use `Stream.intersperseAffixes` to enclose the numbers from 1 to 5 within square brackets, separating them with hyphens.

## Broadcasting

Broadcasting a stream is a way to create multiple streams that contain the same elements as the source stream. This operation allows you to send each element to multiple downstream streams simultaneously. However, the upstream stream can emit events only up to a certain limit, which is determined by the `maximumLag` parameter. Once this limit is reached, the upstream stream slows down to match the speed of the slowest downstream stream.

Let's take a closer look at how broadcasting works in the following example. Here, we are broadcasting a stream of numbers to two downstream streams. One of them calculates the maximum number in the stream, while the other performs some logging with an additional delay. The upstream stream adjusts its speed based on the slower logging stream:

```ts twoslash
import { Console, Effect, Fiber, Schedule, Stream } from 'effect';

const numbers = Effect.scoped(
  Stream.range(1, 21).pipe(
    Stream.tap((n) => Console.log(`Emit ${n} element before broadcasting`)),
    Stream.broadcast(2, 5),
    Stream.flatMap(([first, second]) =>
      Effect.gen(function* () {
        const fiber1 = yield* Stream.runFold(first, 0, (acc, e) =>
          Math.max(acc, e)).pipe(
            Effect.andThen((max) =>
              Console.log(`Maximum: ${max}`)
            ),
            Effect.fork,
          );
        const fiber2 = yield* second.pipe(
          Stream.schedule(Schedule.spaced('1 second')),
          Stream.runForEach((n) => Console.log(`Logging to the Console: ${n}`)),
          Effect.fork,
        );
        yield* Fiber.join(fiber1).pipe(
          Effect.zip(Fiber.join(fiber2), { concurrent: true }),
        );
      })
    ),
    Stream.runCollect,
  ),
);

Effect.runPromise(numbers).then(console.log);
/*
Output:
Emit 1 element before broadcasting
Emit 2 element before broadcasting
Emit 3 element before broadcasting
Emit 4 element before broadcasting
Emit 5 element before broadcasting
Emit 6 element before broadcasting
Emit 7 element before broadcasting
Emit 8 element before broadcasting
Emit 9 element before broadcasting
Emit 10 element before broadcasting
Emit 11 element before broadcasting
Logging to the Console: 1
Logging to the Console: 2
Logging to the Console: 3
Logging to the Console: 4
Logging to the Console: 5
Emit 12 element before broadcasting
Emit 13 element before broadcasting
Emit 14 element before broadcasting
Emit 15 element before broadcasting
Emit 16 element before broadcasting
Logging to the Console: 6
Logging to the Console: 7
Logging to the Console: 8
Logging to the Console: 9
Logging to the Console: 10
Emit 17 element before broadcasting
Emit 18 element before broadcasting
Emit 19 element before broadcasting
Emit 20 element before broadcasting
Logging to the Console: 11
Logging to the Console: 12
Logging to the Console: 13
Logging to the Console: 14
Logging to the Console: 15
Maximum: 20
Logging to the Console: 16
Logging to the Console: 17
Logging to the Console: 18
Logging to the Console: 19
Logging to the Console: 20
{
  _id: "Chunk",
  values: [ undefined ]
}
*/
```

## Buffering

Effect streams operate in a pull-based manner, which means downstream consumers can request elements at their own pace without needing to signal the upstream to slow down. However, there are scenarios where you might need to handle producers and consumers independently, especially when there's a speed mismatch between them. This is where buffering comes into play, allowing you to manage communication between a faster producer and a slower consumer effectively. Effect streams provide a built-in `Stream.buffer` operator to assist with this.

### buffer

The `Stream.buffer` operator is designed to facilitate scenarios where a faster producer needs to work independently of a slower consumer. It achieves this by buffering elements in a queue, allowing the producer to continue working even if the consumer lags behind. You can specify the maximum buffer capacity using the `capacity` option.

Let's walk through an example to see how it works:

```ts twoslash
import { Console, Effect, Schedule, Stream } from 'effect';

const stream = Stream.range(1, 11).pipe(
  Stream.tap((n) => Console.log(`before buffering: ${n}`)),
  Stream.buffer({ capacity: 4 }),
  Stream.tap((n) => Console.log(`after buffering: ${n}`)),
  Stream.schedule(Schedule.spaced('5 seconds')),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
before buffering: 1
before buffering: 2
before buffering: 3
before buffering: 4
before buffering: 5
before buffering: 6
after buffering: 1
after buffering: 2
before buffering: 7
after buffering: 3
before buffering: 8
after buffering: 4
before buffering: 9
after buffering: 5
before buffering: 10
...
*/
```

In this example, we create a stream of numbers from 1 to 11. We use `Stream.buffer({ capacity: 4 })` to buffer up to 4 elements at a time. As you can see, the `Stream.tap` operator allows us to log each element before and after buffering. We've also introduced a 5-second delay between each emission to illustrate the lag between producing and consuming messages.

You can choose from different buffering options based on the type of underlying queue you need:

- Bounded Queue: `{ capacity: number }`
- Unbounded Queue: `{ capacity: "unbounded" }`
- Sliding Queue: `{ capacity: number, strategy: "sliding" }`
- Dropping Queue: `{ capacity: number, strategy: "dropping" }`

## Debouncing

The `Stream.debounce` function plays a crucial role in controlling the rate at which elements are emitted. It introduces a minimum time interval between the emission of each element. This ensures that elements are emitted at a more controlled pace, especially when dealing with rapid or frequent emissions.

```ts twoslash
import { Effect, Stream } from 'effect';

const stream = Stream.make(1, 2, 3).pipe(
  Stream.concat(Stream.fromEffect(Effect.sleep('500 millis'))),
  Stream.concat(Stream.make(4, 5)),
  Stream.concat(Stream.fromEffect(Effect.sleep('10 millis'))),
  Stream.concat(Stream.make(6)),
  Stream.debounce('100 millis'), // Emit only after a pause of at least 100 ms
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 3, 6 ]
}
*/
```

In this example, we have a stream that emits elements at varying intervals. Some elements are emitted rapidly, while others are separated by pauses of different durations. We apply debouncing with a minimum pause requirement of 100 milliseconds using `Stream.debounce("100 millis")`.

The result is that only elements that follow a pause of at least 100 milliseconds are emitted. This means that elements 1, 2, 4, and 5 are effectively skipped because they are emitted too close together. Only elements 3 and 6, which have a pause of at least 100 milliseconds before them, are emitted.

# Introduction to Streams

---

## title: Introduction to Streamsexcerpt: Discover the power of `Stream<A, E, R>` in Effect, a program description that goes beyond the capabilities of `Effect`. Unlike an `Effect` that always produces a single result, a `Stream` can emit zero or more values of type `A`, making it a versatile tool for various tasks. Explore scenarios such as empty streams, single-element streams, finite streams, and infinite streams. Learn how to use `Stream` to handle a wide range of tasks, from processing finite lists to dealing with infinite sequences.bottomNavigation: pagination

In this guide, we'll explore the concept of a `Stream<A, E, R>`. A `Stream` is a program description that, when executed, can emit **zero or more values** of type `A`, handle errors of type `E`, and operates within a context of type `R`.

## Use Cases

Streams are particularly handy whenever you're dealing with sequences of values over time. They can serve as replacements for observables, node streams, and AsyncIterables.

## What is a Stream?

Think of a `Stream` as an extension of an `Effect`. While an `Effect<A, E, R>` represents a program that requires a context of type `R`, may encounter an error of type `E`, and always produces a single result of type `A`, a `Stream<A, E, R>` takes this further by allowing the emission of zero or more values of type `A`.

To clarify, let's examine some examples using `Effect`:

```ts twoslash
import { Chunk, Effect, Option } from 'effect';

// An Effect that fails with a string error
const failedEffect = Effect.fail('fail!');

// An Effect that produces a single number
const oneNumberValue = Effect.succeed(3);

// An Effect that produces a chunk of numbers
const oneListValue = Effect.succeed(Chunk.make(1, 2, 3));

// An Effect that produces an optional number
const oneOption = Effect.succeed(Option.some(1));
```

In each case, the `Effect` always ends with **exactly one value**. There is no variability; you always get one result.

## Understanding Streams

Now, let's shift our focus to `Stream`. A `Stream` represents a program description that shares similarities with `Effect`, it requires a context of type `R`, may signal errors of type `E`, and yields values of type `A`. However, the key distinction is that it can yield **zero or more values**.

Here are the possible scenarios for a `Stream`:

- **An Empty Stream**: It can end up empty, representing a stream with no values.
- **A Single-Element Stream**: It can represent a stream with just one value.
- **A Finite Stream of Elements**: It can represent a stream with a finite number of values.
- **An Infinite Stream of Elements**: It can represent a stream that continues indefinitely, essentially an infinite stream.

Let's see these scenarios in action:

```ts twoslash
import { Stream } from 'effect';

// An empty Stream
const emptyStream = Stream.empty;

// A Stream with a single number
const oneNumberValueStream = Stream.succeed(3);

// A Stream with a range of numbers from 1 to 10
const finiteNumberStream = Stream.range(1, 10);

// An infinite Stream of numbers starting from 1 and incrementing
const infiniteNumberStream = Stream.iterate(1, (n) => n + 1);
```

In summary, a `Stream` is a versatile tool for representing programs that may yield multiple values, making it suitable for a wide range of tasks, from processing finite lists to handling infinite sequences.

# Scheduling Streams

---

## title: Scheduling StreamsnavTitle: Schedulingexcerpt: Introduce specific time intervals between stream element emissions with `Stream.schedule`. Learn to create structured pauses using scheduling combinators for precise control over stream timing.bottomNavigation: pagination

## schedule

When working with streams, you might need to introduce specific time intervals between each emission of stream elements. This can be achieved using the `Stream.schedule` combinator.

```ts twoslash
import { Console, Effect, Schedule, Stream } from 'effect';

const stream = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.schedule(Schedule.spaced('1 second')),
  Stream.tap(Console.log),
);

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
1
2
3
4
5
{
  _id: "Chunk",
  values: [ 1, 2, 3, 4, 5 ]
}
*/
```

In this example, we've used the `Schedule.spaced("1 second")` schedule to introduce a one-second gap between each emission in the stream.

# Resourceful Streams

---

## title: Resourceful Streamsexcerpt: Discover how to manage resources effectively in Effect's `Stream` module. Explore constructors tailored for lifting scoped resources, ensuring safe acquisition and release within streams. Dive into examples illustrating the use of `Stream.acquireRelease` for file operations, finalization for cleanup tasks, and `ensuring` for post-finalization actions. Master the art of resource management in streaming applications with Effect.bottomNavigation: pagination

In the Stream module, you'll find that most of the constructors offer a special variant designed for lifting a scoped resource into a `Stream`. When you use these specific constructors, you're essentially creating streams that are inherently safe with regards to resource management. These constructors, before creating the stream, handle the resource acquisition, and after the stream's usage, they ensure its proper closure.

Stream also provides us with `Stream.acquireRelease` and `Stream.finalizer` constructors that share similarities with `Effect.acquireRelease` and `Effect.addFinalizer`. These tools empower us to perform cleanup or finalization tasks before the stream concludes its operation.

## Acquire Release

In this section, we'll explore an example that demonstrates the use of `Stream.acquireRelease` when working with file operations.

```ts twoslash
import { Console, Effect, Stream } from 'effect';

// Simulating File operations
const open = (filename: string) =>
  Effect.gen(function* () {
    yield* Console.log(`Opening ${filename}`);
    return {
      getLines: Effect.succeed(['Line 1', 'Line 2', 'Line 3']),
      close: Console.log(`Closing ${filename}`),
    };
  });

const stream = Stream.acquireRelease(
  open('file.txt'),
  (file) => file.close,
).pipe(Stream.flatMap((file) => file.getLines));

Effect.runPromise(Stream.runCollect(stream)).then(console.log);
/*
Output:
Opening file.txt
Closing file.txt
{
  _id: "Chunk",
  values: [
    [ "Line 1", "Line 2", "Line 3" ]
  ]
}
*/
```

In this code snippet, we're simulating file operations using the `open` function. The `Stream.acquireRelease` function is employed to ensure that the file is correctly opened and closed, and we then process the lines of the file using the acquired resource.

## Finalization

In this section, we'll explore the concept of finalization in streams. Finalization allows us to execute a specific action before a stream ends. This can be particularly useful when we want to perform cleanup tasks or add final touches to a stream.

Imagine a scenario where our streaming application needs to clean up a temporary directory when it completes its execution. We can achieve this using the `Stream.finalizer` function:

```ts twoslash
import { Console, Effect, Stream } from 'effect';

const application = Stream.fromEffect(Console.log('Application Logic.'));

const deleteDir = (dir: string) => Console.log(`Deleting dir: ${dir}`);

const program = application.pipe(
  Stream.concat(
    Stream.finalizer(
      deleteDir('tmp').pipe(
        Effect.andThen(Console.log('Temporary directory was deleted.')),
      ),
    ),
  ),
);

Effect.runPromise(Stream.runCollect(program)).then(console.log);
/*
Output:
Application Logic.
Deleting dir: tmp
Temporary directory was deleted.
{
  _id: "Chunk",
  values: [ undefined, undefined ]
}
*/
```

In this code example, we start with our application logic represented by the `application` stream. We then use `Stream.finalizer` to define a finalization step, which deletes a temporary directory and logs a message. This ensures that the temporary directory is cleaned up properly when the application completes its execution.

## Ensuring

In this section, we'll explore a scenario where we need to perform actions after the finalization of a stream. To achieve this, we can utilize the `Stream.ensuring` operator.

Consider a situation where our application has completed its primary logic and finalized some resources, but we also need to perform additional actions afterward. We can use `Stream.ensuring` for this purpose:

```ts twoslash
import { Console, Effect, Stream } from 'effect';

const program = Stream.fromEffect(Console.log('Application Logic.')).pipe(
  Stream.concat(Stream.finalizer(Console.log('Finalizing the stream'))),
  Stream.ensuring(
    Console.log("Doing some other works after stream's finalization"),
  ),
);

Effect.runPromise(Stream.runCollect(program)).then(console.log);
/*
Output:
Application Logic.
Finalizing the stream
Doing some other works after stream's finalization
{
  _id: "Chunk",
  values: [ undefined, undefined ]
}
*/
```

In this code example, we start with our application logic represented by the `Application Logic.` message. We then use `Stream.finalizer` to specify the finalization step, which logs `Finalizing the stream`. After that, we use `Stream.ensuring` to indicate that we want to perform additional tasks after the stream's finalization, resulting in the message `Performing additional tasks after stream's finalization`. This ensures that our post-finalization actions are executed as expected.

# SubscriptionRef

---

## title: SubscriptionRefexcerpt: Explore the capabilities of `SubscriptionRef` in Effect, a specialized form of `SynchronizedRef`. Learn how it allows you to subscribe and receive updates on the current value and any changes made to that value. Understand the power of the `changes` stream, which facilitates observing the value and subsequent changes. Dive into practical examples demonstrating the use of `SubscriptionRef` in modeling shared state, especially in scenarios where multiple observers need to react to every change. Witness the seamless integration of `SubscriptionRef` with asynchronous tasks and discover how it enhances efficient state management in your programs.bottomNavigation: pagination

A `SubscriptionRef<A>` is a specialized form of a [SynchronizedRef](../state-management/synchronizedref). It allows us to subscribe and receive updates on the current value and any changes made to that value.

```ts
export interface SubscriptionRef<A> extends Synchronized.SynchronizedRef<A> {
  /**
   * A stream containing the current value of the `Ref` as well as all changes
   * to that value.
   */
  readonly changes: Stream<A>;
}
```

You can perform all the usual operations on a `SubscriptionRef`, such as `get`, `set`, or `modify` to work with the current value.

The `changes` stream is where the magic happens. It lets you observe the current value and all subsequent changes. Each time you run this stream, you'll get the current value as of that moment and any changes that occurred afterward.

To create a `SubscriptionRef`, you can use the `make` constructor, specifying the initial value:

```ts twoslash
import { SubscriptionRef } from 'effect';

const ref = SubscriptionRef.make(0);
```

A `SubscriptionRef` can be invaluable when modeling shared state, especially when multiple observers need to react to every change in that shared state. For example, in a functional reactive programming context, the `SubscriptionRef` value might represent a part of the application state, and each observer could update various user interface elements based on changes to that state.

To see how this works, let's create a simple example where a "server" repeatedly updates a value observed by multiple "clients":

```ts twoslash
import { Effect, Ref } from 'effect';

const server = (ref: Ref.Ref<number>) =>
  Ref.update(ref, (n) => n + 1).pipe(Effect.forever);
```

Note that the `server` function operates on a regular `Ref` and doesn't need to know about `SubscriptionRef`. It simply updates a value.

```ts twoslash
import { Effect, Random, Ref, Stream } from 'effect';

const server = (ref: Ref.Ref<number>) =>
  Ref.update(ref, (n) => n + 1).pipe(Effect.forever);

const client = (changes: Stream.Stream<number>) =>
  Effect.gen(function* () {
    const n = yield* Random.nextIntBetween(1, 10);
    const chunk = yield* Stream.runCollect(Stream.take(changes, n));
    return chunk;
  });
```

Similarly, the `client` function only works with a `Stream` of values and doesn't concern itself with the source of these values.

To tie everything together, we start the server, launch multiple client instances in parallel, and then shut down the server when we're finished. We also create the `SubscriptionRef` in this process.

```ts twoslash
import { Effect, Fiber, Random, Ref, Stream, SubscriptionRef } from 'effect';

const server = (ref: Ref.Ref<number>) =>
  Ref.update(ref, (n) => n + 1).pipe(Effect.forever);

const client = (changes: Stream.Stream<number>) =>
  Effect.gen(function* () {
    const n = yield* Random.nextIntBetween(1, 10);
    const chunk = yield* Stream.runCollect(Stream.take(changes, n));
    return chunk;
  });

const program = Effect.gen(function* () {
  const ref = yield* SubscriptionRef.make(0);
  const serverFiber = yield* Effect.fork(server(ref));
  const clients = new Array(5).fill(null).map(() => client(ref.changes));
  const chunks = yield* Effect.all(clients, { concurrency: 'unbounded' });
  yield* Fiber.interrupt(serverFiber);
  for (const chunk of chunks) {
    console.log(chunk);
  }
});

Effect.runPromise(program);
/*
Output:
{
  _id: "Chunk",
  values: [ 2, 3, 4 ]
}
{
  _id: "Chunk",
  values: [ 2 ]
}
{
  _id: "Chunk",
  values: [ 2, 3, 4, 5, 6, 7 ]
}
{
  _id: "Chunk",
  values: [ 2, 3, 4 ]
}
{
  _id: "Chunk",
  values: [ 2, 3, 4, 5, 6, 7, 8, 9 ]
}
*/
```

This setup ensures that each client observes the current value when it starts and receives all subsequent changes to the value.

Since the changes are represented as streams, you can easily build more complex programs using familiar stream operators. You can transform, filter, or merge these streams with other streams to achieve more sophisticated behavior.

# Guides

---

## title: Guidesexcerpt: GuidesbottomNavigation: childCards

# Semaphore

---

## title: Semaphoreexcerpt: Discover the power of semaphores in Effect, a synchronization mechanism that regulates access to shared resources and coordinates tasks in an asynchronous and concurrent environment. Delve into the fundamental concept of semaphores, learn how they function in Effect, and explore real-world examples showcasing their application in controlling asynchronous tasks. Gain insights into precise control over concurrency using permits and understand how semaphores elevate your ability to manage resources effectively.bottomNavigation: pagination

A semaphore, in the context of programming, is a synchronization mechanism that allows you to control access to a shared resource. In Effect, semaphores are used to manage access to resources or coordinate tasks in an asynchronous and concurrent environment. Let's dive into the concept of semaphores and how they work in Effect.

## What is a Semaphore?

A semaphore is a generalization of a mutex. It has a certain number of **permits**, which can be held and released concurrently by different parties. Think of permits as tickets that allow entities (e.g., tasks or fibers) to access a shared resource or perform a specific operation. If there are no permits available and an entity tries to acquire one, it will be suspended until a permit becomes available.

Let's take a look at an example using asynchronous tasks:

```ts filename="mutex.ts" twoslash
import { Effect } from 'effect';

const task = Effect.gen(function* () {
  yield* Effect.log('start');
  yield* Effect.sleep('2 seconds');
  yield* Effect.log('end');
});

const semTask = (sem: Effect.Semaphore) => sem.withPermits(1)(task);

const semTaskSeq = (sem: Effect.Semaphore) =>
  [1, 2, 3].map(() => semTask(sem).pipe(Effect.withLogSpan('elapsed')));

const program = Effect.gen(function* () {
  const mutex = yield* Effect.makeSemaphore(1);
  yield* Effect.all(semTaskSeq(mutex), { concurrency: 'unbounded' });
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#1 message=start elapsed=3ms
timestamp=... level=INFO fiber=#1 message=end elapsed=2010ms
timestamp=... level=INFO fiber=#2 message=start elapsed=2012ms
timestamp=... level=INFO fiber=#2 message=end elapsed=4017ms
timestamp=... level=INFO fiber=#3 message=start elapsed=4018ms
timestamp=... level=INFO fiber=#3 message=end elapsed=6026ms
*/
```

Here, we synchronize and control the execution of asynchronous tasks using a semaphore with one permit. When all permits are in use, additional tasks attempting to acquire permits will wait until some become available.

In another scenario, we create a semaphore with five permits. We then utilize `withPermits(n)` to acquire and release varying numbers of permits for each task:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  const sem = yield* Effect.makeSemaphore(5);

  yield* Effect.forEach(
    [1, 2, 3, 4, 5],
    (n) =>
      sem
        .withPermits(n)(
          Effect.delay(Effect.log(`process: ${n}`), '2 seconds'),
        )
        .pipe(Effect.withLogSpan('elasped')),
    { concurrency: 'unbounded' },
  );
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#1 message="process: 1" elasped=2011ms
timestamp=... level=INFO fiber=#2 message="process: 2" elasped=2017ms
timestamp=... level=INFO fiber=#3 message="process: 3" elasped=4020ms
timestamp=... level=INFO fiber=#4 message="process: 4" elasped=6025ms
timestamp=... level=INFO fiber=#5 message="process: 5" elasped=8034ms
*/
```

In this example, we show that you can acquire and release any number of permits with `withPermits(n)`. This flexibility allows for precise control over concurrency.

One crucial aspect to remember is that `withPermits` ensures that each acquisition is matched with an equivalent number of releases, regardless of whether the task succeeds, fails, or gets interrupted.

# Concurrency Options

---

## title: Concurrency Optionsexcerpt: Effect provides powerful options to manage the execution of effects, offering control over the concurrency of operations. Explore the `concurrency` option, a key factor in determining how many effects can run concurrently. This concise guide delves into sequential execution, numbered concurrency, unbounded concurrency, and the flexible inherit concurrency option. Learn to harness these options to optimize the performance of your Effect programs and tailor the concurrency behavior to your specific use cases.bottomNavigation: pagination

Effect offers various options to manage how effects are executed and control the overall operation's result. These options help determine how many effects can run at the same time concurrently.

```ts
type Options = {
  readonly concurrency?: Concurrency;
  /* ... other options ... */
};
```

In this section, we'll focus on the option that handles concurrency, which is the `concurrency` option with a type of `Concurrency`:

```ts
type Concurrency = number | 'unbounded' | 'inherit';
```

Let's understand the meaning of each configuration value.

<Info>
  The following examples use the `Effect.all` function, but the concept
  applies to many other Effect APIs that accept concurrency options, such as
  `Effect.forEach`.
</Info>

## Sequential Execution (Default)

By default, if you don't specify any concurrency option, effects will run sequentially, one after the other. This means each effect starts only after the previous one completes.

```ts twoslash
import { Duration, Effect } from 'effect';

const makeTask = (n: number, delay: Duration.DurationInput) =>
  Effect.promise(
    () =>
      new Promise<void>((resolve) => {
        console.log(`start task${n}`);
        setTimeout(() => {
          console.log(`task${n} done`);
          resolve();
        }, Duration.toMillis(delay));
      }),
  );

const task1 = makeTask(1, '200 millis');
const task2 = makeTask(2, '100 millis');

const sequential = Effect.all([task1, task2]);

Effect.runPromise(sequential);
/*
Output:
start task1
task1 done
start task2 <-- task2 starts only after task1 completes
task2 done
*/
```

## Numbered Concurrency

You can control the number of concurrent operations with the `concurrency` option. For example, with `concurrency: 2`, up to 2 effects will run simultaneously.

```ts twoslash
import { Duration, Effect } from 'effect';

const makeTask = (n: number, delay: Duration.DurationInput) =>
  Effect.promise(
    () =>
      new Promise<void>((resolve) => {
        console.log(`start task${n}`);
        setTimeout(() => {
          console.log(`task${n} done`);
          resolve();
        }, Duration.toMillis(delay));
      }),
  );

const task1 = makeTask(1, '200 millis');
const task2 = makeTask(2, '100 millis');
const task3 = makeTask(3, '210 millis');
const task4 = makeTask(4, '110 millis');
const task5 = makeTask(5, '150 millis');

const number = Effect.all([task1, task2, task3, task4, task5], {
  concurrency: 2,
});

Effect.runPromise(number);
/*
Output:
start task1
start task2 <-- active tasks: task1, task2
task2 done
start task3 <-- active tasks: task1, task3
task1 done
start task4 <-- active tasks: task3, task4
task4 done
start task5 <-- active tasks: task3, task5
task3 done
task5 done
*/
```

## Unbounded Concurrency

If you set `concurrency: "unbounded"`, as many effects as needed will run concurrently, without any specific limit.

```ts twoslash
import { Duration, Effect } from 'effect';

const makeTask = (n: number, delay: Duration.DurationInput) =>
  Effect.promise(
    () =>
      new Promise<void>((resolve) => {
        console.log(`start task${n}`);
        setTimeout(() => {
          console.log(`task${n} done`);
          resolve();
        }, Duration.toMillis(delay));
      }),
  );

const task1 = makeTask(1, '200 millis');
const task2 = makeTask(2, '100 millis');
const task3 = makeTask(3, '210 millis');
const task4 = makeTask(4, '110 millis');
const task5 = makeTask(5, '150 millis');

const unbounded = Effect.all([task1, task2, task3, task4, task5], {
  concurrency: 'unbounded',
});

Effect.runPromise(unbounded);
/*
Output:
start task1
start task2
start task3
start task4
start task5
task2 done
task4 done
task5 done
task1 done
task3 done
*/
```

## Inherit Concurrency

The `concurrency: "inherit"` option adapts based on context, controlled by `Effect.withConcurrency(number | "unbounded")`.

If there's no `Effect.withConcurrency` call, the default is `"unbounded"`. Otherwise, it inherits the configuration set by `Effect.withConcurrency`.

```ts twoslash
import { Duration, Effect } from 'effect';

const makeTask = (n: number, delay: Duration.DurationInput) =>
  Effect.promise(
    () =>
      new Promise<void>((resolve) => {
        console.log(`start task${n}`);
        setTimeout(() => {
          console.log(`task${n} done`);
          resolve();
        }, Duration.toMillis(delay));
      }),
  );

const task1 = makeTask(1, '200 millis');
const task2 = makeTask(2, '100 millis');
const task3 = makeTask(3, '210 millis');
const task4 = makeTask(4, '110 millis');
const task5 = makeTask(5, '150 millis');

const inherit = Effect.all([task1, task2, task3, task4, task5], {
  concurrency: 'inherit',
});

Effect.runPromise(inherit);
/*
Output:
start task1
start task2
start task3
start task4
start task5
task2 done
task4 done
task5 done
task1 done
task3 done
*/
```

If you use `Effect.withConcurrency`, it will adopt that specific concurrency configuration.

```ts twoslash
import { Duration, Effect } from 'effect';

const makeTask = (n: number, delay: Duration.DurationInput) =>
  Effect.promise(
    () =>
      new Promise<void>((resolve) => {
        console.log(`start task${n}`);
        setTimeout(() => {
          console.log(`task${n} done`);
          resolve();
        }, Duration.toMillis(delay));
      }),
  );

const task1 = makeTask(1, '200 millis');
const task2 = makeTask(2, '100 millis');
const task3 = makeTask(3, '210 millis');
const task4 = makeTask(4, '110 millis');
const task5 = makeTask(5, '150 millis');

const inherit = Effect.all([task1, task2, task3, task4, task5], {
  concurrency: 'inherit',
});

const withConcurrency = inherit.pipe(Effect.withConcurrency(2));

Effect.runPromise(withConcurrency);
/*
Output:
start task1
start task2 <-- active tasks: task1, task2
task2 done
start task3 <-- active tasks: task1, task3
task1 done
start task4 <-- active tasks: task3, task4
task4 done
start task5 <-- active tasks: task3, task5
task3 done
task5 done
*/
```

# Introduction to Effect's Interruption Model

---

## title: Introduction to Effect's Interruption ModelnavTitle: Interruption Modelexcerpt: Explore the intricacies of Effect's interruption model, a crucial aspect in concurrent application development. Learn the nuances of handling fiber interruptions, including scenarios such as parent fibers terminating child fibers, racing fibers, user-initiated interruptions, and timeouts. Delve into the comparison between polling and asynchronous interruption, understanding the advantages of the latter in maintaining consistency and adhering to functional paradigms. Gain insights into when fibers get interrupted, providing examples and scenarios for a comprehensive understanding of this vital feature.bottomNavigation: pagination

## Handling Fiber Interruption

While developing concurrent applications, there are several cases that we need to _interrupt_ the execution of other fibers, for example:

1. A parent fiber might start some child fibers to perform a task, and later the parent might decide that, it doesn't need the result of some or all of the child fibers.

2. Two or more fibers start race with each other. The fiber whose result is computed first wins, and all other fibers are no longer needed, and should be interrupted.

3. In interactive applications, a user may want to stop some already running tasks, such as clicking on the "stop" button to prevent downloading more files.

4. Computations that run longer than expected should be aborted by using timeout operations.

5. When we have an application that perform compute-intensive tasks based on the user inputs, if the user changes the input we should cancel the current task and perform another one.

## Polling vs. Asynchronous Interruption

When it comes to interrupting fibers, a naive approach is to allow one fiber to forcefully terminate another fiber. However, this approach is not ideal because it can leave shared state in an inconsistent and unreliable state if the target fiber is in the middle of modifying that state. Therefore, it does not guarantee internal consistency of the shared mutable state.

Instead, there are two popular and valid solutions to tackle this problem:

1. **Semi-asynchronous Interruption (Polling for Interruption)**: Imperative languages often employ polling as a semi-asynchronous signaling mechanism, such as Java. In this model, a fiber sends an interruption request to another fiber. The target fiber continuously polls the interrupt status and checks whether it has received any interruption requests from other fibers. If an interruption request is detected, the target fiber terminates itself as soon as possible.

   With this solution, the fiber itself handles critical sections. So, if a fiber is in the middle of a critical section and receives an interruption request, it ignores the interruption and defers its handling until after the critical section.

   However, one drawback of this approach is that if the programmer forgets to poll regularly, the target fiber can become unresponsive, leading to deadlocks. Additionally, polling a global flag is not aligned with the functional paradigm followed by Effect.

2. **Asynchronous Interruption**: In asynchronous interruption, a fiber is allowed to terminate another fiber. The target fiber is not responsible for polling the interrupt status. Instead, during critical sections, the target fiber disables the interruptibility of those regions. This is a purely functional solution that doesn't require polling a global state. Effect adopts this solution for its interruption model, which is a fully asynchronous signaling mechanism.

   This mechanism overcomes the drawback of forgetting to poll regularly. It is also fully compatible with the functional paradigm because in a purely functional computation, we can abort the computation at any point, except during critical sections where interruption is disabled.

## When Does a Fiber Get Interrupted?

There are several ways and situations in which fibers can be interrupted. Let's explore each one and provide examples to illustrate how to reproduce these scenarios.

### Calling Effect.interrupt

A fiber can be interrupted by invoking the `Effect.interrupt` operator on that particular fiber.

Without interruptions

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('start');
  yield* Effect.sleep('2 seconds');
  yield* Effect.log('done');
});

Effect.runPromise(program).catch((error) =>
  console.log(`interrupted: ${error}`)
);
/*
Output:
timestamp=... level=INFO fiber=#0 message=start
timestamp=... level=INFO fiber=#0 message=done
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.log('start').pipe(
  Effect.andThen(Effect.sleep('2 seconds')),
  Effect.andThen(Effect.log('done')),
);

Effect.runPromise(program).catch((error) =>
  console.log(`interrupted: ${error}`)
);
/*
Output:
timestamp=... level=INFO fiber=#0 message=start
timestamp=... level=INFO fiber=#0 message=done
*/
```

</Tab>
</Tabs>

With interruptions

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts {6} twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('start');
  yield* Effect.sleep('2 seconds');
  yield* Effect.interrupt;
  yield* Effect.log('done');
});

Effect.runPromiseExit(program).then(console.log);
/*
Output:
timestamp=... level=INFO fiber=#0 message=start
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Interrupt',
    fiberId: {
      _id: 'FiberId',
      _tag: 'Runtime',
      id: 0,
      startTimeMillis: ...
    }
  }
}
*/
```

</Tab>
<Tab>

```ts {5} twoslash
import { Effect } from 'effect';

const program = Effect.log('start').pipe(
  Effect.andThen(Effect.sleep('2 seconds')),
  Effect.andThen(Effect.interrupt),
  Effect.andThen(Effect.log('done')),
);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
timestamp=... level=INFO fiber=#0 message=start
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Interrupt',
    fiberId: {
      _id: 'FiberId',
      _tag: 'Runtime',
      id: 0,
      startTimeMillis: ...
    }
  }
}
*/
```

</Tab>
</Tabs>

### Interruption of Concurrent Effects

When we combine multiple concurrent effects using functions like `Effect.forEach`, it's important to note that if one of the effects is interrupted, all the other concurrent effects will also be interrupted. Let's take a look at an example:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.forEach(
  [1, 2, 3],
  (n) =>
    Effect.gen(function* () {
      yield* Effect.log(`start #${n}`);
      yield* Effect.sleep(`${n} seconds`);
      if (n > 1) {
        yield* Effect.interrupt;
      }
      yield* Effect.log(`done #${n}`);
    }),
  { concurrency: 'unbounded' },
);

Effect.runPromiseExit(program).then((exit) =>
  console.log(JSON.stringify(exit, null, 2))
);
/*
Output:
timestamp=... level=INFO fiber=#1 message="start #1"
timestamp=... level=INFO fiber=#2 message="start #2"
timestamp=... level=INFO fiber=#3 message="start #3"
timestamp=... level=INFO fiber=#1 message="done #1"
{
  "_id": "Exit",
  "_tag": "Failure",
  "cause": {
    "_id": "Cause",
    "_tag": "Parallel",
    "left": {
      "_id": "Cause",
      "_tag": "Interrupt",
      "fiberId": {
        "_id": "FiberId",
        "_tag": "Runtime",
        "id": 3,
        "startTimeMillis": 1712582275153
      }
    },
    "right": {
      "_id": "Cause",
      "_tag": "Sequential",
      "left": {
        "_id": "Cause",
        "_tag": "Empty"
      },
      "right": {
        "_id": "Cause",
        "_tag": "Interrupt",
        "fiberId": {
          "_id": "FiberId",
          "_tag": "Runtime",
          "id": 0,
          "startTimeMillis": 1712582275147
        }
      }
    }
  }
}
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.forEach(
  [1, 2, 3],
  (n) =>
    Effect.log(`start #${n}`).pipe(
      Effect.andThen(() => {
        const effect = Effect.sleep(`${n} seconds`);
        if (n > 1) {
          return Effect.andThen(effect, () => Effect.interrupt);
        } else {
          return effect;
        }
      }),
      Effect.andThen(Effect.log(`done #${n}`)),
    ),
  { concurrency: 'unbounded' },
);

Effect.runPromiseExit(program).then((exit) =>
  console.log(JSON.stringify(exit, null, 2))
);
/*
Output:
timestamp=... level=INFO fiber=#1 message="start #1"
timestamp=... level=INFO fiber=#2 message="start #2"
timestamp=... level=INFO fiber=#3 message="start #3"
timestamp=... level=INFO fiber=#1 message="done #1"
{
  "_id": "Exit",
  "_tag": "Failure",
  "cause": {
    "_id": "Cause",
    "_tag": "Parallel",
    "left": {
      "_id": "Cause",
      "_tag": "Interrupt",
      "fiberId": {
        "_id": "FiberId",
        "_tag": "Runtime",
        "id": 3,
        "startTimeMillis": 1712582275153
      }
    },
    "right": {
      "_id": "Cause",
      "_tag": "Sequential",
      "left": {
        "_id": "Cause",
        "_tag": "Empty"
      },
      "right": {
        "_id": "Cause",
        "_tag": "Interrupt",
        "fiberId": {
          "_id": "FiberId",
          "_tag": "Runtime",
          "id": 0,
          "startTimeMillis": 1712582275147
        }
      }
    }
  }
}
*/
```

</Tab>
</Tabs>

In this example, we have an array `[1, 2, 3]` representing three concurrent tasks. We use `Effect.forEach` to iterate over each element and perform some operations. The `Effect.log` function is used to log messages indicating the start and completion of each task.

Looking at the output, we can see that the task with `n = 1` starts and completes successfully. However, the task with `n = 2` is interrupted using `Effect.interrupt` before it finishes. As a result, all the fibers are interrupted, and the program terminates with the message "All fibers interrupted without errors."

This example demonstrates how interruption works with concurrent effects. If one of the concurrent tasks is interrupted, it triggers the interruption of all the other concurrent tasks as well.

# Concurrency

---

## title: Concurrencyexcerpt: Concurrencycollapsible: truebottomNavigation: childCards

# PubSub

---

## title: PubSubexcerpt: Dive into the world of `PubSub` with Effect, a powerful asynchronous message hub that facilitates seamless communication between publishers and subscribers. Learn the core operations, explore different types of pubsubs, and discover the optimal scenarios for their use. Understand the versatile operators available on pubsubs, from publishing multiple values to checking size and gracefully shutting down. Gain insights into the unique qualities that set pubsubs apart and their equivalence to queues in various scenarios. Elevate your understanding of `PubSub` to enhance your asynchronous workflows.bottomNavigation: pagination

In this guide, we'll explore the concept of a `PubSub`, which is an asynchronous message hub. It allows publishers to send messages to the pubsub, and subscribers can receive those messages.

Unlike a [Queue](queue), where each value offered to the queue can be taken by **one** taker, each value published to a pubsub can be received by **all** subscribers.

Whereas a [Queue](queue) represents the optimal solution to the problem of how to **distribute** values, a `PubSub` represents the optimal solution to the problem of how to **broadcast** them.

## Basic Operations

The core operations of a `PubSub` are `PubSub.publish` and `PubSub.subscribe`:

- The `publish` operation sends a message of type `A` to the pubsub. It returns an effect that indicates whether the message was successfully published.
- The `subscribe` operation returns a scoped effect that allows you to subscribe to the pubsub. It automatically unsubscribes when the scope is closed. Within the scope, you gain access to a `Dequeue`, which is essentially a `Queue` for dequeuing messages published to the pubsub.

Let's look at an example to understand how to use a pubsub:

```ts twoslash
import { Console, Effect, PubSub, Queue } from 'effect';

const program = PubSub.bounded<string>(2).pipe(
  Effect.andThen((pubsub) =>
    Effect.scoped(
      Effect.gen(function* () {
        const dequeue1 = yield* PubSub.subscribe(pubsub);
        const dequeue2 = yield* PubSub.subscribe(pubsub);
        yield* PubSub.publish(pubsub, 'Hello from a PubSub!');
        yield* Queue.take(dequeue1).pipe(Effect.andThen(Console.log));
        yield* Queue.take(dequeue2).pipe(Effect.andThen(Console.log));
      }),
    )
  ),
);

Effect.runPromise(program);
/*
Output:
Hello from a PubSub!
Hello from a PubSub!
*/
```

It's important to note that a subscriber will only receive messages published to the pubsub while it's subscribed. To ensure that a specific message reaches a subscriber, make sure that the subscription has been established before publishing the message.

## Creating PubSubs

You can create a pubsub using various constructors provided by the PubSub module:

### Bounded PubSub

A bounded pubsub applies back pressure to publishers when it's at capacity, meaning publishers will block if the pubsub is full.

```ts twoslash
import { PubSub } from 'effect';

const boundedPubSub = PubSub.bounded<string>(2);
```

Back pressure ensures that all subscribers receive all messages while they are subscribed. However, it can lead to slower message delivery if a subscriber is slow.

### Dropping PubSub

A dropping pubsub simply discards values if it's full. The `PubSub.publish` function will return `false` when the pubsub is full.

```ts twoslash
import { PubSub } from 'effect';

const droppingPubSub = PubSub.dropping<string>(2);
```

In a dropping pubsub, publishers can continue to publish new values, but subscribers are not guaranteed to receive all messages.

### Sliding PubSub

A sliding pubsub drops the oldest value when it's full, ensuring that publishing always succeeds immediately.

```ts twoslash
import { PubSub } from 'effect';

const slidingPubSub = PubSub.sliding<string>(2);
```

A sliding pubsub prevents slow subscribers from impacting the message delivery rate. However, there's still a risk that slow subscribers may miss some messages.

### Unbounded PubSub

An unbounded pubsub can never be full, and publishing always succeeds immediately.

```ts twoslash
import { PubSub } from 'effect';

const unboundedPubSub = PubSub.unbounded<string>();
```

Unbounded pubsubs guarantee that all subscribers receive all messages without slowing down message delivery. However, they can grow indefinitely if messages are published faster than they are consumed.

Generally, it's recommended to use bounded, dropping, or sliding pubsubs unless you have specific use cases for unbounded pubsubs.

## Operators On PubSubs

PubSubs support various operations similar to those available on queues.

### Publishing Multiple Values

You can use the `PubSub.publishAll` operator to publish multiple values to the pubsub at once:

```ts twoslash
import { Console, Effect, PubSub, Queue } from 'effect';

const program = PubSub.bounded<string>(2).pipe(
  Effect.andThen((pubsub) =>
    Effect.scoped(
      Effect.gen(function* () {
        const dequeue = yield* PubSub.subscribe(pubsub);
        yield* PubSub.publishAll(pubsub, ['Message 1', 'Message 2']);
        yield* Queue.takeAll(dequeue).pipe(Effect.andThen(Console.log));
      }),
    )
  ),
);

Effect.runPromise(program);
/*
Output:
{
  _id: "Chunk",
  values: [ "Message 1", "Message 2" ]
}
*/
```

### Checking Size

You can determine the capacity and current size of the pubsub using `PubSub.capacity` and `PubSub.size`:

```ts twoslash
import { Console, Effect, PubSub } from 'effect';

const program = PubSub.bounded<number>(2).pipe(
  Effect.tap((pubsub) => Console.log(`capacity: ${PubSub.capacity(pubsub)}`)),
  Effect.tap((pubsub) =>
    PubSub.size(pubsub).pipe(
      Effect.andThen((size) => Console.log(`size: ${size}`)),
    )
  ),
);

Effect.runPromise(program);
/*
Output:
capacity: 2
size: 0
*/
```

Note that `capacity` returns a `number` because the capacity is set at pubsub creation and never changes. In contrast, `size` returns an effect that determines the current size of the pubsub since the number of messages in the pubsub can change over time.

### Shutting Down a PubSub

You can shut down a pubsub using `PubSub.shutdown`, check if it's shut down with `PubSub.isShutdown`, or await its shutdown with `PubSub.awaitShutdown`. Shutting down a pubsub also shuts down all associated queues, ensuring the proper propagation of the shutdown signal.

## PubSub as an Enqueue

As you can see, the operators on `PubSub` are identical to the ones on [Queue](queue) with the exception of `PubSub.publish` and `PubSub.subscribe` replacing `Queue.offer` and `Queue.take`. So if you know how to use a `Queue`, you already know how to use a `PubSub`.

In fact, a `PubSub` can be viewed as a `Queue` that can only be written to:

```ts
interface PubSub<A> extends Queue.Enqueue<A> {}
```

Here, the `Enqueue` type represents a queue that can only be enqueued. Enqueuing to the queue publishes a value to the pubsub, and actions like shutting down the queue also shut down the pubsub.

This versatility allows you to use a `PubSub` wherever you currently use a `Queue` that you only write to.

# Queue

---

## title: Queueexcerpt: Explore the lightweight, in-memory `Queue` in Effect, designed for composable and transparent back-pressure. Learn about its fully asynchronous, purely-functional, and type-safe characteristics. Delve into basic operations, creating different types of queues, and efficiently adding and consuming items. Discover how to shut down a queue gracefully and handle exclusive capabilities with offer-only and take-only queues. Enhance your understanding of `Queue` and leverage its power for seamless coordination in your asynchronous workflows.bottomNavigation: pagination

A `Queue` is a lightweight in-memory queue built on Effect with composable and transparent back-pressure.
It is fully asynchronous (no locks or blocking), purely-functional and type-safe.

## Basic Operations

A `Queue<A>` stores values of type `A` and provides two fundamental operations:

- `Queue.offer`: This operation adds a value of type `A` to the `Queue`.
- `Queue.take`: It removes and returns the oldest value from the `Queue`.

Here's an example demonstrating these basic operations:

```ts twoslash
import { Effect, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  yield* Queue.offer(queue, 1); // Add 1 to the queue
  const value = yield* Queue.take(queue); // Retrieve and remove the oldest value
  return value;
});

Effect.runPromise(program).then(console.log); // Output: 1
```

## Creating a Queue

A `Queue` can have bounded (limited capacity) or unbounded storage. Depending on your requirements, you can choose from various strategies to handle new values when the queue reaches its capacity.

### Bounded Queue

A bounded queue provides back-pressure when it's full. This means that if the queue is full, any attempt to add more items will be suspended until there's space available.

```ts twoslash
import { Queue } from 'effect';

// Creating a bounded queue with a capacity of 100
const boundedQueue = Queue.bounded<number>(100);
```

### Dropping Queue

A dropping queue simply drops new items when it's full. It doesn't wait for space to become available.

```ts twoslash
import { Queue } from 'effect';

// Creating a dropping queue with a capacity of 100
const droppingQueue = Queue.dropping<number>(100);
```

### Sliding Queue

A sliding queue removes old items when it's full to accommodate new ones.

```ts twoslash
import { Queue } from 'effect';

// Creating a sliding queue with a capacity of 100
const slidingQueue = Queue.sliding<number>(100);
```

### Unbounded Queue

An unbounded queue has no capacity limit.

```ts twoslash
import { Queue } from 'effect';

// Creating an unbounded queue
const unboundedQueue = Queue.unbounded<number>();
```

## Adding Items to a Queue

To add a value to the queue, you can use the `Queue.offer` operation:

```ts twoslash
import { Effect, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  yield* Queue.offer(queue, 1); // put 1 in the queue
});
```

If you're using a back-pressured queue and it's full, the `offer` operation might suspend. In such cases, you can use `Effect.fork` to wait in a different execution context (fiber).

```ts twoslash
import { Effect, Fiber, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(1);
  yield* Queue.offer(queue, 1);
  const fiber = yield* Effect.fork(Queue.offer(queue, 2)); // will be suspended because the queue is full
  yield* Queue.take(queue);
  yield* Fiber.join(fiber);
});
```

You can also add multiple values at once using `Queue.offerAll`:

```ts twoslash
import { Array, Effect, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  const items = Array.range(1, 10);
  yield* Queue.offerAll(queue, items);
  return yield* Queue.size(queue);
});

Effect.runPromise(program).then(console.log); // Output: 10
```

## Consuming Items from a Queue

The `Queue.take` operation removes the oldest item from the queue and returns it. If the queue is empty, it will suspend and resume only when an item is added to the queue. You can also use `Effect.fork` to wait for the value in a different execution context (fiber).

```ts twoslash
import { Effect, Fiber, Queue } from 'effect';

const oldestItem = Effect.gen(function* () {
  const queue = yield* Queue.bounded<string>(100);
  const fiber = yield* Effect.fork(Queue.take(queue)); // will be suspended because the queue is empty
  yield* Queue.offer(queue, 'something');
  const value = yield* Fiber.join(fiber);
  return value;
});

Effect.runPromise(oldestItem).then(console.log); // Output: something
```

You can retrieve the first item using `Queue.poll`. If the queue is empty, you'll get `None`; otherwise, the top item will be wrapped in `Some`.

```ts twoslash
import { Effect, Queue } from 'effect';

const polled = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  yield* Queue.offer(queue, 10);
  yield* Queue.offer(queue, 20);
  const head = yield* Queue.poll(queue);
  return head;
});

Effect.runPromise(polled).then(console.log);
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 10
}
*/
```

You can retrieve multiple items at once using `Queue.takeUpTo`. If the queue doesn't have enough items to return, it will return all the available items without waiting for more offers.

```ts twoslash
import { Effect, Queue } from 'effect';

const polled = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  yield* Queue.offer(queue, 10);
  yield* Queue.offer(queue, 20);
  yield* Queue.offer(queue, 30);
  const chunk = yield* Queue.takeUpTo(queue, 2);
  return chunk;
});

Effect.runPromise(polled).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 10, 20 ]
}
*/
```

Similarly, you can retrieve all items at once using `Queue.takeAll`. It returns immediately, providing an empty collection if the queue is empty.

```ts twoslash
import { Effect, Queue } from 'effect';

const polled = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(100);
  yield* Queue.offer(queue, 10);
  yield* Queue.offer(queue, 20);
  yield* Queue.offer(queue, 30);
  const chunk = yield* Queue.takeAll(queue);
  return chunk;
});

Effect.runPromise(polled).then(console.log);
/*
Output:
{
  _id: "Chunk",
  values: [ 10, 20, 30 ]
}
*/
```

## Shutting Down a Queue

With `Queue.shutdown`, you can interrupt all fibers that are suspended on `offer*` or `take*`. It also empties the queue and causes all future `offer*` and `take*` calls to terminate immediately.

```ts twoslash
import { Effect, Fiber, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(3);
  const fiber = yield* Effect.fork(Queue.take(queue));
  yield* Queue.shutdown(queue); // will interrupt fiber
  yield* Fiber.join(fiber); // will terminate
});
```

You can use `Queue.awaitShutdown` to execute an effect when the queue is shut down. This function waits until the queue is shut down, and if it's already shut down, it resumes immediately.

```ts twoslash
import { Console, Effect, Fiber, Queue } from 'effect';

const program = Effect.gen(function* () {
  const queue = yield* Queue.bounded<number>(3);
  const fiber = yield* Effect.fork(
    Queue.awaitShutdown(queue).pipe(
      Effect.andThen(Console.log('shutting down')),
    ),
  );
  yield* Queue.shutdown(queue);
  yield* Fiber.join(fiber);
});

Effect.runPromise(program); // Output: shutting down
```

## Offer-only / Take-only Queues

In some situations, you may need specific parts of your code to have exclusive capabilities, such as only offering values (`Enqueue`) or only taking values (`Dequeue`) from a queue. Effect provides a straightforward way to achieve this.

All operations related to offering values are defined by the `Enqueue` interface. Here's an example of how to use it:

```ts twoslash
import { Queue } from 'effect';

const send = (offerOnlyQueue: Queue.Enqueue<number>, value: number) => {
  // This enqueue can only be used to offer values

  // @ts-expect-error
  Queue.take(offerOnlyQueue);

  // Ok
  return Queue.offer(offerOnlyQueue, value);
};
```

Similarly, all operations related to taking values are defined by the `Dequeue` interface. Here's an example:

```ts twoslash
import { Queue } from 'effect';

const receive = (takeOnlyQueue: Queue.Dequeue<number>) => {
  // This dequeue can only be used to take values

  // @ts-expect-error
  Queue.offer(takeOnlyQueue, 1);

  // Ok
  return Queue.take(takeOnlyQueue);
};
```

The `Queue` type extends both `Enqueue` and `Dequeue`, allowing you to conveniently pass it to different parts of your code where you want to enforce either `Enqueue` or `Dequeue` behavior:

```ts twoslash
import { Effect, Queue } from 'effect';

const send = (offerOnlyQueue: Queue.Enqueue<number>, value: number) => {
  return Queue.offer(offerOnlyQueue, value);
};

const receive = (takeOnlyQueue: Queue.Dequeue<number>) => {
  return Queue.take(takeOnlyQueue);
};

const program = Effect.gen(function* () {
  const queue = yield* Queue.unbounded<number>();

  // Offer values to the queue
  yield* send(queue, 1);
  yield* send(queue, 2);

  // Take values from the queue
  console.log(yield* receive(queue));
  console.log(yield* receive(queue));
});

Effect.runPromise(program);
/*
Output:
1
2
*/
```

# Basic Concurrency

---

## title: Basic Concurrencyexcerpt: Basic ConcurrencybottomNavigation: pagination

Effect is a highly concurrent framework powered by fibers. Fibers are lightweight **virtual threads** with resource-safe cancellation capabilities, enabling many features in Effect.

In this section, you will learn the basics of fibers and get familiar with some of the powerful high-level operators that utilize fibers.

## What Are Virtual Threads?

JavaScript is inherently single-threaded, meaning it executes code in a single sequence of instructions. However, modern JavaScript environments use an event loop to manage asynchronous operations, creating the illusion of multitasking. In this context, virtual threads, or fibers, are logical threads simulated by the Effect runtime. They allow concurrent execution without relying on true multi-threading, which is not natively supported in JavaScript.

## Fibers

All effects in Effect are executed by fibers. If you didn't create the fiber yourself, it was created by an operation you're using (if it's concurrent) or by the Effect runtime system.

Even if you write "single-threaded" code with no concurrent operations, there will always be at least one fiber: the "main" fiber that executes your effect.

Effect fibers have a well-defined lifecycle based on the effect they are executing.

Every fiber exits with either a failure or success, depending on whether the effect it is executing fails or succeeds.

Effect fibers have unique identities, local state, and a status (such as done, running, or suspended).

### The Fiber Data Type

The Fiber data type in Effect represents a "handle" on the execution of an effect.

The `Fiber<A, E>` data type has two type parameters:

- **A (Success Type)**: The type of value the fiber may succeed with.
- **E (Failure Type)**: The type of value the fiber may fail with.

Fibers do not have an `R` type parameter because they only execute effects that have already had their requirements provided to them.

### Forking Effects

One of the fundamental ways to create a fiber is by forking an existing effect. When you fork an effect, it starts executing the effect on a new fiber, giving you a reference to this newly-created fiber.

The following code demonstrates how to create a single fiber using the `fork` function. This fiber will execute the function `fib(100)` independently of the main fiber:

```ts twoslash
import { Effect } from 'effect';

const fib = (n: number): Effect.Effect<number> =>
  Effect.suspend(() => {
    if (n <= 1) {
      return Effect.succeed(n);
    }
    return fib(n - 1).pipe(Effect.zipWith(fib(n - 2), (a, b) => a + b));
  });

const fib10Fiber = Effect.fork(fib(10));
```

### Joining Fibers

A common operation with fibers is joining them using the `Fiber.join` function. This function returns an `Effect` that will succeed or fail based on the outcome of the fiber it joins:

```ts twoslash
import { Effect, Fiber } from 'effect';

const fib = (n: number): Effect.Effect<number> =>
  Effect.suspend(() => {
    if (n <= 1) {
      return Effect.succeed(n);
    }
    return fib(n - 1).pipe(Effect.zipWith(fib(n - 2), (a, b) => a + b));
  });

const fib10Fiber = Effect.fork(fib(10));

const program = Effect.gen(function* () {
  const fiber = yield* fib10Fiber;
  const n = yield* Fiber.join(fiber);
  console.log(n);
});

Effect.runPromise(program); // 55
```

### Awaiting Fibers

Another useful function for fibers is `Fiber.await`. This function returns an effect containing an [Exit](../../other/data-types/exit) value, which provides detailed information about how the fiber completed.

```ts twoslash
import { Effect, Fiber } from 'effect';

const fib = (n: number): Effect.Effect<number> =>
  Effect.suspend(() => {
    if (n <= 1) {
      return Effect.succeed(n);
    }
    return fib(n - 1).pipe(Effect.zipWith(fib(n - 2), (a, b) => a + b));
  });

const fib10Fiber = Effect.fork(fib(10));

const program = Effect.gen(function* () {
  const fiber = yield* fib10Fiber;
  const exit = yield* Fiber.await(fiber);
  console.log(exit);
});

Effect.runPromise(program); // { _id: 'Exit', _tag: 'Success', value: 55 }
```

### Interrupting Fibers

If a fiber's result is no longer needed, it can be interrupted, which immediately terminates the fiber and safely releases all resources by running all finalizers.

Similar to `Fiber.await`, `Fiber.interrupt` returns an [Exit](../../other/data-types/exit)` value describing how the fiber completed.

```ts twoslash
import { Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const fiber = yield* Effect.fork(Effect.forever(Effect.succeed('Hi!')));
  const exit = yield* Fiber.interrupt(fiber);
  console.log(exit);
});

Effect.runPromise(program);
/*
Output
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Interrupt',
    fiberId: {
      _id: 'FiberId',
      _tag: 'Runtime',
      id: 0,
      startTimeMillis: 1715787137490
    }
  }
}
*/
```

By design, the effect returned by `Fiber.interrupt` does not resume until the fiber has completed, ensuring that your code does not start new fibers until the old one has terminated. This behavior, often called "back-pressuring," can be overridden if needed.

If you do not need back-pressuring, you can fork the interruption itself into a new fiber:

```ts twoslash
import { Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const fiber = yield* Effect.fork(Effect.forever(Effect.succeed('Hi!')));
  const _ = yield* Effect.fork(Fiber.interrupt(fiber));
});
```

There is also a shorthand for background interruption called `Fiber.interruptFork`.

```ts twoslash
import { Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const fiber = yield* Effect.fork(Effect.forever(Effect.succeed('Hi!')));
  const _ = yield* Fiber.interruptFork(fiber);
});
```

**Note**: It is also possible to perform interruptions using the high-level API `Effect.interrupt`. For more information, see [Effect.interrupt](interruption-model#calling-effectinterrupt).

### Composing Fibers

The `Fiber.zip` and `Fiber.zipWith` functions allow you to combine two fibers into a single fiber. The resulting fiber produces the results of both input fibers. If either of the input fibers fails, the composed fiber will also fail.

Here's an example using `Fiber.zip`:

```ts twoslash
import { Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const fiber1 = yield* Effect.fork(Effect.succeed('Hi!'));
  const fiber2 = yield* Effect.fork(Effect.succeed('Bye!'));
  const fiber = Fiber.zip(fiber1, fiber2);
  const tuple = yield* Fiber.join(fiber);
  console.log(tuple);
});

Effect.runPromise(program);
/*
Output:
[ 'Hi!', 'Bye!' ]
*/
```

Another way to compose fibers is with the `Fiber.orElse` function. This function allows you to specify an alternative fiber that will be executed if the first fiber fails. If the first fiber succeeds, the composed fiber will return its result. If the first fiber fails, the composed fiber will complete with the result of the second fiber, regardless of whether it succeeds or fails.

Here's an example using `Fiber.orElse`:

```ts twoslash
import { Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const fiber1 = yield* Effect.fork(Effect.fail('Uh oh!'));
  const fiber2 = yield* Effect.fork(Effect.succeed('Hurray!'));
  const fiber = Fiber.orElse(fiber1, fiber2);
  const message = yield* Fiber.join(fiber);
  console.log(message);
});

Effect.runPromise(program);
/*
Output:
Hurray!
*/
```

## Concurrency Options

Effect provides many functions that accept [Concurrency Options](concurrency-options) to help you identify opportunities to parallelize your code.

For example, the standard `Effect.zip` function combines two effects sequentially. However, there is also a concurrent version, `Effect.zip({_, _, { concurrent: true })`, which combines two effects concurrently.

In the following example, we use `Effect.zip` to run two tasks sequentially. The first task takes 1 second, and the second task takes 2 seconds, resulting in a total duration of approximately 3 seconds:

```ts twoslash
import { Console, Effect } from 'effect';

const task1 = Effect.delay(Console.log('task1'), '1 second');
const task2 = Effect.delay(Console.log('task2'), '2 seconds');

const program = Effect.zip(task1, task2);

Effect.runPromise(Effect.timed(program)).then(([duration]) =>
  console.log(String(duration))
);
/*
Output:
task1
task2
Duration(3s 5ms 369875ns)
*/
```

In this example, we use the concurrent version of `Effect.zip` to run two tasks concurrently. The total duration will be approximately equal to the duration of the longest task, which is 2 seconds:

```ts twoslash
import { Console, Effect } from 'effect';

const task1 = Effect.delay(Console.log('task1'), '1 second');
const task2 = Effect.delay(Console.log('task2'), '2 seconds');

const program = Effect.zip(task1, task2, { concurrent: true });

Effect.runPromise(Effect.timed(program)).then(([duration]) =>
  console.log(String(duration))
);
/*
Output:
task1
task2
Duration(2s 8ms 179666ns)
*/
```

## Racing

The `Effect.race` function lets you race multiple effects concurrently and returns the result of the first one that successfully completes. Here's an example:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.delay(Effect.fail('task1'), '1 second');
const task2 = Effect.delay(Effect.succeed('task2'), '2 seconds');

const program = Effect.race(task1, task2);

Effect.runPromise(program).then(console.log);
/*
Output:
task2
*/
```

In this example, `task1` is set to fail after 1 second, while `task2` is set to succeed after 2 seconds. The `Effect.race` function runs both tasks concurrently, and since `task2` is the first to succeed, its result is returned.

If you need to handle the first effect to complete, whether it succeeds or fails, you can use the `Effect.either` function. This function wraps the result in an [Either](../../other/data-types/either) type, allowing you to see if the outcome was a success (`Right`) or a failure (`Left`):

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.delay(Effect.fail('task1'), '1 second');
const task2 = Effect.delay(Effect.succeed('task2'), '2 seconds');

const program = Effect.race(Effect.either(task1), Effect.either(task2));

Effect.runPromise(program).then(console.log);
/*
Output:
{ _id: 'Either', _tag: 'Left', left: 'task1' }
*/
```

In this example, `task1` fails after 1 second, and `task2` succeeds after 2 seconds. By using `Effect.either`, the program returns the result of `task1`, showing that it was a failure (`Left`).

## Timeout

When working with asynchronous tasks, it's often important to ensure that they complete within a reasonable time.
Effect provides a convenient way to enforce time limits on effects using the `Effect.timeout` function.
This function returns a new effect that will fail with a `TimeoutException` if the original effect does not complete within the specified duration.

Here's an example demonstrating how to use `Effect.timeout`:

```ts twoslash
import { Effect } from 'effect';

const task = Effect.delay(Effect.succeed('task1'), '10 seconds');

const program = Effect.timeout(task, '2 seconds');

Effect.runPromise(program);
/*
throws:
TimeoutException
*/
```

In this example, `task` is an effect that succeeds after 10 seconds. By wrapping `task` with `Effect.timeout` and specifying a timeout of 2 seconds, the resulting program will fail with a `TimeoutException` because the task takes longer than the allowed time.

If an effect times out, the `effect` library automatically interrupts it to prevent it from continuing to execute in the background. This interruption ensures efficient use of resources by stopping unnecessary work.

# Deferred

---

## title: Deferredexcerpt: Explore the power of `Deferred` in Effect, a specialized subtype of `Effect` that acts as a one-time variable with unique characteristics. Discover how `Deferred` serves as a synchronization tool for managing asynchronous operations, allowing coordination between different parts of your code. Learn common use cases, including coordinating fibers, synchronization, handing over work, and suspending execution. Dive into operations such as creating, awaiting, completing, and polling `Deferred`, providing practical examples and scenarios to enhance your understanding of this powerful tool.bottomNavigation: pagination

A `Deferred<A, E>` is a special subtype of `Effect` that acts as a variable, but with some unique characteristics. It can only be set once, making it a powerful synchronization tool for managing asynchronous operations.

A `Deferred` is essentially a synchronization primitive that represents a value that may not be available immediately. When you create a `Deferred`, it starts with an empty value. Later on, you can complete it exactly once with either a success value (`A`) or a failure value (`E`). Once completed, a `Deferred` can never be modified or emptied again.

## Common Use Cases

`Deferred` becomes incredibly useful when you need to wait for something specific to happen in your program. It's ideal for scenarios where you want one part of your code to signal another part when it's ready. Here are a few common use cases:

- **Coordinating Fibers**: When you have multiple concurrent tasks (fibers) and need to coordinate their actions, `Deferred` can help one fiber signal to another when it has completed its task.

- **Synchronization**: Anytime you want to ensure that one piece of code doesn't proceed until another piece of code has finished its work, `Deferred` can provide the synchronization you need.

- **Handing Over Work**: You can use `Deferred` to hand over work from one fiber to another. For example, one fiber can prepare some data, and then a second fiber can continue processing it.

- **Suspending Execution**: When you want a fiber to pause its execution until some condition is met, a `Deferred` can be used to block it until the condition is satisfied.

When a fiber calls `await` on a `Deferred`, it essentially blocks until that `Deferred` is completed with either a value or an error. Importantly, in Effect, blocking fibers don't actually block the main thread; they block only semantically. While one fiber is blocked, the underlying thread can execute other fibers, ensuring efficient concurrency.

A `Deferred` in Effect is conceptually similar to JavaScript's `Promise`. The key difference is that `Deferred` has two type parameters (`E` and `A`) instead of just one. This allows `Deferred` to represent both successful results (`A`) and errors (`E`).

## Operations

### Creating

You can create a `Deferred` using `Deferred.make<A, E>()`. This returns an `Effect<Deferred<A, E>>`, which describes the creation of a `Deferred`. Note that `Deferred`s can only be created within an `Effect` because creating them involves effectful memory allocation, which must be managed safely within an `Effect`.

### Awaiting

To retrieve a value from a `Deferred`, you can use `Deferred.await`. This operation suspends the calling fiber until the `Deferred` is completed with a value or an error.

```ts twoslash
import { Deferred, Effect } from 'effect';

const effectDeferred = Deferred.make<string, Error>();

const effectGet = effectDeferred.pipe(
  Effect.andThen((deferred) => Deferred.await(deferred)),
);
```

### Completing

You can complete a `Deferred<A, E>` in different ways:

There are several ways to complete a `Deferred`:

- `Deferred.succeed`: Completes the `Deferred` successfully with a value of type `A`.
- `Deferred.done`: Completes the `Deferred` with an `Exit<A, E>` type.
- `Deferred.complete`: Completes the `Deferred` with the result of an effect `Effect<A, E>`.
- `Deferred.completeWith`: Completes the `Deferred` with an effect `Effect<A, E>`. This effect will be executed by each waiting fiber, so use it carefully.
- `Deferred.fail`: Fails the `Deferred` with an error of type `E`.
- `Deferred.die`: Defects the `Deferred` with a user-defined error.
- `Deferred.failCause`: Fails or defects the `Deferred` with a `Cause<E>`.
- `Deferred.interrupt`: Interrupts the `Deferred`. This can be used to forcefully stop or interrupt the waiting fibers.

Here's an example that demonstrates the usage of these completion methods:

```ts twoslash
import { Cause, Deferred, Effect, Exit } from 'effect';

const program = Effect.gen(function* () {
  const deferred = yield* Deferred.make<number, string>();

  // Completing the Deferred in various ways
  yield* Deferred.succeed(deferred, 1).pipe(Effect.fork);
  yield* Deferred.complete(deferred, Effect.succeed(2)).pipe(Effect.fork);
  yield* Deferred.completeWith(deferred, Effect.succeed(3)).pipe(Effect.fork);
  yield* Deferred.done(deferred, Exit.succeed(4)).pipe(Effect.fork);
  yield* Deferred.fail(deferred, '5').pipe(Effect.fork);
  yield* Deferred.failCause(deferred, Cause.die(new Error('6'))).pipe(
    Effect.fork,
  );
  yield* Deferred.die(deferred, new Error('7')).pipe(Effect.fork);
  yield* Deferred.interrupt(deferred).pipe(Effect.fork);

  // Awaiting the Deferred to get its value
  const value = yield* Deferred.await(deferred);
  return value;
});

Effect.runPromise(program).then(console.log, console.error); // Output: 1
```

When you complete a `Deferred`, it results in an `Effect<boolean>`. This effect returns `true` if the `Deferred` value has been set and `false` if it was already set before completion. This can be useful for checking the state of the `Deferred`.

Here's an example demonstrating the state change of a `Deferred`:

```ts twoslash
import { Deferred, Effect } from 'effect';

const program = Effect.gen(function* () {
  const deferred = yield* Deferred.make<number, string>();
  const b1 = yield* Deferred.fail(deferred, 'oh no!');
  const b2 = yield* Deferred.succeed(deferred, 1);
  return [b1, b2];
});

Effect.runPromise(program).then(console.log); // Output: [ true, false ]
```

### Polling

Sometimes, you may want to check whether a `Deferred` has been completed without causing the fiber to suspend. To achieve this, you can use the `Deferred.poll` method. Here's how it works:

- `Deferred.poll` returns an `Option<Effect<A, E>>`.
  - If the `Deferred` is not yet completed, it returns `None`.
  - If the `Deferred` is completed, it returns `Some`, which contains the result or error.

Additionally, you can use the `Deferred.isDone` method, which returns an `Effect<boolean>`. This effect evaluates to `true` if the `Deferred` is already completed, allowing you to quickly check the completion status.

Here's a practical example:

```ts twoslash
import { Deferred, Effect } from 'effect';

const program = Effect.gen(function* () {
  const deferred = yield* Deferred.make<number, string>();

  // Polling the Deferred
  const done1 = yield* Deferred.poll(deferred);

  // Checking if the Deferred is already completed
  const done2 = yield* Deferred.isDone(deferred);

  return [done1, done2];
});

Effect.runPromise(program).then(console.log); // Output: [ none(), false ]
```

In this example, we first create a `Deferred` and then use `Deferred.poll` to check its completion status. Since it's not completed yet, `done1` is `none()`. We also use `Deferred.isDone` to confirm that the `Deferred` is indeed not completed, so `done2` is `false`.

## Example: Using Deferred to Coordinate Two Fibers

Here's a scenario where we use a `Deferred` to hand over a value between two fibers:

```ts twoslash
import { Deferred, Effect, Fiber } from 'effect';

const program = Effect.gen(function* () {
  const deferred = yield* Deferred.make<string, string>();

  // Fiber A: Set the Deferred value after waiting for 1 second
  const sendHelloWorld = Effect.gen(function* () {
    yield* Effect.sleep('1 second');
    return yield* Deferred.succeed(deferred, 'hello world');
  });

  // Fiber B: Wait for the Deferred and print the value
  const getAndPrint = Effect.gen(function* () {
    const s = yield* Deferred.await(deferred);
    console.log(s);
    return s;
  });

  // Run both fibers concurrently
  const fiberA = yield* Effect.fork(sendHelloWorld);
  const fiberB = yield* Effect.fork(getAndPrint);

  // Wait for both fibers to complete
  return yield* Fiber.join(Fiber.zip(fiberA, fiberB));
});

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
hello world
[ true, "hello world" ]
*/
```

In this example, we have two fibers, `fiberA` and `fiberB`, that communicate using a `Deferred`:

- `fiberA` sets the `Deferred` value to "hello world" after waiting for 1 second.
- `fiberB` waits for the `Deferred` to be completed and then prints the received value to the console.

By running both fibers concurrently and using the `Deferred` as a synchronization point, we can ensure that `fiberB` only proceeds after `fiberA` has completed its task. This coordination mechanism allows you to hand over values or coordinate work between different parts of your program effectively.

# Fibers

---

## title: Fibersexcerpt: Discover the power of fibers in Effect, providing a lightweight and efficient way to manage concurrency and asynchronous tasks. Learn the fundamentals of fibers, their role in multitasking, and how they contribute to responsive applications. Explore the creation of fibers, their lifetimes, and various forking strategies, gaining insights into structured concurrency and daemon fibers. Unravel the intricacies of when fibers run, enabling you to optimize their execution and harness the full potential of concurrent programming in Effect.bottomNavigation: pagination

## What is a Fiber?

A "fiber" is a small unit of work or a lightweight thread of execution. It represents a specific computation or an effectful operation in a program. Fibers are used to manage concurrency and asynchronous tasks.

Think of a fiber as a worker that performs a specific job. It can be started, paused, resumed, and even interrupted. Fibers are useful when we want to perform multiple tasks simultaneously or handle long-running operations without blocking the main program.

By using fibers, developers can control and coordinate the execution of tasks, allowing for efficient multitasking and responsiveness in their applications.

To summarize:

- An `Effect` is a higher-level concept that describes an effectful computation. It is lazy and immutable, meaning it represents a computation that may produce a value or fail but does not immediately execute.
- A fiber, on the other hand, represents the running execution of an `Effect`. It can be interrupted or awaited to retrieve its result. Think of it as a way to control and interact with the ongoing computation.

## Creating Fibers

A fiber is created any time an effect is run. When running effects concurrently, a fiber is created for each concurrent effect.

## Lifetime of Child Fibers

When we fork fibers, depending on how we fork them we can have four different lifetime strategies for the child fibers:

1. **Fork With Automatic Supervision**. If we use the ordinary `Effect.fork` operation, the child fiber will be automatically supervised by the parent fiber. The lifetime child fibers are tied to the lifetime of their parent fiber. This means that these fibers will be terminated either when they end naturally, or when their parent fiber is terminated.

2. **Fork in Global Scope (Daemon)**. Sometimes we want to run long-running background fibers that aren't tied to their parent fiber, and also we want to fork them in a global scope. Any fiber that is forked in global scope will become daemon fiber. This can be achieved by using the `Effect.forkDaemon` operator. As these fibers have no parent, they are not supervised, and they will be terminated when they end naturally, or when our application is terminated.

3. **Fork in Local Scope**. Sometimes, we want to run a background fiber that isn't tied to its parent fiber, but we want to live that fiber in the local scope. We can fork fibers in the local scope by using `Effect.forkScoped`. Such fibers can outlive their parent fiber (so they are not supervised by their parents), and they will be terminated when their life end or their local scope is closed.

4. **Fork in Specific Scope**. This is similar to the previous strategy, but we can have more fine-grained control over the lifetime of the child fiber by forking it in a specific scope. We can do this by using the `Effect.forkIn` operator.

### Fork with Automatic Supervision

Effect employs a **structured concurrency** model where the lifetimes of fibers are neatly nested. Simply put, the lifespan of a fiber depends on the lifespan of its parent fiber.

To help clarify this concept, let's explore the following example.
In this scenario, the `parent` fiber spawns the `child` fiber.
The `child` fiber is engaged in a long-running task that never completes.
What's important to note here is that Effect ensures the `child` fiber will not outlive the `parent` fiber:

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const child = Effect.repeat(
  Console.log('child: still running!'),
  Schedule.fixed('1 second'),
);

const parent = Effect.gen(function* () {
  console.log('parent: started!');
  yield* Effect.fork(child);
  yield* Effect.sleep('3 seconds');
  console.log('parent: finished!');
});

Effect.runPromise(parent);
```

When you run the above program, you'll see the following output:

```sh filename="Terminal"
parent: started!
child: still running!
child: still running!
child: still running!
parent: finished!
```

This pattern can be extended to any level of nested fibers.

### Fork in Global Scope (Daemon)

Using `Effect.forkDaemon` we can create a daemon fiber from an effect. Its lifetime is tied to the global scope.
So if the parent fiber terminates, the daemon fiber will not be terminated.
It will only will be terminated when the global scope is closed, or its life end naturally.

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const daemon = Effect.repeat(
  Console.log('daemon: still running!'),
  Schedule.fixed('1 second'),
);

const parent = Effect.gen(function* () {
  console.log('parent: started!');
  yield* Effect.forkDaemon(daemon);
  yield* Effect.sleep('3 seconds');
  console.log('parent: finished!');
});

Effect.runPromise(parent);
```

If we run the above program, we will see the following output which shows that while the lifetime of the `parent` fiber ends after 3 seconds, the `daemon` fiber is still running:

```sh filename="Terminal"
parent: started!
daemon: still running!
daemon: still running!
daemon: still running!
parent: finished!
daemon: still running!
daemon: still running!
daemon: still running!
daemon: still running!
daemon: still running!
...etc...
```

Even if we interrupt the `parent` fiber, the `daemon` fiber will not be interrupted:

```ts twoslash
import { Console, Effect, Fiber, Schedule } from 'effect';

const daemon = Effect.repeat(
  Console.log('daemon: still running!'),
  Schedule.fixed('1 second'),
);

const parent = Effect.gen(function* () {
  console.log('parent: started!');
  yield* Effect.forkDaemon(daemon);
  yield* Effect.sleep('3 seconds');
  console.log('parent: finished!');
}).pipe(Effect.onInterrupt(() => Console.log('parent: interrupted!')));

const program = Effect.gen(function* () {
  const fiber = yield* Effect.fork(parent);
  yield* Effect.sleep('2 seconds');
  yield* Fiber.interrupt(fiber);
});

Effect.runPromise(program);
```

The output:

```sh filename="Terminal"
parent: started!
daemon: still running!
daemon: still running!
parent: interrupted!
daemon: still running!
daemon: still running!
daemon: still running!
daemon: still running!
daemon: still running!
...etc...
```

### Fork in Local Scope

Sometimes we want to attach fiber to a local scope. In such cases, we can use the `Effect.forkScoped` operator.
By using this operator, the lifetime of the forked fiber can be outlived the lifetime of its parent fiber, and it will be terminated when the local scope is closed:

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const child = Effect.repeat(
  Console.log('child: still running!'),
  Schedule.fixed('1 second'),
);

const parent = Effect.gen(function* () {
  console.log('parent: started!');
  yield* Effect.forkScoped(child);
  yield* Effect.sleep('3 seconds');
  console.log('parent: finished!');
});

const program = Effect.scoped(
  Effect.gen(function* () {
    console.log('Local scope started!');
    yield* Effect.fork(parent);
    yield* Effect.sleep('5 seconds');
    console.log('Leaving the local scope!');
  }),
);

Effect.runPromise(program);
```

In the above example, the `child` fiber forked in the local scope has bigger lifetime than its `parent` fiber.
So, when its `parent` fiber is terminated, the `child` fiber still running in the local scope until the local scope is closed.
Let's see the output:

```sh filename="Terminal"
Local scope started!
parent: started!
child: still running!
child: still running!
child: still running!
parent: finished!
child: still running!
child: still running!
Leaving the local scope!
```

### Fork in Specific Scope

There are some cases where we need more fine-grained control, so we want to fork a fiber in a specific scope.
We can use the `Effect.forkIn` operator which takes the target scope as an argument:

```ts twoslash
import { Console, Effect, Schedule } from 'effect';

const child = Console.log('child: still running!').pipe(
  Effect.repeat(Schedule.fixed('1 second')),
);

const program = Effect.scoped(
  Effect.gen(function* () {
    yield* Effect.addFinalizer(() =>
      Console.log('The outer scope is about to be closed!')
    );

    const outerScope = yield* Effect.scope;

    yield* Effect.scoped(
      Effect.gen(function* () {
        yield* Effect.addFinalizer(() =>
          Console.log('The inner scope is about to be closed!')
        );
        yield* Effect.forkIn(child, outerScope);
        yield* Effect.sleep('3 seconds');
      }),
    );

    yield* Effect.sleep('5 seconds');
  }),
);

Effect.runPromise(program);
```

The output:

```sh filename="Terminal"
child: still running!
child: still running!
child: still running!
The inner scope is about to be closed!
child: still running!
child: still running!
child: still running!
child: still running!
child: still running!
child: still running!
The outer scope is about to be closed!
```

## When do Fibers run?

New fibers begin execution after the current fiber completes or yields. This is necessary to prevent infinite loops in some cases, and is useful to know when using the `fork` APIs.

In the following example the `SubscriptionRef` `changes` stream only contains a single value `2` because the fiber (created by `fork`) to run the stream is started _after_ the value has been updated.

```ts twoslash
import { Console, Effect, Stream, SubscriptionRef } from 'effect';

const program = Effect.gen(function* () {
  const ref = yield* SubscriptionRef.make(0);
  yield* ref.changes.pipe(
    Stream.tap((n) => Console.log(`SubscriptionRef changed to ${n}`)),
    Stream.runDrain,
    Effect.fork,
  );
  yield* SubscriptionRef.set(ref, 1);
  yield* SubscriptionRef.set(ref, 2);
});

Effect.runPromise(program);
/*
Output:
SubscriptionRef changed to 2
*/
```

If we add `Effect.yieldNow()` to force the current fiber to yield then the stream will contain all values `0`, `1`, and `2` because the fiber running the stream has an opportunity to start before the value is changed.

```ts twoslash
import { Console, Effect, Stream, SubscriptionRef } from 'effect';

const program = Effect.gen(function* () {
  const ref = yield* SubscriptionRef.make(0);
  yield* ref.changes.pipe(
    Stream.tap((n) => Console.log(`SubscriptionRef changed to ${n}`)),
    Stream.runDrain,
    Effect.fork,
  );
  yield* Effect.yieldNow();
  yield* SubscriptionRef.set(ref, 1);
  yield* SubscriptionRef.set(ref, 2);
});

Effect.runPromise(program);
/*
Output:
SubscriptionRef changed to 0
SubscriptionRef changed to 1
SubscriptionRef changed to 2
*/
```

# Introduction to Runtime

---

## title: Introduction to Runtimeexcerpt: Effect is a powerful TypeScript library designed to help developers easily create complex, synchronous, and asynchronous programs.bottomNavigation: pagination

The `Runtime<R>` data type represents a Runtime System that can execute effects. To execute any effect, we need a `Runtime` that includes the necessary requirements for that effect.

A `Runtime<R>` consists of three main components:

- a value of type `Context<R>`
- a value of type `FiberRefs`
- a value of type `RuntimeFlags`

## The Default Runtime

When we use functions like `Effect.run*`, we are actually using the **default runtime** without explicitly mentioning it. These functions are designed as convenient shortcuts for executing our effects using the default runtime.

For instance, in the `Runtime` module, there is a corresponding `Runtime.run*(defaultRuntime)` function that is called internally by `Effect.run*`, e.g. `Effect.runSync` is simply an alias for `Runtime.runSync(defaultRuntime)`.

The default runtime includes:

- An empty `Context<never>`
- A set of `FiberRefs` that include the default services
- A default configuration for `RuntimeFlags` that enables `Interruption` and `CooperativeYielding`

In most cases, using the default runtime is sufficient. However, it can be useful to create a custom runtime to reuse a specific context or configuration. It is common to create a `Runtime<R>` by initializing a `Layer<R, Err, RIn>`. This allows for context reuse across execution boundaries, such as in a React App or when executing operations on a server in response to API requests.

## What is a Runtime System?

When we write an Effect program, we construct an `Effect` using constructors and combinators. Essentially, we are creating a blueprint of a program. An `Effect` is merely a data structure that describes the execution of a concurrent program. It represents a tree-like structure that combines various primitives to define what the `Effect` should do.

However, this data structure itself does not perform any actions; it is solely a description of a concurrent program.

Therefore, it is crucial to understand that when working with a functional effect system like Effect, our code for actions such as printing to the console, reading files, or querying databases is actually building a workflow or blueprint for an application. We are constructing a data structure.

So how does Effect actually run these workflows? This is where the Effect Runtime System comes into play. When we invoke a `Runtime.run*` function, the Runtime System takes over. First, it creates an empty root Fiber with:

- The initial context
- The initial fiberRefs
- The initial Effect

After the creation of the Fiber, it invokes the Fiber's runLoop, which follows the instructions described by the `Effect` and executes them step by step.

To simplify, we can envision the Runtime System as a black box that takes both the effect [Effect&lt;A, E, R&gt;](essentials/the-effect-type) and its associated context `Context<R>`. It runs the effect and returns the result as an [Exit&lt;A, E&gt;](../other/data-types/exit) value.

![Runtime](/images/mmd/runtime.svg)

## Responsibilities of the Runtime System

Runtime Systems have a lot of responsibilities:

1. **Execute every step of the blueprint**. They have to execute every step of the blueprint in a while loop until it's done.

2. **Handle unexpected errors**. They have to handle unexpected errors, not just the expected ones but also the unexpected ones.

3. **Spawn concurrent fiber**. They are actually responsible for the concurrency that effect systems have. They have to spawn a fiber every time we call `fork` on an effect to spawn off a new fiber.

4. **Cooperatively yield to other fibers**. They have to cooperatively yield to other fibers so that fibers that are sort of hogging the spotlight, don't get to monopolize all the CPU resources.

5. **Ensure finalizers are run appropriately**. They have to ensure finalizers are run appropriately at the right point in all circumstances to make sure that resources are closed that clean-up logic is executed. This is the feature that powers [Scope](./resource-management/scope) and all the other resource-safe constructs in Effect.

6. **Handle asynchronous callback**. They have to handle this messy job of dealing with asynchronous callbacks. So we don't have to deal with async code. When we are using Effect, everything can be interpreted as async or sync out of the box.

## Default Runtime

Effect provides a default runtime named `Runtime.defaultRuntime` designed for mainstream usage.

The default runtime provides the minimum capabilities to bootstrap execution of Effect tasks.

Both of the following executions are equivalent:

```ts twoslash
import { Effect, Runtime } from 'effect';

const program = Effect.log('Application started!');

Effect.runSync(program);
/*
Output:
... level=INFO fiber=#0 message="Application started!"
*/

Runtime.runSync(Runtime.defaultRuntime)(program);
/*
Output:
... level=INFO fiber=#0 message="Application started!"
*/
```

Under the hood, `Effect.runSync` (and the same principle applies to other `Effect.run*` functions) serves as a convenient shorthand for `Runtime.runSync(Runtime.defaultRuntime)`.

## Locally Scoped Runtime Configuration

In Effect, runtime configurations are typically inherited from their parent workflows. This means that when we access a runtime configuration or obtain a runtime inside a workflow, we are essentially using the configuration of the parent workflow. However, there are cases where we want to temporarily override the runtime configuration for a specific part of our code. This concept is known as locally scoped runtime configuration. Once the execution of that code region is completed, the runtime configuration reverts to its original settings.

To achieve this, we make use of `Effect.provide*` functions, which allow us to provide a new runtime configuration to a specific section of our code.

### Configuring Runtime by Providing Configuration Layers

By utilizing the `Effect.provide` function and providing runtime configuration layers to an Effect workflow, we can easily modify runtime configurations.

Here's an example:

```ts twoslash
import { Effect, Logger } from 'effect';

// Define a configuration layer
const addSimpleLogger = Logger.replace(
  Logger.defaultLogger,
  Logger.make(({ message }) => console.log(message)),
);

const program = Effect.gen(function* () {
  yield* Effect.log('Application started!');
  yield* Effect.log('Application is about to exit!');
});

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="Application started!"
timestamp=... level=INFO fiber=#0 message="Application is about to exit!"
*/

// Overriding the default logger
Effect.runSync(program.pipe(Effect.provide(addSimpleLogger)));
/*
Output:
Application started!
Application is about to exit!
*/
```

In this example, we first create a configuration layer for a simple logger using `Logger.replace`.
Then, we use `Effect.provide` to provide this configuration to our program, effectively overriding the default logger with the simple logger.

To ensure that the runtime configuration is only applied to a specific part of an Effect application, we should provide the configuration layer exclusively to that particular section, as demonstrated in the following example:

```ts twoslash
import { Effect, Logger } from 'effect';

// Define a configuration layer
const addSimpleLogger = Logger.replace(
  Logger.defaultLogger,
  Logger.make(({ message }) => console.log(message)),
);

const program = Effect.gen(function* () {
  yield* Effect.log('Application started!');
  yield* Effect.gen(function* () {
    yield* Effect.log("I'm not going to be logged!");
    yield* Effect.log('I will be logged by the simple logger.').pipe(
      Effect.provide(addSimpleLogger),
    );
    yield* Effect.log(
      "Reset back to the previous configuration, so I won't be logged.",
    );
  }).pipe(Effect.provide(Logger.remove(Logger.defaultLogger)));
  yield* Effect.log('Application is about to exit!');
});

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="Application started!"
I will be logged by the simple logger.
timestamp=... level=INFO fiber=#0 message="Application is about to exit!"
*/
```

## Top-level Runtime Configuration

When developing an Effect application and executing it using `Effect.run*` functions, the application is automatically run using the default runtime behind the scenes.
While we can adjust and customize specific aspects of our Effect application by providing locally scoped configuration layers using `Effect.provide` operations,
there are scenarios where we need to customize the runtime configuration for the entire application from the top level.

In such situations, we can create a top-level runtime by converting a configuration layer into a runtime using the `ManagedRuntime.make` constructor.

### ManagedRuntime

```ts twoslash
import { Effect, Logger, ManagedRuntime } from 'effect';

// Define a configuration layer
const appLayer = Logger.replace(
  Logger.defaultLogger,
  Logger.make(({ message }) => console.log(message)),
);

// Transform the configuration layer into a runtime
const runtime = ManagedRuntime.make(appLayer);

const program = Effect.log('Application started!');

// Execute the program using the custom runtime
runtime.runSync(program);

// Cleaning up any resources used by the configuration layer
Effect.runFork(runtime.disposeEffect);
/*
Output:
Application started!
*/
```

In this example, we first create a custom configuration layer called `appLayer`, which includes modifications to the logger configuration.
Next, we transform this configuration layer into a runtime using `ManagedRuntime.make`.
This results in a top-level runtime that encapsulates the desired configuration for the entire Effect application.

By customizing the top-level runtime configuration, we can tailor the behavior of our entire Effect application to meet our specific needs and requirements.

### Effect.Tag

When you utilize a runtime that you pass around, you can use `Effect.Tag` to define a new tag and simplify access to a service. This incorporates the service shape directly into the static side of the tag class.

You can define a new tag using `Effect.Tag` as shown below:

```ts twoslash
import { Effect } from 'effect';

class Notifications extends Effect.Tag('Notifications')<
  Notifications,
  { readonly notify: (message: string) => Effect.Effect<void> }
>() {}
```

In this setup, every field of the service shape is converted into a static property of the `Notifications` class.

This allows you to access the service shape directly:

```ts twoslash
import { Effect } from 'effect';

class Notifications extends Effect.Tag('Notifications')<
  Notifications,
  { readonly notify: (message: string) => Effect.Effect<void> }
>() {}

// ---cut---
const action = Notifications.notify('Hello, world!');
```

As you can see, `action` depends on `Notifications`, but this isn't a problem because you can later construct a `Layer` that provides `Notifications` and build a `ManagedRuntime` with it.

### Integrations

The `ManagedRuntime` simplifies the integration of services and layers with other frameworks or tools, particularly in environments where Effect is not the primary framework and access to the main entry point is restricted.

For instance, `ManagedRuntime` can be particularly useful in environments like React or other frameworks where control over the main application entry point is limited. Here's how you can use `ManagedRuntime` to manage service lifecycle within an external framework:

```ts twoslash
import { Console, Effect, Layer, ManagedRuntime } from 'effect';

class Notifications extends Effect.Tag('Notifications')<
  Notifications,
  { readonly notify: (message: string) => Effect.Effect<void> }
>() {
  static Live = Layer.succeed(this, {
    notify: (message) => Console.log(message),
  });
}

// Example entry point for an external framework
async function main() {
  const runtime = ManagedRuntime.make(Notifications.Live);
  await runtime.runPromise(Notifications.notify('Hello, world!'));
  await runtime.dispose();
}
```

# Configuration

---

## title: Configurationexcerpt: Effect is a powerful TypeScript library designed to help developers easily create complex, synchronous, and asynchronous programs.bottomNavigation: pagination

Configuration is an essential aspect of any cloud-native application. Effect simplifies the process of managing configuration by offering a convenient interface for configuration providers.

The configuration front-end in Effect enables ecosystem libraries and applications to specify their configuration requirements in a declarative manner. It offloads the complex tasks to a `ConfigProvider`, which can be supplied by third-party libraries.

Effect comes bundled with a straightforward default `ConfigProvider` that retrieves configuration data from environment variables. This default provider can be used during development or as a starting point before transitioning to more advanced configuration providers.

To make our application configurable, we need to understand three essential elements:

- **Config Description**: We describe the configuration data using an instance of `Config<A>`. If the configuration data is simple, such as a `string`, `number`, or `boolean`, we can use the built-in functions provided by the `Config` module. For more complex data types like [HostPort](#custom-configurations), we can combine primitive configs to create a custom configuration description.

- **Config Frontend**: We utilize the instance of `Config<A>` to load the configuration data described by the instance (a `Config` is, in itself, an effect). This process leverages the current `ConfigProvider` to retrieve the configuration.

- **Config Backend**: The `ConfigProvider` serves as the underlying engine that manages the configuration loading process. Effect comes with a default config provider as part of its default services. This default provider reads the configuration data from environment variables. If we want to use a custom config provider, we can utilize the `Layer.setConfigProvider` layer to configure the Effect runtime accordingly.

## Getting Started

Effect provides a set of primitives for the most common types like `string`, `number`, `boolean`, `integer`, etc.

Let's start with a simple example of how to read configuration from environment variables:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts filename="primitives.ts" twoslash
import { Config, Effect } from 'effect';

const program = Effect.gen(function* () {
  const host = yield* Config.string('HOST');
  const port = yield* Config.number('PORT');
  console.log(`Application started: ${host}:${port}`);
});

Effect.runSync(program);
```

</Tab>
<Tab>

```ts filename="primitives.ts" twoslash
import { Config, Console, Effect } from 'effect';

const program = Effect.all([
  Config.string('HOST'),
  Config.number('PORT'),
]).pipe(
  Effect.andThen(([host, port]) =>
    Console.log(`Application started: ${host}:${port}`)
  ),
);

Effect.runSync(program);
```

</Tab>
</Tabs>

If we run this program we will get the following output:

```bash filename="Terminal"
npx ts-node primitives.ts
(Missing data at HOST: "Expected HOST to exist in the process context")
```

This is because we have not provided any configuration. Let's try running it with the following environment variables:

```bash filename="Terminal"
HOST=localhost PORT=8080 npx ts-node primitives.ts
Application started: localhost:8080
```

## Primitives

Effect offers these basic types out of the box:

- `string`: Constructs a config for a string value.
- `number`: Constructs a config for a float value.
- `boolean`: Constructs a config for a boolean value.
- `integer`: Constructs a config for a integer value.
- `date`: Constructs a config for a date value.
- `literal`: Constructs a config for a literal (\*) value.
- `logLevel`: Constructs a config for a [LogLevel](observability/logging#log-levels) value.
- `duration`: Constructs a config for a duration value.
- `redacted`: Constructs a config for a secret value.

(\*) `string | number | boolean | null | bigint`

## Default Values

In some cases, you may encounter situations where an environment variable is not set, leading to a missing value in the configuration. To handle such scenarios, Effect provides the `Config.withDefault` function. This function allows you to specify a fallback or default value to use when an environment variable is not present.

Here's how you can use `Config.withDefault` to handle fallback values:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts filename="withDefault.ts" twoslash
import { Config, Effect } from 'effect';

const program = Effect.gen(function* () {
  const host = yield* Config.string('HOST');
  const port = yield* Config.number('PORT').pipe(Config.withDefault(8080));
  console.log(`Application started: ${host}:${port}`);
});

Effect.runSync(program);
```

</Tab>
<Tab>

```ts filename="withDefault.ts" twoslash
import { Config, Console, Effect } from 'effect';

const program = Effect.all([
  Config.string('HOST'),
  Config.number('PORT').pipe(Config.withDefault(8080)),
]).pipe(
  Effect.andThen(([host, port]) =>
    Console.log(`Application started: ${host}:${port}`)
  ),
);

Effect.runSync(program);
```

</Tab>
</Tabs>

When running the program with the command:

```bash filename="Terminal"
HOST=localhost npx ts-node withDefault.ts
```

you will see the following output:

```bash
Application started: localhost:8080
```

Even though the `PORT` environment variable is not set, the fallback value of `8080` is used, ensuring that the program continues to run smoothly with a default value.

## Constructors

Effect provides several built-in constructors. These are functions that take a `Config` as input and produce another `Config`.

- `array`: Constructs a config for an array of values.
- `chunk`: Constructs a config for a sequence of values.
- `option`: Returns an optional version of this config, which will be `None` if the data is missing from configuration, and `Some` otherwise.
- `repeat`: Returns a config that describes a sequence of values, each of which has the structure of this config.
- `hashSet`: Constructs a config for a sequence of values.
- `hashMap`: Constructs a config for a sequence of values.

In addition to the basic ones, there are three special constructors you might find useful:

- `succeed`: Constructs a config which contains the specified value.
- `fail`: Constructs a config that fails with the specified message.
- `all`: Constructs a config from a tuple / struct / arguments of configs.

**Example**

```ts filename="array.ts" twoslash
import { Config, Effect } from 'effect';

const program = Effect.gen(function* () {
  const config = yield* Config.array(Config.string(), 'MY_ARRAY');
  console.log(config);
});

Effect.runSync(program);
```

```bash filename="Terminal"
MY_ARRAY=a,b,c npx ts-node array.ts

[ 'a', 'b', 'c' ]
```

## Operators

Effect comes with a set of built-in operators to help you manipulate and handle configurations.

### Transforming Operators

These operators allow you to transform a config into a new one:

- `validate`: Returns a config that describes the same structure as this one, but which performs validation during loading.
- `map`: Creates a new config with the same structure as the original but with values transformed using a given function.
- `mapAttempt`: Similar to `map`, but if the function throws an error, it's caught and turned into a validation error.
- `mapOrFail`: Like `map`, but allows for functions that might fail. If the function fails, it results in a validation error.

**Example**

```ts filename="validate.ts" twoslash
import { Config, Effect } from 'effect';

const program = Effect.gen(function* () {
  const config = yield* Config.string('NAME').pipe(
    Config.validate({
      message: 'Expected a string at least 4 characters long',
      validation: (s) => s.length >= 4,
    }),
  );
  console.log(config);
});

Effect.runSync(program);
```

```bash filename="Terminal"
NAME=foo npx ts-node validate.ts

[(Invalid data at NAME: "Expected a string at least 4 characters long")]
```

### Fallback Operators

These operators help you set up fallbacks in case of errors or missing data:

- `orElse`: Sets up a config that tries to use this config first. If there's an issue, it falls back to another specified config.
- `orElseIf`: This one also tries to use the main config first but switches to a fallback config if there's an error that matches a specific condition.

**Example**

In this example, we have a program that requires two configurations: `A` and `B`. We will use two configuration providers, where each provider has only one of the configurations. We will demonstrate how to set up fallbacks using the `orElse` operator.

```ts filename="orElse.ts" twoslash
import { Config, ConfigProvider, Effect, Layer } from 'effect';

// A program that requires two configurations: A and B
const program = Effect.gen(function* () {
  const A = yield* Config.string('A');
  const B = yield* Config.string('B');
  console.log(`A: ${A}`, `B: ${B}`);
});

const provider1 = ConfigProvider.fromMap(
  new Map([
    ['A', 'A'],
    // B is missing
  ]),
);

const provider2 = ConfigProvider.fromMap(
  new Map([
    // A is missing
    ['B', 'B'],
  ]),
);

const layer = Layer.setConfigProvider(
  provider1.pipe(ConfigProvider.orElse(() => provider2)),
);

Effect.runSync(Effect.provide(program, layer));
```

```bash filename="Terminal"
ts-node npx orElse.ts

A: A B: B
```

<Info>
  The `ConfigProvider.fromMap` method used in this example creates a
  configuration provider from a `Map`. This behavior is explained in more
  detail in the [Testing Services](#testing-services) section.
</Info>

## Custom Configurations

In addition to primitive types, we can also define configurations for custom types. To achieve this, we use primitive configs and combine them using `Config` operators (`zip`, `orElse`, `map`, etc.) and constructors (`array`, `hashSet`, etc.).

Let's consider the `HostPort` data type, which consists of two fields: `host` and `port`.

```ts
class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}
}
```

We can define a configuration for this data type by combining primitive configs for `string` and `number`:

```ts filename="HostPort.ts" twoslash
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);
```

In the above example, we use the `Config.all(configs)` operator to combine two primitive configs `Config<string>` and `Config<number>` into a `Config<[string, number]>`.

If we use this customized configuration in our application:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts filename="App.ts" twoslash
// @filename: HostPort.ts
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);

// @filename: App.ts
// ---cut---
import { Effect } from 'effect';
import * as HostPort from './HostPort';

export const program = Effect.gen(function* () {
  const hostPort = yield* HostPort.config;
  console.log(`Application started: ${hostPort.url}`);
});
```

</Tab>
<Tab>

```ts filename="App.ts" twoslash
// @filename: HostPort.ts
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);

// @filename: App.ts
// ---cut---
import { Console, Effect } from 'effect';
import * as HostPort from './HostPort';

export const program = HostPort.config.pipe(
  Effect.andThen((hostPort) =>
    Console.log(`Application started: ${hostPort.url}`)
  ),
);
```

</Tab>
</Tabs>

when you run the program using `Effect.runSync(program)`, it will attempt to read the corresponding values from environment variables (`HOST` and `PORT`):

```bash filename="Terminal"
HOST=localhost PORT=8080 npx ts-node HostPort.ts

Application started: localhost:8080
```

## Top-level and Nested Configurations

So far, we have learned how to define configurations in a top-level manner, whether they are for primitive or custom types. However, we can also define nested configurations.

Let's assume we have a `ServiceConfig` data type that consists of two fields: `hostPort` and `timeout`.

```ts filename="ServiceConfig.ts" twoslash
// @filename: HostPort.ts
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);

// @filename: ServiceConfig.ts
// ---cut---
import * as HostPort from './HostPort';
import { Config } from 'effect';

class ServiceConfig {
  constructor(
    readonly hostPort: HostPort.HostPort,
    readonly timeout: number,
  ) {}
}

const config = Config.map(
  Config.all([HostPort.config, Config.number('TIMEOUT')]),
  ([hostPort, timeout]) => new ServiceConfig(hostPort, timeout),
);
```

If we use this customized config in our application, it tries to read corresponding values from environment variables: `HOST`, `PORT`, and `TIMEOUT`.

However, in many cases, we don't want to read all configurations from the top-level namespace. Instead, we may want to nest them under a common namespace. For example, we want to read both `HOST` and `PORT` from the `HOSTPORT` namespace, and `TIMEOUT` from the root namespace.

To achieve this, we can use the `Config.nested` combinator. It allows us to nest configs under a specific namespace. Here's how we can update our configuration:

```ts twoslash
// @filename: HostPort.ts
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);

// @filename: ServiceConfig.ts
import * as HostPort from './HostPort';
import { Config } from 'effect';

class ServiceConfig {
  constructor(
    readonly hostPort: HostPort.HostPort,
    readonly timeout: number,
  ) {}
}

// ---cut---
const config = Config.map(
  Config.all([
    Config.nested(HostPort.config, 'HOSTPORT'),
    Config.number('TIMEOUT'),
  ]),
  ([hostPort, timeout]) => new ServiceConfig(hostPort, timeout),
);
```

Now, if we run our application, it will attempt to read the corresponding values from the environment variables: `HOSTPORT_HOST`, `HOSTPORT_PORT`, and `TIMEOUT`.

## Testing Services

When testing services, there are scenarios where we need to provide specific configurations to them. In such cases, we should be able to mock the backend that reads the configuration data.

To accomplish this, we can use the `ConfigProvider.fromMap` constructor. This constructor takes a `Map<string, string>` that represents the configuration data, and it returns a config provider that reads the configuration from that map.

Once we have the mock config provider, we can use `Layer.setConfigProvider` function. This function allows us to override the default config provider and provide our own custom config provider. It returns a `Layer` that can be used to configure the Effect runtime for our test specs.

Here's an example of how we can mock a config provider for testing purposes:

```ts filename="mockConfigProvider.ts" twoslash
// @filename: HostPort.ts
import { Config } from 'effect';

export class HostPort {
  constructor(
    readonly host: string,
    readonly port: number,
  ) {}

  get url() {
    return `${this.host}:${this.port}`;
  }
}

const both = Config.all([Config.string('HOST'), Config.number('PORT')]);

export const config = Config.map(
  both,
  ([host, port]) => new HostPort(host, port),
);

// @filename: App.ts
import { Console, Effect } from 'effect';
import * as HostPort from './HostPort';

export const program = HostPort.config.pipe(
  Effect.andThen((hostPort) =>
    Console.log(`Application started: ${hostPort.url}`)
  ),
);

// @filename: mockConfigProvider.ts
// ---cut---
import { ConfigProvider, Effect, Layer } from 'effect';
import * as App from './App';

// Create a mock config provider using ConfigProvider.fromMap
const mockConfigProvider = ConfigProvider.fromMap(
  new Map([
    ['HOST', 'localhost'],
    ['PORT', '8080'],
  ]),
);

// Create a layer using Layer.setConfigProvider to override the default config provider
const layer = Layer.setConfigProvider(mockConfigProvider);

// Run the program using the provided layer
Effect.runSync(Effect.provide(App.program, layer));
// Output: Application started: localhost:8080
```

By using this approach, we can easily mock the configuration data and test our services with different configurations in a controlled manner.

## Redacted

What sets `Config.redacted` apart from `Config.string` is its handling of sensitive information.
It parses the config value and wraps it in a `Redacted<string>`, a [data type](../other/data-types/redacted) designed for holding secrets.

When you use `Console.log` on a redacted, the actual value remains hidden, providing an added layer of security.
The only way to access the value is by using `Redacted.value`.

```ts filename="Redacted.ts" twoslash
import { Config, Console, Effect, Redacted } from 'effect';

const program = Config.redacted('API_KEY').pipe(
  Effect.tap((redacted) => Console.log(`Console output: ${redacted}`)),
  Effect.tap((redacted) =>
    Console.log(`Actual value: ${Redacted.value(redacted)}`)
  ),
);

Effect.runSync(program);
```

If we run this program we will get the following output:

```bash filename="Terminal"
API_KEY=my-api-key tsx Redacted.ts
Console output: <redacted>
Actual value: my-api-key
```

In this example, you can see that when logging the redacted using `Console.log`, the actual value is replaced with `<redacted>`, ensuring that sensitive information is not exposed.
The `Redacted.value` function, on the other hand, provides a controlled way to retrieve the original secret value.

## Secret

<Warning>
  Deprecated since version 3.3.0: Please use [Config.redacted](#redacted) for
  handling sensitive information going forward.
</Warning>

`Config.secret` functions similarly to `Config.redacted` by securing sensitive information.
It wraps configuration values in a `Secret` type, which also obscures details when logged but allows access through the `Secret.value` method.

```ts filename="Secret.ts" twoslash
import { Config, Console, Effect, Secret } from 'effect';

const program = Config.secret('API_KEY').pipe(
  Effect.tap((secret) => Console.log(`Console output: ${secret}`)),
  Effect.tap((secret) => Console.log(`Secret value: ${Secret.value(secret)}`)),
);

Effect.runSync(program);
```

If we run this program we will get the following output:

```bash filename="Terminal"
API_KEY=my-api-key tsx Secret.ts
Console output: Secret(<redacted>)
Secret value: my-api-key
```

# Patterns

---

## title: Patternsexcerpt: Resource Management Patternscollapsible: truebottomNavigation: childCards

# Sequence of Operations with Compensating Actions on Failure

---

## title: Sequence of Operations with Compensating Actions on Failureexcerpt: Effect facilitates sequential operations where success depends on prior steps, with rollback on failure.bottomNavigation: pagination

In certain scenarios, you might need to perform a sequence of chained operations where the success of each operation depends on the previous one. However, if any of the operations fail, you would want to reverse the effects of all previous successful operations. This pattern is valuable when you need to ensure that either all operations succeed, or none of them have any effect at all.

Effect offers a way to achieve this pattern using the [Effect.acquireRelease](../scope#defining-resources) function in combination with the [Exit](../../../other/data-types/exit) type.
The [Effect.acquireRelease](../scope#defining-resources) function allows you to acquire a resource, perform operations with it, and release the resource when you're done.
The [Exit](../../../other/data-types/exit) type represents the outcome of an effectful computation, indicating whether it succeeded or failed.

Let's go through an example of implementing this pattern. Suppose we want to create a "Workspace" in our application, which involves creating an S3 bucket, an ElasticSearch index, and a Database entry that relies on the previous two.

To begin, we define the domain model for the required [services](./context-management/services): `S3`, `ElasticSearch`, and `Database`.

```twoslash include Services
import { Effect, Context } from "effect"

export class S3Error {
  readonly _tag = "S3Error"
}

export interface Bucket {
  readonly name: string
}

export class S3 extends Context.Tag("S3")<
  S3,
  {
    readonly createBucket: Effect.Effect<Bucket, S3Error>
    readonly deleteBucket: (bucket: Bucket) => Effect.Effect<void>
  }
>() {}

export class ElasticSearchError {
  readonly _tag = "ElasticSearchError"
}

export interface Index {
  readonly id: string
}

export class ElasticSearch extends Context.Tag("ElasticSearch")<
  ElasticSearch,
  {
    readonly createIndex: Effect.Effect<Index, ElasticSearchError>
    readonly deleteIndex: (index: Index) => Effect.Effect<void>
  }
>() {}

export class DatabaseError {
  readonly _tag = "DatabaseError"
}

export interface Entry {
  readonly id: string
}

export class Database extends Context.Tag("Database")<
  Database,
  {
    readonly createEntry: (
      bucket: Bucket,
      index: Index
    ) => Effect.Effect<Entry, DatabaseError>
    readonly deleteEntry: (entry: Entry) => Effect.Effect<void>
  }
>() {}
```

```ts filename="Services.ts" twoslash
// @include: Services
```

Next, we define the three create actions and the overall transaction (`make`) for the Workspace.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts filename="Workspace.ts" twoslash
// @filename: Services.ts
// @include: Services

// @filename: Workspace.ts
// ---cut---
import { Effect, Exit } from 'effect';
import * as Services from './Services';

// Create a bucket, and define the release function that deletes the bucket if the operation fails.
const createBucket = Effect.gen(function* () {
  const { createBucket, deleteBucket } = yield* Services.S3;
  return yield* Effect.acquireRelease(createBucket, (bucket, exit) =>
    // The release function for the Effect.acquireRelease operation is responsible for handling the acquired resource (bucket) after the main effect has completed.
    // It is called regardless of whether the main effect succeeded or failed.
    // If the main effect failed, Exit.isFailure(exit) will be true, and the function will perform a rollback by calling deleteBucket(bucket).
    // If the main effect succeeded, Exit.isFailure(exit) will be false, and the function will return Effect.void, representing a successful, but do-nothing effect.
    Exit.isFailure(exit) ? deleteBucket(bucket) : Effect.void);
});

// Create an index, and define the release function that deletes the index if the operation fails.
const createIndex = Effect.gen(function* () {
  const { createIndex, deleteIndex } = yield* Services.ElasticSearch;
  return yield* Effect.acquireRelease(
    createIndex,
    (index, exit) => Exit.isFailure(exit) ? deleteIndex(index) : Effect.void,
  );
});

// Create an entry in the database, and define the release function that deletes the entry if the operation fails.
const createEntry = (bucket: Services.Bucket, index: Services.Index) =>
  Effect.gen(function* () {
    const { createEntry, deleteEntry } = yield* Services.Database;
    return yield* Effect.acquireRelease(
      createEntry(bucket, index),
      (entry, exit) => Exit.isFailure(exit) ? deleteEntry(entry) : Effect.void,
    );
  });

export const make = Effect.scoped(
  Effect.gen(function* () {
    const bucket = yield* createBucket;
    const index = yield* createIndex;
    return yield* createEntry(bucket, index);
  }),
);
```

</Tab>
<Tab>

```ts filename="Workspace.ts" twoslash
// @filename: Services.ts
// @include: Services

// @filename: Workspace.ts
// ---cut---
import { Effect, Exit } from 'effect';
import * as Services from './Services';

// Create a bucket, and define the release function that deletes the bucket if the operation fails.
const createBucket = Services.S3.pipe(
  Effect.andThen(({ createBucket, deleteBucket }) =>
    Effect.acquireRelease(createBucket, (bucket, exit) =>
      // The release function for the Effect.acquireRelease operation is responsible for handling the acquired resource (bucket) after the main effect has completed.
      // It is called regardless of whether the main effect succeeded or failed.
      // If the main effect failed, Exit.isFailure(exit) will be true, and the function will perform a rollback by calling deleteBucket(bucket).
      // If the main effect succeeded, Exit.isFailure(exit) will be false, and the function will return Effect.void, representing a successful, but do-nothing effect.
      Exit.isFailure(exit) ? deleteBucket(bucket) : Effect.void)
  ),
);

// Create an index, and define the release function that deletes the index if the operation fails.
const createIndex = Services.ElasticSearch.pipe(
  Effect.andThen(({ createIndex, deleteIndex }) =>
    Effect.acquireRelease(
      createIndex,
      (index, exit) => Exit.isFailure(exit) ? deleteIndex(index) : Effect.void,
    )
  ),
);

// Create an entry in the database, and define the release function that deletes the entry if the operation fails.
const createEntry = (bucket: Services.Bucket, index: Services.Index) =>
  Services.Database.pipe(
    Effect.andThen(({ createEntry, deleteEntry }) =>
      Effect.acquireRelease(
        createEntry(bucket, index),
        (entry, exit) =>
          Exit.isFailure(exit) ? deleteEntry(entry) : Effect.void,
      )
    ),
  );

export const make = Effect.scoped(
  Effect.Do.pipe(
    Effect.bind('bucket', () => createBucket),
    Effect.bind('index', () => createIndex),
    Effect.andThen(({ bucket, index }) => createEntry(bucket, index)),
  ),
);
```

</Tab>
</Tabs>

We then create simple service implementations to test the behavior of our Workspace code.
To achieve this, we will utilize [layers](./context-management/layers) to construct test services.
These layers will be able to handle various scenarios, including errors, which we can control using the `FailureCase` type.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts filename="WorkspaceTest.ts" twoslash
// @filename: Services.ts
// @include: Services

// @filename: Workspace.ts
import { Effect, Exit } from 'effect';
import * as Services from './Services';

const createBucket = Services.S3.pipe(
  Effect.andThen(({ createBucket, deleteBucket }) =>
    Effect.acquireRelease(
      createBucket,
      (bucket, exit) =>
        Exit.isFailure(exit) ? deleteBucket(bucket) : Effect.void,
    )
  ),
);

const createIndex = Services.ElasticSearch.pipe(
  Effect.andThen(({ createIndex, deleteIndex }) =>
    Effect.acquireRelease(
      createIndex,
      (index, exit) => Exit.isFailure(exit) ? deleteIndex(index) : Effect.void,
    )
  ),
);

const createEntry = (bucket: Services.Bucket, index: Services.Index) =>
  Services.Database.pipe(
    Effect.andThen(({ createEntry, deleteEntry }) =>
      Effect.acquireRelease(
        createEntry(bucket, index),
        (entry, exit) =>
          Exit.isFailure(exit) ? deleteEntry(entry) : Effect.void,
      )
    ),
  );

export const make = Effect.scoped(
  Effect.Do.pipe(
    Effect.bind('bucket', () => createBucket),
    Effect.bind('index', () => createIndex),
    Effect.andThen(({ bucket, index }) => createEntry(bucket, index)),
  ),
);

// @filename: WorkspaceTest.ts
// ---cut---
import { Console, Context, Effect, Layer } from 'effect';
import * as Services from './Services';
import * as Workspace from './Workspace';

// The `FailureCaseLiterals` type allows us to provide different error scenarios while testing our services.
// For example, by providing the value "S3", we can simulate an error scenario specific to the S3 service.
// This helps us ensure that our program handles errors correctly and behaves as expected in various situations.
// Similarly, we can provide other values like "ElasticSearch" or "Database" to simulate error scenarios for those services.
// In cases where we want to test the absence of errors, we can provide `undefined`.
// By using this parameter, we can thoroughly test our services and verify their behavior under different error conditions.
type FailureCaseLiterals = 'S3' | 'ElasticSearch' | 'Database' | undefined;

class FailureCase extends Context.Tag('FailureCase')<
  FailureCase,
  FailureCaseLiterals
>() {}

// Create a test layer for the S3 service

const S3Test = Layer.effect(
  Services.S3,
  Effect.gen(function* () {
    const failureCase = yield* FailureCase;
    return {
      createBucket: Effect.gen(function* () {
        console.log('[S3] creating bucket');
        if (failureCase === 'S3') {
          return yield* Effect.fail(new Services.S3Error());
        } else {
          return { name: '<bucket.name>' };
        }
      }),
      deleteBucket: (bucket) =>
        Console.log(`[S3] delete bucket ${bucket.name}`),
    };
  }),
);

// Create a test layer for the ElasticSearch service

const ElasticSearchTest = Layer.effect(
  Services.ElasticSearch,
  Effect.gen(function* () {
    const failureCase = yield* FailureCase;
    return {
      createIndex: Effect.gen(function* () {
        console.log('[ElasticSearch] creating index');
        if (failureCase === 'ElasticSearch') {
          return yield* Effect.fail(new Services.ElasticSearchError());
        } else {
          return { id: '<index.id>' };
        }
      }),
      deleteIndex: (index) =>
        Console.log(`[ElasticSearch] delete index ${index.id}`),
    };
  }),
);

// Create a test layer for the Database service

const DatabaseTest = Layer.effect(
  Services.Database,
  Effect.gen(function* () {
    const failureCase = yield* FailureCase;
    return {
      createEntry: (bucket, index) =>
        Effect.gen(function* () {
          console.log(
            `[Database] creating entry for bucket ${bucket.name} and index ${index.id}`,
          );
          if (failureCase === 'Database') {
            return yield* Effect.fail(new Services.DatabaseError());
          } else {
            return { id: '<entry.id>' };
          }
        }),
      deleteEntry: (entry) =>
        Console.log(`[Database] delete entry ${entry.id}`),
    };
  }),
);

// Merge all the test layers for S3, ElasticSearch, and Database services into a single layer

const layer = Layer.mergeAll(S3Test, ElasticSearchTest, DatabaseTest);

// Create a runnable effect to test the Workspace code
// The effect is provided with the test layer and a FailureCase service with undefined value (no failure case)

const runnable = Workspace.make.pipe(
  Effect.provide(layer),
  Effect.provideService(FailureCase, undefined),
);

Effect.runPromise(Effect.either(runnable)).then(console.log);
```

</Tab>
<Tab>

```ts filename="Workspace.ts" twoslash
// @filename: Services.ts
// @include: Services

// @filename: Workspace.ts
import { Effect, Exit } from 'effect';
import * as Services from './Services';

const createBucket = Services.S3.pipe(
  Effect.andThen(({ createBucket, deleteBucket }) =>
    Effect.acquireRelease(
      createBucket,
      (bucket, exit) =>
        Exit.isFailure(exit) ? deleteBucket(bucket) : Effect.void,
    )
  ),
);

const createIndex = Services.ElasticSearch.pipe(
  Effect.andThen(({ createIndex, deleteIndex }) =>
    Effect.acquireRelease(
      createIndex,
      (index, exit) => Exit.isFailure(exit) ? deleteIndex(index) : Effect.void,
    )
  ),
);

const createEntry = (bucket: Services.Bucket, index: Services.Index) =>
  Services.Database.pipe(
    Effect.andThen(({ createEntry, deleteEntry }) =>
      Effect.acquireRelease(
        createEntry(bucket, index),
        (entry, exit) =>
          Exit.isFailure(exit) ? deleteEntry(entry) : Effect.void,
      )
    ),
  );

export const make = Effect.scoped(
  Effect.Do.pipe(
    Effect.bind('bucket', () => createBucket),
    Effect.bind('index', () => createIndex),
    Effect.andThen(({ bucket, index }) => createEntry(bucket, index)),
  ),
);

// @filename: WorkspaceTest.ts
// ---cut---
import { Console, Context, Effect, Layer } from 'effect';
import * as Services from './Services';
import * as Workspace from './Workspace';

// The `FailureCaseLiterals` type allows us to provide different error scenarios while testing our services.
// For example, by providing the value "S3", we can simulate an error scenario specific to the S3 service.
// This helps us ensure that our program handle errors correctly and behave as expected in various situations.
// Similarly, we can provide other values like "ElasticSearch" or "Database" to simulate error scenarios for those services.
// In cases where we want to test the absence of errors, we can provide `undefined`.
// By using this parameter, we can thoroughly test our services and verify their behavior under different error conditions.
type FailureCaseLiterals = 'S3' | 'ElasticSearch' | 'Database' | undefined;

class FailureCase extends Context.Tag('FailureCase')<
  FailureCase,
  FailureCaseLiterals
>() {}

// Create a test layer for the S3 service

const S3Test = Layer.effect(
  Services.S3,
  Effect.andThen(FailureCase, (failureCase) => ({
    createBucket: Console.log('[S3] creating bucket').pipe(
      Effect.andThen(
        failureCase === 'S3'
          ? Effect.fail(new Services.S3Error())
          : Effect.succeed({ name: '<bucket.name>' }),
      ),
    ),
    deleteBucket: (bucket) => Console.log(`[S3] delete bucket ${bucket.name}`),
  })),
);

// Create a test layer for the ElasticSearch service

const ElasticSearchTest = Layer.effect(
  Services.ElasticSearch,
  Effect.andThen(FailureCase, (failureCase) => ({
    createIndex: Console.log('[ElasticSearch] creating index').pipe(
      Effect.andThen(
        failureCase === 'ElasticSearch'
          ? Effect.fail(new Services.ElasticSearchError())
          : Effect.succeed({ id: '<index.id>' }),
      ),
    ),
    deleteIndex: (index) =>
      Console.log(`[ElasticSearch] delete index ${index.id}`),
  })),
);

// Create a test layer for the Database service

const DatabaseTest = Layer.effect(
  Services.Database,
  Effect.andThen(FailureCase, (failureCase) => ({
    createEntry: (bucket, index) =>
      Console.log(
        `[Database] creating entry for bucket ${bucket.name} and index ${index.id}`,
      ).pipe(
        Effect.andThen(
          failureCase === 'Database'
            ? Effect.fail(new Services.DatabaseError())
            : Effect.succeed({ id: '<entry.id>' }),
        ),
      ),
    deleteEntry: (entry) => Console.log(`[Database] delete entry ${entry.id}`),
  })),
);

// Merge all the test layers for S3, ElasticSearch, and Database services into a single layer

const layer = Layer.mergeAll(S3Test, ElasticSearchTest, DatabaseTest);

// Create a runnable effect to test the Workspace code
// The effect is provided with the test layer and a FailureCase service with undefined value (no failure case)

const runnable = Workspace.make.pipe(
  Effect.provide(layer),
  Effect.provideService(FailureCase, undefined),
);

Effect.runPromise(Effect.either(runnable)).then(console.log);
```

</Tab>
</Tabs>

Let's examine the test results for the scenario where `FailureCase` is set to `undefined` (happy path):

```
[S3] creating bucket
[ElasticSearch] creating index
[Database] creating entry for bucket <bucket.name> and index <index.id>
{
  _id: "Either",
  _tag: "Right",
  right: {
    id: "<entry.id>"
  }
}
```

In this case, all operations succeed, and we see a successful result with `right({ id: '<entry.id>' })`.

Now, let's simulate a failure in the `Database`:

```ts
const runnable = Workspace.make.pipe(
  Effect.provide(layer),
  Effect.provideService(FailureCase, 'Database'),
);
```

The console output will be:

```
[S3] creating bucket
[ElasticSearch] creating index
[Database] creating entry for bucket <bucket.name> and index <index.id>
[ElasticSearch] delete index <index.id>
[S3] delete bucket <bucket.name>
{
  _id: "Either",
  _tag: "Left",
  left: {
    _tag: "DatabaseError"
  }
}
```

You can observe that once the `Database` error occurs, there is a complete rollback that deletes the `ElasticSearch` index first and then the associated `S3` bucket. The result is a failure with `left(new DatabaseError())`.

Let's now make the index creation fail instead:

```ts
const runnable = Workspace.make.pipe(
  Effect.provide(layer),
  Effect.provideService(FailureCase, 'ElasticSearch'),
);
```

In this case, the console output will be:

```
[S3] creating bucket
[ElasticSearch] creating index
[S3] delete bucket <bucket.name>
{
  _id: "Either",
  _tag: "Left",
  left: {
    _tag: "ElasticSearchError"
  }
}
```

As expected, once the `ElasticSearch` index creation fails, there is a rollback that deletes the `S3` bucket. The result is a failure with `left(new ElasticSearchError())`.

# Resource Management

---

## title: Resource Managementexcerpt: Resource Managementcollapsible: truebottomNavigation: childCards

# Scope

---

## title: Scopeexcerpt: Explore the importance of resource management in developing large-scale applications using the Effect library. Learn about robust constructs, such as the `Scope` data type, and discover how Effect simplifies resource management and ensures safety in your applications.bottomNavigation: pagination

In the context of developing long-lived applications, resource management plays a critical role. Effective resource management is indispensable when building large-scale applications. It's imperative that our application is resource-efficient and does not result in resource leaks.

Resource leaks, such as unclosed socket connections, database connections, or file descriptors, are unacceptable in web applications. Effect offers robust constructs to address this concern effectively.

To create an application that manages resources safely, we must ensure that every time we open a resource, we have a mechanism in place to close it. This applies whether we fully utilize the resource or encounter exceptions during its use.

In the following sections, we'll delve deeper into how Effect simplifies resource management and ensures resource safety in your applications.

## Scope

The `Scope` data type is fundamental for managing resources safely and in a composable manner in Effect.

In simple terms, a scope represents the lifetime of one or more resources. When a scope is closed, the resources associated with it are guaranteed to be released.

With the `Scope` data type, you can:

- **Add finalizers**, which represent the release of a resource.
- **Close** the scope, releasing all acquired resources and executing any added finalizers.

To grasp the concept better, let's delve into an example that demonstrates how it works.
It's worth noting that in typical Effect usage, you won't often find yourself working with these low-level APIs for managing scopes.

```ts twoslash
import { Console, Effect, Exit, Scope } from 'effect';

const program =
  // create a new scope
  Scope.make().pipe(
    // add finalizer 1
    Effect.tap((scope) =>
      Scope.addFinalizer(scope, Console.log('finalizer 1'))
    ),
    // add finalizer 2
    Effect.tap((scope) =>
      Scope.addFinalizer(scope, Console.log('finalizer 2'))
    ),
    // close the scope
    Effect.andThen((scope) =>
      Scope.close(scope, Exit.succeed('scope closed successfully'))
    ),
  );

Effect.runPromise(program);
/*
Output:
finalizer 2 <-- finalizers are closed in reverse order
finalizer 1
*/
```

By default, when a `Scope` is closed, all finalizers added to that `Scope` are executed in the reverse order in which they were added. This approach makes sense because releasing resources in the reverse order of acquisition ensures that resources are properly closed.

For instance, if you open a network connection and then access a file on a remote server, you must close the file before closing the network connection. This sequence is critical to maintaining the ability to interact with the remote server.

By combining `Scope` with the Effect context, we gain a powerful way to manage resources effectively.

## addFinalizer

Now, let's dive into the `Effect.addFinalizer` function, which provides a higher-level API for adding finalizers to the scope of an `Effect` value. These finalizers are guaranteed to execute when the associated scope is closed, and their behavior may depend on the `Exit` value with which the scope is closed.

Let's explore some examples to understand this better.

Let's observe how things behave in the event of success:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.addFinalizer((exit) =>
    Console.log(`finalizer after ${exit._tag}`)
  );
  return 1;
});

const runnable = Effect.scoped(program);

Effect.runPromise(runnable).then(console.log, console.error);
/*
Output:
finalizer after Success
1
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.addFinalizer((exit) =>
  Console.log(`finalizer after ${exit._tag}`)
).pipe(Effect.andThen(Effect.succeed(1)));

const runnable = Effect.scoped(program);

Effect.runPromise(runnable).then(console.log, console.error);
/*
Output:
finalizer after Success
1
*/
```

</Tab>
</Tabs>

Here, the `Effect.addFinalizer` operator adds a `Scope` to the context required by the workflow, as indicated by:

```ts
Effect<void, never, Scope>;
```

This signifies that the workflow needs a `Scope` to execute. You can provide this `Scope` using the `Effect.scoped` operator. It creates a new `Scope`, supplies it to the workflow, and closes the `Scope` once the workflow is complete.

The `Effect.scoped` operator removes the `Scope` from the context, indicating that the workflow no longer requires any resources associated with a scope.

Next, let's explore how things behave in the event of a failure:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.addFinalizer((exit) =>
    Console.log(`finalizer after ${exit._tag}`)
  );
  return yield* Effect.fail('Uh oh!');
});

const runnable = Effect.scoped(program);

Effect.runPromiseExit(runnable).then(console.log);
/*
Output:
finalizer after Failure
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Uh oh!' }
}
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.addFinalizer((exit) =>
  Console.log(`finalizer after ${exit._tag}`)
).pipe(Effect.andThen(Effect.fail('Uh oh!')));

const runnable = Effect.scoped(program);

Effect.runPromiseExit(runnable).then(console.log);
/*
Output:
finalizer after Failure
{
  id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Uh oh!' }
}
*/
```

</Tab>
</Tabs>

Finally, let's explore the behavior in the event of an interruption:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.addFinalizer((exit) =>
    Console.log(`finalizer after ${exit._tag}`)
  );
  return yield* Effect.interrupt;
});

const runnable = Effect.scoped(program);

Effect.runPromiseExit(runnable).then(console.log);
/*
Output:
finalizer after Failure
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Interrupt',
    fiberId: {
      _id: 'FiberId',
      _tag: 'Runtime',
      id: 0,
      startTimeMillis: ...
    }
  }
}
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.addFinalizer((exit) =>
  Console.log(`finalizer after ${exit._tag}`)
).pipe(Effect.andThen(Effect.interrupt));

const runnable = Effect.scoped(program);

Effect.runPromiseExit(runnable).then(console.log);
/*
Output:
finalizer after Failure
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Interrupt',
    fiberId: {
      _id: 'FiberId',
      _tag: 'Runtime',
      id: 0,
      startTimeMillis: ...
    }
  }
}
*/
```

</Tab>
</Tabs>

## Manually Create and Close Scopes

When you're working with multiple scoped resources within a single operation, it's important to understand how their scopes interact. By default, these scopes are merged into one, but you can have more fine-grained control over when each scope is closed by manually creating and closing them.

Let's start by looking at how scopes are merged by default. Take a look at this code example:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('task 1');
  yield* Effect.addFinalizer(() => Console.log('finalizer after task 1'));
});

const task2 = Effect.gen(function* () {
  console.log('task 2');
  yield* Effect.addFinalizer(() => Console.log('finalizer after task 2'));
});

const program = Effect.gen(function* () {
  // Both of these scopes are merged into one
  yield* task1;
  yield* task2;
});

Effect.runPromise(program.pipe(Effect.scoped));
/*
Output:
task 1
task 2
finalizer after task 2
finalizer after task 1
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const task1 = Console.log('task 1').pipe(
  Effect.tap(() =>
    Effect.addFinalizer(() => Console.log('finalizer after task 1'))
  ),
);

const task2 = Console.log('task 2').pipe(
  Effect.tap(() =>
    Effect.addFinalizer(() => Console.log('finalizer after task 2'))
  ),
);

const program =
  // Both of these scopes are merged into one
  Effect.all([task1, task2], { discard: true });

Effect.runPromise(program.pipe(Effect.scoped));
/*
Output:
task 1
task 2
finalizer after task 2
finalizer after task 1
*/
```

</Tab>
</Tabs>

In this case, the scopes of `task1` and `task2` are merged into a single scope, and when the program is run, it outputs the tasks and their finalizers in a specific order.

If you want more control over when each scope is closed, you can manually create and close them, as shown in this example:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect, Exit, Scope } from 'effect';

const task1 = Effect.gen(function* () {
  console.log('task 1');
  yield* Effect.addFinalizer(() => Console.log('finalizer after task 1'));
});

const task2 = Effect.gen(function* () {
  console.log('task 2');
  yield* Effect.addFinalizer(() => Console.log('finalizer after task 2'));
});

const program = Effect.gen(function* () {
  const scope1 = yield* Scope.make();
  const scope2 = yield* Scope.make();

  // Extend the scope of task1 into scope1
  yield* task1.pipe(Scope.extend(scope1));

  // Extend the scope of task2 into scope2
  yield* task2.pipe(Scope.extend(scope2));

  // Close scope1 and scope2 manually
  yield* Scope.close(scope1, Exit.void);
  yield* Console.log('doing something else');
  yield* Scope.close(scope2, Exit.void);
});

Effect.runPromise(program);
/*
Output:
task 1
task 2
finalizer after task 1
doing something else
finalizer after task 2
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect, Exit, Scope } from 'effect';

const task1 = Console.log('task 1').pipe(
  Effect.tap(() =>
    Effect.addFinalizer(() => Console.log('finalizer after task 1'))
  ),
);

const task2 = Console.log('task 2').pipe(
  Effect.tap(() =>
    Effect.addFinalizer(() => Console.log('finalizer after task 2'))
  ),
);

const program = Effect.all([Scope.make(), Scope.make()]).pipe(
  Effect.andThen(([scope1, scope2]) =>
    Scope.extend(task1, scope1).pipe(
      Effect.andThen(Scope.extend(task2, scope2)),
      Effect.andThen(Scope.close(scope1, Exit.void)),
      Effect.andThen(Console.log('doing something else')),
      Effect.andThen(Scope.close(scope2, Exit.void)),
    )
  ),
);

Effect.runPromise(program);
/*
Output:
task 1
task 2
finalizer after task 1
doing something else
finalizer after task 2
*/
```

</Tab>
</Tabs>

In this example, we create two separate scopes, `scope1` and `scope2`, and extend the scope of each task into its respective scope. When you run the program, it outputs the tasks and their finalizers in a different order.

<Info>
  The `Scope.extend` function allows you to extend the scope of an `Effect`
  workflow that requires a scope into another scope without closing the scope
  when the workflow finishes executing. This allows you to extend a scoped
  value into a larger scope.
</Info>

You might wonder what happens when a scope is closed, but a task within that scope hasn't completed yet. The key point to note is that the scope closing doesn't force the task to be interrupted. It will continue running, and the finalizer will execute immediately when registered. The call to `close` will only wait for the finalizers that have already been registered.

So, finalizers run when the scope is closed, not necessarily when the effect finishes running. When you're using `Effect.scoped`, the scope is managed automatically, and finalizers are executed accordingly. However, when you manage the scope manually, you have control over when finalizers are executed.

## Defining Resources

We can define a resource using operators like `Effect.acquireRelease(acquire, release)`, which allows us to create a scoped value from an `acquire` and `release` workflow.

Every acquire release requires three actions:

- **Acquiring Resource**. An effect describing the acquisition of resource. For example, opening a file.
- **Using Resource**. An effect describing the actual process to produce a result. For example, counting the number of lines in a file.
- **Releasing Resource**. An effect describing the final step of releasing or cleaning up the resource. For example, closing a file.

The `Effect.acquireRelease` operator performs the `acquire` workflow **uninterruptibly**.
This is important because if we allowed interruption during resource acquisition we could be interrupted when the resource was partially acquired.

The guarantee of the `Effect.acquireRelease` operator is that if the `acquire` workflow successfully completes execution then the `release` workflow is guaranteed to be run when the `Scope` is closed.

For example, let's define a simple resource:

```twoslash include resource
import { Effect } from "effect"

// Define the interface for the resource
export interface MyResource {
  readonly contents: string
  readonly close: () => Promise<void>
}

// Simulate getting the resource
const getMyResource = (): Promise<MyResource> =>
  Promise.resolve({
    contents: "lorem ipsum",
    close: () =>
      new Promise((resolve) => {
        console.log("Resource released")
        resolve()
      })
  })

// Define the acquisition of the resource with error handling
export const acquire = Effect.tryPromise({
  try: () =>
    getMyResource().then((res) => {
      console.log("Resource acquired")
      return res
    }),
  catch: () => new Error("getMyResourceError")
})

// Define the release of the resource
export const release = (res: MyResource) => Effect.promise(() => res.close())

export const resource = Effect.acquireRelease(acquire, release)
```

```ts filename="resource.ts" twoslash
// @include: resource
```

Notice that the `Effect.acquireRelease` operator added a `Scope` to the context required by the workflow:

```ts
Effect<MyResource, Error, Scope>;
```

This indicates that the workflow needs a `Scope` to run and adds a finalizer that will close the resource when the scope is closed.

We can continue working with the resource for as long as we want by using `Effect.andThen` or other Effect operators. For example, here's how we can read the contents:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: resource.ts
// @include: resource

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { resource } from './resource';

const program = Effect.gen(function* () {
  const res = yield* resource;
  console.log(`content is ${res.contents}`);
});
```

</Tab>
<Tab>

```ts twoslash
// @filename: resource.ts
// @include: resource

// @filename: index.ts
// ---cut---
import { Console, Effect } from 'effect';
import { resource } from './resource';

const program = resource.pipe(
  Effect.andThen((res) => Console.log(`content is ${res.contents}`)),
);
```

</Tab>
</Tabs>

Once we are done working with the resource, we can close the scope using the `Effect.scoped` operator. It creates a new `Scope`, provides it to the workflow, and closes the `Scope` when the workflow is finished.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @filename: resource.ts
// @include: resource

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { resource } from './resource';

const program = Effect.scoped(
  Effect.gen(function* () {
    const res = yield* resource;
    console.log(`content is ${res.contents}`);
  }),
);
```

</Tab>
<Tab>

```ts twoslash
// @filename: resource.ts
// @include: resource

// @filename: index.ts
// ---cut---
import { Console, Effect } from 'effect';
import { resource } from './resource';

const program = Effect.scoped(
  resource.pipe(
    Effect.andThen((res) => Console.log(`content is ${res.contents}`)),
  ),
);
```

</Tab>
</Tabs>

The `Effect.scoped` operator removes the `Scope` from the context, indicating that there are no longer any resources used by this workflow which require a scope.

We now have a workflow that is ready to run:

```ts
Effect.runPromise(program);
/*
Resource acquired
content is lorem ipsum
Resource released
*/
```

## acquireUseRelease

The `Effect.acquireUseRelease(acquire, use, release)` function is a specialized version of the `Effect.acquireRelease` function that simplifies resource management by automatically handling the scoping of resources.

The main difference is that `acquireUseRelease` eliminates the need to manually call `Effect.scoped` to manage the resource's scope. It has additional knowledge about when you are done using the resource created with the `acquire` step. This is achieved by providing a `use` argument, which represents the function that operates on the acquired resource. As a result, `acquireUseRelease` can automatically determine when it should execute the release step.

Here's an example that demonstrates the usage of `acquireUseRelease`:

```ts twoslash
// @filename: resource.ts
// @include: resource

// @filename: index.ts
// ---cut---
import { Console, Effect } from 'effect';
import { acquire, MyResource, release } from './resource';

const use = (res: MyResource) => Console.log(`content is ${res.contents}`);

const program = Effect.acquireUseRelease(acquire, use, release);

Effect.runPromise(program);
/*
Output:
Resource acquired
content is lorem ipsum
Resource released
*/
```

# Caching

---

## title: Cachingexcerpt: Cachingcollapsible: truebottomNavigation: childCards

# Caching Effects

---

## title: Caching Effectsexcerpt: Caching EffectsbottomNavigation: pagination

This section outlines several functions provided by the library that help manage caching and memoization in your application:

| Function Name               | Description                                                                                                                                                                                                 |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **cachedFunction**          | Returns a memoized version of a function with effects. Memoization ensures that results are stored and reused for the same inputs, reducing the need to recompute them.                                     |
| **once**                    | Returns an effect that executes only once, regardless of how many times it's called.                                                                                                                        |
| **cached**                  | Returns an effect that computes a result lazily and caches it. Subsequent evaluations of this effect will return the cached result without re-executing the logic.                                          |
| **cachedWithTTL**           | Returns an effect that caches its result for a specified duration, known as the `timeToLive`. When the cache expires after the duration, the effect will be recomputed upon next evaluation.                |
| **cachedInvalidateWithTTL** | Similar to `cachedWithTTL`, this function caches an effect's result for a specified duration. It also includes an additional effect for manually invalidating the cached value before it naturally expires. |

## cachedFunction

Returns a memoized version of a function with effects. Memoization ensures that results are stored and reused for the same inputs, reducing the need to recompute them.

```ts twoslash
import { Effect, Random } from 'effect';

const program = Effect.gen(function* () {
  const randomNumber = (n: number) => Random.nextIntBetween(1, n);
  console.log('non-memoized version:');
  console.log(yield* randomNumber(10));
  console.log(yield* randomNumber(10));

  console.log('memoized version:');
  const memoized = yield* Effect.cachedFunction(randomNumber);
  console.log(yield* memoized(10));
  console.log(yield* memoized(10));
});

Effect.runFork(program);
/*
Example Output:
non-memoized version:
2
8
memoized version:
5
5
*/
```

## once

Returns an effect that executes only once, regardless of how many times it's called.

```ts twoslash
import { Console, Effect } from 'effect';

const program = Effect.gen(function* () {
  const task1 = Console.log('task1');
  yield* Effect.repeatN(task1, 2);
  const task2 = yield* Effect.once(Console.log('task2'));
  yield* Effect.repeatN(task2, 2);
});

Effect.runFork(program);
/*
Output:
task1
task1
task1
task2
*/
```

## cached

Returns an effect that computes a result lazily and caches it. Subsequent evaluations of this effect will return the cached result without re-executing the logic.

```ts twoslash
import { Console, Effect } from 'effect';

let i = 1;
const expensiveTask = Effect.promise<string>(() => {
  console.log('expensive task...');
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve(`result ${i++}`);
    }, 100);
  });
});

const program = Effect.gen(function* () {
  console.log('non-cached version:');
  yield* expensiveTask.pipe(Effect.andThen(Console.log));
  yield* expensiveTask.pipe(Effect.andThen(Console.log));
  console.log('cached version:');
  const cached = yield* Effect.cached(expensiveTask);
  yield* cached.pipe(Effect.andThen(Console.log));
  yield* cached.pipe(Effect.andThen(Console.log));
});

Effect.runFork(program);
/*
Output:
non-cached version:
expensive task...
result 1
expensive task...
result 2
cached version:
expensive task...
result 3
result 3
*/
```

## cachedWithTTL

Returns an effect that caches its result for a specified duration, known as the `timeToLive`. When the cache expires after the duration, the effect will be recomputed upon next evaluation.

```ts twoslash
import { Console, Effect } from 'effect';

let i = 1;
const expensiveTask = Effect.promise<string>(() => {
  console.log('expensive task...');
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve(`result ${i++}`);
    }, 100);
  });
});

const program = Effect.gen(function* () {
  const cached = yield* Effect.cachedWithTTL(expensiveTask, '150 millis');
  yield* cached.pipe(Effect.andThen(Console.log));
  yield* cached.pipe(Effect.andThen(Console.log));
  yield* Effect.sleep('100 millis');
  yield* cached.pipe(Effect.andThen(Console.log));
});

Effect.runFork(program);
/*
Output:
expensive task...
result 1
result 1
expensive task...
result 2
*/
```

## cachedInvalidateWithTTL

Similar to `cachedWithTTL`, this function caches an effect's result for a specified duration. It also includes an additional effect for manually invalidating the cached value before it naturally expires.

```ts
import { Console, Effect } from 'effect';

let i = 1;
const expensiveTask = Effect.promise<string>(() => {
  console.log('expensive task...');
  return new Promise((resolve) => {
    setTimeout(() => {
      resolve(`result ${i++}`);
    }, 100);
  });
});

const program = Effect.gen(function* () {
  const [cached, invalidate] = yield* Effect.cachedInvalidateWithTTL(
    expensiveTask,
    '1 hour',
  );
  yield* cached.pipe(Effect.andThen(Console.log));
  yield* cached.pipe(Effect.andThen(Console.log));
  yield* invalidate;
  yield* cached.pipe(Effect.andThen(Console.log));
});

Effect.runFork(program);
/*
Output:
expensive task...
result 1
result 1
expensive task...
result 2
*/
```

# Cache

---

## title: Cacheexcerpt: CachebottomNavigation: pagination

The Cache module makes it easy to optimize the performance of our application by caching values.

## Introduction

In many applications, we may encounter scenarios where overlapping work is performed. For example, if we are developing a service that handles incoming requests, it is essential to avoid processing duplicate requests. By using the Cache module, we can enhance our application's performance by preventing redundant work.

Key Features of Cache:

- **Compositionality**: Cache allows different parts of our application to perform overlapping work while still benefiting from compositional programming principles.

- **Unification of Synchronous and Asynchronous Caches**: The compositional definition of a cache through a lookup function unifies both synchronous and asynchronous caches, allowing the lookup function to compute values either synchronously or asynchronously.

- **Deep Effect Integration**: Cache is designed to work natively with the Effect library, supporting concurrent lookups, failure handling, and interruption without losing the power of Effect.

- **Caching Policy**: Caching policies determine when values should be removed from the cache, providing flexibility for complex and custom caching strategies. The policy has two parts:

  - **Priority (Optional Removal)**: Defines the order in which values **might** be removed when the cache is running out of space.
  - **Evict (Mandatory Removal)**: Specifies when values **must** be removed because they are no longer valid (e.g., they are too old or no longer satisfy business requirements).

- **Composition Caching Policy**: Allows the definition of complex caching policies using simpler ones.

- **Cache/Entry Statistics**: Cache tracks metrics such as entries, hits, misses, helping us to assess and optimize cache performance.

## How to Define a Cache?

A cache is defined by a lookup function that describes how to compute the value associated with a key if it is not already in the cache.

```ts
export type Lookup<Key, Value, Error = never, Environment = never> = (
  key: Key,
) => Effect.Effect<Value, Error, Environment>;
```

The lookup function takes a key of type `Key` and returns an `Effect` that requires an environment of type `Environment` and can fail with an error of type `Error` or succeed with a value of type `Value`. Since the lookup function returns an `Effect`, it can describe both synchronous and asynchronous workflows.

In short, if you can describe it with an `Effect`, you can use it as the lookup function for a cache.

We construct a cache using a lookup function along with a maximum size and a time to live.

```ts
export declare const make: <
  Key,
  Value,
  Error = never,
  Environment = never,
>(options: {
  readonly capacity: number;
  readonly timeToLive: Duration.DurationInput;
  readonly lookup: Lookup<Key, Value, Error, Environment>;
}) => Effect.Effect<Cache<Key, Value, Error>, never, Environment>;
```

Once a cache is created, the most idiomatic way to work with it is the `get` operator. The `get` operator returns the current value in the cache if it exists, or computes a new value, puts it in the cache, and returns it.

If multiple concurrent processes request the same value, it will only be computed once. All other processes will receive the computed value as soon as it is available. This is managed using Effect's fiber-based concurrency model without blocking the underlying thread.

### Example

In this example, we call `timeConsumingEffect` three times in parallel with the same key. The Cache runs this effect only once, so concurrent lookups will wait until the value is available:

```ts twoslash
import { Cache, Duration, Effect } from 'effect';

const timeConsumingEffect = (key: string) =>
  Effect.sleep('2 seconds').pipe(Effect.as(key.length));

const program = Effect.gen(function* () {
  const cache = yield* Cache.make({
    capacity: 100,
    timeToLive: Duration.infinity,
    lookup: timeConsumingEffect,
  });
  const result = yield* cache
    .get('key1')
    .pipe(
      Effect.zip(cache.get('key1'), { concurrent: true }),
      Effect.zip(cache.get('key1'), { concurrent: true }),
    );
  console.log(
    `Result of parallel execution of three effects with the same key: ${result}`,
  );

  const hits = yield* cache.cacheStats.pipe(Effect.map((_) => _.hits));
  const misses = yield* cache.cacheStats.pipe(Effect.map((_) => _.misses));
  console.log(`Number of cache hits: ${hits}`);
  console.log(`Number of cache misses: ${misses}`);
});

Effect.runPromise(program);
/*
Output:
Result of parallel execution of three effects with the same key: 4,4,4
Number of cache hits: 2
Number of cache misses: 1
*/
```

## Concurrent Access

The cache is designed to be safe for concurrent access and efficient under concurrent conditions. If two concurrent processes request the same value and it is not in the cache, the value will be computed once and provided to both processes as soon as it is available. Concurrent processes will wait for the value without blocking operating system threads.

If the lookup function fails or is interrupted, the error will be propagated to all concurrent processes waiting for the value. Failures are cached to prevent repeated computation of the same failed value. If interrupted, the key will be removed from the cache, so subsequent calls will attempt to compute the value again.

## Capacity

A cache is created with a specified capacity. When the cache reaches capacity, the least recently accessed values will be removed first. The cache size may slightly exceed the specified capacity between operations.

## Time To Live (TTL)

A cache can also have a specified time to live (TTL). Values older than the TTL will not be returned. The age is calculated from when the value was loaded into the cache.

## Operators

In addition to `get`, Cache provides several other operators:

- **refresh**: Similar to `get`, but triggers a re-computation of the value without invalidating it, allowing requests to the associated key to be served while the value is being re-computed.
- **size**: Returns the current size of the cache. Under concurrent access, the size is approximate.
- **contains**: Checks if a value associated with a specified key exists in the cache. Under concurrent access, the result is valid as of the check time but may change immediately after.
- **invalidate**: Evicts the value associated with a specified key.
- **invalidateAll**: Evicts all values in the cache.

# Fallback

---

## title: Fallbackexcerpt: Explore techniques for handling failures and fallbacks in Effect, including `orElse` to try alternate effects, `orElseFail` and `orElseSucceed` to modify failures, and `firstSuccessOf` to retrieve the result of the first successful effect. Learn how to gracefully handle errors and create fallback mechanisms in your Effect programs.bottomNavigation: pagination

## orElse

We can attempt one effect, and if it fails, we can try another effect using the `Effect.orElse` combinator:

```ts twoslash
import { Effect } from 'effect';

const success = Effect.succeed('success');
const failure = Effect.fail('failure');
const fallback = Effect.succeed('fallback');

const program1 = Effect.orElse(success, () => fallback);
console.log(Effect.runSync(program1)); // Output: "success"

const program2 = Effect.orElse(failure, () => fallback);
console.log(Effect.runSync(program2)); // Output: "fallback"
```

## orElseFail / orElseSucceed

These two operators modify the original failure by replacing it with constant succeed or failure values.

The `Effect.orElseFail` will always replace the original failure with the new one:

```twoslash include validate
import { Effect } from "effect"

class NegativeAgeError {
  readonly _tag = "NegativeAgeError"
  constructor(readonly age: number) {}
}

class IllegalAgeError {
  readonly _tag = "IllegalAgeError"
  constructor(readonly age: number) {}
}

const validate = (
  age: number
): Effect.Effect<number, NegativeAgeError | IllegalAgeError> => {
  if (age < 0) {
    return Effect.fail(new NegativeAgeError(age))
  } else if (age < 18) {
    return Effect.fail(new IllegalAgeError(age))
  } else {
    return Effect.succeed(age)
  }
}
```

```ts twoslash
// @include: validate

const program1 = Effect.orElseFail(validate(3), () => 'invalid age');
```

The `Effect.orElseSucceed` will always replace the original failure with a success value, so the resulting effect cannot fail:

```ts twoslash
// @include: validate
// ---cut---
const program2 = Effect.orElseSucceed(validate(3), () => 0);
```

## firstSuccessOf

The `firstSuccessOf` operator simplifies running a series of effects and returns the result of the first one that succeeds. If none of the effects succeed, the resulting effect will fail with the error of the last effect in the series.

This operator utilizes `Effect.orElse` to combine multiple effects into a single effect.

In the following example, we attempt to retrieve a configuration from different nodes. If retrieving from the primary node fails, we successively try retrieving from the next available nodes until we find a successful result:

```ts twoslash
import { Console, Effect } from 'effect';

interface Config {
  // ...
}

const makeConfig = (/* ... */): Config => ({});

const remoteConfig = (name: string): Effect.Effect<Config, Error> =>
  Effect.gen(function* () {
    if (name === 'node3') {
      yield* Console.log(`Config for ${name} found`);
      return makeConfig();
    } else {
      yield* Console.log(`Unavailable config for ${name}`);
      return yield* Effect.fail(new Error());
    }
  });

const masterConfig = remoteConfig('master');

const nodeConfigs = ['node1', 'node2', 'node3', 'node4'].map(remoteConfig);

const config = Effect.firstSuccessOf([masterConfig, ...nodeConfigs]);

console.log(Effect.runSync(config));
/*
Output:
Unavailable config for master
Unavailable config for node1
Unavailable config for node2
Config for node3 found
{}
*/
```

<Warning>
  If the collection provided to the `Effect.firstSuccessOf` function is empty,
  it will throw an `IllegalArgumentException` error.
</Warning>

# Retrying

---

## title: Retryingexcerpt: Learn how to enhance the resilience of your applications by mastering the retrying capabilities of Effect. Explore `retry`, `retryN`, and `retryOrElse` functions, along with scheduling policies, to automatically handle transient failures. Whether dealing with network requests, database interactions, or other error-prone operations, discover how Effect simplifies the implementation of robust retry strategies.bottomNavigation: pagination

In software development, it's common to encounter situations where an operation may fail temporarily due to various factors such as network issues, resource unavailability, or external dependencies. In such cases, it's often desirable to retry the operation automatically, allowing it to succeed eventually.

Retrying is a powerful mechanism to handle transient failures and ensure the successful execution of critical operations. In Effect retrying is made simple and flexible with built-in functions and scheduling strategies.

In this guide, we will explore the concept of retrying in Effect and learn how to use the `retry` and `retryOrElse` functions to handle failure scenarios. We'll see how to define retry policies using schedules, which dictate when and how many times the operation should be retried.

Whether you're working on network requests, database interactions, or any other potentially error-prone operations, mastering the retrying capabilities of Effect can significantly enhance the resilience and reliability of your applications.

To demonstrate the functionality of different retry functions, we will be working with the following helper that simulates an effect with possible failures:

```twoslash include fake
import { Effect } from "effect"

let count = 0

// Simulates an effect with possible failures
export const effect = Effect.async<string, Error>((resume) => {
  if (count <= 2) {
    count++
    console.log("failure")
    resume(Effect.fail(new Error()))
  } else {
    console.log("success")
    resume(Effect.succeed("yay!"))
  }
})
```

```ts filename="fake.ts" twoslash
// @include: fake
```

## retry

The basic syntax of `retry` is as follows:

```ts
Effect.retry(effect, policy);
```

**Example**

```ts twoslash
// @filename: fake.ts
// @include: fake

// @filename: index.ts
// ---cut---
import { Effect, Schedule } from 'effect';
import { effect } from './fake';

// Define a repetition policy using a fixed delay between retries
const policy = Schedule.fixed('100 millis');

const repeated = Effect.retry(effect, policy);

Effect.runPromise(repeated).then(console.log);
/*
Output:
failure
failure
failure
success
yay!
*/
```

## retry n times

There is a shortcut when the policy is trivial and the failed effect is immediately retried:

```ts twoslash
// @filename: fake.ts
// @include: fake

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { effect } from './fake';

Effect.runPromise(Effect.retry(effect, { times: 5 }));
/*
Output:
failure
failure
failure
success
*/
```

## retryOrElse

There is another version of `retry` that allows us to define a fallback strategy in case of errors.
If something goes wrong, we can handle it using the `retryOrElse` function.
It lets us add an `orElse` callback that will run when the repetition fails.

The basic syntax of `retryOrElse` is as follows:

```ts
Effect.retryOrElse(effect, policy, fallback);
```

**Example**

```ts twoslash
// @filename: fake.ts
// @include: fake

// @filename: index.ts
// ---cut---
import { Console, Effect, Schedule } from 'effect';
import { effect } from './fake';

const policy = Schedule.addDelay(
  Schedule.recurs(2), // Retry for a maximum of 2 times
  () => '100 millis', // Add a delay of 100 milliseconds between retries
);

// Create a new effect that retries the effect with the specified policy,
// and provides a fallback effect if all retries fail
const repeated = Effect.retryOrElse(
  effect,
  policy,
  () => Console.log('orElse').pipe(Effect.as('default value')),
);

Effect.runPromise(repeated).then(console.log);
/*
Output:
failure
failure
failure
orElse
default value
*/
```

# Two Types of Errors

---

## title: Two Types of Errorsexcerpt: Explore the distinction between expected and unexpected errors in Effect programs. Learn how developers handle anticipated errors, known as "expected errors," and discover the nature of "unexpected errors" that occur outside the normal program flow. Understand how Effect provides detailed failure messages to aid in error recovery.bottomNavigation: pagination

Just like any other program, Effect programs may fail for expected or unexpected reasons.
The difference between a non-Effect program and an Effect program is in the detail provided to you when your program fails.
Effect attempts to preserve as much information as possible about what caused your program to fail to produce a detailed,
comprehensive, and human readable failure message.

In an Effect program, there are two possible ways for a program to fail:

- **Expected Errors**: These are errors that developers anticipate and expect as part of normal program execution.

- **Unexpected Errors**: These are errors that occur unexpectedly and are not part of the intended program flow.

## Expected Errors

These errors, also referred to as _failures_, _typed errors_
or _recoverable errors_, are errors that developers anticipate as part of the normal program execution.
They serve a similar purpose to checked exceptions and play a role in defining the program's domain and control flow.

Expected errors **are tracked** at the type level by the `Effect` data type in the "Error" channel.

In the following example, it is evident from the type that the program can fail with an error of type `HttpError`:

```ts
Effect<string, HttpError>;
```

## Unexpected Errors

Unexpected errors, also referred to as _defects_, _untyped errors_, or _unrecoverable errors_, are errors that developers
do not anticipate occurring during normal program execution.
Unlike expected errors, which are considered part of a program's domain and control flow,
unexpected errors resemble unchecked exceptions and lie outside the expected behavior of the program.

Since these errors are not expected, Effect **does not track** them at the type level.
However, the Effect runtime does keep track of these errors and provides several methods to aid in recovering from unexpected errors.

# Matching

---

## title: Matchingexcerpt: Discover how to handle both success and failure cases in the Effect data type using functions like `match` and `matchEffect`. Learn techniques to perform side effects, ignore values, and access the full cause of failures. Effectively manage control flow and handle errors in your Effect programs.bottomNavigation: pagination

In the `Effect` data type, just like other data types such as [Option](../../other/data-types/option#matching) and [Exit](../../other/data-types/exit#matching), we have a `match` function that allows us to handle different cases simultaneously. When working with effects, we also have several functions that enable us to handle both success and failure scenarios.

## match

The `Effect.match` function allows us to **handle both success and failure cases** in a non-effectful manner by providing a handler for each case:

```ts twoslash
import { Effect } from 'effect';

const success: Effect.Effect<number, Error> = Effect.succeed(42);
const failure: Effect.Effect<number, Error> = Effect.fail(new Error('Uh oh!'));

const program1 = Effect.match(success, {
  onFailure: (error) => `failure: ${error.message}`,
  onSuccess: (value) => `success: ${value}`,
});

Effect.runPromise(program1).then(console.log); // Output: "success: 42"

const program2 = Effect.match(failure, {
  onFailure: (error) => `failure: ${error.message}`,
  onSuccess: (value) => `success: ${value}`,
});

Effect.runPromise(program2).then(console.log); // Output: "failure: Uh oh!"
```

We can also choose to ignore the success and failure values if we're not interested in them:

```ts twoslash
import { Effect } from 'effect';
import { constVoid } from 'effect/Function';

const task = Effect.fail('Uh oh!').pipe(Effect.as(5));

const program = Effect.match(task, {
  onFailure: constVoid,
  onSuccess: constVoid,
});
```

In this case, we use the `constVoid` function from the `Function` module, which constantly returns `void`, to provide handlers that perform no operation. This effectively discards the success and failure values and focuses solely on the control flow or side effects of the program. Alternatively, we can achieve the same result using the `Effect.ignore` function:

```ts twoslash
import { Effect } from 'effect';

const task = Effect.fail('Uh oh!').pipe(Effect.as(5));

const program = Effect.ignore(task);
```

## matchEffect

In addition to `Effect.match`, we have the `Effect.matchEffect` function, which allows us to handle success and failure cases while performing **additional side effects**. Let's see an example:

```ts twoslash
import { Effect } from 'effect';

const success: Effect.Effect<number, Error> = Effect.succeed(42);
const failure: Effect.Effect<number, Error> = Effect.fail(new Error('Uh oh!'));

const program1 = Effect.matchEffect(success, {
  onFailure: (error) =>
    Effect.succeed(`failure: ${error.message}`).pipe(Effect.tap(Effect.log)),
  onSuccess: (value) =>
    Effect.succeed(`success: ${value}`).pipe(Effect.tap(Effect.log)),
});

console.log(Effect.runSync(program1));
/*
Output:
... message="success: 42"
success: 42
*/

const program2 = Effect.matchEffect(failure, {
  onFailure: (error) =>
    Effect.succeed(`failure: ${error.message}`).pipe(Effect.tap(Effect.log)),
  onSuccess: (value) =>
    Effect.succeed(`success: ${value}`).pipe(Effect.tap(Effect.log)),
});

console.log(Effect.runSync(program2));
/*
Output:
... message="failure: Uh oh!"
failure: Uh oh!
*/
```

In this example, we use `Effect.matchEffect` instead of `Effect.match`. The `Effect.matchEffect` function allows us to perform additional side effects while handling success and failure cases. We can log messages or perform other side effects within the respective handlers.

## matchCause / matchCauseEffect

Effect also provides `Effect.matchCause` and `Effect.matchCauseEffect` functions, which are useful for **accessing the full cause** of the underlying fiber in case of failure. This allows us to handle different failure causes separately and take appropriate actions. Here's an example:

```ts twoslash
import { Console, Effect } from 'effect';

declare const exceptionalEffect: Effect.Effect<void, Error>;

const program = Effect.matchCauseEffect(exceptionalEffect, {
  onFailure: (cause) => {
    switch (cause._tag) {
      case 'Fail':
        return Console.log(`Fail: ${cause.error.message}`);
      case 'Die':
        return Console.log(`Die: ${cause.defect}`);
      case 'Interrupt':
        return Console.log(`${cause.fiberId} interrupted!`);
    }
    return Console.log('failed due to other causes');
  },
  onSuccess: (value) => Console.log(`succeeded with ${value} value`),
});
```

In this example, we have an `exceptionalEffect` that may fail or encounter other types of exceptions. The `matchCauseEffect` function allows us to match and handle different failure causes separately.

# Sandboxing

---

## title: Sandboxingexcerpt: Learn how to utilize the powerful `Effect.sandbox` function to encapsulate and understand the causes of errors in your code. This guide explores error sandboxing, allowing you to expose detailed causes of errors, and demonstrates how to handle specific error conditions effectively using standard error-handling operators like `Effect.catchAll` and `Effect.catchTags`.bottomNavigation: pagination

Errors are a common part of programming, and they can happen for various reasons, such as failures, defects, fiber interruptions, or even a combination of these factors. In this guide, we'll explore how to use the `Effect.sandbox` function to isolate and understand the causes of errors in your code.

## sandbox

The `Effect.sandbox` function is a valuable tool that allows you to encapsulate all the potential causes of an error in an effect. It exposes the full cause of an effect, whether it's due to a failure, defect, fiber interruption, or a combination of these factors.

Here's the signature of the `Effect.sandbox` function:

```ts
sandbox: Effect<A, E, R> -> Effect<A, Cause<E>, R>
```

In simple terms, it takes an effect `Effect<A, E, R>` and transforms it into an effect `Effect<A, Cause<E>, R>` where the error channel now contains a detailed cause of the error.

By using the `Effect.sandbox` function, you gain access to the underlying causes of exceptional effects. These causes are represented as a type of `Cause<E>` and are available in the error channel of the `Effect` data type.

Once you have exposed the causes, you can utilize standard error-handling operators like `Effect.catchAll` and `Effect.catchTags` to handle errors more effectively. These operators allow you to respond to specific error conditions.

Let's walk through an example to illustrate how error sandboxing works:

```ts twoslash
import { Console, Effect } from 'effect';

const effect = Effect.fail('Oh uh!').pipe(Effect.as('primary result'));

const sandboxed = Effect.sandbox(effect);

const program = Effect.catchTags(sandboxed, {
  Die: (cause) =>
    Console.log(`Caught a defect: ${cause.defect}`).pipe(
      Effect.as('fallback result on defect'),
    ),
  Interrupt: (cause) =>
    Console.log(`Caught a defect: ${cause.fiberId}`).pipe(
      Effect.as('fallback result on fiber interruption'),
    ),
  Fail: (cause) =>
    Console.log(`Caught a defect: ${cause.error}`).pipe(
      Effect.as('fallback result on failure'),
    ),
});

const main = Effect.unsandbox(program);

Effect.runPromise(main).then(console.log);
/*
Output:
Caught a defect: Oh uh!
fallback result on failure
*/
```

In this example, we expose the full cause of an effect using `Effect.sandbox`. Then, we handle specific error conditions using `Effect.catchTags`. Finally, if needed, we can undo the sandboxing operation with `Effect.unsandbox`.

# Error Management

---

## title: Error Managementexcerpt: Error Managementcollapsible: truebottomNavigation: childCards

# Timing out

---

## title: Timing outexcerpt: Learn how to set time constraints on operations with `Effect.timeout`. Discover how to handle scenarios where tasks need to complete within a specified timeframe. Explore variations like `timeoutTo`, `timeoutFail`, and `timeoutFailCause` to customize behavior when a timeout occurs, providing more control and flexibility in managing time-sensitive operations.bottomNavigation: pagination

In the world of programming, we often deal with tasks that take some time to complete.
Sometimes, we want to set a limit on how long we are willing to wait for a task to finish.
This is where the `Effect.timeout` function comes into play.
It allows us to put a time constraint on an operation, ensuring that it doesn't run indefinitely.

## Basic Usage

The `Effect.timeout` function employs a [Duration](../../other/data-types/duration) parameter to establish a time limit on an operation. If the operation exceeds this limit, a `TimeoutException` is triggered, indicating a timeout has occurred.

Here's a basic example where `Effect.timeout` is applied to an operation:

```ts twoslash
import { Effect } from 'effect';

const myEffect = Effect.gen(function* () {
  console.log('Start processing...');
  yield* Effect.sleep('2 seconds'); // Simulates a delay in processing // Simulates a delay in processing
  console.log('Processing complete.');
  return 'Result';
});

// wraps this effect, setting a maximum allowable duration of 3 seconds
const timedEffect = myEffect.pipe(Effect.timeout('3 seconds'));

// Output will show that the task completes successfully
// as it falls within the timeout duration
Effect.runPromiseExit(timedEffect).then(console.log);
/*
Output:
Start processing...
Processing complete.
{ _id: 'Exit', _tag: 'Success', value: 'Result' }
*/
```

## Handling Timeouts

When an operation does not finish within the specified duration, the behavior of the `Effect.timeout` depends on whether the operation is uninterruptible.

<Info>
  An **uninterruptible** effect is one that, once started, cannot be stopped
  mid-execution by the timeout mechanism directly. This could be because the
  operations within the effect need to run to completion to avoid leaving the
  system in an inconsistent state.
</Info>

1. **Interruptible Operation**: If the operation can be interrupted, it is terminated immediately once the timeout threshold is reached, resulting in a `TimeoutException`.

   ```ts twoslash
   import { Effect } from 'effect';

   const myEffect = Effect.gen(function* () {
     console.log('Start processing...');
     yield* Effect.sleep('2 seconds'); // Simulates a delay in processing
     console.log('Processing complete.');
     return 'Result';
   });

   const timedEffect = myEffect.pipe(Effect.timeout('1 second'));

   Effect.runPromiseExit(timedEffect).then(console.log);
   /*
   Output:
   Start processing...
   {
     _id: 'Exit',
     _tag: 'Failure',
     cause: { _id: 'Cause', _tag: 'Fail', failure: { _tag: 'TimeoutException' } }
   }
   */
   ```

2. **Uninterruptible Operation**: If the operation is uninterruptible, it continues until completion before the `TimeoutException` is assessed.

   ```ts twoslash
   import { Effect } from 'effect';

   const myEffect = Effect.gen(function* () {
     console.log('Start processing...');
     yield* Effect.sleep('2 seconds'); // Simulates a delay in processing
     console.log('Processing complete.');
     return 'Result';
   });

   const timedEffect = myEffect.pipe(
     Effect.uninterruptible,
     Effect.timeout('1 second'),
   );

   // Outputs a TimeoutException after the task completes, because the task is uninterruptible
   Effect.runPromiseExit(timedEffect).then(console.log);
   /*
   Output:
   Start processing...
   Processing complete.
   {
     _id: 'Exit',
     _tag: 'Failure',
     cause: { _id: 'Cause', _tag: 'Fail', failure: { _tag: 'TimeoutException' } }
   }
   */
   ```

## Disconnection on Timeout

The `Effect.disconnect` function is used to handle timeouts in a nuanced way, particularly when dealing with uninterruptible effects.

It allows the uninterruptible effect to complete its operations in the background, while the main control flow proceeds as if a timeout had occurred.

Here's the distinction:

- **Without Effect.disconnect**:

  - An uninterruptible effect will ignore the timeout and continue executing until it completes, after which the timeout error is assessed.
  - This can lead to delays in recognizing a timeout condition because the system must wait for the effect to complete.

- **With Effect.disconnect**:

  - The uninterruptible effect is allowed to continue in the background, independent of the main control flow.
  - The main control flow recognizes the timeout immediately and proceeds with the timeout error or alternative logic, without having to wait for the effect to complete.
  - This method is particularly useful when the operations of the effect do not need to block the continuation of the program, despite being marked as uninterruptible.

**Example**

Consider a scenario where a long-running data processing task is initiated, and you want to ensure the system remains responsive, even if the data processing takes too long:

```ts twoslash
import { Effect } from 'effect';

const longRunningTask = Effect.gen(function* () {
  console.log('Start heavy processing...');
  yield* Effect.sleep('5 seconds'); // Simulate a long process
  console.log('Heavy processing done.');
  return 'Data processed';
});

const timedEffect = longRunningTask.pipe(
  Effect.uninterruptible,
  Effect.disconnect, // Allows the task to finish independently if it times out
  Effect.timeout('1 second'),
);

Effect.runPromiseExit(timedEffect).then(console.log);
/*
Output:
Start heavy processing...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: { _tag: 'TimeoutException' } }
}
Heavy processing done.
*/
```

## Customizing Timeout Behavior

In addition to the basic `Effect.timeout` function, there are variations available that allow you to customize the behavior when a timeout occurs.

### timeoutTo

The `timeoutTo` function is similar to `Effect.timeout`, but it provides more control over the final result type.
It allows you to define alternative outcomes for both successful and timed-out operations:

```ts twoslash
import { Effect, Either } from 'effect';

const myEffect = Effect.gen(function* () {
  console.log('Start processing...');
  yield* Effect.sleep('2 seconds'); // Simulates a delay in processing
  console.log('Processing complete.');
  return 'Result';
});

const main = myEffect.pipe(
  Effect.timeoutTo({
    duration: '1 second',
    // let's return an Either
    onSuccess: (result): Either.Either<string, string> => Either.right(result),
    onTimeout: (): Either.Either<string, string> => Either.left('Timed out!'),
  }),
);

Effect.runPromise(main).then(console.log);
/*
Output:
Start processing...
{
  _id: "Either",
  _tag: "Left",
  left: "Timed out!"
}
*/
```

### timeoutFail

The `timeoutFail` function allows you to produce a specific error when a timeout happens:

```ts twoslash
import { Effect } from 'effect';

const myEffect = Effect.gen(function* () {
  console.log('Start processing...');
  yield* Effect.sleep('2 seconds'); // Simulates a delay in processing
  console.log('Processing complete.');
  return 'Result';
});

class MyTimeoutError {
  readonly _tag = 'MyTimeoutError';
}

const main = myEffect.pipe(
  Effect.timeoutFail({
    duration: '1 second',
    onTimeout: () => new MyTimeoutError(),
  }),
);

Effect.runPromiseExit(main).then(console.log);
/*
Output:
Start processing...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Fail',
    failure: MyTimeoutError { _tag: 'MyTimeoutError' }
  }
}
*/
```

### timeoutFailCause

The `timeoutFailCause` function allows you to produce a specific defect when a timeout occurs.
This is useful when you need to handle timeouts as exceptional cases in your code:

```ts twoslash
import { Cause, Effect } from 'effect';

const myEffect = Effect.gen(function* () {
  console.log('Start processing...');
  yield* Effect.sleep('2 seconds'); // Simulates a delay in processing
  console.log('Processing complete.');
  return 'Result';
});

const main = myEffect.pipe(
  Effect.timeoutFailCause({
    duration: '1 second',
    onTimeout: () => Cause.die('Timed out!'),
  }),
);

Effect.runPromiseExit(main).then(console.log);
/*
Output:
Start processing...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Die', defect: 'Timed out!' }
}
*/
```

# Parallel and Sequential Errors

---

## title: Parallel and Sequential Errorsexcerpt: Learn how to handle parallel and sequential errors in Effect programming. Understand the behavior of error handling in scenarios involving parallel computations and sequential operations. Explore combinator `Effect.parallelErrors` to expose and handle multiple parallel failures efficiently.bottomNavigation: pagination

In a typical Effect application, when an error occurs, it usually fails with the first error encountered by the Effect runtime. Let's look at an example:

```ts twoslash
import { Effect } from 'effect';

const fail = Effect.fail('Oh uh!');
const die = Effect.dieMessage('Boom!');

const program = Effect.all([fail, die]).pipe(
  Effect.andThen(die),
  Effect.asVoid,
);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Oh uh!' }
}
*/
```

In this case, the `program` will fail with the first error, which is "Oh uh!":

## Parallel Errors

However, in some situations, you may encounter multiple errors, especially when performing parallel computations. When parallel computations are involved, the application may fail due to multiple errors. Here's an example:

```ts twoslash
import { Effect } from 'effect';

const fail = Effect.fail('Oh uh!');
const die = Effect.dieMessage('Boom!');

const program = Effect.all([fail, die], { concurrency: 'unbounded' }).pipe(
  Effect.asVoid,
);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Parallel',
    left: { _id: 'Cause', _tag: 'Fail', failure: 'Oh uh!' },
    right: { _id: 'Cause', _tag: 'Die', defect: [Object] }
  }
}
*/
```

In this example, the `program` runs both `fail` and `die` concurrently, and if both fail, it will result in multiple errors.

### parallelErrors

Effect provides a useful combinator called `Effect.parallelErrors` that exposes all parallel failure errors in the error channel. Here's how you can use it:

```ts twoslash
import { Effect } from 'effect';

const fail1 = Effect.fail('Oh uh!');
const fail2 = Effect.fail('Oh no!');
const die = Effect.dieMessage('Boom!');

const program = Effect.all([fail1, fail2, die], {
  concurrency: 'unbounded',
}).pipe(Effect.asVoid, Effect.parallelErrors);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: [ 'Oh uh!', 'Oh no!' ] }
}
*/
```

In this example, `Effect.parallelErrors` combines the errors from `fail1` and `fail2` into a single error.

<Warning>
  Note that this operator is **only for failures**, not defects or
  interruptions.
</Warning>

## Sequential Errors

When working with resource-safety operators like `Effect.ensuring`, you may encounter multiple sequential errors. This happens because regardless of whether the original effect has any errors or not, the finalizer is uninterruptible and will run. Here's an example:

```ts twoslash
import { Effect } from 'effect';

const fail = Effect.fail('Oh uh!');
const die = Effect.dieMessage('Boom!');

const program = fail.pipe(Effect.ensuring(die));

Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Sequential',
    left: { _id: 'Cause', _tag: 'Fail', failure: 'Oh uh!' },
    right: { _id: 'Cause', _tag: 'Die', defect: [Object] }
  }
}
*/
```

In this case, the `program` will result in multiple sequential errors if both `fail` and the finalizer `die` encounter errors.

# Error Accumulation

---

## title: Error Accumulationexcerpt: Discover how to handle errors in your Effect programming by exploring sequential combinators, such as `Effect.zip` and `Effect.forEach`. Learn about the "fail fast" policy and explore alternative approaches for error accumulation using functions like `Effect.validate`, `Effect.validateAll`, `Effect.validateFirst`, and `Effect.partition`.bottomNavigation: pagination

Sequential combinators such as `Effect.zip` and `Effect.forEach` have a "fail fast" policy when it comes to error management. This means that they stop and return immediately when they encounter the first error.

Let's take a look at an example using the `Effect.zip` operator. In this example, we can see that `Effect.zip` will fail as soon as it encounters the first failure. As a result, only the first error is displayed:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.succeed(1);
const task2 = Effect.fail('Oh uh!').pipe(Effect.as(2));
const task3 = Effect.succeed(3);
const task4 = Effect.fail('Oh no!').pipe(Effect.as(4));

const program = task1.pipe(
  Effect.zip(task2),
  Effect.zip(task3),
  Effect.zip(task4),
);

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
(FiberFailure) Error: Oh uh!
*/
```

The `Effect.forEach` function behaves similarly. It takes a collection and an effectful operation, and tries to apply the operation to all elements of the collection. However, it also follows the "fail fast" policy and fails when it encounters the first error:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.forEach([1, 2, 3, 4, 5], (n) => {
  if (n < 4) {
    return Effect.succeed(n);
  } else {
    return Effect.fail(`${n} is not less that 4`);
  }
});

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
(FiberFailure) Error: 4 is not less that 4
*/
```

However, there are situations where we may need to collect all potential errors in a computation instead of failing fast. In such cases, we can use operators that accumulate errors as well as successes.

## validate

The `Effect.validate` function is similar to `Effect.zip`, but if it encounters an error, it continues the zip operation instead of stopping. It combines the effects and accumulates both errors and successes:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.succeed(1);
const task2 = Effect.fail('Oh uh!').pipe(Effect.as(2));
const task3 = Effect.succeed(3);
const task4 = Effect.fail('Oh no!').pipe(Effect.as(4));

const program = task1.pipe(
  Effect.validate(task2),
  Effect.validate(task3),
  Effect.validate(task4),
);

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
(FiberFailure) Error: Oh uh!
Error: Oh no!
*/
```

With `Effect.validate`, we can collect all the errors encountered during the computation instead of stopping at the first error. This allows us to have a complete picture of all the potential errors and successes in our program.

## validateAll

The `Effect.validateAll` function is similar to the `Effect.forEach` function. It transforms all elements of a collection using the provided effectful operation, but it collects all errors in the error channel, as well as the success values in the success channel.

```ts twoslash
import { Effect } from 'effect';

const program = Effect.validateAll([1, 2, 3, 4, 5], (n) => {
  if (n < 4) {
    return Effect.succeed(n);
  } else {
    return Effect.fail(`${n} is not less that 4`);
  }
});

Effect.runPromise(program).then(console.log, console.error);
/*
Output:
(FiberFailure) Error: ["4 is not less that 4","5 is not less that 4"]
*/
```

<Warning>
  Note that this function is lossy, which means that if there are any errors,
  all successes will be lost. If you need a function that preserves both
  successes and failures, please refer to the [partition](#partition)
  function.
</Warning>

## validateFirst

The `Effect.validateFirst` function is similar to `Effect.validateAll` but it will return the first success (or all the failures):

```ts twoslash
import { Effect } from 'effect';

const program = Effect.validateFirst([1, 2, 3, 4, 5], (n) => {
  if (n < 4) {
    return Effect.fail(`${n} is not less that 4`);
  } else {
    return Effect.succeed(n);
  }
});

Effect.runPromise(program).then(console.log, console.error);
// Output: 4
```

Please note that the return type is `number` instead of `number[]`, as in the case of `validateAll`.

## partition

The `Effect.partition` function takes an iterable and an effectful function that transforms each value of the iterable. It then creates a tuple of both failures and successes in the success channel:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.partition([0, 1, 2, 3, 4], (n) => {
  if (n % 2 === 0) {
    return Effect.succeed(n);
  } else {
    return Effect.fail(`${n} is not even`);
  }
});

Effect.runPromise(program).then(console.log, console.error);
// Output: [ [ '1 is not even', '3 is not even' ], [ 0, 2, 4 ] ]
```

Please note that this operator is an unexceptional effect, which means that the type of the error channel is `never`. Therefore, if we encounter a failure case, the whole effect doesn't fail.

# Error Channel Operations

---

## title: Error Channel Operationsexcerpt: Explore various operations on the error channel in Effect, including error mapping, both channel mapping, filtering success values, inspecting errors, exposing errors, merging error and success channels, and flipping error and success channels. Learn how to handle errors effectively in your Effect programming.bottomNavigation: pagination

In Effect you can perform various operations on the error channel of effects. These operations allow you to transform, inspect, and handle errors in different ways. Let's explore some of these operations.

## Map Operations

### mapError

The `Effect.mapError` function is used when you need to **transform or modify an error** produced by an effect, without affecting the success value. This can be helpful when you want to add extra information to the error or change its type.

```ts twoslash
import { Effect } from 'effect';

const simulatedTask = Effect.fail('Oh no!').pipe(Effect.as(1));

const mapped = Effect.mapError(simulatedTask, (message) => new Error(message));
```

We can observe that the type in the error channel of our program has changed from `string` to `Error`.

<Info>
  It's important to note that using the `Effect.mapError` function **does not
  change** the overall success or failure of the effect. If the mapped effect
  is successful, then the mapping function is ignored. In other words, the
  `Effect.mapError` operation only applies the transformation to the error
  channel of the effect, while leaving the success channel unchanged.
</Info>

### mapBoth

The `Effect.mapBoth` function allows you to **apply transformations to both channels**: the error channel and the success channel of an effect. It takes two map functions as arguments: one for the error channel and the other for the success channel.

```ts twoslash
import { Effect } from 'effect';

const simulatedTask = Effect.fail('Oh no!').pipe(Effect.as(1));

const modified = Effect.mapBoth(simulatedTask, {
  onFailure: (message) => new Error(message),
  onSuccess: (n) => n > 0,
});
```

After using `mapBoth`, we can observe that the type of our program has changed from `Effect<number, string>` to `Effect<boolean, Error>`.

<Info>
  It's important to note that using the `mapBoth` function **does not change**
  the overall success or failure of the effect. It only transforms the values
  in the error and success channels while preserving the effect's original
  success or failure status.
</Info>

## Filtering the Success Channel

The Effect library provides several operators to **filter values on the success channel** based on a given predicate. These operators offer different strategies for handling cases where the predicate fails. Let's explore them:

| **Function**                                         | **Description**                                                                                                                                                                                                                                   |
| ---------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Effect.filterOrFail`                                | This operator filters the values on the success channel based on a predicate. If the predicate fails for any value, the original effect fails with an error.                                                                                      |
| `Effect.filterOrDie` and `Effect.filterOrDieMessage` | These operators also filter the values on the success channel based on a predicate. If the predicate fails for any value, the original effect terminates abruptly. The `filterOrDieMessage` variant allows you to provide a custom error message. |
| `Effect.filterOrElse`                                | This operator filters the values on the success channel based on a predicate. If the predicate fails for any value, an alternative effect is executed instead.                                                                                    |

Here's an example that demonstrates these filtering operators in action:

```ts twoslash
import { Cause, Effect, Random } from 'effect';

const task1 = Effect.filterOrFail(
  Random.nextRange(-1, 1),
  (n) => n >= 0,
  () => 'random number is negative',
);

const task2 = Effect.filterOrDie(
  Random.nextRange(-1, 1),
  (n) => n >= 0,
  () => new Cause.IllegalArgumentException('random number is negative'),
);

const task3 = Effect.filterOrDieMessage(
  Random.nextRange(-1, 1),
  (n) => n >= 0,
  'random number is negative',
);

const task4 = Effect.filterOrElse(
  Random.nextRange(-1, 1),
  (n) => n >= 0,
  () => task3,
);
```

It's important to note that depending on the specific filtering operator used, the effect can either fail, terminate abruptly, or execute an alternative effect when the predicate fails. Choose the appropriate operator based on your desired error handling strategy and program logic.

In addition to the filtering capabilities discussed earlier, you have the option to further refine and narrow down the type of the success channel by providing a [user-defined type guard](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates) to the `filterOr*` APIs. This not only enhances type safety but also improves code clarity. Let's explore this concept through an example:

```ts twoslash
import { Effect, pipe } from 'effect';

// Define a user interface
interface User {
  readonly name: string;
}

// Assume an asynchronous authentication function
declare const auth: () => Promise<User | null>;

const program = pipe(
  Effect.promise(() => auth()),
  Effect.filterOrFail(
    // Define a guard to narrow down the type
    (user): user is User => user !== null,
    () => new Error('Unauthorized'),
  ),
  Effect.andThen((user) => user.name), // The 'user' here has type `User`, not `User | null`
);
```

In the example above, a guard is used within the `filterOrFail` API to ensure that the `user` is of type `User` rather than `User | null`. This refined type information improves the reliability of your code and makes it more understandable.

If you prefer, you can utilize a pre-made guard like [Predicate.isNotNull](https://effect-ts.github.io/effect/effect/Predicate.ts.html#isnotnull) for simplicity and consistency.

## Inspecting Errors

Similar to [tapping](../essentials/pipeline#tap) for success values, Effect provides several operators for **inspecting error values**. These operators allow us to peek into failures or underlying defects or causes:

- `tapError`
- `tapBoth`
- `tapErrorCause`
- `tapDefect`

Let's see an example of how to use these operators:

```ts twoslash
import { Console, Effect, Random } from 'effect';

const task = Effect.filterOrFail(
  Random.nextRange(-1, 1),
  (n) => n >= 0,
  () => 'random number is negative',
);

const tapping1 = Effect.tapError(
  task,
  (error) => Console.log(`failure: ${error}`),
);

const tapping2 = Effect.tapBoth(task, {
  onFailure: (error) => Console.log(`failure: ${error}`),
  onSuccess: (randomNumber) => Console.log(`random number: ${randomNumber}`),
});
```

<Info>
  It's important to note that tapping into error values **does not change**
  the type of the program.
</Info>

## Exposing Errors in The Success Channel

You can use the `Effect.either` function to convert an `Effect<A, E, R>` into another effect where both its failure (`E`) and success (`A`) channels have been lifted into an [Either&lt;A, E&gt;](../../other/data-types/either) data type:

```ts
Effect<A, E, R> -> Effect<Either<A, E>, never, R>
```

The resulting effect is an unexceptional effect, which means it cannot fail, because the failure case has been exposed as part of the `Either` left case. Therefore, the error parameter of the returned Effect is `never`, as it is guaranteed that the effect does not model failure.

This function becomes especially useful when recovering from effects that may fail when using `Effect.gen`.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect, Either } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(simulatedTask);
  if (Either.isLeft(failureOrSuccess)) {
    const error = failureOrSuccess.left;
    yield* Console.log(`failure: ${error}`);
    return 0;
  } else {
    const value = failureOrSuccess.right;
    yield* Console.log(`success: ${value}`);
    return value;
  }
});
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect, Either } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.either(simulatedTask).pipe(
  Effect.andThen((failureOrSuccess) =>
    Either.match(failureOrSuccess, {
      onLeft: (error) => Console.log(`failure: ${error}`).pipe(Effect.as(0)),
      onRight: (value) =>
        Console.log(`success: ${value}`).pipe(Effect.as(value)),
    })
  ),
);
```

</Tab>
</Tabs>

## Exposing the Cause in The Success Channel

You can use the `Effect.cause` function to **expose the cause** of an effect, which is a more detailed representation of failures, including error messages and defects.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.gen(function* () {
  const cause = yield* Effect.cause(simulatedTask);
  yield* Console.log(cause);
});
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.cause(simulatedTask).pipe(
  Effect.andThen((cause) => Console.log(cause)),
);
```

</Tab>
</Tabs>

## Merging the Error Channel into the Success Channel

Using the `Effect.merge` function, you can **merge the error channel into the success channel**, creating an effect that always succeeds with the merged value.

```ts twoslash
import { Effect } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const merged = Effect.merge(simulatedTask);
```

## Flipping Error and Success Channels

Using the `Effect.flip` function, you can **flip the error and success channels** of an effect, effectively swapping their roles.

```ts twoslash
import { Effect } from 'effect';

const simulatedTask = Effect.fail('Oh uh!').pipe(Effect.as(2));

const flipped = Effect.flip(simulatedTask);
```

# Yieldable Errors

---

## title: Yieldable Errorsexcerpt: Learn about "Yieldable Errors" in Effect programming, a convenient way to handle custom errors within generator functions. Explore the `Data.Error` and `Data.TaggedError` constructors for creating base and tagged yieldable errors, simplifying error handling in your code.bottomNavigation: pagination

"Yieldable Errors" are special types of errors that can be yielded within a [generator function](../essentials/using-generators) used by `Effect.gen`. The unique feature of these errors is that you don't need to use the `Effect.fail` API explicitly to handle them. They offer a more intuitive and convenient way to work with custom errors in your code.

## Data.Error

The `Data.Error` constructor enables you to create a base yieldable error class. This class can be used to represent different types of errors in your code. Here's how you can use it:

```ts twoslash
import { Data, Effect } from 'effect';

class MyError extends Data.Error<{ message: string }> {}

export const program = Effect.gen(function* () {
  yield* new MyError({ message: 'Oh no!' }); // same as yield* Effect.fail(new MyError({ message: "Oh no!" })
});

Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: { message: 'Oh no!' } }
}
*/
```

## Data.TaggedError

The `Data.TaggedError` constructor is useful for creating tagged yieldable errors. These errors bear a distinct property named `_tag`, which acts as their unique identifier, allowing you to differentiate them from one another. Here's how you can use it:

```ts twoslash
import { Data, Effect, Random } from 'effect';

// An error with _tag: "Foo"
class FooError extends Data.TaggedError('Foo')<{
  message: string;
}> {}

// An error with _tag: "Bar"
class BarError extends Data.TaggedError('Bar')<{
  randomNumber: number;
}> {}

export const program = Effect.gen(function* () {
  const n = yield* Random.next;
  return n > 0.5
    ? 'yay!'
    : n < 0.2
    ? yield* new FooError({ message: 'Oh no!' })
    : yield* new BarError({ randomNumber: n });
}).pipe(
  Effect.catchTags({
    Foo: (error) => Effect.succeed(`Foo error: ${error.message}`),
    Bar: (error) => Effect.succeed(`Bar error: ${error.randomNumber}`),
  }),
);

Effect.runPromise(program).then(console.log, console.error);
/*
Example Output (n < 0.2):
Foo error: Oh no!
*/
```

In this example, we create `FooError` and `BarError` classes with distinct tags ("Foo" and "Bar"). These tags help identify the type of error when handling errors in your code.

# Unexpected Errors

---

## title: Unexpected Errorsexcerpt: Learn how Effect handles unrecoverable errors, such as defects, providing functions like `die`, `dieMessage`, `orDie`, and `orDieWith`. Explore techniques to terminate effect execution, handle unexpected errors, and recover from defects. Discover the use of `catchAllDefect` and `catchSomeDefect` to manage and selectively recover from specific defects.bottomNavigation: pagination

There are situations where you may encounter unexpected errors, and you need to decide how to handle them. Effect provides functions to help you deal with such scenarios, allowing you to take appropriate actions when errors occur during the execution of your effects.

## Creating Unrecoverable Errors

In the same way it is possible to leverage combinators such as `fail` to create values of type `Effect<never, E, never>` the Effect library provides tools to create defects.

Creating defects is a common necessity when dealing with errors from which it is not possible to recover from a business logic perspective, such as attempting to establish a connection that is refused after multiple retries.

In those cases terminating the execution of the effect and moving into reporting, through an output such as stdout or some external monitoring service, might be the best solution.

The following functions and combinators allow for termination of the effect and are often used to convert values of type `Effect<A, E, R>` into values of type `Effect<A, never, R>` allowing the programmer an escape hatch from having to handle and recover from errors for which there is no sensible way to recover.

### die / dieMessage

The `Effect.die` function returns an effect that throws a specified error, while `Effect.dieMessage` throws a `RuntimeException` with a specified text message. These functions are useful for terminating a fiber when a defect, a critical and unexpected error, is detected in the code.

Example using `die`:

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number> =>
  b === 0
    ? Effect.die(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);

Effect.runSync(divide(1, 0)); // throws Error: Cannot divide by zero
```

Example using `dieMessage`:

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number> =>
  b === 0 ? Effect.dieMessage('Cannot divide by zero') : Effect.succeed(a / b);

Effect.runSync(divide(1, 0)); // throws RuntimeException: Cannot divide by zero
```

### orDie

The `Effect.orDie` function transforms an effect's failure into a termination of the fiber, making all failures unchecked and not part of the type of the effect. It can be used to handle errors that you do not wish to recover from.

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number, Error> =>
  b === 0
    ? Effect.fail(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);

const program = Effect.orDie(divide(1, 0));

Effect.runSync(program); // throws Error: Cannot divide by zero
```

After using `Effect.orDie`, the error channel type of the `program` is `never`, indicating that all failures are unchecked, and the effect is expected to terminate the fiber when an error occurs.

### orDieWith

Similar to `Effect.orDie`, the `Effect.orDieWith` function transforms an effect's failure into a termination of the fiber using a specified mapping function. It allows you to customize the error message before terminating the fiber.

```ts twoslash
import { Effect } from 'effect';

const divide = (a: number, b: number): Effect.Effect<number, Error> =>
  b === 0
    ? Effect.fail(new Error('Cannot divide by zero'))
    : Effect.succeed(a / b);

const program = Effect.orDieWith(
  divide(1, 0),
  (error) => new Error(`defect: ${error.message}`),
);

Effect.runSync(program); // throws Error: defect: Cannot divide by zero
```

After using `Effect.orDieWith`, the error channel type of the `program` is `never`, just like with `Effect.orDie`.

## Catching

Effect provides two functions that allow you to handle unexpected errors that may occur during the execution of your effects.

<Warning>
  There is no sensible way to recover from defects. The functions we're about
  to discuss should be used only at the boundary between Effect and an
  external system, to transmit information on a defect for diagnostic or
  explanatory purposes.
</Warning>

### catchAllDefect

The `Effect.catchAllDefect` function allows you to recover from all defects using a provided function. Here's an example:

```ts twoslash
import { Cause, Console, Effect } from 'effect';

const program = Effect.catchAllDefect(
  Effect.dieMessage('Boom!'), // Simulating a runtime error
  (defect) => {
    if (Cause.isRuntimeException(defect)) {
      return Console.log(`RuntimeException defect caught: ${defect.message}`);
    }
    return Console.log('Unknown defect caught.');
  },
);

// We get an Exit.Success because we caught all defects
Effect.runPromiseExit(program).then(console.log);
/*
Output:
RuntimeException defect caught: Boom!
{
  _id: "Exit",
  _tag: "Success",
  value: undefined
}
*/
```

It's important to understand that `catchAllDefect` can only handle defects, not expected errors (such as those caused by `Effect.fail`) or interruptions in execution (such as when using `Effect.interrupt`).

A defect refers to an error that cannot be anticipated in advance, and there is no reliable way to respond to it. As a general rule, it's recommended to let defects crash the application, as they often indicate serious issues that need to be addressed.

However, in some specific cases, such as when dealing with dynamically loaded plugins, a controlled recovery approach might be necessary. For example, if our application supports runtime loading of plugins and a defect occurs within a plugin, we may choose to log the defect and then reload only the affected plugin instead of crashing the entire application. This allows for a more resilient and uninterrupted operation of the application.

### catchSomeDefect

The `Effect.catchSomeDefect` function in Effect allows you to recover from specific defects using a provided partial function. Let's take a look at an example:

```ts twoslash
import { Cause, Console, Effect, Option } from 'effect';

const program = Effect.catchSomeDefect(
  Effect.dieMessage('Boom!'), // Simulating a runtime error
  (defect) => {
    if (Cause.isIllegalArgumentException(defect)) {
      return Option.some(
        Console.log(
          `Caught an IllegalArgumentException defect: ${defect.message}`,
        ),
      );
    }
    return Option.none();
  },
);

// Since we are only catching IllegalArgumentException
// we will get an Exit.Failure because we simulated a runtime error.
Effect.runPromiseExit(program).then(console.log);
/*
Output:
{
  _id: "Exit",
  _tag: "Failure",
  cause: {
    _id: "Cause",
    _tag: "Die",
    defect: {
      _tag: "RuntimeException",
      message: "Boom!",
      [Symbol(@effect/io/Cause/errors/RuntimeException)]: Symbol(@effect/io/Cause/errors/RuntimeException),
      toString: [Function: toString]
    }
  }
}
*/
```

It's important to understand that `catchSomeDefect` can only handle defects, not [expected errors](expected-errors) (such as those caused by `Effect.fail`) or [interruptions](../concurrency/interruption-model) in execution (such as when using `Effect.interrupt`).

# Expected Errors

---

## title: Expected Errorsexcerpt: Explore how Effect represents and manages expected errors. Learn about creating error instances, tracking errors at the type level, and the short-circuiting behavior of Effect programs. Discover techniques to catch and recover from errors, and gain insights into error handling strategies using Effect's powerful combinators.bottomNavigation: pagination

In this guide you will learn:

- How Effect represents expected errors
- The tools Effect provides for robust and comprehensive error management

As we saw in the guide [Creating Effects](../essentials/creating-effects), we can use the `fail` constructor to create an Effect
that represents an error:

```ts twoslash
import { Effect } from 'effect';

class HttpError {
  readonly _tag = 'HttpError';
}

const program = Effect.fail(new HttpError());
```

<Info>
  We use a class to represent the `HttpError` type above simply to gain access
  to both the error type and a free constructor. However, you can use whatever
  you like to model your error types.
</Info>

It's worth noting that we added a readonly `_tag` field as discriminant to our error in the example:

```ts {1}
class HttpError {
  readonly _tag = 'HttpError';
}
```

<Idea>
  Adding a discriminant field, such as `_tag`, can be beneficial for
  distinguishing between different types of errors during error handling. It
  also prevents TypeScript from unifying types, ensuring that each error is
  treated uniquely based on its discriminant value.
</Idea>

Expected errors **are tracked at the type level** by the `Effect` data type in the "Error" channel.

It is evident from the type of `program` that can fail with an error of type `HttpError`:

```ts
Effect<never, HttpError, never>;
```

## Error Tracking

The following program serves as an illustration of how errors are automatically tracked for you:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```twoslash include error-tracking
import { Effect, Random } from "effect"

export class FooError {
  readonly _tag = "FooError"
}

export class BarError {
  readonly _tag = "BarError"
}

export const program = Effect.gen(function* () {
  const n1 = yield* Random.next
  const n2 = yield* Random.next

  const foo = n1 > 0.5 ? "yay!" : yield* Effect.fail(new FooError())

  const bar = n2 > 0.5 ? "yay!" : yield* Effect.fail(new BarError())

  return foo + bar
})
```

```ts filename="error-tracking.ts" twoslash
// @include: error-tracking

Effect.runPromise(program).then(console.log, console.error);
```

In the above program, we compute two values: `foo` and `bar`, each representing a potential source of error.

</Tab>
<Tab>

```ts filename="error-tracking.ts" twoslash
import { Effect, Random } from 'effect';

export class FooError {
  readonly _tag = 'FooError';
}

export class BarError {
  readonly _tag = 'BarError';
}

const flakyFoo = Random.next.pipe(
  Effect.andThen((n1) =>
    n1 > 0.5 ? Effect.succeed('yay!') : Effect.fail(new FooError())
  ),
);

const flakyBar = Random.next.pipe(
  Effect.andThen((n2) =>
    n2 > 0.5 ? Effect.succeed('yay!') : Effect.fail(new BarError())
  ),
);

export const program = Effect.all([flakyFoo, flakyBar]).pipe(
  Effect.andThen(([foo, bar]) => foo + bar),
);
```

In the above program, we have two operations: `flakyFoo` and `flakyBar`, each representing a potential source of error.
These operations are combined using the `Effect.all(effects)` function from the Effect library, which allows us to sequence them together.

</Tab>
</Tabs>

Effect automatically keeps track of the possible errors that can occur during the execution of the program.
In this case, we have `FooError` and `BarError` as the possible error types.
The error channel of the `program` is specified as

```ts
Effect<string, FooError | BarError, never>;
```

indicating that it can potentially fail with either a `FooError` or a `BarError`.

## Short-Circuiting

When working with APIs like `Effect.gen`, `Effect.map`, `Effect.flatMap`, `Effect.andThen` and `Effect.all`, it's important to understand how they handle errors.
These APIs are designed to **short-circuit the execution** upon encountering the **first error**.

What does this mean for you as a developer? Well, let's say you have a chain of operations or a collection of effects to be executed in sequence. If any error occurs during the execution of one of these effects, the remaining computations will be skipped, and the error will be propagated to the final result.

In simpler terms, the short-circuiting behavior ensures that if something goes wrong at any step of your program, it won't waste time executing unnecessary computations. Instead, it will immediately stop and return the error to let you know that something went wrong.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

// Define three effects representing different tasks.
const task1 = Console.log('Executing task1...');
const task2 = Effect.fail('Something went wrong!');
const task3 = Console.log('Executing task3...');

// Compose the three tasks to run them in sequence.
// If one of the tasks fails, the subsequent tasks won't be executed.
const program = Effect.gen(function* () {
  yield* task1;
  yield* task2; // After task1, task2 is executed, but it fails with an error
  yield* task3; // This computation won't be executed because the previous one fails
});

Effect.runPromiseExit(program).then(console.log);
/*
Output:
Executing task1...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Something went wrong!' }
}
*/
```

</Tab>
<Tab>

```ts twoslash
import { Console, Effect } from 'effect';

// Define three effects representing different tasks.
const task1 = Console.log('Executing task1...');
const task2 = Effect.fail('Something went wrong!');
const task3 = Console.log('Executing task3...');

// Compose the three tasks using `Effect.andThen` to run them in sequence.
// The `Effect.andThen` function allows us to chain effects together.
// If one of the tasks fails, the subsequent tasks won't be executed.
const program = task1.pipe(
  Effect.andThen(task2), // After task1, task2 is executed, but it fails with an error
  Effect.andThen(task3), // This computation won't be executed because the previous one fails
);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
Executing task1...
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Something went wrong!' }
}
*/
```

</Tab>
</Tabs>

This code snippet demonstrates the short-circuiting behavior when an error occurs.
Each operation depends on the successful execution of the previous one.
If any error occurs, the execution is short-circuited, and the error is propagated.
In this specific example, `task3` is never executed because an error occurs in `task2`.

## Catching all Errors

### either

The `Effect.either` function converts an `Effect<A, E, R>` into another effect where both its failure (`E`) and success (`A`) channels have been lifted into an [Either&lt;A, E&gt;](../../other/data-types/either) data type:

```ts
Effect<A, E, R> -> Effect<Either<A, E>, never, R>
```

The [Either&lt;R, L&gt;](../../other/data-types/either) data type represents a value that can be either a `Right` value (`R`) or a `Left` value (`L`).
By yielding an `Either`, we gain the ability to "pattern match" on this type to handle both failure and success cases within the generator function.

```ts twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect, Either } from 'effect';
import { program } from './error-tracking';

const recovered = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(program);
  if (Either.isLeft(failureOrSuccess)) {
    // failure case: you can extract the error from the `left` property
    const error = failureOrSuccess.left;
    return `Recovering from ${error._tag}`;
  } else {
    // success case: you can extract the value from the `right` property
    return failureOrSuccess.right;
  }
});
```

We can make the code less verbose by using the `Either.match` function, which directly accepts the two callback functions for handling errors and successful values:

```ts twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect, Either } from 'effect';
import { program } from './error-tracking';

const recovered = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(program);
  return Either.match(failureOrSuccess, {
    onLeft: (error) => `Recovering from ${error._tag}`,
    onRight: (value) => value, // do nothing in case of success
  });
});
```

### catchAll

The `Effect.catchAll` function allows you to catch any error that occurs in the program and provide a fallback.

```ts {5} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchAll((error) => Effect.succeed(`Recovering from ${error._tag}`)),
);
```

We can observe that the type in the error channel of our program has changed to `never`,
indicating that all errors have been handled.

## Catching Some Errors

Suppose we want to handle a specific error, such as `FooError`.

```ts {8-10} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect, Either } from 'effect';
import { program } from './error-tracking';

const recovered = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(program);
  if (Either.isLeft(failureOrSuccess)) {
    const error = failureOrSuccess.left;
    if (error._tag === 'FooError') {
      return 'Recovering from FooError';
    }
    return yield* Effect.fail(error);
  } else {
    return failureOrSuccess.right;
  }
});
```

We can observe that the type in the error channel of our program has changed to only show `BarError`,
indicating that `FooError` has been handled.

If we also want to handle `BarError`, we can easily add another case to our code:

```ts {11} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect, Either } from 'effect';
import { program } from './error-tracking';

const recovered = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(program);
  if (Either.isLeft(failureOrSuccess)) {
    const error = failureOrSuccess.left;
    if (error._tag === 'FooError') {
      return 'Recovering from FooError';
    } else {
      return 'Recovering from BarError';
    }
  } else {
    return failureOrSuccess.right;
  }
});
```

We can observe that the type in the error channel of our program has changed to `never`,
indicating that all errors have been handled.

### catchSome

If we want to catch and recover from only some types of errors and effectfully attempt recovery, we can use the `Effect.catchSome` function:

```ts twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect, Option } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchSome((error) => {
    if (error._tag === 'FooError') {
      return Option.some(Effect.succeed('Recovering from FooError'));
    }
    return Option.none();
  }),
);
```

In the code above, `Effect.catchSome` takes a function that examines the error (`error`) and decides whether to attempt recovery or not. If the error matches a specific condition, recovery can be attempted by returning `Option.some(effect)`. If no recovery is possible, you can simply return `Option.none()`.

It's important to note that while `Effect.catchSome` lets you catch specific errors, it **doesn't alter the error type** itself. Therefore, the resulting effect (`recovered` in this case) will still have the same error type (`FooError | BarError`) as the original effect.

### catchIf

Similar to `Effect.catchSome`, the function `Effect.catchIf` allows you to recover from specific errors based on a predicate:

```ts twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchIf(
    (error) => error._tag === 'FooError',
    () => Effect.succeed('Recovering from FooError'),
  ),
);
```

It's important to note that for TypeScript versions < 5.5, while `Effect.catchIf` lets you catch specific errors, it **doesn't alter the error type** itself. Therefore, the resulting effect (`recovered` in this case) will still have the same error type (`FooError | BarError`) as the original effect. In TypeScript versions >= 5.5, improved type narrowing causes the resulting error type to be inferred as `BarError`.

For TypeScript versions < 5.5, if you provide a [user-defined type guard](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates) instead of a predicate, the resulting error type will be pruned, returning an `Effect<string, BarError, never>`:

```ts {6} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { FooError, program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchIf(
    (error): error is FooError => error._tag === 'FooError',
    () => Effect.succeed('Recovering from FooError'),
  ),
);
```

### catchTag

If your program's errors are all tagged with a `_tag` field that acts as a discriminator you can use the `Effect.catchTag` function to catch and handle specific errors with precision.

```ts {5-7} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchTag(
    'FooError',
    (_fooError) => Effect.succeed('Recovering from FooError'),
  ),
);
```

In the example above, the `Effect.catchTag` function allows us to handle `FooError` specifically.
If a `FooError` occurs during the execution of the program, the provided error handler function will be invoked,
and the program will proceed with the recovery logic specified within the handler.

We can observe that the type in the error channel of our program has changed to only show `BarError`,
indicating that `FooError` has been handled.

If we also wanted to handle `BarError`, we can simply add another `catchTag`:

```ts {8-10} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchTag(
    'FooError',
    (_fooError) => Effect.succeed('Recovering from FooError'),
  ),
  Effect.catchTag(
    'BarError',
    (_barError) => Effect.succeed('Recovering from BarError'),
  ),
);
```

We can observe that the type in the error channel of our program has changed to `never`,
indicating that all errors have been handled.

<Warning>
  It is important to ensure that the error type used with `catchTag` has a
  `readonly _tag` discriminant field. This field is required for the matching
  and handling of specific error tags.
</Warning>

### catchTags

Instead of using the `Effect.catchTag` function multiple times to handle individual error types, we have a more convenient option called `Effect.catchTags`. With `Effect.catchTags`, we can handle multiple errors in a single block of code.

```ts {5-8} twoslash
// @filename: error-tracking.ts
// @include: error-tracking

// @filename: index.ts
// ---cut---
import { Effect } from 'effect';
import { program } from './error-tracking';

const recovered = program.pipe(
  Effect.catchTags({
    FooError: (_fooError) => Effect.succeed(`Recovering from FooError`),
    BarError: (_barError) => Effect.succeed(`Recovering from BarError`),
  }),
);
```

In the above example, instead of using `Effect.catchTag` multiple times to handle individual errors, we utilize the `Effect.catchTags` combinator.
This combinator takes an object where each property represents a specific error `_tag` (`"FooError"` and `"BarError"` in this case),
and the corresponding value is the error handler function to be executed when that particular error occurs.

<Warning>
  It is important to ensure that all the error types used with
  `Effect.catchTags` have a `readonly _tag` discriminant field. This field is
  required for the matching and handling of specific error tags.
</Warning>

# Introduction to Effect's Control Flow Operators

---

## title: Introduction to Effect's Control Flow OperatorsnavTitle: Control Flowexcerpt: Effect is a powerful TypeScript library designed to help developers easily create complex, synchronous, and asynchronous programs.bottomNavigation: pagination

Even though JavaScript provides built-in control flow structures, Effect offers additional control flow functions that are useful in Effect applications. In this section, we will introduce different ways to control the flow of execution.

## if Expression

When working with Effect values, we can use the standard JavaScript if-then-else expressions:

```ts twoslash
import { Effect, Option } from 'effect';

const validateWeightOption = (
  weight: number,
): Effect.Effect<Option.Option<number>> => {
  if (weight >= 0) {
    return Effect.succeed(Option.some(weight));
  } else {
    return Effect.succeed(Option.none());
  }
};
```

Here we are using the [Option](../other/data-types/option) data type to represent the absence of a valid value.

We can also handle invalid inputs by using the error channel:

```ts twoslash
import { Effect } from 'effect';

const validateWeightOrFail = (
  weight: number,
): Effect.Effect<number, string> => {
  if (weight >= 0) {
    return Effect.succeed(weight);
  } else {
    return Effect.fail(`negative input: ${weight}`);
  }
};
```

## Conditional Operators

### when

Instead of using `if (condition) expression`, we can use the `Effect.when` function:

```ts twoslash
import { Effect, Option } from 'effect';

const validateWeightOption = (
  weight: number,
): Effect.Effect<Option.Option<number>> =>
  Effect.succeed(weight).pipe(Effect.when(() => weight >= 0));
```

Here we are using the [Option](../other/data-types/option) data type to represent the absence of a valid value.

If the condition evaluates to `true`, the effect inside the `Effect.when` will be executed and the result will be wrapped in a `Some`, otherwise it returns `None`:

```ts twoslash
import { Effect, Option } from 'effect';

const validateWeightOption = (
  weight: number,
): Effect.Effect<Option.Option<number>> =>
  Effect.succeed(weight).pipe(Effect.when(() => weight >= 0));

// ---cut---
Effect.runPromise(validateWeightOption(100)).then(console.log);
/*
Output:
{
  _id: "Option",
  _tag: "Some",
  value: 100
}
*/

Effect.runPromise(validateWeightOption(-5)).then(console.log);
/*
Output:
{
  _id: "Option",
  _tag: "None"
}
*/
```

If the condition itself involves an effect, we can use `Effect.whenEffect`.

For example, the following function creates a random option of an integer value:

```ts twoslash
import { Effect, Random } from 'effect';

const randomIntOption = Random.nextInt.pipe(
  Effect.whenEffect(Random.nextBoolean),
);
```

### unless

The `Effect.unless` and `Effect.unlessEffect` functions are similar to the `when*` functions, but they are equivalent to the `if (!condition) expression` construct.

### if

The `Effect.if` function allows you to provide an effectful predicate. If the predicate evaluates to `true`, the `onTrue` effect will be executed. Otherwise, the `onFalse` effect will be executed.

Let's use this function to create a simple virtual coin flip function:

```ts twoslash
import { Console, Effect, Random } from 'effect';

const flipTheCoin = Effect.if(Random.nextBoolean, {
  onTrue: () => Console.log('Head'),
  onFalse: () => Console.log('Tail'),
});

Effect.runPromise(flipTheCoin);
```

In this example, we generate a random boolean value using `Random.nextBoolean`. If the value is `true`, the effect `onTrue` will be executed, which logs "Head". Otherwise, if the value is `false`, the effect `onFalse` will be executed, logging "Tail".

## Zipping

### zip

The `Effect.zip` function allows you to combine two effects into a single effect.
This combined effect yields a tuple containing the results of both input effects once they succeed:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.succeed(1).pipe(
  Effect.delay('200 millis'),
  Effect.tap(Effect.log('task1 done')),
);
const task2 = Effect.succeed('hello').pipe(
  Effect.delay('100 millis'),
  Effect.tap(Effect.log('task2 done')),
);

const task3 = Effect.zip(task1, task2);

Effect.runPromise(task3).then(console.log);
/*
Output:
timestamp=... level=INFO fiber=#0 message="task1 done"
timestamp=... level=INFO fiber=#0 message="task2 done"
[ 1, 'hello' ]
*/
```

Note that `Effect.zip` processes effects sequentially: it first completes the effect on the left and then the effect on the right.

If you want to run the effects concurrently, you can use the `concurrent` option:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.succeed(1).pipe(
  Effect.delay('200 millis'),
  Effect.tap(Effect.log('task1 done')),
);
const task2 = Effect.succeed('hello').pipe(
  Effect.delay('100 millis'),
  Effect.tap(Effect.log('task2 done')),
);
// ---cut---
const task3 = Effect.zip(task1, task2, { concurrent: true });

Effect.runPromise(task3).then(console.log);
/*
Output:
timestamp=... level=INFO fiber=#3 message="task2 done"
timestamp=... level=INFO fiber=#2 message="task1 done"
[ 1, 'hello' ]
*/
```

### zipWith

The `Effect.zipWith` function operates similarly to [Effect.zip](#zip) by combining two effects.
However, instead of returning a tuple, it allows you to apply a function to the results of the combined effects, transforming them into a single value:

```ts twoslash
import { Effect } from 'effect';

const task1 = Effect.succeed(1).pipe(
  Effect.delay('200 millis'),
  Effect.tap(Effect.log('task1 done')),
);
const task2 = Effect.succeed('hello').pipe(
  Effect.delay('100 millis'),
  Effect.tap(Effect.log('task2 done')),
);

const task3 = Effect.zipWith(
  task1,
  task2,
  (number, string) => number + string.length,
);

Effect.runPromise(task3).then(console.log);
/*
Output:
timestamp=2024-06-19T16:37:36.837Z level=INFO fiber=#3 message="task1 done"
timestamp=2024-06-19T16:37:36.936Z level=INFO fiber=#2 message="task2 done"
6
*/
```

## Loop Operators

### loop

The `Effect.loop` function allows you to repeatedly change the state based on an `step` function until a condition given by the `while` function is evaluated to `true`:

```ts
Effect.loop(initial, options: { while, step, body })
```

It collects all intermediate states in an array and returns it as the final result.

We can think of `Effect.loop` as equivalent to a `while` loop in JavaScript:

```ts
let state = initial;
const result = [];

while (options.while(state)) {
  result.push(options.body(state));
  state = options.step(state);
}

return result;
```

**Example**

```ts twoslash
import { Effect } from 'effect';

const result = Effect.loop(
  1, // Initial state
  {
    while: (state) => state <= 5, // Condition to continue looping
    step: (state) => state + 1, // State update function
    body: (state) => Effect.succeed(state), // Effect to be performed on each iteration
  },
);

Effect.runPromise(result).then(console.log); // Output: [1, 2, 3, 4, 5]
```

In this example, the loop starts with an initial state of `1`. The loop continues as long as the condition `n <= 5` is `true`, and in each iteration, the state `n` is incremented by `1`. The effect `Effect.succeed(n)` is performed on each iteration, collecting all intermediate states in an array.

You can also use the `discard` option if you're not interested in collecting the intermediate results. It discards all intermediate states and returns `undefined` as the final result.

**Example** (`discard: true`)

```ts twoslash
import { Console, Effect } from 'effect';

const result = Effect.loop(
  1, // Initial state
  {
    while: (state) => state <= 5, // Condition to continue looping,
    step: (state) => state + 1, // State update function,
    body: (state) => Console.log(`Currently at state ${state}`), // Effect to be performed on each iteration,
    discard: true,
  },
);

Effect.runPromise(result).then(console.log);
/*
Output:
Currently at state 1
Currently at state 2
Currently at state 3
Currently at state 4
Currently at state 5
undefined
*/
```

In this example, the loop performs a side effect of logging the current index on each iteration, but it discards all intermediate results. The final result is `undefined`.

### iterate

The `Effect.iterate` function allows you to iterate with an effectful operation. It uses an effectful `body` operation to change the state during each iteration and continues the iteration as long as the `while` function evaluates to `true`:

```ts
Effect.iterate(initial, options: { while, body })
```

We can think of `Effect.iterate` as equivalent to a `while` loop in JavaScript:

```ts
let result = initial;

while (options.while(result)) {
  result = options.body(result);
}

return result;
```

Here's an example of how it works:

```ts twoslash
import { Effect } from 'effect';

const result = Effect.iterate(
  1, // Initial result
  {
    while: (result) => result <= 5, // Condition to continue iterating
    body: (result) => Effect.succeed(result + 1), // Operation to change the result
  },
);

Effect.runPromise(result).then(console.log); // Output: 6
```

### forEach

The `Effect.forEach` function allows you to iterate over an `Iterable` and perform an effectful operation for each element.

The syntax for `forEach` is as follows:

```ts
import { Effect } from 'effect';

const combinedEffect = Effect.forEach(iterable, operation, options);
```

It applies the given effectful operation to each element of the `Iterable`. By default, it executes each effect in **sequence** (to explore options for managing concurrency and controlling how these effects are executed, you can refer to the [Concurrency Options](./concurrency/concurrency-options) documentation).

This function returns a new effect that produces an array containing the results of each individual effect.

Let's take a look at an example:

```ts twoslash
import { Console, Effect } from 'effect';

const result = Effect.forEach(
  [1, 2, 3, 4, 5],
  (n, index) =>
    Console.log(`Currently at index ${index}`).pipe(Effect.as(n * 2)),
);

Effect.runPromise(result).then(console.log);
/*
Output:
Currently at index 0
Currently at index 1
Currently at index 2
Currently at index 3
Currently at index 4
[ 2, 4, 6, 8, 10 ]
*/
```

In this example, we have an array `[1, 2, 3, 4, 5]`, and for each element we perform an effectful operation. The output shows that the operation is executed for each element in the array, displaying the current index.

The `Effect.forEach` combinator collects the results of each effectful operation in an array, which is why the final output is `[ 2, 4, 6, 8, 10 ]`.

We also have the `discard` option, which when set to `true` discards the results of each effectful operation:

```ts twoslash
import { Console, Effect } from 'effect';

const result = Effect.forEach(
  [1, 2, 3, 4, 5],
  (n, index) =>
    Console.log(`Currently at index ${index}`).pipe(Effect.as(n * 2)),
  { discard: true },
);

Effect.runPromise(result).then(console.log);
/*
Output:
Currently at index 0
Currently at index 1
Currently at index 2
Currently at index 3
Currently at index 4
undefined
*/
```

In this case, the output is the same, but the final result is `undefined` since the results of each effectful operation are discarded.

### all

The `Effect.all` function in the Effect library is a powerful tool that allows you to merge multiple effects into a single effect, offering flexibility by working with various structured formats such as tuples, iterables, structs, and records.

The syntax for `all` is as follows:

```ts
import { Effect } from 'effect';

const combinedEffect = Effect.all(effects, options);
```

where `effects` is a collection of individual effects that you wish to merge.

By default, the `all` function will execute each effect in **sequence** (to explore options for managing concurrency and controlling how these effects are executed, you can refer to the [Concurrency Options](./concurrency/concurrency-options) documentation).

It will return a new effect that produces a result with a shape that depends on the shape of the `effects` argument.

Let's explore examples for each supported shape: tuples, iterables, structs, and records.

**Tuples**

```ts twoslash
import { Console, Effect } from 'effect';

const tuple = [
  Effect.succeed(42).pipe(Effect.tap(Console.log)),
  Effect.succeed('Hello').pipe(Effect.tap(Console.log)),
] as const;

const combinedEffect = Effect.all(tuple);

Effect.runPromise(combinedEffect).then(console.log);
/*
Output:
42
Hello
[ 42, 'Hello' ]
*/
```

**Iterables**

```ts twoslash
import { Console, Effect } from 'effect';

const iterable: Iterable<Effect.Effect<number>> = [1, 2, 3].map((n) =>
  Effect.succeed(n).pipe(Effect.tap(Console.log))
);

const combinedEffect = Effect.all(iterable);

Effect.runPromise(combinedEffect).then(console.log);
/*
Output:
1
2
3
[ 1, 2, 3 ]
*/
```

**Structs**

```ts twoslash
import { Console, Effect } from 'effect';

const struct = {
  a: Effect.succeed(42).pipe(Effect.tap(Console.log)),
  b: Effect.succeed('Hello').pipe(Effect.tap(Console.log)),
};

const combinedEffect = Effect.all(struct);

Effect.runPromise(combinedEffect).then(console.log);
/*
Output:
42
Hello
{ a: 42, b: 'Hello' }
*/
```

**Records**

```ts twoslash
import { Console, Effect } from 'effect';

const record: Record<string, Effect.Effect<number>> = {
  key1: Effect.succeed(1).pipe(Effect.tap(Console.log)),
  key2: Effect.succeed(2).pipe(Effect.tap(Console.log)),
};

const combinedEffect = Effect.all(record);

Effect.runPromise(combinedEffect).then(console.log);
/*
Output:
1
2
{ key1: 1, key2: 2 }
*/
```

#### The Role of Short-Circuiting

When working with the `Effect.all` API, it's important to understand how it manages errors.
This API is designed to **short-circuit the execution** upon encountering the **first error**.

What does this mean for you as a developer? Well, let's say you have a collection of effects to be executed in sequence. If any error occurs during the execution of one of these effects, the remaining computations will be skipped, and the error will be propagated to the final result.

In simpler terms, the short-circuiting behavior ensures that if something goes wrong at any step of your program it will immediately stop and return the error to let you know that something went wrong.

```ts twoslash
import { Console, Effect } from 'effect';

const effects = [
  Effect.succeed('Task1').pipe(Effect.tap(Console.log)),
  Effect.fail('Task2: Oh no!').pipe(Effect.tap(Console.log)),
  Effect.succeed('Task3').pipe(Effect.tap(Console.log)), // this task won't be executed
];

const program = Effect.all(effects);

Effect.runPromiseExit(program).then(console.log);
/*
Output:
Task1
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Task2: Oh no!' }
}
*/
```

You can override this behavior by using the `mode` option.

#### The mode option

When you use the `{ mode: "either" }` option with `Effect.all`, it modifies the behavior of the API to handle errors differently. Instead of short-circuiting the entire computation on the first error, it continues to execute all effects, collecting both successes and failures. The result is an array of `Either` instances, representing either a successful outcome (`Right`) or a failure (`Left`) for each individual effect.

Here's a breakdown:

```ts twoslash
import { Console, Effect } from 'effect';

const effects = [
  Effect.succeed('Task1').pipe(Effect.tap(Console.log)),
  Effect.fail('Task2: Oh no!').pipe(Effect.tap(Console.log)),
  Effect.succeed('Task3').pipe(Effect.tap(Console.log)),
];

const program = Effect.all(effects, { mode: 'either' });

Effect.runPromiseExit(program).then(console.log);
/*
Output:
Task1
Task3
{
  _id: 'Exit',
  _tag: 'Success',
  value: [
    { _id: 'Either', _tag: 'Right', right: 'Task1' },
    { _id: 'Either', _tag: 'Left', left: 'Task2: Oh no!' },
    { _id: 'Either', _tag: 'Right', right: 'Task3' }
  ]
}
*/
```

On the other hand, when you use the `{ mode: "validate" }` option with `Effect.all`, it takes a similar approach to `{ mode: "either" }` but uses the `Option` type to represent the success or failure of each effect. The resulting array will contain `None` for successful effects and `Some` with the associated error message for failed effects.

Here's an illustration:

```ts twoslash
import { Console, Effect } from 'effect';

const effects = [
  Effect.succeed('Task1').pipe(Effect.tap(Console.log)),
  Effect.fail('Task2: Oh no!').pipe(Effect.tap(Console.log)),
  Effect.succeed('Task3').pipe(Effect.tap(Console.log)),
];

const program = Effect.all(effects, { mode: 'validate' });

Effect.runPromiseExit(program).then((result) => console.log('%o', result));
/*
Output:
Task1
Task3
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Fail',
    failure: [
      { _id: 'Option', _tag: 'None' },
      { _id: 'Option', _tag: 'Some', value: 'Task2: Oh no!' },
      { _id: 'Option', _tag: 'None' }
    ]
  }
}
*/
```

# Introduction to Metrics in Effect

---

## title: Introduction to Metrics in EffectnavTitle: Metricsexcerpt: Effect Metrics provides a powerful solution for monitoring and analyzing various metrics, offering support for counters, gauges, histograms, summaries, and frequencies. Learn how these metrics enhance visibility into your application's performance and behavior.bottomNavigation: pagination

In complex and highly concurrent applications, managing various interconnected components can be quite challenging. Ensuring that everything runs smoothly and avoiding application downtime becomes crucial in such setups.

Now, let's imagine we have a sophisticated infrastructure with numerous services. These services are replicated and distributed across our servers. However, we often lack insight into what's happening across these services, including error rates, response times, and service uptime. This lack of visibility can make it challenging to identify and address issues effectively. This is where Effect Metrics comes into play; it allows us to capture and analyze various metrics, providing valuable data for later investigation.

Effect Metrics offers support for five different types of metrics:

1. **Counter**: Counters are used to track values that increase over time, such as request counts. They help us keep tabs on how many times a specific event or action has occurred.

2. **Gauge**: Gauges represent a single numerical value that can fluctuate up and down over time. They are often used to monitor metrics like memory usage, which can vary continuously.

3. **Histogram**: Histograms are useful for tracking the distribution of observed values across different buckets. They are commonly used for metrics like request latencies, allowing us to understand how response times are distributed.

4. **Summary**: Summaries provide insight into a sliding window of a time series and offer metrics for specific percentiles of the time series, often referred to as quantiles. This is particularly helpful for understanding latency-related metrics, such as request response times.

5. **Frequency**: Frequency metrics count the occurrences of distinct string values. They are useful when you want to keep track of how often different events or conditions are happening in your application.

## Counter

In the world of metrics, a Counter is a metric that represents a single numerical value that can be both incremented and decremented over time. Think of it like a tally that keeps track of changes, such as the number of a particular type of request received by your application, whether it's increasing or decreasing.

Unlike some other types of metrics (like gauges), where we're interested in the value at a specific moment, with counters, we care about the cumulative value over time. This means it provides a running total of changes, which can go up and down, reflecting the dynamic nature of certain metrics.

### How to Create a Counter

To create a counter, you can use the `Metric.counter` constructor in your code. You have the option to specify the type of the counter as either `number` or `bigint`. Here's how you can do it:

```ts twoslash
import { Metric } from 'effect';

const numberCounter = Metric.counter('request_count', {
  description: 'A counter for tracking requests',
});

const bigintCounter = Metric.counter('error_count', {
  description: 'A counter for tracking errors',
  bigint: true,
});
```

If you wish to create a counter that only increases its value, you can utilize the `incremental: true` option as follows:

```ts twoslash
import { Metric } from 'effect';

const incrementalCounter = Metric.counter('count', {
  description: 'a counter that only increases its value',
  incremental: true,
});
```

With this configuration, Effect ensures that non-incremental updates have no impact on the counter, making it exclusively suitable for counting upwards.

### When to Use Counters

Counters are incredibly useful when you need to keep track of cumulative values that can both increase and decrease over time. So, when should you use counters?

1. **Tracking a Value Over Time**: If you need to monitor something that consistently increases over time, like the number of incoming requests, counters are your go-to choice.

2. **Measuring Growth Rates**: Counters are also handy when you want to measure how fast something is growing. For instance, you can use them to keep tabs on request rates.

Counters find application in various scenarios, including:

- **Request Counts**: Monitoring the number of incoming requests to your server.

- **Completed Tasks**: Keeping track of how many tasks or processes have been successfully completed.

- **Error Counts**: Counting the occurrences of errors in your application.

### Example

Here's a practical example of creating and using a counter in your code:

```ts twoslash
import { Console, Effect, Metric } from 'effect';

// Create a counter named 'task_count' and increment it by 1 every time it's invoked
const taskCount = Metric.counter('task_count').pipe(
  Metric.withConstantInput(1),
);

const task1 = Effect.succeed(1).pipe(Effect.delay('100 millis'));
const task2 = Effect.succeed(2).pipe(Effect.delay('200 millis'));

const program = Effect.gen(function* () {
  const a = yield* taskCount(task1);
  const b = yield* taskCount(task2);
  return a + b;
});

const showMetric = Metric.value(taskCount).pipe(Effect.andThen(Console.log));

Effect.runPromise(program.pipe(Effect.tap(() => showMetric))).then(
  console.log,
);
/*
Output:
CounterState {
  count: 2,
  ...
}
3
*/
```

In this example, we create a counter called `taskCount`, which is incremented by 1 each time it's invoked. We then use it to monitor the number of times certain tasks are executed. The result provides valuable insights into the cumulative count of these tasks.

It's worth noting that applying the `taskCount` metric to an effect doesn't change its type. So, if `task1` has a type of `Effect<number>`, then `taskCount(task1)` still has the same type, `Effect<number>`.

## Gauge

In the world of metrics, a Gauge is a metric that represents a single numerical value that can be set or adjusted. Think of it as a dynamic variable that can change over time. One common use case for a gauge is to monitor something like the current memory usage of your application.

Unlike counters, where we're interested in cumulative values over time, with gauges, our focus is on the current value at a specific point in time.

### How to Create a Gauge

To create a gauge, you can use the `Metric.gauge` constructor in your code. You can specify the type of the gauge as either `number` or `bigint`. Here's how you can do it:

```ts twoslash
import { Metric } from 'effect';

const numberGauge = Metric.gauge('memory_usage', {
  description: 'A gauge for memory usage',
});

const bigintGauge = Metric.gauge('cpu_load', {
  description: 'A gauge for CPU load',
  bigint: true,
});
```

### When to Use Gauges

Gauges are the best choice when you want to monitor values that can both increase and decrease, and you're not interested in tracking their rates of change. In other words, gauges help us measure things that have a specific value at a particular moment:

- **Memory Usage**: Keeping an eye on how much memory your application is using right now.

- **Queue Size**: Monitoring the current size of a queue where tasks are waiting to be processed.

- **In-Progress Request Counts**: Tracking the number of requests currently being handled by your server.

- **Temperature**: Measuring the current temperature, which can fluctuate up and down.

### Example

Let's look at a practical example of creating and using a gauge in your code:

```ts twoslash
import { Console, Effect, Metric, Random } from 'effect';

const temperature = Metric.gauge('temperature');

const getTemperature = Effect.gen(function* () {
  const n = yield* Random.nextIntBetween(-10, 10);
  console.log(`variation: ${n}`);
  return n;
});

const program = Effect.gen(function* () {
  const series: Array<number> = [];
  series.push(yield* temperature(getTemperature));
  series.push(yield* temperature(getTemperature));
  series.push(yield* temperature(getTemperature));
  return series;
});

const showMetric = Metric.value(temperature).pipe(Effect.andThen(Console.log));

Effect.runPromise(program.pipe(Effect.tap(() => showMetric))).then(
  console.log,
);
/*
Output:
variation: 6
variation: -4
variation: -9
GaugeState {
  value: -9,
  ...
}
[ 6, -4, -9 ]
*/
```

## Histogram

A Histogram is a metric that helps us understand how a collection of numerical values is distributed over time. Instead of just focusing on the individual values, histograms organize these values into distinct intervals, called buckets, and record the frequency of values within each bucket.

Histograms are valuable because they not only represent the actual values but also provide insights into their distribution. They are like a summary of a dataset, breaking down the data into buckets and showing how many data points fall into each one.

### How Histograms Work

In a histogram, each incoming sample is assigned to a predefined bucket. When a data point arrives, it increases the count for the corresponding bucket, and then the individual sample is discarded. This bucketed approach allows us to aggregate data across multiple instances. Histograms are especially useful for measuring percentiles, helping us estimate specific percentiles by looking at bucket counts.

### Key Concepts

- **Observing Values:** Histograms observe numerical values and count how many observations fall into specific buckets. Each bucket has an upper boundary, and the count for a bucket increases by 1 if an observed value is less than or equal to the bucket's upper boundary.

- **Overall Count:** A histogram also keeps track of the total count of observed values and the sum of all observed values.

- **Inspired by Prometheus:** The concept of histograms is inspired by [Prometheus](https://prometheus.io/docs/concepts/metric_types/#histogram), a popular monitoring and alerting toolkit.

### When to Use Histograms

Histograms are widely used in software metrics for various purposes, especially in analyzing the performance of software systems. They are valuable for metrics such as response times, latencies, and throughput. By visualizing the distribution of these metrics in a histogram, developers can identify performance bottlenecks, outliers, or variations. This information helps in optimizing code, infrastructure, and system configurations to improve overall performance.

Histograms are the best choice in the following situations:

- When you want to observe many values and later calculate percentiles of those observed values.

- When you can estimate the range of values in advance, as histograms organize observations into predefined buckets.

- When you don't require exact values due to the inherent lossy nature of bucketing data in histograms.

- When you need to aggregate histograms across multiple instances.

### Examples

#### Histogram With Linear Buckets

In this example, we create a histogram with linear buckets, ranging from 0 to 100 in increments of 10, and an "Infinity" bucket. It's suitable for effects yielding a `number`. The program then generates random values, records them in the histogram, and displays the histogram's state.

```ts twoslash
import { Effect, Metric, MetricBoundaries, Random } from 'effect';

const latencyHistogram = Metric.histogram(
  'request_latency',
  MetricBoundaries.linear({ start: 0, width: 10, count: 11 }),
);

const program = latencyHistogram(Random.nextIntBetween(1, 120)).pipe(
  Effect.repeatN(99),
);

Effect.runPromise(
  program.pipe(Effect.andThen(Metric.value(latencyHistogram))),
).then((histogramState) => console.log('%o', histogramState));
/*
Output:
HistogramState {
  buckets: [
    [ 0, 0 ],
    [ 10, 7 ],
    [ 20, 11 ],
    [ 30, 20 ],
    [ 40, 27 ],
    [ 50, 38 ],
    [ 60, 53 ],
    [ 70, 64 ],
    [ 80, 73 ],
    [ 90, 84 ],
    [ Infinity, 100 ],
    [length]: 11
  ],
  count: 100,
  min: 1,
  max: 119,
  sum: 5980,
  ...
}
*/
```

#### Timer Metric

This example demonstrates the use of a timer metric to track workflow durations. It generates random values, simulates waiting times, records durations in the timer metric, and displays the histogram's state.

```ts twoslash
import { Array, Effect, Metric, Random } from 'effect';

// Metric<Histogram, Duration, Histogram>
const timer = Metric.timerWithBoundaries('timer', Array.range(1, 10));

const program = Random.nextIntBetween(1, 10).pipe(
  Effect.andThen((n) => Effect.sleep(`${n} millis`)),
  Metric.trackDuration(timer),
  Effect.repeatN(99),
);

Effect.runPromise(program.pipe(Effect.andThen(Metric.value(timer)))).then(
  (histogramState) => console.log('%o', histogramState),
);
/*
Output:
HistogramState {
  buckets: [
    [ 1, 3 ],
    [ 2, 13 ],
    [ 3, 17 ],
    [ 4, 26 ],
    [ 5, 35 ],
    [ 6, 43 ],
    [ 7, 53 ],
    [ 8, 56 ],
    [ 9, 65 ],
    [ 10, 72 ],
    [ Infinity, 100 ],
    [length]: 11
  ],
  count: 100,
  min: 0.25797,
  max: 12.25421,
  sum: 683.0266810000002,
  ...
}
*/
```

These examples showcase how histograms can be used to analyze and understand the distribution of data in various scenarios, making them a valuable tool in software metrics.

## Summary

A Summary is a metric that provides valuable insights into a time series by calculating specific percentiles. These percentiles help us understand the distribution of values within the time series. Imagine you're tracking response times for requests over the past hour; you might be interested in percentiles like the 50th, 90th, 95th, and 99th to analyze performance.

### How Summaries Work

Summaries, much like histograms, observe `number` values. However, instead of directly modifying bucket counters and discarding samples, summaries retain the observed samples in their internal state. To prevent uncontrolled growth of the sample set, a summary is configured with a maximum age `maxAge` and a maximum size `maxSize`. When calculating statistics, it uses a maximum of `maxSize` samples, all of which are not older than `maxAge`.

Think of the set of samples as a sliding window over the most recent observations that meet the specified conditions.

Summaries are primarily used to calculate quantiles over the current set of samples. A quantile is defined by a `number` value `q` with `0 <= q <= 1` and results in a `number` as well.

The value of a specific quantile `q` is determined as the maximum value `v` from the current sample buffer (with size `n`) where at most `q * n` values from the sample buffer are less than or equal to `v`.

Common quantiles for observation include `0.5` (the median) and `0.95`. Quantiles are particularly useful for monitoring Service Level Agreements (SLAs).

The Effect Metrics API also allows summaries to be configured with an error margin `error`. This margin is applied to the count of values, so a quantile `q` for a set of size `s` resolves to value `v` if the count `n` of values less than or equal to `v` falls within the range `(1 - error)q * s <= n <= (1 + error)q`.

### When to Use Summaries

Summaries are excellent for monitoring latencies when histograms are not the right fit due to accuracy concerns. They shine in situations where:

- The range of values is not well-estimated, making histograms less suitable.

- There's no need for aggregation or averaging across multiple instances, as summary calculations are performed on the application side.

### Example

Let's create a summary to hold `100` samples, with a maximum sample age of `1 day`, and an error margin of `3%`. This summary should report the `10%`, `50%`, and `90%` quantiles. It can be applied to effects yielding integers:

```ts twoslash
import { Effect, Metric, Random } from 'effect';

const responseTimeSummary = Metric.summary({
  name: 'response_time_summary',
  maxAge: '1 day',
  maxSize: 100,
  error: 0.03,
  quantiles: [0.1, 0.5, 0.9],
});

const program = responseTimeSummary(Random.nextIntBetween(1, 120)).pipe(
  Effect.repeatN(99),
);

Effect.runPromise(
  program.pipe(Effect.andThen(Metric.value(responseTimeSummary))),
).then((summaryState) => console.log('%o', summaryState));
/*
Output:
SummaryState {
  error: 0.03,
  quantiles: [
    [ 0.1, { _id: 'Option', _tag: 'Some', value: 17 } ],
    [ 0.5, { _id: 'Option', _tag: 'Some', value: 62 } ],
    [ 0.9, { _id: 'Option', _tag: 'Some', value: 109 } ]
  ],
  count: 100,
  min: 4,
  max: 119,
  sum: 6058,
  ...
}
*/
```

## Frequency

Frequencies are metrics that help us count the occurrences of specific values. Think of them as a set of counters, each associated with a unique value. When new values are observed, frequencies automatically create new counters for them.

### When to Use Frequencies

Frequencies are invaluable for counting the occurrences of distinct string values. Consider using frequencies in scenarios like:

- Tracking the number of invocations for each service in an application that uses logical names for its services.

- Monitoring the frequency of different types of failures.

### Example

Let's create a Frequency to observe the occurrences of unique strings. This example can be applied to effects that yield a `string`:

```ts twoslash
import { Effect, Metric, Random } from 'effect';

const errorFrequency = Metric.frequency('error_frequency');

const program = errorFrequency(
  Random.nextIntBetween(1, 10).pipe(Effect.andThen((n) => `Error-${n}`)),
).pipe(Effect.repeatN(99));

Effect.runPromise(
  program.pipe(Effect.andThen(Metric.value(errorFrequency))),
).then((frequencyState) => console.log('%o', frequencyState));
/*
Output:
FrequencyState {
  occurrences: Map(9) {
    'Error-7' => 12,
    'Error-2' => 12,
    'Error-4' => 14,
    'Error-1' => 14,
    'Error-9' => 8,
    'Error-6' => 11,
    'Error-5' => 9,
    'Error-3' => 14,
    'Error-8' => 6
  },
  ...
}
*/
```

## Tagging Metrics

When creating metrics, you can add tags to them. Tags are key-value pairs that provide additional context, helping in categorizing and filtering metrics. This makes it easier to analyze and monitor specific aspects of your application.

### Tagging multiple Metrics

Use `Effect.tagMetrics` to apply tags to all metrics created in the same context. This is useful for adding common tags that apply to multiple metrics.

```ts twoslash
import { Effect, Metric } from 'effect';

const taskCount = Metric.counter('task_count');
const task1 = Effect.succeed(1).pipe(Effect.delay('100 millis'));

Effect.gen(function* () {
  yield* taskCount(task1);
}).pipe(
  Effect.tagMetrics('environment', 'production'),
);
```

Alternatively, use `Effect.tagMetricsScoped` to apply tags within a specific scope.

### Tagging a specific Metric

For individual metrics, use `Metric.tagged`. This method allows you to apply tags to a specific metric.

```ts twoslash
import { Metric } from 'effect';

const counter = Metric.counter('request_count').pipe(
  Metric.tagged('environment', 'production'),
);
```

# Telemetry

---

## title: Telemetryexcerpt: Telemetrycollapsible: truebottomNavigation: childCards

# Introduction to Tracing in Effect

---

## title: Introduction to Tracing in EffectnavTitle: Tracingexcerpt: Explore the necessity of tracing in distributed systems beyond logs and metrics. Discover spans and traces, crucial for understanding request lifecycles. Learn to create, print, and annotate spans, and visualize traces for effective debugging and optimization.bottomNavigation: pagination

Although logs and metrics are useful to understand the behavior of individual services, they are not enough to provide a complete overview of the lifetime of a request in a distributed system.

In a distributed system, a request can span multiple services and each service can make multiple requests to other services to fulfill the request. In such a scenario, we need to have a way to track the lifetime of a request across multiple services to diagnose what services are the bottlenecks and where the request is spending most of its time.

## Spans

A span represents a unit of work or operation. It tracks specific operations that a request makes, painting a picture of what happened during the time in which that operation was executed.

A typical Span contains the following information:

- **Name:** Describes the operation being tracked.

- **Time-Related Data:** Timestamps to measure when the operation started and how long it took.

- **Structured Log Messages:** Records essential information during the operation.

- **Metadata (Attributes):** Additional data that provides context about the operation.

## Traces

A trace records the paths taken by requests (made by an application or end-user) as they propagate through multi-service architectures, like microservice and serverless applications.

Without tracing, it is challenging to pinpoint the cause of performance problems in a distributed system.

A trace is made of one or more spans. The first span represents the root span. Each root span represents a request from start to finish. The spans underneath the parent provide a more in-depth context of what occurs during a request (or what steps make up a request).

Many Observability back-ends visualize traces as waterfall diagrams that may look something like this:

<img
  src="/pages/tracing/waterfall-trace.svg"
  alt="Sample Trace"
  title="Trace waterfall diagram"
/>

Waterfall diagrams show the parent-child relationship between a root span and its child spans. When a span encapsulates another span, this also represents a nested relationship.

## Creating Spans

You can instrument an effect with a Span using the `Effect.withSpan` API. Here's how you can do it:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.void.pipe(Effect.delay('100 millis'));

const instrumented = program.pipe(Effect.withSpan('myspan'));
```

It's important to note that instrumenting an effect doesn't change its type. You start with an `Effect<void>`, and you still get an `Effect<void>`.

## Printing Spans

Now, let's print our Span to the console. To achieve this, we need specific tools, including

- `@effect/opentelemetry`
- `@opentelemetry/sdk-metrics`
- `@opentelemetry/sdk-trace-base`
- `@opentelemetry/sdk-trace-node`
- `@opentelemetry/sdk-trace-web`

With these in place, we can visualize and understand the Spans in our application.

Here's a code snippet demonstrating how to set up the necessary environment and print the Span to the console:

```ts twoslash
import { Effect } from 'effect';
import { NodeSdk } from '@effect/opentelemetry';
import {
  BatchSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base';

const program = Effect.void.pipe(Effect.delay('100 millis'));

const instrumented = program.pipe(Effect.withSpan('myspan'));

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: { serviceName: 'example' },
  spanProcessor: new BatchSpanProcessor(new ConsoleSpanExporter()),
}));

Effect.runPromise(instrumented.pipe(Effect.provide(NodeSdkLive)));
/*
Example Output:
{
  traceId: 'd0f730abfc366205806469596092b239',
  parentId: undefined,
  traceState: undefined,
  name: 'myspan',
  id: 'ab4e42592e7f1f7c',
  kind: 0,
  timestamp: 1697040012664380.5,
  duration: 2895.769,
  attributes: {},
  status: { code: 1 },
  events: [],
  links: []
}
*/
```

Here's a breakdown of the output:

| Field        | Description                                                                                                                                                                                                    |
| ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `traceId`    | A unique identifier for the entire trace, helping trace requests or operations as they move through an application.                                                                                            |
| `parentId`   | Identifies the parent span of the current span, marked as `undefined` in the output when there is no parent span, making it a root span.                                                                       |
| `name`       | Describes the name of the span, indicating the operation being tracked (e.g., "myspan").                                                                                                                       |
| `id`         | A unique identifier for the current span, distinguishing it from other spans within a trace.                                                                                                                   |
| `timestamp`  | A timestamp representing when the span started, measured in microseconds since the Unix epoch.                                                                                                                 |
| `duration`   | Specifies the duration of the span, representing the time taken to complete the operation (e.g., `2895.769` microseconds).                                                                                     |
| `attributes` | Spans may contain attributes, which are key-value pairs providing additional context or information about the operation. In this output, it's an empty object, indicating no specific attributes in this span. |
| `status`     | The status field provides information about the span's status. In this case, it has a code of 1, which typically indicates an OK status (whereas a code of 2 signifies an ERROR status)                        |
| `events`     | Spans can include events, which are records of specific moments during the span's lifecycle. In this output, it's an empty array, suggesting no specific events recorded.                                      |
| `links`      | Links can be used to associate this span with other spans in different traces. In the output, it's an empty array, indicating no specific links for this span.                                                 |

Let's examine the output of an effect that encountered an error:

```ts twoslash
import { Effect } from 'effect';
import { NodeSdk } from '@effect/opentelemetry';
import {
  BatchSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base';

const program = Effect.fail('Oh no!').pipe(
  Effect.delay('100 millis'),
  Effect.withSpan('myspan'),
);

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: { serviceName: 'example' },
  spanProcessor: new BatchSpanProcessor(new ConsoleSpanExporter()),
}));

Effect.runPromiseExit(program.pipe(Effect.provide(NodeSdkLive))).then(
  console.log,
);
/*
Example Output:
{
  traceId: '760510a3f9a0881a09de990c87ec1cef',
  parentId: undefined,
  traceState: undefined,
  name: 'myspan',
  id: 'a528e38e82e848a5',
  kind: 0,
  timestamp: 1697091363002970.5,
  duration: 110371.664,
  attributes: {},
  status: { code: 2, message: 'Error: Oh no!' },
  events: [],
  links: []
}
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: { _id: 'Cause', _tag: 'Fail', failure: 'Oh no!' }
}
*/
```

## Adding Annotations

You can provide extra information to a span by utilizing the `Effect.annotateCurrentSpan` function.
This tool allows you to associate key-value pairs, offering more context about the execution of the span.

```ts twoslash
import { Effect } from 'effect';
import { NodeSdk } from '@effect/opentelemetry';
import {
  BatchSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base';

const program = Effect.void.pipe(
  Effect.delay('100 millis'),
  Effect.tap(() => Effect.annotateCurrentSpan('key', 'value')),
  Effect.withSpan('myspan'),
);

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: { serviceName: 'example' },
  spanProcessor: new BatchSpanProcessor(new ConsoleSpanExporter()),
}));

Effect.runPromise(program.pipe(Effect.provide(NodeSdkLive)));
/*
Example Output:
{
  traceId: '869c9d74d9db14a4ba4393ca8e0f61db',
  parentId: undefined,
  traceState: undefined,
  name: 'myspan',
  id: '31eb49570d197f8d',
  kind: 0,
  timestamp: 1697045981663321.5,
  duration: 109563.353,
  attributes: { key: 'value' },
  status: { code: 1 },
  events: [],
  links: []
}
*/
```

## Logs as events

Logs are transformed into what are known as "Span Events." These events provide structured information and a timeline of occurrences within your application.

```ts twoslash
import { Effect } from 'effect';
import { NodeSdk } from '@effect/opentelemetry';
import {
  BatchSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base';

const program = Effect.log('Hello').pipe(
  Effect.delay('100 millis'),
  Effect.withSpan('myspan'),
);

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: { serviceName: 'example' },
  spanProcessor: new BatchSpanProcessor(new ConsoleSpanExporter()),
}));

Effect.runPromise(program.pipe(Effect.provide(NodeSdkLive)));
/*
Example Output:
{
  traceId: 'ad708d58c15f9e5c7b5cca2eeb6838a2',
  parentId: undefined,
  traceState: undefined,
  name: 'myspan',
  id: '4353fd47423e786a',
  kind: 0,
  timestamp: 1697043230170724.2,
  duration: 112052.514,
  attributes: {},
  status: { code: 1 },
  events: [
    {
      name: 'Hello',
      attributes: { 'effect.fiberId': '#0', 'effect.logLevel': 'INFO' },
      time: [ 1697043230, 280923805 ],
      droppedAttributesCount: 0
    }
  ],
  links: []
}
*/
```

Spans can contain events, which are records of specific moments during the span's lifecycle. In this output, there is one event named `'Hello'`. It includes associated attributes, such as `'effect.fiberId'` and `'effect.logLevel'`, providing information about the logged event. The `time` field represents the timestamp when the event occurred.

## Nesting Spans

Spans can be nested, creating a hierarchy of operations. This concept is illustrated in the following code:

```ts twoslash
import { Effect } from 'effect';
import { NodeSdk } from '@effect/opentelemetry';
import {
  BatchSpanProcessor,
  ConsoleSpanExporter,
} from '@opentelemetry/sdk-trace-base';

const child = Effect.void.pipe(
  Effect.delay('100 millis'),
  Effect.withSpan('child'),
);

const parent = Effect.gen(function* () {
  yield* Effect.sleep('20 millis');
  yield* child;
  yield* Effect.sleep('10 millis');
}).pipe(Effect.withSpan('parent'));

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: { serviceName: 'example' },
  spanProcessor: new BatchSpanProcessor(new ConsoleSpanExporter()),
}));

Effect.runPromise(parent.pipe(Effect.provide(NodeSdkLive)));
/*
Example Output:
{
  traceId: '92fe81f1454d9c099198568cf867dc59',
  parentId: 'b953d6c7d37ad93d',
  traceState: undefined,
  name: 'child',
  id: '2fd19c8c23ebc7e8',
  kind: 0,
  timestamp: 1697043815321888.2,
  duration: 106536.264,
  attributes: {},
  status: { code: 1 },
  events: [],
  links: []
}
{
  traceId: '92fe81f1454d9c099198568cf867dc59',
  parentId: undefined,
  traceState: undefined,
  name: 'parent',
  id: 'b953d6c7d37ad93d',
  kind: 0,
  timestamp: 1697043815292133.2,
  duration: 149724.295,
  attributes: {},
  status: { code: 1 },
  events: [],
  links: []
}
*/
```

As you can observe, the `b953d6c7d37ad93d` value plays a crucial role in maintaining the parent-child relationship between these spans. It provides a clear indication of how spans can be nested, creating a trace that helps developers understand the flow and hierarchy of operations in their applications.

## Tutorial: Visualizing Traces with Docker, Prometheus, Grafana, and Tempo

In this tutorial, we'll guide you through simulating and visualizing traces using a sample instrumented Node.js application. We will use Docker, Prometheus, Grafana, and Tempo to create, collect, and visualize traces.

### Tools Explained

Let's understand the tools we'll be using in simple terms:

- **Docker**: Docker allows us to run applications in containers. Think of a container as a lightweight and isolated environment where your application can run consistently, regardless of the host system. It's a bit like a virtual machine but more efficient.

- **Prometheus**: Prometheus is a monitoring and alerting toolkit. It collects metrics and data about your applications and stores them for further analysis. This helps in identifying performance issues and understanding the behavior of your applications.

- **Grafana**: Grafana is a visualization and analytics platform. It helps in creating beautiful and interactive dashboards to visualize your application's data. You can use it to graphically represent metrics collected by Prometheus.

- **Tempo**: Tempo is a distributed tracing system that allows you to trace the journey of a request as it flows through your application. It provides insights into how requests are processed and helps in debugging and optimizing your applications.

### Getting Docker

To get Docker, follow these steps:

1. Visit the Docker website at [https://www.docker.com/](https://www.docker.com/).

2. Download Docker Desktop for your operating system (Windows or macOS) and install it.

3. After installation, open Docker Desktop, and it will run in the background.

### Simulating Traces

Now, let's simulate traces using a sample Node.js application. We'll provide you with the code and guide you on setting up the necessary components.

1. **Download Docker Files**. Download the required Docker files: [docker.zip](/pages/tracing/docker.zip).

2. **Set Up docker**. Unzip the downloaded file, navigate to the `/docker/local` directory in your terminal or command prompt and run the following command to start the necessary services:

   ```bash filename="Terminal"
   docker-compose up
   ```

3. **Simulate Traces**. Run the following example code in your Node.js environment.
   This code simulates a set of tasks and generates traces.

   Before proceeding, you'll need to install additional libraries in addition to the latest version of `effect`. Here are the required libraries:

   - `@effect/opentelemetry`
   - `@opentelemetry/exporter-trace-otlp-http`
   - `@opentelemetry/sdk-trace-node`
   - `@opentelemetry/sdk-trace-web`

   ```ts twoslash
   import { Effect } from 'effect';
   import { NodeSdk } from '@effect/opentelemetry';
   import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';
   import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';

   // Function to simulate a task with possible subtasks
   const task = (
     name: string,
     delay: number,
     children: ReadonlyArray<Effect.Effect<void>> = [],
   ) =>
     Effect.gen(function* () {
       yield* Effect.log(name);
       yield* Effect.sleep(`${delay} millis`);
       for (const child of children) {
         yield* child;
       }
       yield* Effect.sleep(`${delay} millis`);
     }).pipe(Effect.withSpan(name));

   const poll = task('/poll', 1);

   // Create a program with tasks and subtasks
   const program = task('client', 2, [
     task('/api', 3, [
       task('/authN', 4, [task('/authZ', 5)]),
       task('/payment Gateway', 6, [task('DB', 7), task('Ext. Merchant', 8)]),
       task('/dispatch', 9, [
         task('/dispatch/search', 10),
         Effect.all([poll, poll, poll], { concurrency: 'inherit' }),
         task('/pollDriver/{id}', 11),
       ]),
     ]),
   ]);

   const NodeSdkLive = NodeSdk.layer(() => ({
     resource: { serviceName: 'example' },
     spanProcessor: new BatchSpanProcessor(new OTLPTraceExporter()),
   }));

   Effect.runPromise(
     program.pipe(
       Effect.provide(NodeSdkLive),
       Effect.catchAllCause(Effect.logError),
     ),
   );
   /*
   Output:
   timestamp=... level=INFO fiber=#0 message=client
   timestamp=... level=INFO fiber=#0 message=/api
   timestamp=... level=INFO fiber=#0 message=/authN
   timestamp=... level=INFO fiber=#0 message=/authZ
   timestamp=... level=INFO fiber=#0 message="/payment Gateway"
   timestamp=... level=INFO fiber=#0 message=DB
   timestamp=... level=INFO fiber=#0 message="Ext. Merchant"
   timestamp=... level=INFO fiber=#0 message=/dispatch
   timestamp=... level=INFO fiber=#0 message=/dispatch/search
   timestamp=... level=INFO fiber=#3 message=/poll
   timestamp=... level=INFO fiber=#4 message=/poll
   timestamp=... level=INFO fiber=#5 message=/poll
   timestamp=... level=INFO fiber=#0 message=/pollDriver/{id}
   */
   ```

4. **Visualize Traces**. Now, open your web browser and go to [http://localhost:3000/explore](http://localhost:3000/explore). You will see a generated `Trace ID` on the web page. Click on it to see the details of the trace.

   ![Traces in Grafana Tempo](/pages/tracing/trace.png)

That's it! You've simulated and visualized traces using Docker, Prometheus, Grafana, and Tempo. You can use these tools to monitor, analyze, and gain insights into your applications' performance and behavior.

# Introduction to Telemetry in Effect

---

## title: Introduction to Telemetry in EffectnavTitle: Introduction to Telemetryexcerpt: Explore the seamless integration of Telemetry in Effect, providing insights into metrics and traces. Learn how Telemetry empowers developers to monitor, analyze, and optimize the performance and behavior of TypeScript applications, enhancing observability and debugging capabilities.bottomNavigation: pagination

Telemetry enables developers to collect, process, and export telemetry data such as [metrics](metrics) and [traces](tracing), providing valuable insights into the performance and behavior of their applications. In this guide, we will explore how Telemetry can be seamlessly integrated into Effect.

By incorporating Telemetry, you can gain deep visibility into the inner workings of your TypeScript applications, effortlessly tracing the flow of requests, pinpointing bottlenecks, and identifying performance optimizations. This integration empowers you to monitor, analyze, and improve your application's reliability and efficiency, ensuring a better user experience.

In the following sections, we will delve into the fundamentals of Telemetry, how it works within the Effect framework, and the benefits it brings to your TypeScript projects. Whether you are building a small-scale application or a complex distributed system, this guide will help you harness the power of Telemetry to enhance your observability and debugging capabilities in Effect.

# Supervisor

---

## title: Supervisorexcerpt: Learn about Effect's `Supervisor` for managing fibers, creating supervisors with `Supervisor.track`, and supervising effects with `Effect.supervised`. Explore an example that demonstrates periodic monitoring of fibers throughout an application's lifecycle using supervisors.bottomNavigation: pagination

A `Supervisor<A>` is a tool that manages the creation and termination of fibers, producing some visible value of type `A` based on its supervision.

## Creating

### track

To create a supervisor, you can use the `Supervisor.track` function. It generates a new supervisor that keeps track of its child fibers in a set.

## Supervising

### supervised

Whenever you need to supervise an effect, you can employ the `Effect.supervised` function. This function takes a supervisor and returns an effect that behaves the same as the original effect. However, all child fibers forked within this effect are reported to the specified supervisor.

By doing this, you associate the behavior of child fibers with the provided supervisor, giving you access to all the information about these child fibers through the supervisor.

## Example

In the following example, we will periodically monitor the number of fibers throughout our application's lifecycle:

```ts twoslash
import { Effect, Fiber, FiberStatus, Schedule, Supervisor } from 'effect';

const program = Effect.gen(function* () {
  const supervisor = yield* Supervisor.track;
  const fibFiber = yield* fib(20).pipe(
    Effect.supervised(supervisor),
    Effect.fork,
  );
  const policy = Schedule.spaced('500 millis').pipe(
    Schedule.whileInputEffect((_) =>
      Fiber.status(fibFiber).pipe(
        Effect.andThen((status) => status !== FiberStatus.done),
      )
    ),
  );
  const monitorFiber = yield* monitorFibers(supervisor).pipe(
    Effect.repeat(policy),
    Effect.fork,
  );
  yield* Fiber.join(monitorFiber);
  const result = yield* Fiber.join(fibFiber);
  console.log(`fibonacci result: ${result}`);
});

const monitorFibers = (
  supervisor: Supervisor.Supervisor<Array<Fiber.RuntimeFiber<any, any>>>,
): Effect.Effect<void> =>
  Effect.gen(function* () {
    const fibers = yield* supervisor.value;
    console.log(`number of fibers: ${fibers.length}`);
  });

const fib = (n: number): Effect.Effect<number> =>
  Effect.gen(function* () {
    if (n <= 1) {
      return 1;
    }
    yield* Effect.sleep('500 millis');
    const fiber1 = yield* Effect.fork(fib(n - 2));
    const fiber2 = yield* Effect.fork(fib(n - 1));
    const v1 = yield* Fiber.join(fiber1);
    const v2 = yield* Fiber.join(fiber2);
    return v1 + v2;
  });

Effect.runPromise(program);
/*
Output:
number of fibers: 0
number of fibers: 2
number of fibers: 6
number of fibers: 14
number of fibers: 30
number of fibers: 62
number of fibers: 126
number of fibers: 254
number of fibers: 510
number of fibers: 1022
number of fibers: 2034
number of fibers: 3795
number of fibers: 5810
number of fibers: 6474
number of fibers: 4942
number of fibers: 2515
number of fibers: 832
number of fibers: 170
number of fibers: 18
number of fibers: 0
fibonacci result: 10946
*/
```

# Observability

---

## title: Observabilityexcerpt: Observabilitycollapsible: truebottomNavigation: childCards

# Logging

---

## title: Loggingexcerpt: Explore the power of logging in Effect for enhanced debugging and monitoring. Learn about dynamic log level control, custom logging output, fine-grained logging, environment-based logging, and additional features. Dive into specific logging utilities such as log, logDebug, logInfo, logWarning, logError, logFatal, and spans. Discover how to disable default logging and load log levels from configuration. Finally, explore the creation of custom loggers to tailor logging to your needs.bottomNavigation: pagination

Logging is a crucial aspect of software development, especially when it comes to debugging and monitoring the behavior of your applications. In this section, we'll delve into Effect's logging utilities and explore their advantages over traditional methods like `console.log`.

## Advantages Over Traditional Logging

Effect's logging utilities offer several advantages over traditional logging methods like `console.log`:

1. **Dynamic Log Level Control**: With Effect's logging, you have the ability to change the log level dynamically. This means you can control which log messages get displayed based on their severity. For example, you can configure your application to log only warnings or errors, which can be extremely helpful in production environments to reduce noise.

2. **Custom Logging Output**: Effect's logging utilities allow you to change how logs are handled. You can direct log messages to various destinations, such as a service or a file, using a [custom logger](#custom-loggers). This flexibility ensures that logs are stored and processed in a way that best suits your application's requirements.

3. **Fine-Grained Logging**: Effect enables fine-grained control over logging on a per-part basis of your program. You can set different log levels for different parts of your application, tailoring the level of detail to each specific component. This can be invaluable for debugging and troubleshooting, as you can focus on the information that matters most.

4. **Environment-Based Logging**: Effect's logging utilities can be combined with deployment environments to achieve granular logging strategies. For instance, during development, you might choose to log everything at a trace level and above for detailed debugging. In contrast, your production version could be configured to log only errors or critical issues, minimizing the impact on performance and noise in production logs.

5. **Additional Features**: Effect's logging utilities come with additional features such as the ability to measure time spans, alter log levels on a per-effect basis, and integrate spans for performance monitoring.

Now, let's dive into the specific logging utilities provided by Effect.

## log

The `Effect.log` function outputs a log message at the default `INFO` level.

```ts twoslash
import { Effect } from 'effect';

const program = Effect.log('Application started');

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="Application started"
*/
```

Details included in a log message:

- `timestamp`: The timestamp when the log message was generated.
- `level`: The log level at which the message is logged.
- `fiber`: The identifier of the [fiber](../concurrency/fibers) executing the program.
- `message`: The log content, which can include multiple items.
- `span`: (Optional) The duration of the [span](#spans) in milliseconds.

You can log multiple messages simultaneously:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.log('message1', 'message2', 'message3');

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=message1 message=message2 message=message3
*/
```

For added context, you can also include one or more [Cause](../../other/data-types/cause) instances in your logs,
which provide detailed error information under an additional `cause` annotation:

```ts twoslash
import { Cause, Effect } from 'effect';

const program = Effect.log(
  'message1',
  'message2',
  Cause.die('Oh no!'),
  Cause.die('Oh uh!'),
);

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=message1 message=message2 cause="Error: Oh no!
Error: Oh uh!"
*/
```

## Log Levels

### logDebug

By default, `DEBUG` messages are **not** printed.

However, you can configure the default logger to enable them using `Logger.withMinimumLogLevel` and setting the minimum log level to `LogLevel.Debug`.

Here's an example that demonstrates how to enable `DEBUG` messages for a specific task (`task1`):

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect, Logger, LogLevel } from 'effect';

const task1 = Effect.gen(function* () {
  yield* Effect.sleep('2 seconds');
  yield* Effect.logDebug('task1 done');
}).pipe(Logger.withMinimumLogLevel(LogLevel.Debug));

const task2 = Effect.gen(function* () {
  yield* Effect.sleep('1 second');
  yield* Effect.logDebug('task2 done');
});

const program = Effect.gen(function* () {
  yield* Effect.log('start');
  yield* task1;
  yield* task2;
  yield* Effect.log('done');
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO message=start
timestamp=... level=DEBUG message="task1 done" <-- 2 seconds later
timestamp=... level=INFO message=done <-- 1 second later
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect, Logger, LogLevel } from 'effect';

const task1 = Effect.sleep('2 seconds').pipe(
  Effect.andThen(Effect.logDebug('task1 done')),
  Logger.withMinimumLogLevel(LogLevel.Debug),
);

const task2 = Effect.sleep('1 second').pipe(
  Effect.andThen(Effect.logDebug('task2 done')),
);

const program = Effect.log('start').pipe(
  Effect.andThen(task1),
  Effect.andThen(task2),
  Effect.andThen(Effect.log('done')),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO message=start
timestamp=... level=DEBUG message="task1 done" <-- 2 seconds later
timestamp=... level=INFO message=done <-- 1 second later
*/
```

</Tab>
</Tabs>

In the above example, we enable `DEBUG` messages specifically for `task1` by using the `Logger.withMinimumLogLevel` function.

By using `Logger.withMinimumLogLevel(effect, level)`, you have the flexibility to selectively enable different log levels for specific effects in your program. This allows you to control the level of detail in your logs and focus on the information that is most relevant to your debugging and troubleshooting needs.

### logInfo

By default, `INFO` messages are printed.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.logInfo('start');
  yield* Effect.sleep('2 seconds');
  yield* Effect.sleep('1 second');
  yield* Effect.logInfo('done');
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO message=start
timestamp=... level=INFO message=done <-- 3 seconds later
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.logInfo('start').pipe(
  Effect.andThen(Effect.sleep('2 seconds')),
  Effect.andThen(Effect.sleep('1 second')),
  Effect.andThen(Effect.logInfo('done')),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO message=start
timestamp=... level=INFO message=done <-- 3 seconds later
*/
```

</Tab>
</Tabs>

In the above example, the `Effect.log` function is used to log an `INFO` message with the content `"start"` and `"done"`. These messages will be printed during the execution of the program.

### logWarning

By default, `WARN` messages are printed.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect, Either } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(task);
  if (Either.isLeft(failureOrSuccess)) {
    yield* Effect.logWarning(failureOrSuccess.left);
    return 0;
  } else {
    return failureOrSuccess.right;
  }
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=WARN fiber=#0 message="Oh uh!"
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = task.pipe(
  Effect.catchAll((error) => Effect.logWarning(error).pipe(Effect.as(0))),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=WARN fiber=#0 message="Oh uh!"
*/
```

</Tab>
</Tabs>

### logError

By default, `ERROR` messages are printed.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect, Either } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(task);
  if (Either.isLeft(failureOrSuccess)) {
    yield* Effect.logError(failureOrSuccess.left);
    return 0;
  } else {
    return failureOrSuccess.right;
  }
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=ERROR fiber=#0 message="Oh uh!"
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = task.pipe(
  Effect.catchAll((error) => Effect.logError(error).pipe(Effect.as(0))),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=ERROR fiber=#0 message="Oh uh!"
*/
```

</Tab>
</Tabs>

### logFatal

By default, `FATAL` messages are printed.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect, Either } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = Effect.gen(function* () {
  const failureOrSuccess = yield* Effect.either(task);
  if (Either.isLeft(failureOrSuccess)) {
    yield* Effect.logFatal(failureOrSuccess.left);
    return 0;
  } else {
    return failureOrSuccess.right;
  }
});

Effect.runPromise(program);
/*
Output:
timestamp=... level=FATAL fiber=#0 message="Oh uh!"
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const task = Effect.fail('Oh uh!').pipe(Effect.as(2));

const program = task.pipe(
  Effect.catchAll((error) => Effect.logFatal(error).pipe(Effect.as(0))),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=FATAL fiber=#0 message="Oh uh!"
*/
```

</Tab>
</Tabs>

## Custom Annotations

Enhance your log outputs by incorporating custom annotations with the `Effect.annotateLogs` function.
This function allows you to append additional metadata to each log entry of an effect, enhancing traceability and context.

Here's how to apply a single annotation as a key/value pair:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('message1');
  yield* Effect.log('message2');
}).pipe(Effect.annotateLogs('key', 'value')); // Annotation as key/value pair

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=message1 key=value
timestamp=... level=INFO fiber=#0 message=message2 key=value
*/
```

To apply multiple annotations at once, you can pass an object containing several key/value pairs:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('message1');
  yield* Effect.log('message2');
}).pipe(Effect.annotateLogs({ key1: 'value1', key2: 'value2' }));

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message=message1 key2=value2 key1=value1
timestamp=... level=INFO fiber=#0 message=message2 key2=value2 key1=value1
*/
```

Annotations can also be applied with a scoped lifetime using `Effect.annotateLogsScoped`.
This method confines the application of annotations to logs within a specific [Scope](../resource-management/scope) of your effect computation:

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('no annotations');
  yield* Effect.annotateLogsScoped({ key: 'value' });
  yield* Effect.log('message1'); // Annotation is applied to this log
  yield* Effect.log('message2'); // Annotation is applied to this log
}).pipe(Effect.scoped, Effect.andThen(Effect.log('no annotations again')));

Effect.runSync(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="no annotations"
timestamp=... level=INFO fiber=#0 message=message1 key=value
timestamp=... level=INFO fiber=#0 message=message2 key=value
timestamp=... level=INFO fiber=#0 message="no annotations again"
*/
```

## Log Spans

Effect also provides support for log spans, allowing you to measure the duration of specific operations or tasks within your program.

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.sleep('1 second');
  yield* Effect.log('The job is finished!');
}).pipe(Effect.withLogSpan('myspan'));

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="The job is finished!" myspan=1011ms
*/
```

</Tab>
<Tab>

```ts twoslash
import { Effect } from 'effect';

const program = Effect.sleep('1 second').pipe(
  Effect.andThen(Effect.log('The job is finished!')),
  Effect.withLogSpan('myspan'),
);

Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="The job is finished!" myspan=1011ms
*/
```

</Tab>
</Tabs>

In the above example, a log span is created using the `Effect.withLogSpan(label)` function.
It measures the duration of the code block within the span.
The resulting duration is then automatically recorded as an annotation within the log message.

## Disabling Default Logging

If you ever find yourself needing to turn off default logging, perhaps during test execution, there are various ways to achieve this within the Effect framework. In this section, we'll explore different methods to disable default logging.

**Using withMinimumLogLevel**

Effect provides a convenient function called `withMinimumLogLevel` that allows you to set the minimum log level, effectively disabling logging:

```ts twoslash
import { Effect, Logger, LogLevel } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('Executing task...');
  yield* Effect.sleep('100 millis');
  console.log('task done');
});

// Logging enabled (default)
Effect.runPromise(program);
/*
Output:
timestamp=... level=INFO fiber=#0 message="Executing task..."
task done
*/

// Logging disabled using withMinimumLogLevel
Effect.runPromise(program.pipe(Logger.withMinimumLogLevel(LogLevel.None)));
/*
Output:
task done
*/
```

By setting the log level to `LogLevel.None`, you effectively disable logging, and only the final result will be displayed.

**Using a Layer**

Another approach to disable logging is by creating a layer that sets the minimum log level to `LogLevel.None`, effectively turning off all logging:

```ts twoslash
import { Effect, Logger, LogLevel } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('Executing task...');
  yield* Effect.sleep('100 millis');
  console.log('task done');
});

const layer = Logger.minimumLogLevel(LogLevel.None);

// Logging disabled using a layer
Effect.runPromise(program.pipe(Effect.provide(layer)));
/*
Output:
task done
*/
```

**Using a Custom Runtime**

You can also disable logging by creating a custom runtime that includes the configuration to turn off logging:

```ts twoslash
import { Effect, Layer, Logger, LogLevel, Runtime } from 'effect';

const program = Effect.gen(function* () {
  yield* Effect.log('Executing task...');
  yield* Effect.sleep('100 millis');
  console.log('task done');
});

const customRuntime = Effect.runSync(
  Effect.scoped(Layer.toRuntime(Logger.minimumLogLevel(LogLevel.None))),
);

// Logging disabled using a custom runtime
const customRunPromise = Runtime.runPromise(customRuntime);

customRunPromise(program);
/*
Output:
task done
*/
```

In this approach, you create a custom runtime that incorporates the configuration to disable logging, and then you execute your program using this custom runtime.

## Loading the Log Level from Configuration

To retrieve the log level from a [configuration](../configuration) and incorporate it into your program, utilize the layer produced by `Logger.minimumLogLevel`:

```ts twoslash
import {
  Config,
  ConfigProvider,
  Effect,
  Layer,
  Logger,
  LogLevel,
} from 'effect';

// Simulate a program with logs
const program = Effect.gen(function* () {
  yield* Effect.logError('ERROR!');
  yield* Effect.logWarning('WARNING!');
  yield* Effect.logInfo('INFO!');
  yield* Effect.logDebug('DEBUG!');
});

// Load the log level from the configuration as a layer
const LogLevelLive = Config.logLevel('LOG_LEVEL').pipe(
  Effect.andThen((level) => Logger.minimumLogLevel(level)),
  Layer.unwrapEffect,
);

// Configure the program with the loaded log level
const configured = Effect.provide(program, LogLevelLive);

// Test the configured program using ConfigProvider.fromMap
const test = Effect.provide(
  configured,
  Layer.setConfigProvider(
    ConfigProvider.fromMap(new Map([['LOG_LEVEL', LogLevel.Warning.label]])),
  ),
);

Effect.runPromise(test);
/*
Output:
... level=ERROR fiber=#0 message=ERROR!
... level=WARN fiber=#0 message=WARNING!
*/
```

To evaluate the configured program, you can utilize `ConfigProvider.fromMap` for testing (refer to [Testing Services](../configuration.mdx#testing-services) for more details).

## Custom loggers

In this section, we will learn how to define a custom logger and set it as the default logger in our program.

First, let's define our custom logger:

```twoslash include CustomLogger
import { Logger } from "effect"

export const logger = Logger.make(({ logLevel, message }) => {
  globalThis.console.log(`[${logLevel.label}] ${message}`)
})
```

```ts filename="CustomLogger.ts" twoslash
// @include: CustomLogger
```

Assuming we have defined the following program:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```twoslash include program
import { Effect } from "effect"

const task1 = Effect.gen(function* () {
  yield* Effect.sleep("2 seconds")
  yield* Effect.logDebug("task1 done")
})

const task2 = Effect.gen(function* () {
  yield* Effect.sleep("1 second")
  yield* Effect.logDebug("task2 done")
})

export const program = Effect.gen(function* () {
  yield* Effect.log("start")
  yield* task1
  yield* task2
  yield* Effect.log("done")
})
```

```ts filename="program.ts" twoslash
// @include: program
```

</Tab>
<Tab>

```ts filename="program.ts" twoslash
import { Effect } from 'effect';

const task1 = Effect.sleep('2 seconds').pipe(
  Effect.andThen(Effect.logDebug('task1 done')),
);

const task2 = Effect.sleep('1 second').pipe(
  Effect.andThen(Effect.logDebug('task2 done')),
);

export const program = Effect.log('start').pipe(
  Effect.andThen(task1),
  Effect.andThen(task2),
  Effect.andThen(Effect.log('done')),
);
```

</Tab>
</Tabs>

To replace the default logger, we simply need to create a specific layer using `Logger.replace` and provide it to our program using `Effect.provide` before executing it:

```ts filename="index.ts" twoslash
// @filename: CustomLogger.ts
// @include: CustomLogger

// @filename: program.ts
// @include: program

// @filename: index.ts
// ---cut---
import { Effect, Logger, LogLevel } from 'effect';
import * as CustomLogger from './CustomLogger';
import { program } from './program';

const layer = Logger.replace(Logger.defaultLogger, CustomLogger.logger);

Effect.runPromise(
  Effect.provide(Logger.withMinimumLogLevel(program, LogLevel.Debug), layer),
);
```

This is what we see printed on the console after executing the program:

```bash filename="Terminal"
[INFO] start
[DEBUG] task1 done
[DEBUG] task2 done
[INFO] done
```

# Testing

---

## title: Testingexcerpt: Testingcollapsible: truebottomNavigation: childCards

# TestClock

---

## title: TestClockexcerpt: Utilize Effect's `TestClock` to control time during testing. Learn how to simulate the passage of time and efficiently test time-related functionality. Examples include testing `Effect.timeout`, recurring effects, `Clock`, and `Deferred`.bottomNavigation: pagination

In most cases, we want our unit tests to run as quickly as possible. Waiting for real time to pass can slow down our tests significantly. Effect provides a handy tool called `TestClock` that allows us to **control time during testing**. This means we can efficiently and predictably test code that involves time without having to wait for the actual time to pass.

The `TestClock` in Effect allows us to control time for testing purposes. It lets us schedule effects to run at specific times, making it ideal for testing time-related functionality.

Instead of waiting for real time to pass, we use the `TestClock` to set the clock time to a specific point. Any effects scheduled to run at or before that time will be executed in order.

## How TestClock Works

Imagine `TestClock` as a wall clock, but with a twistâ€”it doesn't tick on its own. Instead, it only changes when we manually adjust it using the `TestClock.adjust` and `TestClock.setTime` functions. The clock time never progresses on its own.

When we adjust the clock time, any effects scheduled to run at or before the new time will be executed. This allows us to simulate the passage of time in our tests without waiting for real time.

Let's look at an example of how to test `Effect.timeout` using the `TestClock`:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @types: node
import { Effect, Fiber, Option, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = Effect.gen(function* () {
  // Create a fiber that sleeps for 5 minutes and then times out after 1 minute
  const fiber = yield* Effect.sleep('5 minutes').pipe(
    Effect.timeoutTo({
      duration: '1 minute',
      onSuccess: Option.some,
      onTimeout: () => Option.none<void>(),
    }),
    Effect.fork,
  );

  // Adjust the TestClock by 1 minute to simulate the passage of time
  yield* TestClock.adjust('1 minute');

  // Get the result of the fiber
  const result = yield* Fiber.join(fiber);

  // Check if the result is None, indicating a timeout
  assert.ok(Option.isNone(result));
}).pipe(Effect.provide(TestContext.TestContext));

Effect.runPromise(test);
```

</Tab>
<Tab>

```ts twoslash
// @types: node
import { Effect, Fiber, Option, pipe, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = pipe(
  Effect.sleep('5 minutes'),
  Effect.timeoutTo({
    duration: '1 minute',
    onSuccess: Option.some,
    onTimeout: () => Option.none<void>(),
  }),
  Effect.fork,
  Effect.tap(() =>
    // Adjust the TestClock by 1 minute to simulate the passage of time
    TestClock.adjust('1 minute')
  ),
  Effect.andThen((fiber) =>
    // Get the result of the fiber
    Fiber.join(fiber)
  ),
  Effect.andThen((result) => {
    // Check if the result is None, indicating a timeout
    assert.ok(Option.isNone(result));
  }),
  Effect.provide(TestContext.TestContext),
);

Effect.runPromise(test);
```

</Tab>
</Tabs>

In this example, we create a test scenario involving a fiber that sleeps for 5 minutes and then times out after 1 minute. Instead of waiting for the full 5 minutes to elapse in real time, we utilize the `TestClock` to instantly advance time by 1 minute.

A critical point to note is the forking of the fiber where `Effect.sleep` is invoked. Calls to `Effect.sleep` and related methods wait until the clock time matches or surpasses the scheduled time for their execution. By forking the fiber, we ensure that we have control over the clock time adjustment.

<Idea>
  The recommended pattern when using the `TestClock` involves forking the
  effect being tested, adjusting the clock time as needed, and then verifying
  that the expected effects have occurred.
</Idea>

## More Examples

### Testing Recurring Effects

Let's explore an example demonstrating how to test an effect that runs at fixed intervals using the `TestClock`:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @types: node
import { Effect, Option, Queue, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = Effect.gen(function* () {
  const q = yield* Queue.unbounded();

  yield* Queue.offer(q, undefined).pipe(
    // Delay the effect for 60 minutes and repeat it forever
    Effect.delay('60 minutes'),
    Effect.forever,
    Effect.fork,
  );

  // Check if no effect is performed before the recurrence period
  const a = yield* Queue.poll(q).pipe(Effect.andThen(Option.isNone));

  // Adjust the TestClock by 60 minutes to simulate the passage of time
  yield* TestClock.adjust('60 minutes');

  // Check if an effect is performed after the recurrence period
  const b = yield* Queue.take(q).pipe(Effect.as(true));

  // Check if the effect is performed exactly once
  const c = yield* Queue.poll(q).pipe(Effect.andThen(Option.isNone));

  // Adjust the TestClock by another 60 minutes
  yield* TestClock.adjust('60 minutes');

  // Check if another effect is performed
  const d = yield* Queue.take(q).pipe(Effect.as(true));
  const e = yield* Queue.poll(q).pipe(Effect.andThen(Option.isNone));

  // Ensure that all conditions are met
  assert.ok(a && b && c && d && e);
}).pipe(Effect.provide(TestContext.TestContext));

Effect.runPromise(test);
```

</Tab>
<Tab>

```ts twoslash
// @types: node
import { Effect, Option, pipe, Queue, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = pipe(
  Queue.unbounded(),
  Effect.andThen((q) =>
    pipe(
      Queue.offer(q, undefined),
      // Delay the effect for 60 minutes and repeat it forever
      Effect.delay('60 minutes'),
      Effect.forever,
      Effect.fork,
      Effect.andThen(
        pipe(
          Effect.Do,
          // Check if no effect is performed before the recurrence period
          Effect.bind('a', () =>
            pipe(Queue.poll(q), Effect.andThen(Option.isNone))),
          // Adjust the TestClock by 60 minutes to simulate the passage of time
          Effect.tap(() =>
            TestClock.adjust('60 minutes')
          ),
          // Check if an effect is performed after the recurrence period
          Effect.bind('b', () => pipe(Queue.take(q), Effect.as(true))),
          // Check if the effect is performed exactly once
          Effect.bind('c', () =>
            pipe(Queue.poll(q), Effect.andThen(Option.isNone))),
          // Adjust the TestClock by another 60 minutes
          Effect.tap(() =>
            TestClock.adjust('60 minutes')
          ),
          // Check if another effect is performed
          Effect.bind('d', () => pipe(Queue.take(q), Effect.as(true))),
          Effect.bind('e', () =>
            pipe(Queue.poll(q), Effect.andThen(Option.isNone))),
        ),
      ),
      Effect.andThen(({ a, b, c, d, e }) => {
        // Ensure that all conditions are met
        assert.ok(a && b && c && d && e);
      }),
    )
  ),
  Effect.provide(TestContext.TestContext),
);

Effect.runPromise(test);
```

</Tab>
</Tabs>

In this example, we aim to test an effect that runs at regular intervals. We use an unbounded queue to manage the effects. We verify that:

1. No effect is performed before the specified recurrence period.
2. An effect is performed after the recurrence period.
3. The effect is executed exactly once.

It's crucial to note that after each recurrence, the next occurrence is scheduled to happen at the appropriate time in the future. When we adjust the clock by 60 minutes, precisely one value is placed in the queue, and when we adjust the clock by another 60 minutes, another value is added to the queue.

### Testing Clock

Let's explore an example that demonstrates how to test the behavior of the `Clock` using the `TestClock`:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @types: node
import { Clock, Effect, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = Effect.gen(function* () {
  // Get the current time using the Clock
  const startTime = yield* Clock.currentTimeMillis;

  // Adjust the TestClock by 1 minute to simulate the passage of time
  yield* TestClock.adjust('1 minute');

  // Get the current time again
  const endTime = yield* Clock.currentTimeMillis;

  // Check if the time difference is at least 60,000 milliseconds (1 minute)
  assert.ok(endTime - startTime >= 60_000);
}).pipe(Effect.provide(TestContext.TestContext));

Effect.runPromise(test);
```

</Tab>
<Tab>

```ts twoslash
// @types: node
import { Clock, Effect, pipe, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = pipe(
  // Get the current time using the Clock
  Clock.currentTimeMillis,
  Effect.andThen((startTime) =>
    // Adjust the TestClock by 1 minute to simulate the passage of time
    TestClock.adjust('1 minute').pipe(
      // Get the current time again
      Effect.andThen(Clock.currentTimeMillis),
      Effect.andThen((endTime) => {
        // Check if the time difference is at least 60,000 milliseconds (1 minute)
        assert.ok(endTime - startTime >= 60_000);
      }),
    )
  ),
  Effect.provide(TestContext.TestContext),
);

Effect.runPromise(test);
```

</Tab>
</Tabs>

### Testing Deferred

`TestClock` also affects asynchronous code scheduled to run after a certain time:

<Tabs items={["Using Effect.gen", "Using pipe"]}>
<Tab>

```ts twoslash
// @types: node
import { Deferred, Effect, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = Effect.gen(function* () {
  // Create a deferred value
  const deferred = yield* Deferred.make<number, void>();

  // Run two effects concurrently: sleep for 10 seconds and succeed the deferred with a value of 1
  yield* Effect.all(
    [Effect.sleep('10 seconds'), Deferred.succeed(deferred, 1)],
    { concurrency: 'unbounded' },
  ).pipe(Effect.fork);

  // Adjust the TestClock by 10 seconds
  yield* TestClock.adjust('10 seconds');

  // Await the value from the deferred
  const readRef = yield* Deferred.await(deferred);

  assert.ok(1 === readRef);
}).pipe(Effect.provide(TestContext.TestContext));

Effect.runPromise(test);
```

</Tab>
<Tab>

```ts twoslash
// @types: node
import { Deferred, Effect, pipe, TestClock, TestContext } from 'effect';
import * as assert from 'node:assert';

const test = pipe(
  // Create a deferred value
  Deferred.make<number, void>(),
  Effect.tap((deferred) =>
    // Run two effects concurrently: sleep for 10 seconds and succeed the deferred with a value of 1
    Effect.fork(
      Effect.all(
        [Effect.sleep('10 seconds'), Deferred.succeed(deferred, 1)],
        {
          concurrency: 'unbounded',
        },
      ),
    )
  ),
  // Adjust the TestClock by 10 seconds
  Effect.tap(() => TestClock.adjust('10 seconds')),
  // Await the value from the deferred
  Effect.andThen((deferred) => Deferred.await(deferred)),
  Effect.andThen((readRef) => {
    assert.ok(1 === readRef);
  }),
  Effect.provide(TestContext.TestContext),
);

Effect.runPromise(test);
```

</Tab>
</Tabs>

In this code, we create a scenario where a value is set in a `Deferred` after 10 seconds asynchronously. We use `Effect.fork` to run this asynchronously. By adjusting the `TestClock` by 10 seconds, we can simulate the passage of time and test the code without waiting for the actual 10 seconds to elapse.

# effect

# README.md

# Installation

Installing `@effect/cli` is straightforward and can be done using any of the popular package managers. Follow the steps below to get started with setting up `@effect/cli` on your system.

### Step 1: Install `@effect/cli`

Choose your preferred package manager and run one of the following commands in your terminal:

- **Using npm:**

  ```sh
  npm install @effect/cli
  ```

- **Using pnpm:**

  ```sh
  pnpm add @effect/cli
  ```

- **Using yarn:**
  ```sh
  yarn add @effect/cli
  ```

### Step 2: Install Platform-Specific Packages

`@effect/cli` interacts directly with various platform-specific services like the file system and the terminal. Depending on the environment where you'll run your command-line application, you need to install the appropriate `@effect/platform` package.

#### For Node.js Environments

If your application will run in a Node.js environment, you'll need to install `@effect/platform-node`. This package ensures that `@effect/cli` can effectively interact with Node.js-specific functionalities.

Run one of the following commands based on your package manager:

- **Using npm:**

  ```sh
  npm install @effect/platform-node
  ```

- **Using pnpm:**

  ```sh
  pnpm add @effect/platform-node
  ```

- **Using yarn:**
  ```sh
  yarn add @effect/platform-node
  ```

### Step 3: Configure Your Application

After installing the necessary packages, you must configure your application to use the `NodeContext.layer` from `@effect/platform-node`. This step is crucial as it grants `@effect/cli` access to all necessary Node.js services and APIs, ensuring your CLI tool functions correctly within the Node.js environment.

Here's how you can incorporate `NodeContext.layer` into your application:

```ts
import { NodeContext, NodeRuntime } from '@effect/platform-node';
// Your application's setup code here
```

This configuration will make sure that your CLI application is fully integrated with the Node.js runtime, allowing it to perform optimally with access to system resources and services.

For a more detailed walkthrough, take a read through the [Tutorial](#tutorial) below.

# Built-In Options

`@effect/cli` comes equipped with several powerful built-in options that enhance the functionality of your CLI applications without the need for additional coding. These options are ready to use immediately after installation and are designed to simplify common tasks and improve the user experience.

### Overview of Built-In Options

Here's a breakdown of the key built-in options available in `@effect/cli`:

- **Shell Completions (`[--completions]`)**:

  - **Description**: Automatically generates shell completion scripts to enhance user experience. Shell completions suggest possible command options when you type a command and hit the tab key.
  - **Usage**: `--completions (bash | sh | fish | zsh)`
  - **Functionality**: Depending on your shell environment (bash, sh, fish, or zsh), this option generates a script that, when sourced, provides tab completions for your CLI commands.

- **Help (`[-h | --help]`)**:

  - **Description**: Instantly generates and displays helpful documentation about your CLI application's commands and options.
  - **Usage**: `-h` or `--help`
  - **Functionality**: When this option is used, it displays all available commands and options along with descriptions, usage patterns, and examples if available. This is crucial for new users or when you need a quick reminder about the tool's capabilities.

- **Version (`[--version]`)**:

  - **Description**: Displays the current version number of your CLI application.
  - **Usage**: `--version`
  - **Functionality**: This is particularly useful for debugging and ensuring compatibility, as it lets you confirm the version of the CLI tool you are currently using.

- **Wizard Mode (`[--wizard]`)**:
  - **Description**: Activates a guided interface to help users construct commands.
  - **Usage**: `--wizard`
  - **Functionality**: This interactive mode takes users step-by-step through the process of building a command, making it ideal for newcomers or complex commands. It asks questions and uses the responses to form the correct command syntax, which can then be executed or edited further.

### Practical Applications

These built-in options are designed to make the CLI user-friendly and more accessible, especially for those who are new to command-line interfaces. They reduce the learning curve and provide immediate assistance, enhancing productivity and user engagement.

For instance, a new user can type the following to get a list of all commands and options:

```sh
your-cli-app --help
```

Or, to quickly add command completion to their shell, they might use:

```sh
source <(your-cli-app --completions bash)
```

# Overview

`@effect/cli` is a powerful framework designed to simplify the development of command-line applications in TypeScript. It employs a modular architecture that allows developers to create scalable and maintainable CLI tools. Below is a table highlighting its key features:

| Feature                       | Description                                                                                                                                        |
| ----------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| Command Structure             | Supports a hierarchical command structure with a top-level command and potentially multiple nested subcommands.                                    |
| Parsing Arguments             | Built-in support for parsing command-line arguments efficiently.                                                                                   |
| Generating Help Text          | Automatically generates and displays help documentation for each command.                                                                          |
| Handling Subcommands          | Facilitates the management and execution of nested subcommands.                                                                                    |
| Built-in Options              | Includes built-in options such as `--help`, `--version`, and shell completions for enhanced usability.                                             |
| Wizard Mode                   | Offers a Wizard Mode that guides users through constructing commands interactively.                                                                |
| Platform-Specific Integration | Integrates with platform-specific services via `@effect/platform` packages, ensuring compatibility with diverse environments like Node.js. and Bun |

## Command Structure

Every command-line application built with `@effect/cli` consists of one or more commands (`Command`). There is always a top-level command representing the application itself, and potentially multiple nested subcommands:

- **Top-Level Command**: This is the main command that represents your application. It's always of type `Command`.
- **Subcommands**: These are nested commands under the top-level command. Each subcommand is also of type `Command`, allowing you to organize functionality into distinct actions.
- **Options**: Commands can have zero or more options (such as `--help` or `--version`). These are specified using `Options` and can be either required or optional. Options can be boolean flags or can accept values from user input.
- **Arguments**: Commands can also have zero or more arguments (such as `<directory>`). These are specified using `Args` and represent the data that users need to provide to commands.
- **Command Handler**: Each command has a command handler, which is a function responsible for the actual execution of the command. This is where you define what the command does when it runs.

This structure allows you to build complex CLI tools that are easy to extend and maintain. Whether you are adding new options to existing commands, creating new subcommands, or handling user inputs, `@effect/cli` provides a structured and intuitive way to scale your application.

# Getting Started with Your First CLI Application

## Creating a Simple "Hello World" CLI

Starting with a basic "Hello World" application is a great way to get familiar with the `@effect/cli`. Below is a step-by-step guide to creating your first command-line interface (CLI) application.

### 1. Set Up Your Project

Begin by creating a new file for your project:

- **File Name**: `hello-world.ts`
- **Purpose**: This file will hold all the necessary code for your CLI application.

### 2. Write the CLI Code

Now, let's write the code for your CLI. Open your `hello-world.ts` file in your favorite code editor and insert the following TypeScript code:

```ts
// Import necessary modules from the libraries
import { Command } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Console, Effect } from 'effect';

// Define the top-level command
const command = Command.make(
  'hello-world',
  {},
  () => Console.log('Hello World'),
);

// Set up the CLI application
const cli = Command.run(command, {
  name: 'Hello World CLI',
  version: 'v1.0.0',
});

// Prepare and run the CLI application
cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

**Explanation of Code:**

- **Import Statements**:

  - `Command` from `@effect/cli` allows you to define commands and subcommands.
  - `NodeContext` and `NodeRuntime` from `@effect/platform-node` enable your CLI to interact and integrate seamlessly with the Node.js runtime environment. This setup is crucial for running your CLI on Node.js, as it ensures that all Node-specific APIs and functionalities are accessible.
  - `Console` and `Effect` from `effect` provide utilities for logging and managing effects, which are essential for handling asynchronous operations and side effects in your CLI.

- **Command Definition**:

  - The `Command.make` function creates a new command named "hello-world". This command is configured to print "Hello World" when executed, serving as the basic functionality of your CLI.

- **CLI Configuration**:

  - The `Command.run` function initializes your CLI application with a specific name and version, preparing it for execution.

- **Execution Setup**:
  - The `cli(process.argv)` call processes the command-line arguments.
  - It uses `Effect.provide` to inject the `NodeContext.layer`, which integrates the CLI with the Node.js environment, allowing your application to utilize Node-specific features and settings.
  - `NodeRuntime.runMain` ensures that your application is executed within the Node.js main runtime, handling any asynchronous tasks and managing the lifecycle of your CLI.

### 3. Run Your CLI

After saving your `hello-world.ts` file, you can run your CLI application directly from your terminal to see it in action. Here's how:

```sh
npx tsx hello-world.ts
# Expected Output: Hello World
```

**Explanation of the Command:**

- **`tsx`**: This is a command-line tool that enables direct execution of TypeScript files. It simplifies the development process by eliminating the need to manually compile TypeScript (`*.ts`) files into JavaScript (`*.js`) before running them. `tsx` automatically compiles the TypeScript code on-the-fly and executes it, leveraging the Node.js environment.

- **`npx`**: Part of the npm (Node Package Manager) suite, `npx` is used to execute packages. When you run `npx tsx`, it temporarily installs `tsx` if it isn't already present in your project's local `node_modules` folder or globally on your machine. Then, `npx` executes `tsx` with the specified TypeScript file as its argument.

- **Usage in Your CLI**: By using `npx tsx hello-world.ts`, you're instructing `npx` to execute your TypeScript file using `tsx`. This command is especially useful for quick testing and development purposes, as it allows you to run your code directly without setting up a full TypeScript compilation workflow beforehand.

## Exploring CLI Features

Your new CLI comes with a variety of built-in features designed to enhance usability and help you manage your application effectively:

### Check the Version

You can display the version of your CLI by using the `--version` option:

```sh
npx tsx hello-world.ts --version
# Output: v1.0.0
```

### Access Help Information

Your CLI automatically generates help documentation that describes available commands and options. This feature is useful when you need guidance on how the CLI operates or when you want to learn more about its capabilities.

```sh
npx tsx hello-world.ts --help # or -h
```

When you request help, the CLI will display information like this:

```
Hello World CLI

Hello World CLI v1.0.0

USAGE

$ hello-world

OPTIONS

--completions sh | bash | fish | zsh

  One of the following: sh, bash, fish, zsh

  Generate a completion script for a specific shell

  This setting is optional.

(-h, --help)

  A true or false value.

  Show the help documentation for a command

  This setting is optional.

--wizard

  A true or false value.

  Start wizard mode for a command

  This setting is optional.

--version

  A true or false value.

  Show the version of the application

  This setting is optional.
```

### Using the Wizard Mode

The `--wizard` option activates the Wizard Mode in your CLI application, which provides a guided process for constructing commands. This is especially helpful for users who are new to your CLI or need assistance in building the correct command syntax.

To initiate the Wizard Mode, run your CLI application with the `--wizard` option like this:

```sh
npx tsx hello-world.ts --wizard
```

When you start the Wizard Mode, the CLI will interactively guide you through the process of setting up a command. Here's what the interaction might look like:

```
Wizard Mode for CLI Application: Hello World CLI (v1.0.0)

Instructions

  The wizard mode will assist you with constructing commands for Hello World CLI (v1.0.0).

  Please answer all prompts provided by the wizard.

COMMAND: hello-world

Wizard Mode Complete!

You may now execute your command directly with the following options and arguments:

    hello-world

âœ” Would you like to run the command? â€¦ yes / no
```

# Basic Usage

## Adding Arguments to Commands

Adding arguments to your commands allows your CLI applications to accept and process user input dynamically. Let's create a simple `echo` CLI that echoes back whatever text you pass to it.

### Setting Up Your CLI

Begin by creating a new TypeScript file named `echo.ts`. This file will contain all the code necessary to define a command that accepts user input as an argument.

```ts
// Import the necessary modules from the Effect libraries
import { Args, Command } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Console, Effect } from 'effect';

// Define a text argument
const text = Args.text({ name: 'text' });

// Create a command that logs the provided text argument to the console
const command = Command.make('echo', { text }, ({ text }) => Console.log(text));

// Configure and initialize the CLI application
const cli = Command.run(command, {
  name: 'Echo CLI',
  version: 'v0.0.1',
});

// Prepare and run the CLI application, providing necessary context and runtime
cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

**Understanding the Code:**

- **Arguments**: The `text` declaration creates an input parameter that users need to provide when they run your CLI.
- **Command Definition**: The `Command.make` function sets up your CLI command. It's designed to take the `text` argument and display it using `Console.log`.
- **Command Execution:** By using `Command.run`, the CLI application is formally structured with a specified name and version, and is ready to execute based on the defined command structure.
- **Execution Setup**: The `cli(process.argv)` call processes the command-line arguments and runs the CLI application. The `Effect.provide(NodeContext.layer)` injects the necessary Node.js context, and `NodeRuntime.runMain` ensures proper execution within the Node.js environment.

### Running the CLI

With your `echo.ts` script ready, you can run it to interact with the argument you've set up.

**Run Without Arguments**

If you try running the CLI without specifying any arguments, it will remind you to provide the required text:

```sh
npx tsx echo.ts
# Output: Missing argument <text>
```

**Run With Arguments**

To pass the text argument correctly, wrap your input in quotes to treat it as a single string:

```sh
npx tsx echo.ts "This is a test"
# Output: This is a test
```

**Common Mistake**

Forgetting to use quotes can cause issues since each word might be interpreted as a separate argument:

```sh
npx tsx echo.ts This is a test
# Output: Received unknown argument: 'is'
```

## Adding Options to Commands

Let's enhance the `echo` CLI we built earlier by introducing an option that allows text to be displayed in bold. This tutorial will guide you on adding a `--bold` option, abbreviated as `-b`, to your command.

### Modify Your TypeScript File

First, open the TypeScript file (`echo.ts`) where your `echo` command is defined. We will add a new option that enables users to choose whether their text output should be bold.

### Update the Code

Below is the updated version of your code with the bold option included:

```ts
import { Args, Command, Options } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Console, Effect } from 'effect';

const text = Args.text({ name: 'text' });

// Define the 'bold' option with an alias '-b'
const bold = Options.boolean('bold').pipe(Options.withAlias('b'));

// Create the command that outputs the text with bold formatting if the bold option is used
const command = Command.make(
  'echo',
  { text, bold },
  ({ bold, text }) => Console.log(bold ? `\x1b[1m${text}\x1b[0m` : text),
);

const cli = Command.run(command, {
  name: 'Echo CLI',
  version: 'v0.0.2',
});

cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

### Explanation of the Changes

- **Bold Option**: The `bold` declaration creates a boolean option that users can toggle. Using `Options.withAlias("b")` allows the option to be invoked with a shorter `-b` flag. This makes the command easier to type and remember.

- **Command Functionality**: Within the function of the command, there's a check to see if the `bold` option is true. If it is, the text is formatted with ANSI escape codes (`\x1b[1m` and `\x1b[0m`) to appear bold in the terminal. This formatting adds visual emphasis and can help distinguish output in complex console applications.

### Running the Updated CLI

With the command updated, you can now see the effect of the `--bold` or `-b` option by running:

```sh
npx tsx echo.ts --bold "This is a test"
```

or

```sh
npx tsx echo.ts -b "This is a test"
```

**Expected Output:**

Both commands will display "This is a test" in bold text, assuming your terminal supports ANSI escape codes.

## Important Note on Argument Order

When using your CLI, it's crucial to understand the order in which you specify options and arguments. By default, the `@effect/cli` parses `Options` and `Args` **before** any subcommands. This means that options need to be placed directly after the main command, and before any subcommands or additional arguments.

For example, the command:

```sh
npx tsx echo.ts "This is a test" -b
```

**would not work** because the `-b` option appears after the text argument `"This is a test"`. The parser expects options to be specified before any standalone arguments or subcommands. This ensures that the options are correctly associated with the main command and not misinterpreted as arguments for a subcommand or additional text.

## Adding Valued Options to Commands

In this section, we will continue to improve our `echo` CLI by introducing options to customize the color of the output text. This enhancement not only adds visual customization but also demonstrates how to use valued options to modify the behavior of commands.

### Update Your TypeScript File

Start by opening the TypeScript file where your `echo` command is defined. We will add new functionalities that allow for text coloring and optional bold formatting.

### Code Implementation

Below is the modified version of your code, now including options for text color:

```ts
import { Args, Command, Options } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Console, Effect, Option } from 'effect';

// Define a text argument
const text = Args.text({ name: 'text' });

// Define the 'bold' option with an alias '-b'
const bold = Options.boolean('bold').pipe(Options.withAlias('b'));

// Define the 'color' option with choices and an alias '-c'
const color = Options.choice('color', ['red', 'green', 'blue']).pipe(
  Options.withAlias('c'),
  Options.optional,
);

// Color codes for ANSI escape sequences
const colorCodes = {
  red: '\x1b[31m',
  green: '\x1b[32m',
  blue: '\x1b[34m',
};
const resetCode = '\x1b[0m';

// Function to apply ANSI color codes based on user input
const applyColor = (text: string, color: Option.Option<string>): string =>
  Option.match(color, {
    onNone: () => text,
    onSome: (color) => `${colorCodes[color]}${text}${resetCode}`,
  });

// Create the command that outputs formatted text
const command = Command.make(
  'echo',
  { text, bold, color },
  ({ bold, color, text }) => {
    let formattedText = applyColor(text, color);
    if (bold) {
      formattedText = `\x1b[1m${formattedText}\x1b[0m`;
    }
    return Console.log(formattedText);
  },
);

const cli = Command.run(command, {
  name: 'Echo CLI',
  version: 'v0.0.3',
});

cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

### Explanation of the Changes

- **Color Options**: The `color` option enables users to specify the text color as "red", "green", or "blue", enhancing the visual aspect of the output. This option uses `Options.choice` to provide a list of possible values.

- **applyColor Function**: This function applies the chosen ANSI color code to the text. If no color is selected, the text remains unchanged. This allows for dynamic customization of the output based on user preference.

### Running the Enhanced CLI

With the new color and bold options, you can now run the CLI and see colored text output. Here's how to use these options:

```sh
npx tsx echo.ts --bold --color red "This is a test"
npx tsx echo.ts -b -c green "Another test"
```

**Expected Output:**

These commands will print "This is a test" in bold red and "Another test" in bold green, provided your terminal supports ANSI colors.

## Adding Subcommands

Let's enhance the functionality of your `echo` CLI by adding a new subcommand called `repeat`. This subcommand will allow users to repeat a specified message multiple times, providing a practical example of how to extend a CLI application.

### Update Your TypeScript File

Open the TypeScript file where your `echo` command is defined. We'll incorporate the `repeat` subcommand into this setup.

### Implementing the `Repeat` Subcommand

Here is how you can update your code to include the `repeat` subcommand:

```ts
import { Args, Command, Options } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Console, Effect, Option } from 'effect';

const text = Args.text({ name: 'text' });

const bold = Options.boolean('bold').pipe(Options.withAlias('b'));

const color = Options.choice('color', ['red', 'green', 'blue']).pipe(
  Options.withAlias('c'),
  Options.optional,
);

const colorCodes: { [key: string]: string } = {
  red: '\x1b[31m',
  green: '\x1b[32m',
  blue: '\x1b[34m',
};
const resetCode = '\x1b[0m';

const applyColor = (text: string, color: Option.Option<string>): string =>
  Option.match(color, {
    onNone: () => text,
    onSome: (color) => `${colorCodes[color]}${text}${resetCode}`,
  });

// Argument for the number of repetitions
const count = Args.integer().pipe(Args.withDefault(1));

// Creating the repeat subcommand
const repeat = Command.make('repeat', { count }, ({ count }) =>
  echo.pipe(
    Effect.andThen((config) => Effect.repeatN(echo.handler(config), count - 1)),
  ));

// Main echo command
const echo = Command.make(
  'echo',
  { text, bold, color },
  ({ bold, color, text }) => {
    let formattedText = applyColor(text, color);
    if (bold) {
      formattedText = `\x1b[1m${formattedText}\x1b[0m`;
    }
    return Console.log(formattedText);
  },
);

// Combining commands
const command = echo.pipe(Command.withSubcommands([repeat]));

const cli = Command.run(command, {
  name: 'Echo CLI',
  version: 'v0.0.4',
});

cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

### Explanation of the Changes

- **Count Argument**: We introduced a new argument named `count`. This argument specifies the number of times the echo message will be repeated.
- **Repeat Command**: This new subcommand leverages the `count` argument to repeat the message the specified number of times.
- **Integration with Main Command**: We integrated the `repeat` subcommand into the existing `echo` command structure. This means users can activate this feature by simply appending the `repeat` keyword followed by the desired count after their message in the command line. For example, `echo "Hello" repeat 5` would output "Hello" five times.

> [!NOTE]
> Since `Command` is a subtype of `Effect`, you can use `Effect.andThen` within a subcommand's handler to directly access and utilize the `Config` from a parent command, and subsequently apply its handler.

### Running the `Repeat` Subcommand

With the `repeat` subcommand added, you can now use it to repeat messages:

```sh
npx tsx echo.ts -b -c red "This is a test" repeat 3
```

**Expected Output:**

This command will output "This is a test" in bold red text three times, demonstrating both the color and repeat functionalities.

# Tutorial: Building Your Own Git-Style CLI

In this tutorial, we will create a basic version of a Git-like command-line interface (CLI) called `minigit` using the powerful `@effect/cli` library. Our goal is to replicate a small set of Git commands to demonstrate how you can build structured CLI tools:

```
minigit       [-v | --version] [-h | --help] [-c <name>=<value>]
minigit add   [-v | --verbose] [--] [<pathspec>...]
minigit clone [--depth <depth>] [--] <repository> [<directory>]
```

> [!NOTE]
> This guide focuses on the setup and parsing of commands. Implementing the actual functionality of these commands is beyond the scope of this tutorial but can be developed further based on the patterns shown here.

The full code for this CLI application can be found in our [examples directory](./examples/minigit.ts).

## Creating the Command-Line Application

Begin by creating a TypeScript file named `minigit.ts`. This file will host all your CLI application code. We will structure our CLI with three main commands, demonstrating the powerful features of the `@effect/cli` library.

### Setting Up the Main Command

Let's start by setting up the primary command for our CLI, named `minigit`. To do this, we use the `Command.make` constructor which is pivotal for structuring commands in the `@effect/cli` framework.

```ts
import { Command } from '@effect/cli';
import { Effect } from 'effect';

// Define the main 'minigit' command
const minigit = Command.make(
  'minigit',
  // Configuration object for the command
  {},
  // Handler function that executes the command
  (config) => Effect.succeed('Welcome to Minigit!'),
);
```

#### Breakdown of Key Components

- **`Command.make` Function:** This function constructs a new `Command`. It requires three parameters:
  - **Name:** This is the command name, like 'minigit', which you use to call the command from the command line.
  - **Configuration:** This object specifies the options (`Options`) and arguments (`Args`) that the command can accept.
  - **Handler:** This function is executed when the command is called. It receives the parsed configuration and carries out the command's core functionalities.

#### Understanding the Command Type Signature

The `Command` interface in `@effect/cli` is structured as follows:

```ts
export interface Command<Name extends string, R, E, A> {
  readonly handler: (_: A) => Effect<void, E, R>;
  // Additional properties and methods...
}
```

- **`Name` (`Name extends string`):** A unique string that identifies the command.
- **`R` (Environment):** Defines the dependencies or the environment needed by the command's handler.
- **`E` (Expected Errors):** Specifies the types of errors the command might expect during its execution.
- **`A` (Arguments/Configuration):** Represents the configuration object the handler receives.

### Detailed Explanation of Parameters

**Command Name:**

The `name` parameter in `Command.make` designates the command's identifier. This name is crucial as it is used to invoke the command from the command line. For example, if we have a CLI application called `my-cli-app` with a single subcommand named `foo`, then executing the following command will run the `foo` command in your CLI application:

```sh
my-cli-app foo
```

**Command Configuration:**

The configuration parameter allows you to define what options and arguments the command can accept. This setup includes both simple flags and more complex objects. The `Config` is an object of key/value pairs where the keys are just identifiers and the values are the `Options` and `Args` that the `Command` may receive. The `Config` object can have nested `Config` objects or arrays of `Config` objects. When the CLI application is actually executed, the command `Config` is parsed from the command-line options and arguments following the command name.

**Command Handler:**

This function is where the action happens. It takes the parsed configuration and executes the core functionality of the command, utilizing the full capabilities of the `Effect` framework for managing effects and asynchronous operations.

### Our First Command

Let's apply what we've learned from using the `Command.make` method by defining the primary command for our `minigit` CLI application. This command will include configurations that handle various options like version, help, and custom key-value pairs.

```ts
import { Command, Options } from '@effect/cli';
import { Console, Option } from 'effect';

// minigit [--version] [-h | --help] [-c <name>=<value>]
const configs = Options.keyValueMap('c').pipe(Options.optional);

// Define the main 'minigit' command
const minigit = Command.make(
  'minigit',
  // Configuration object for the command
  { configs },
  // Handler function that executes the command
  ({ configs }) =>
    Option.match(configs, {
      onNone: () => Console.log("Running 'minigit'"),
      onSome: (configs) => {
        const keyValuePairs = Array.from(configs)
          .map(([key, value]) => `${key}=${value}`)
          .join(', ');
        return Console.log(
          `Running 'minigit' with the following configs: ${keyValuePairs}`,
        );
      },
    }),
);
```

#### Key Aspects of the Code:

- **Options Configuration:**

  - **`Options.keyValueMap("c")`:** This line sets up an option that accepts key-value pairs, allowing the user to input configurations in the format `-c key=value`.
  - **`Options.optional`:** By chaining this combinator, the `-c` option becomes optional, meaning the CLI will operate correctly whether or not this option is provided.

- **Command Execution:**
  - The command handler utilizes the `Option.match` function to determine how to respond based on whether the user has provided any key-value configurations.
  - If no configurations are provided (`onNone`), it simply logs "Running 'minigit'."
  - If configurations are provided (`onSome`), it logs these configurations in a readable string format, enhancing user feedback and interaction.

#### Built-In Options:

You may have noticed the lack of explicit version and help options in our command setup. This is due to `@effect/cli`'s design, which includes several built-in options such as `--version` and `--help` (see [Built-In Options](#built-in-options). These are automatically available and do not need to be manually configured, simplifying the setup of common CLI functionalities.

### Expanding the `minigit` CLI with Subcommands

Building on our basic `minigit` CLI, we'll now introduce two key subcommands: `add` and `clone`. These subcommands will demonstrate how to handle more complex command structures and multiple parameters using the `@effect/cli` library.

#### Adding Subcommands

We'll continue our `minigit` CLI development by incorporating `add` and `clone` subcommands to handle specific actions, much like the original Git commands.

```ts
import { Args, Command, Options } from '@effect/cli';
import { Array, Console, Option } from 'effect';

// minigit [--version] [-h | --help] [-c <name>=<value>]
const configs = Options.keyValueMap('c').pipe(Options.optional);

const minigit = Command.make(
  'minigit',
  { configs },
  ({ configs }) =>
    Option.match(configs, {
      onNone: () => Console.log("Running 'minigit'"),
      onSome: (configs) => {
        const keyValuePairs = Array.fromIterable(configs)
          .map(([key, value]) => `${key}=${value}`)
          .join(', ');
        return Console.log(
          `Running 'minigit' with the following configs: ${keyValuePairs}`,
        );
      },
    }),
);

// minigit add [-v | --verbose] [--] [<pathspec>...]
const pathspec = Args.text({ name: 'pathspec' }).pipe(Args.repeated);
const verbose = Options.boolean('verbose').pipe(Options.withAlias('v'));
const minigitAdd = Command.make(
  'add',
  { pathspec, verbose },
  ({ pathspec, verbose }) => {
    const paths = Array.match(pathspec, {
      onEmpty: () => '',
      onNonEmpty: (paths) => ` ${Array.join(paths, ' ')}`,
    });
    return Console.log(
      `Running 'minigit add${paths}' with '--verbose ${verbose}'`,
    );
  },
);

// minigit clone [--depth <depth>] [--] <repository> [<directory>]
const repository = Args.text({ name: 'repository' });
const directory = Args.text({ name: 'directory' }).pipe(Args.optional);
const depth = Options.integer('depth').pipe(Options.optional);
const minigitClone = Command.make(
  'clone',
  { repository, directory, depth },
  (config) => {
    const depth = Option.map(config.depth, (depth) => `--depth ${depth}`);
    const repository = Option.some(config.repository);
    const optionsAndArgs = Array.getSomes([
      depth,
      repository,
      config.directory,
    ]);
    return Console.log(
      "Running 'minigit clone' with the following options and arguments: " +
        `'${Array.join(optionsAndArgs, ', ')}'`,
    );
  },
);
```

#### Key Points to Note:

1. **Importing Modules:**

   - The `Args` module from `@effect/cli` is utilized to define positional arguments for both `add` and `clone` subcommands.
   - The `Array` module from `effect` is used to handle arrays and provide utility functions like `Array.match` and `Array.join`.

2. **Configuring Commands:**

   - Both subcommands utilize options and arguments that allow for detailed configuration, reflecting common use cases in command-line interfaces.
   - The `Options.withAlias` method simplifies command usage by providing shorthand aliases like `-v` for `--verbose`.

3. **Command Handlers:**
   - Each subcommand has a handler that logs execution details, which helps in understanding the flow and actions of the CLI commands.

### Assembling Your CLI Application

Now that you've defined all the necessary commands for your CLI application, it's time to assemble them into a fully functional command-line interface. This section will guide you through setting up the CLI to run within a NodeJS environment, assuming that you've already installed `@effect/platform-node` as described in the [Installation](#installation) guide.

Let's put together the `minigit` CLI:

```ts
import { Args, Command, Options } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Array, Console, Effect, Option } from 'effect';

// minigit [--version] [-h | --help] [-c <name>=<value>]
const configs = Options.keyValueMap('c').pipe(Options.optional);
const minigit = Command.make(
  'minigit',
  { configs },
  ({ configs }) =>
    Option.match(configs, {
      onNone: () => Console.log("Running 'minigit'"),
      onSome: (configs) => {
        const keyValuePairs = Array.fromIterable(configs)
          .map(([key, value]) => `${key}=${value}`)
          .join(', ');
        return Console.log(
          `Running 'minigit' with the following configs: ${keyValuePairs}`,
        );
      },
    }),
);

// minigit add [-v | --verbose] [--] [<pathspec>...]
const pathspec = Args.text({ name: 'pathspec' }).pipe(Args.repeated);
const verbose = Options.boolean('verbose').pipe(Options.withAlias('v'));
const minigitAdd = Command.make(
  'add',
  { pathspec, verbose },
  ({ pathspec, verbose }) => {
    const paths = Array.match(pathspec, {
      onEmpty: () => '',
      onNonEmpty: (paths) => ` ${Array.join(paths, ' ')}`,
    });
    return Console.log(
      `Running 'minigit add${paths}' with '--verbose ${verbose}'`,
    );
  },
);

// minigit clone [--depth <depth>] [--] <repository> [<directory>]
const repository = Args.text({ name: 'repository' });
const directory = Args.text({ name: 'directory' }).pipe(Args.optional);
const depth = Options.integer('depth').pipe(Options.optional);
const minigitClone = Command.make(
  'clone',
  { repository, directory, depth },
  (config) => {
    const depth = Option.map(config.depth, (depth) => `--depth ${depth}`);
    const repository = Option.some(config.repository);
    const optionsAndArgs = Array.getSomes([
      depth,
      repository,
      config.directory,
    ]);
    return Console.log(
      "Running 'minigit clone' with the following options and arguments: " +
        `'${Array.join(optionsAndArgs, ', ')}'`,
    );
  },
);

// Combine all commands into the main 'minigit' command
const command = minigit.pipe(
  Command.withSubcommands([minigitAdd, minigitClone]),
);

// Initialize and run the CLI application
const cli = Command.run(command, {
  name: 'Minigit Distributed Version Control',
  version: 'v1.0.0',
});

cli(process.argv).pipe(Effect.provide(NodeContext.layer), NodeRuntime.runMain);
```

#### Key Features and Configuration:

- **Command Integration:** The `minigit` command integrates both `add` and `clone` as subcommands, enabling a structured approach to handle different functionalities within the same CLI application.
- **Environment Setup:** We've imported `NodeContext` and `NodeRuntime` to ensure that our CLI application correctly interacts with NodeJS's runtime environment, making full use of Node-specific features.
- **Command Execution:** By using `Command.run`, the CLI application is formally structured with a specified name and version, and is ready to execute based on the defined command structure.
- **Execution Setup**: The `cli(process.argv)` call processes the command-line arguments and runs the CLI application. The `Effect.provide(NodeContext.layer)` injects the necessary Node.js context, and `NodeRuntime.runMain` ensures proper execution within the Node.js environment.

### Running the CLI Application

Now that your CLI application, `minigit`, is fully assembled and prepared, it's time to see it in action! This section will guide you through running `minigit` directly from the command line, using the example file `minigit.ts`. If you are experimenting using the `minigit` example from the provided [repository](./examples/minigit.ts), the same instructions apply, just replace the command file name with `npx tsx ./examples/minigit.ts`.

#### Executing Built-In Options

First, letâ€™s test out the built-in options to understand the core functionalities of our CLI application.

Run the following command to display the current version of your CLI application:

```sh
npx tsx minigit.ts --version
# Output: v1.0.0
```

To view the help documentation and understand the usage of each command within `minigit`, use the `-h` or `--help` option:

```sh
npx tsx minigit.ts --help
```

Output:

```
Minigit Distributed Version Control

Minigit Distributed Version Control v1.0.0

USAGE

$ minigit [-c text]

OPTIONS

-c text

  A user-defined piece of text.

  This setting is a property argument which:

    - May be specified a single time:  '-c key1=value key2=value2'

    - May be specified multiple times: '-c key1=value -c key2=value2'

  This setting is optional.

--completions sh | bash | fish | zsh

  One of the following: sh, bash, fish, zsh

  Generate a completion script for a specific shell

  This setting is optional.

(-h, --help)

  A true or false value.

  Show the help documentation for a command

  This setting is optional.

--wizard

  A true or false value.

  Start wizard mode for a command

  This setting is optional.

--version

  A true or false value.

  Show the version of the application

  This setting is optional.

COMMANDS

  - add [(-v, --verbose)] <pathspec>...

  - clone [--depth integer] <repository> [<directory>]
```

This output provides a breakdown of all available commands and options, helping users navigate through the functionalities offered by `minigit`.

To get more detailed help on subcommands like `add`, simply append `--help` after the subcommand:

```sh
npx tsx minigit.ts add --help
```

Output:

```
Minigit Distributed Version Control

Minigit Distributed Version Control v1.0.0

USAGE

$ add [(-v, --verbose)] <pathspec>...

ARGUMENTS

<pathspec>...

  A user-defined piece of text.

  This argument may be repeated zero or more times.

OPTIONS

(-v, --verbose)

  A true or false value.

  This setting is optional.

--completions sh | bash | fish | zsh

  One of the following: sh, bash, fish, zsh

  Generate a completion script for a specific shell

  This setting is optional.

(-h, --help)

  A true or false value.

  Show the help documentation for a command

  This setting is optional.

--wizard

  A true or false value.

  Start wizard mode for a command

  This setting is optional.

--version

  A true or false value.

  Show the version of the application

  This setting is optional.
```

#### Executing User-Defined Commands

Beyond viewing documentation, `minigit` allows you to execute commands with specific options to tailor its behavior.

Here's how you can add files with the verbose option enabled or disabled:

```sh
npx tsx minigit.ts add .
# Output: Running 'minigit add .' with '--verbose false'
```

```sh
npx tsx minigit.ts add --verbose .
# Output: Running 'minigit add .' with '--verbose true'
```

```sh
npx tsx minigit.ts clone --depth 1 https://github.com/Effect-TS/cli.git
# Output: Running 'minigit clone' with the following options and arguments: '--depth 1, https://github.com/Effect-TS/cli.git'
```

## Accessing Parent Arguments in Subcommands

In certain scenarios, you may want your subcommands to have access to the `Options` and `Args` passed to their parent commands.

Since `Command` is a subtype of `Effect`, you can use `Effect.flatMap` within a subcommand's handler to extract the `Config` from a parent command. This technique allows subcommands to utilize the configuration parameters specified at higher levels in the command hierarchy.

For example, let's say our `minigit clone` subcommand needs access to the configuration parameters passed to the parent `minigit` command via `minigit -c key=value`. We can accomplish this by modifying the `clone` command's handler to use `Effect.flatMap` with the parent `minigit` command:

```ts
const repository = Args.text({ name: 'repository' });
const directory = Args.directory().pipe(Args.optional);
const depth = Options.integer('depth').pipe(Options.optional);
const minigitClone = Command.make(
  'clone',
  { repository, directory, depth },
  (subcommandConfig) =>
    // By using `Effect.flatMap` on the parent command, we get access to its parsed config
    Effect.flatMap(minigit, (parentConfig) => {
      const depth = Option.map(
        subcommandConfig.depth,
        (depth) => `--depth ${depth}`,
      );
      const repository = Option.some(subcommandConfig.repository);
      const optionsAndArgs = Array.getSomes([
        depth,
        repository,
        subcommandConfig.directory,
      ]);
      const configs = Option.match(parentConfig.configs, {
        onNone: () => '',
        onSome: (map) =>
          Array.fromIterable(map)
            .map(([key, value]) => `${key}=${value}`)
            .join(', '),
      });
      return Console.log(
        "Running 'minigit clone' with the following options and arguments: " +
          `'${Array.join(optionsAndArgs, ', ')}'\n` +
          `and the following configuration parameters: ${configs}`,
      );
    }),
);
```

By examining the type of `minigitClone` after incorporating the parent command, you can see the added context:

```ts
const minigitClone: Command.Command<
  'clone',
  // The parent `minigit` command has been added to the environment required by
  // the subcommand's handler
  Command.Command.Context<'minigit'>,
  never,
  {
    readonly repository: string;
    readonly directory: Option.Option<string>;
    readonly depth: Option.Option<number>;
  }
>;
```

The parent command's context will be "erased" from the subcommand's environment when using `Command.withSubcommands`:

```ts
const command = minigit.pipe(Command.withSubcommands([minigitClone]));
//    ^? Command<"minigit", never, ..., ...>
```

Finally, run the command with some configuration parameters to see the result:

```sh
npx tsx minigit.ts -c key1=value1 clone --depth 1 https://github.com/Effect-TS/cli.git
# Running 'minigit clone' with the following options and arguments: '--depth 1, https://github.com/Effect-TS/cli.git'
# and the following configuration parameters: key1=value1
```

# Frequently Asked Questions (FAQ)

## Command-Line Argument Parsing Specification

Understanding how command-line arguments are parsed in your applications is crucial for designing effective and user-friendly command interfaces. Here are the key rules that the internal command-line argument parser follows:

### 1. Order of Options and Subcommands

Options and arguments (collectively referred to as `Options` / `Args`) associated with a command must be specified **before** any subcommands. This rule helps the parser determine which command the options apply to.

**Examples:**

- **Correct Usage**:

  ```sh
  program -v subcommand
  ```

  In this example, the `-v` option applies to the main program before the subcommand is processed.

- **Incorrect Usage**:
  ```sh
  program subcommand -v
  ```
  Here, placing `-v` after the subcommand causes confusion as to whether `-v` applies to the main program or the subcommand.

### 2. Parsing Options Before Positional Arguments

The parser is designed to recognize options before any positional arguments. This ordering ensures clarity and prevents confusion between options and regular arguments.

**Examples:**

- **Valid Command**:

  ```sh
  program --option arg
  ```

  This command correctly places the `--option` before the positional argument `arg`.

- **Invalid Command**:
  ```sh
  program arg --option
  ```
  Placing an argument before an option is not allowed and can lead to errors in command processing.

### 3. Handling Excess Arguments

If there are excess arguments that do not fit the expected structure of the command, the parser will return a `ValidationError`. This safeguard prevents the execution of malformed or potentially harmful commands.

# API Reference

- https://effect-ts.github.io/effect/docs/cli

# README.md

# Introduction

Welcome to the documentation for `@effect/platform`, a library designed for creating platform-independent abstractions (Node.js, Bun, browsers).

With `@effect/platform`, you can incorporate abstract services like `Terminal` or `FileSystem` into your program. Later, during the assembly of the final application, you can provide specific layers for the target platform using the corresponding packages: `platform-node`, `platform-bun`, and `platform-browser`.

This package empowers you to perform various operations, such as:

| **Operation**  | **Description**                                                                                  |
| -------------- | ------------------------------------------------------------------------------------------------ |
| Terminal       | Reading and writing from/to standard input/output                                                |
| Command        | Creating and running a command with the specified process name and an optional list of arguments |
| FileSystem     | Reading and writing from/to the file system                                                      |
| HTTP Client    | Sending HTTP requests and receiving responses                                                    |
| HTTP Server    | Creating HTTP servers to handle incoming requests                                                |
| HTTP Router    | Routing HTTP requests to specific handlers                                                       |
| KeyValueStore  | Storing and retrieving key-value pairs                                                           |
| PlatformLogger | Creating a logger that writes to a specified file from another string logger                     |

By utilizing `@effect/platform`, you can write code that remains platform-agnostic, ensuring compatibility across different environments.

# Terminal

The `@effect/platform/Terminal` module exports a single `Terminal` tag, which serves as the entry point to reading from and writing to standard input and standard output.

## Writing to standard output

```ts
import { Terminal } from '@effect/platform';
import { NodeRuntime, NodeTerminal } from '@effect/platform-node';
import { Effect } from 'effect';

// const displayMessage: Effect.Effect<void, PlatformError, Terminal.Terminal>
const displayMessage = Effect.gen(function* (_) {
  const terminal = yield* _(Terminal.Terminal);
  yield* _(terminal.display('a message\n'));
});

NodeRuntime.runMain(displayMessage.pipe(Effect.provide(NodeTerminal.layer)));
// Output: "a message"
```

## Reading from standard input

```ts
import { Terminal } from '@effect/platform';
import { NodeRuntime, NodeTerminal } from '@effect/platform-node';
import { Console, Effect } from 'effect';

// const readLine: Effect.Effect<void, Terminal.QuitException, Terminal.Terminal>
const readLine = Effect.gen(function* (_) {
  const terminal = yield* _(Terminal.Terminal);
  const input = yield* _(terminal.readLine);
  yield* _(Console.log(`input: ${input}`));
});

NodeRuntime.runMain(readLine.pipe(Effect.provide(NodeTerminal.layer)));
// Input: "hello"
// Output: "input: hello"
```

These simple examples illustrate how to utilize the `Terminal` module for handling standard input and output in your programs. Let's use this knowledge to build a number guessing game:

```ts
import { Terminal } from '@effect/platform';
import type { PlatformError } from '@effect/platform/Error';
import { Effect, Option, Random } from 'effect';

export const secret = Random.nextIntBetween(1, 100);

const parseGuess = (input: string) => {
  const n = parseInt(input, 10);
  return isNaN(n) || n < 1 || n > 100 ? Option.none() : Option.some(n);
};

const display = (message: string) =>
  Effect.gen(function* (_) {
    const terminal = yield* _(Terminal.Terminal);
    yield* _(terminal.display(`${message}\n`));
  });

const prompt = Effect.gen(function* (_) {
  const terminal = yield* _(Terminal.Terminal);
  yield* _(terminal.display('Enter a guess: '));
  return yield* _(terminal.readLine);
});

const answer: Effect.Effect<
  number,
  Terminal.QuitException | PlatformError,
  Terminal.Terminal
> = Effect.gen(function* (_) {
  const input = yield* _(prompt);
  const guess = parseGuess(input);
  if (Option.isNone(guess)) {
    yield* _(display('You must enter an integer from 1 to 100'));
    return yield* _(answer);
  }
  return guess.value;
});

const check = <A, E, R>(
  secret: number,
  guess: number,
  ok: Effect.Effect<A, E, R>,
  ko: Effect.Effect<A, E, R>,
): Effect.Effect<A, E | PlatformError, R | Terminal.Terminal> =>
  Effect.gen(function* (_) {
    if (guess > secret) {
      yield* _(display('Too high'));
      return yield* _(ko);
    } else if (guess < secret) {
      yield* _(display('Too low'));
      return yield* _(ko);
    } else {
      return yield* _(ok);
    }
  });

const end = display('You guessed it!');

const loop = (
  secret: number,
): Effect.Effect<
  void,
  Terminal.QuitException | PlatformError,
  Terminal.Terminal
> =>
  Effect.gen(function* (_) {
    const guess = yield* _(answer);
    return yield* _(
      check(
        secret,
        guess,
        end,
        Effect.suspend(() => loop(secret)),
      ),
    );
  });

export const game = Effect.gen(function* (_) {
  yield* _(
    display(
      "We have selected a random number between 1 and 100. See if you can guess it in 10 turns or fewer. We'll tell you if your guess was too high or too low.",
    ),
  );
  yield* _(loop(yield* _(secret)));
});
```

Let's run the game in Node.js:

```ts
import { NodeRuntime, NodeTerminal } from '@effect/platform-node';
import * as Effect from 'effect/Effect';
import { game } from './game.js';

NodeRuntime.runMain(game.pipe(Effect.provide(NodeTerminal.layer)));
```

Let's run the game in Bun:

```ts
import { BunRuntime, BunTerminal } from '@effect/platform-bun';
import * as Effect from 'effect/Effect';
import { game } from './game.js';

BunRuntime.runMain(game.pipe(Effect.provide(BunTerminal.layer)));
```

# Command

As an example of using the `@effect/platform/Command` module, let's see how to run the TypeScript compiler `tsc`:

```ts
import { Command, CommandExecutor } from '@effect/platform';
import {
  NodeCommandExecutor,
  NodeFileSystem,
  NodeRuntime,
} from '@effect/platform-node';
import { Effect } from 'effect';

// const program: Effect.Effect<string, PlatformError, CommandExecutor.CommandExecutor>
const program = Effect.gen(function* (_) {
  const executor = yield* _(CommandExecutor.CommandExecutor);

  // Creating a command to run the TypeScript compiler
  const command = Command.make('tsc', '--noEmit');
  console.log('Running tsc...');

  // Executing the command and capturing the output
  const output = yield* _(executor.string(command));
  console.log(output);
  return output;
});

// Running the program with the necessary runtime and executor layers
NodeRuntime.runMain(
  program.pipe(
    Effect.provide(NodeCommandExecutor.layer),
    Effect.provide(NodeFileSystem.layer),
  ),
);
```

## Obtaining Information About the Running Process

Here, we'll explore how to retrieve information about a running process.

```ts
import { Command, CommandExecutor } from '@effect/platform';
import {
  NodeCommandExecutor,
  NodeFileSystem,
  NodeRuntime,
} from '@effect/platform-node';
import { Effect, Stream, String } from 'effect';

const runString = <E, R>(
  stream: Stream.Stream<Uint8Array, E, R>,
): Effect.Effect<string, E, R> =>
  stream.pipe(Stream.decodeText(), Stream.runFold(String.empty, String.concat));

const program = Effect.gen(function* (_) {
  const executor = yield* _(CommandExecutor.CommandExecutor);

  const command = Command.make('ls');

  const [exitCode, stdout, stderr] = yield* _(
    // Start running the command and return a handle to the running process.
    executor.start(command),
    Effect.flatMap((process) =>
      Effect.all(
        [
          // Waits for the process to exit and returns the ExitCode of the command that was run.
          process.exitCode,
          // The standard output stream of the process.
          runString(process.stdout),
          // The standard error stream of the process.
          runString(process.stderr),
        ],
        { concurrency: 3 },
      )
    ),
  );
  console.log({ exitCode, stdout, stderr });
});

NodeRuntime.runMain(
  Effect.scoped(program).pipe(
    Effect.provide(NodeCommandExecutor.layer),
    Effect.provide(NodeFileSystem.layer),
  ),
);
```

## Running a Platform Command with stdout Streamed to process.stdout

To run a command (for example `cat`) and stream its `stdout` to `process.stdout` follow these steps:

```ts
import { Command } from '@effect/platform';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Effect } from 'effect';

// Create a command to run `cat` on a file and inherit stdout
const program = Command.make('cat', './some-file.txt').pipe(
  Command.stdout('inherit'),
  Command.exitCode,
);

// Run the command using NodeRuntime with the NodeContext layer
NodeRuntime.runMain(program.pipe(Effect.provide(NodeContext.layer)));
```

# FileSystem

The `@effect/platform/FileSystem` module provides a single `FileSystem` tag, which acts as the gateway for interacting with the filesystem.

Here's a list of operations that can be performed using the `FileSystem` tag:

| **Name**                    | **Arguments**                                                    | **Return**                                     | **Description**                                                                                                                                                        |
| --------------------------- | ---------------------------------------------------------------- | ---------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **access**                  | `path: string`, `options?: AccessFileOptions`                    | `Effect<void, PlatformError>`                  | Check if a file can be accessed. You can optionally specify the level of access to check for.                                                                          |
| **copy**                    | `fromPath: string`, `toPath: string`, `options?: CopyOptions`    | `Effect<void, PlatformError>`                  | Copy a file or directory from `fromPath` to `toPath`. Equivalent to `cp -r`.                                                                                           |
| **copyFile**                | `fromPath: string`, `toPath: string`                             | `Effect<void, PlatformError>`                  | Copy a file from `fromPath` to `toPath`.                                                                                                                               |
| **chmod**                   | `path: string`, `mode: number`                                   | `Effect<void, PlatformError>`                  | Change the permissions of a file.                                                                                                                                      |
| **chown**                   | `path: string`, `uid: number`, `gid: number`                     | `Effect<void, PlatformError>`                  | Change the owner and group of a file.                                                                                                                                  |
| **exists**                  | `path: string`                                                   | `Effect<boolean, PlatformError>`               | Check if a path exists.                                                                                                                                                |
| **link**                    | `fromPath: string`, `toPath: string`                             | `Effect<void, PlatformError>`                  | Create a hard link from `fromPath` to `toPath`.                                                                                                                        |
| **makeDirectory**           | `path: string`, `options?: MakeDirectoryOptions`                 | `Effect<void, PlatformError>`                  | Create a directory at `path`. You can optionally specify the mode and whether to recursively create nested directories.                                                |
| **makeTempDirectory**       | `options?: MakeTempDirectoryOptions`                             | `Effect<string, PlatformError>`                | Create a temporary directory. By default, the directory will be created inside the system's default temporary directory.                                               |
| **makeTempDirectoryScoped** | `options?: MakeTempDirectoryOptions`                             | `Effect<string, PlatformError, Scope>`         | Create a temporary directory inside a scope. Functionally equivalent to `makeTempDirectory`, but the directory will be automatically deleted when the scope is closed. |
| **makeTempFile**            | `options?: MakeTempFileOptions`                                  | `Effect<string, PlatformError>`                | Create a temporary file. The directory creation is functionally equivalent to `makeTempDirectory`. The file name will be a randomly generated string.                  |
| **makeTempFileScoped**      | `options?: MakeTempFileOptions`                                  | `Effect<string, PlatformError, Scope>`         | Create a temporary file inside a scope. Functionally equivalent to `makeTempFile`, but the file will be automatically deleted when the scope is closed.                |
| **open**                    | `path: string`, `options?: OpenFileOptions`                      | `Effect<File, PlatformError, Scope>`           | Open a file at `path` with the specified `options`. The file handle will be automatically closed when the scope is closed.                                             |
| **readDirectory**           | `path: string`, `options?: ReadDirectoryOptions`                 | `Effect<ReadonlyArray<string>, PlatformError>` | List the contents of a directory. You can recursively list the contents of nested directories by setting the `recursive` option.                                       |
| **readFile**                | `path: string`                                                   | `Effect<Uint8Array, PlatformError>`            | Read the contents of a file.                                                                                                                                           |
| **readFileString**          | `path: string`, `encoding?: string`                              | `Effect<string, PlatformError>`                | Read the contents of a file as a string.                                                                                                                               |
| **readLink**                | `path: string`                                                   | `Effect<string, PlatformError>`                | Read the destination of a symbolic link.                                                                                                                               |
| **realPath**                | `path: string`                                                   | `Effect<string, PlatformError>`                | Resolve a path to its canonicalized absolute pathname.                                                                                                                 |
| **remove**                  | `path: string`, `options?: RemoveOptions`                        | `Effect<void, PlatformError>`                  | Remove a file or directory. By setting the `recursive` option to `true`, you can recursively remove nested directories.                                                |
| **rename**                  | `oldPath: string`, `newPath: string`                             | `Effect<void, PlatformError>`                  | Rename a file or directory.                                                                                                                                            |
| **sink**                    | `path: string`, `options?: SinkOptions`                          | `Sink<void, Uint8Array, never, PlatformError>` | Create a writable `Sink` for the specified `path`.                                                                                                                     |
| **stat**                    | `path: string`                                                   | `Effect<File.Info, PlatformError>`             | Get information about a file at `path`.                                                                                                                                |
| **stream**                  | `path: string`, `options?: StreamOptions`                        | `Stream<Uint8Array, PlatformError>`            | Create a readable `Stream` for the specified `path`.                                                                                                                   |
| **symlink**                 | `fromPath: string`, `toPath: string`                             | `Effect<void, PlatformError>`                  | Create a symbolic link from `fromPath` to `toPath`.                                                                                                                    |
| **truncate**                | `path: string`, `length?: SizeInput`                             | `Effect<void, PlatformError>`                  | Truncate a file to a specified length. If the `length` is not specified, the file will be truncated to length `0`.                                                     |
| **utimes**                  | `path: string`, `atime: Date \| number`, `mtime: Date \| number` | `Effect<void, PlatformError>`                  | Change the file system timestamps of the file at `path`.                                                                                                               |
| **watch**                   | `path: string`                                                   | `Stream<WatchEvent, PlatformError>`            | Watch a directory or file for changes.                                                                                                                                 |

Let's explore a simple example using `readFileString`:

```ts
import { FileSystem } from '@effect/platform';
import { NodeFileSystem, NodeRuntime } from '@effect/platform-node';
import { Effect } from 'effect';

// const readFileString: Effect.Effect<void, PlatformError, FileSystem.FileSystem>
const readFileString = Effect.gen(function* (_) {
  const fs = yield* _(FileSystem.FileSystem);

  // Reading the content of the same file where this code is written
  const content = yield* _(fs.readFileString('./index.ts', 'utf8'));
  console.log(content);
});

NodeRuntime.runMain(readFileString.pipe(Effect.provide(NodeFileSystem.layer)));
```

# KeyValueStore

## Overview

The `KeyValueStore` module provides a robust and effectful interface for managing key-value pairs. It supports asynchronous operations, ensuring data integrity and consistency, and includes built-in implementations for in-memory, file system-based, and schema-validated stores.

## Basic Usage

The `KeyValueStore` interface includes the following operations:

- **get**: Retrieve a value by key.
- **set**: Store a key-value pair.
- **remove**: Delete a key-value pair.
- **clear**: Remove all key-value pairs.
- **size**: Get the number of stored pairs.
- **modify**: Atomically modify a value.
- **has**: Check if a key exists.
- **isEmpty**: Check if the store is empty.

**Example**

```ts
import { KeyValueStore, layerMemory } from '@effect/platform/KeyValueStore';
import { Effect } from 'effect';

const program = Effect.gen(function* () {
  const store = yield* KeyValueStore;
  console.log(yield* store.size); // Outputs: 0

  yield* store.set('key', 'value');
  console.log(yield* store.size); // Outputs: 1

  const value = yield* store.get('key');
  console.log(value); // Outputs: { _id: 'Option', _tag: 'Some', value: 'value' }

  yield* store.remove('key');
  console.log(yield* store.size); // Outputs: 0
});

Effect.runPromise(program.pipe(Effect.provide(layerMemory)));
```

## Built-in Implementations

The module provides several built-in implementations to suit different needs:

- **In-Memory Store**: `layerMemory` provides a simple, in-memory key-value store, ideal for lightweight or testing scenarios.
- **File System Store**: `layerFileSystem` offers a file-based store for persistent storage needs.
- **Schema Store**: `layerSchema` enables schema-based validation for stored values, ensuring data integrity and type safety.

## Schema Store

The `SchemaStore` implementation allows you to validate and parse values according to a defined schema. This ensures that all data stored in the key-value store adheres to the specified structure, enhancing data integrity and type safety.

**Example**

```ts
import { KeyValueStore, layerMemory } from '@effect/platform/KeyValueStore';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';

// Define a schema for the values
const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const program = Effect.gen(function* () {
  const store = (yield* KeyValueStore).forSchema(Person);

  // Create a value that adheres to the schema
  const value = { name: 'Alice', age: 30 };
  yield* store.set('user1', value);
  console.log(yield* store.size); // Outputs: 1

  // Retrieve and validate the value
  const retrievedValue = yield* store.get('user1');
  console.log(retrievedValue); // Outputs: { _id: 'Option', _tag: 'Some', value: { name: 'Alice', age: 30 } }
});

Effect.runPromise(program.pipe(Effect.provide(layerMemory)));
```

In this example:

- **Person**: Defines the structure for the values stored in the key-value store.
- **store.set**: Stores a value adhering to `Person`.
- **store.get**: Retrieves and validates the stored value against `Person`.

# HTTP Client

## Retrieving Data (GET)

In this section, we'll explore how to retrieve data using the `HttpClient` module from `@effect/platform`.

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const getPostAsJson = Http.request
  .get('https://jsonplaceholder.typicode.com/posts/1')
  .pipe(Http.client.fetch, Http.response.json);

NodeRuntime.runMain(
  getPostAsJson.pipe(Effect.andThen((post) => Console.log(typeof post, post))),
);
/*
Output:
object {
  userId: 1,
  id: 1,
  title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit',
  body: 'quia et suscipit\n' +
    'suscipit recusandae consequuntur expedita et cum\n' +
    'reprehenderit molestiae ut ut quas totam\n' +
    'nostrum rerum est autem sunt rem eveniet architecto'
}
*/
```

If you want a response in a different format other than JSON, you can utilize other APIs provided by `Http.response`.

In the following example, we fetch the post as text:

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const getPostAsText = Http.request
  .get('https://jsonplaceholder.typicode.com/posts/1')
  .pipe(Http.client.fetch, Http.response.text);

NodeRuntime.runMain(
  getPostAsText.pipe(Effect.andThen((post) => Console.log(typeof post, post))),
);
/*
Output:
string {
  userId: 1,
  id: 1,
  title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit',
  body: 'quia et suscipit\n' +
    'suscipit recusandae consequuntur expedita et cum\n' +
    'reprehenderit molestiae ut ut quas totam\n' +
    'nostrum rerum est autem sunt rem eveniet architecto'
}
*/
```

Here are some APIs you can use to convert the response:

| **API**                       | **Description**                       |
| ----------------------------- | ------------------------------------- |
| `Http.response.arrayBuffer`   | Convert to `ArrayBuffer`              |
| `Http.response.formData`      | Convert to `FormData`                 |
| `Http.response.json`          | Convert to JSON                       |
| `Http.response.stream`        | Convert to a `Stream` of `Uint8Array` |
| `Http.response.text`          | Convert to text                       |
| `Http.response.urlParamsBody` | Convert to `Http.urlParams.UrlParams` |

### Setting Headers

When making HTTP requests, sometimes you need to include additional information in the request headers. You can set headers using the `setHeader` function for a single header or `setHeaders` for multiple headers simultaneously.

```ts
import * as Http from '@effect/platform/HttpClient';

const getPost = Http.request
  .get('https://jsonplaceholder.typicode.com/posts/1')
  .pipe(
    // Setting a single header
    Http.request.setHeader('Content-type', 'application/json; charset=UTF-8'),
    // Setting multiple headers
    Http.request.setHeaders({
      'Content-type': 'application/json; charset=UTF-8',
      Foo: 'Bar',
    }),
    Http.client.fetch,
  );
```

### Decoding Data with Schemas

A common use case when fetching data is to validate the received format. For this purpose, the `HttpClient` module is integrated with `@effect/schema`.

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Schema } from '@effect/schema';
import { Console, Effect } from 'effect';

const Post = Schema.Struct({
  id: Schema.Number,
  title: Schema.String,
});

/*
const getPostAndValidate: Effect.Effect<{
    readonly id: number;
    readonly title: string;
}, Http.error.HttpClientError | ParseError, never>
*/
const getPostAndValidate = Http.request
  .get('https://jsonplaceholder.typicode.com/posts/1')
  .pipe(
    Http.client.fetch,
    Effect.andThen(Http.response.schemaBodyJson(Post)),
    Effect.scoped,
  );

NodeRuntime.runMain(getPostAndValidate.pipe(Effect.andThen(Console.log)));
/*
Output:
{
  id: 1,
  title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'
}
*/
```

In this example, we define a schema for a post object with properties `id` and `title`. Then, we fetch the data and validate it against this schema using `Http.response.schemaBodyJson`. Finally, we log the validated post object.

Note that we use `Effect.scoped` after consuming the response. This ensures that any resources associated with the HTTP request are properly cleaned up once we're done processing the response.

### Filtering And Error Handling

It's important to note that `Http.client.fetch` doesn't consider non-`200` status codes as errors by default. This design choice allows for flexibility in handling different response scenarios. For instance, you might have a schema union where the status code serves as the discriminator, enabling you to define a schema that encompasses all possible response cases.

You can use `Http.client.filterStatusOk`, or `Http.client.fetchOk` to ensure only `2xx` responses are treated as successes.

In this example, we attempt to fetch a non-existent page and don't receive any error:

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const getText = Http.request
  .get('https://jsonplaceholder.typicode.com/non-existing-page')
  .pipe(Http.client.fetch, Http.response.text);

NodeRuntime.runMain(getText.pipe(Effect.andThen(Console.log)));
/*
Output:
{}
*/
```

However, if we use `Http.client.filterStatusOk`, an error is logged:

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const getText = Http.request
  .get('https://jsonplaceholder.typicode.com/non-existing-page')
  .pipe(Http.client.filterStatusOk(Http.client.fetch), Http.response.text);

NodeRuntime.runMain(getText.pipe(Effect.andThen(Console.log)));
/*
Output:
timestamp=2024-03-25T10:21:16.972Z level=ERROR fiber=#0 cause="ResponseError: StatusCode error (404 GET https://jsonplaceholder.typicode.com/non-existing-page): non 2xx status code
*/
```

Note that you can use `Http.client.fetchOk` as a shortcut for `Http.client.filterStatusOk(Http.client.fetch)`:

```ts
const getText = Http.request
  .get('https://jsonplaceholder.typicode.com/non-existing-page')
  .pipe(Http.client.fetchOk, Http.response.text);
```

You can also create your own status-based filters. In fact, `Http.client.filterStatusOk` is just a shortcut for the following filter:

```ts
const getText = Http.request
  .get('https://jsonplaceholder.typicode.com/non-existing-page')
  .pipe(
    Http.client.filterStatus(
      Http.client.fetch,
      (status) => status >= 200 && status < 300,
    ),
    Http.response.text,
  );
```

## POST

To make a POST request, you can use the `Http.request.post` function provided by the `HttpClient` module. Here's an example of how to create and send a POST request:

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const addPost = Http.request
  .post('https://jsonplaceholder.typicode.com/posts')
  .pipe(
    Http.request.jsonBody({
      title: 'foo',
      body: 'bar',
      userId: 1,
    }),
    Effect.andThen(Http.client.fetch),
    Http.response.json,
  );

NodeRuntime.runMain(addPost.pipe(Effect.andThen(Console.log)));
/*
Output:
{ title: 'foo', body: 'bar', userId: 1, id: 101 }
*/
```

If you need to send data in a format other than JSON, such as plain text, you can use different APIs provided by `Http.request`.

In the following example, we send the data as text:

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Console, Effect } from 'effect';

const addPost = Http.request
  .post('https://jsonplaceholder.typicode.com/posts')
  .pipe(
    Http.request.textBody(
      JSON.stringify({
        title: 'foo',
        body: 'bar',
        userId: 1,
      }),
      'application/json; charset=UTF-8',
    ),
    Http.client.fetch,
    Http.response.json,
  );

NodeRuntime.runMain(Effect.andThen(addPost, Console.log));
/*
Output:
{ title: 'foo', body: 'bar', userId: 1, id: 101 }
*/
```

### Decoding Data with Schemas

A common use case when fetching data is to validate the received format. For this purpose, the `HttpClient` module is integrated with `@effect/schema`.

```ts
import { NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpClient';
import { Schema } from '@effect/schema';
import { Console, Effect } from 'effect';

const Post = Schema.Struct({
  id: Schema.Number,
  title: Schema.String,
});

const addPost = Http.request
  .post('https://jsonplaceholder.typicode.com/posts')
  .pipe(
    Http.request.jsonBody({
      title: 'foo',
      body: 'bar',
      userId: 1,
    }),
    Effect.andThen(Http.client.fetch),
    Effect.andThen(Http.response.schemaBodyJson(Post)),
    Effect.scoped,
  );

NodeRuntime.runMain(addPost.pipe(Effect.andThen(Console.log)));
/*
Output:
{ id: 101, title: 'foo' }
*/
```

# HTTP Server

## Overview

This section provides a simplified explanation of key concepts within the `@effect/platform` TypeScript library, focusing on components used to build HTTP servers. Understanding these terms and their relationships helps in structuring and managing server applications effectively.

### Core Concepts

- **HttpApp**: This is an `Effect` which results in a value `A`. It can utilize `ServerRequest` to produce the outcome `A`. Essentially, an `HttpApp` represents an application component that handles HTTP requests and generates responses based on those requests.

- **Default** (HttpApp): A special type of `HttpApp` that specifically produces a `ServerResponse` as its output `A`. This is the most common form of application where each interaction is expected to result in an HTTP response.

- **Server**: A construct that takes a `Default` app and converts it into an `Effect`. This serves as the execution layer where the `Default` app is operated, handling incoming requests and serving responses.

- **Router**: A type of `Default` app where the possible error outcome is `RouteNotFound`. Routers are used to direct incoming requests to appropriate handlers based on the request path and method.

- **Handler**: Another form of `Default` app, which has access to both `RouteContext` and `ServerRequest.ParsedSearchParams`. Handlers are specific functions designed to process requests and generate responses.

- **Middleware**: Functions that transform a `Default` app into another `Default` app. Middleware can be used to modify requests, responses, or handle tasks like logging, authentication, and more. Middleware can be applied in two ways:
  - On a `Router` using `router.use: Handler -> Default` which applies the middleware to specific routes.
  - On a `Server` using `server.serve: () -> Layer | Middleware -> Layer` which applies the middleware globally to all routes handled by the server.

### Applying Concepts

These components are designed to work together in a modular and flexible way, allowing developers to build complex server applications with reusable components. Hereâ€™s how you might typically use these components in a project:

1. **Create Handlers**: Define functions that process specific types of requests (e.g., GET, POST) and return responses.

2. **Set Up Routers**: Organize handlers into routers, where each router manages a subset of application routes.

3. **Apply Middleware**: Enhance routers or entire servers with middleware to add extra functionality like error handling or request logging.

4. **Initialize the Server**: Wrap the main router with server functionality, applying any server-wide middleware, and start listening for requests.

## Getting Started

### Hello world example

In this example, we will create a simple HTTP server that listens on port `3000`. The server will respond with "Hello World!" when a request is made to the root URL (/) and return a `500` error for all other paths.

Node.js Example

```ts
import { HttpServer } from '@effect/platform';
import { NodeHttpServer, NodeRuntime } from '@effect/platform-node';
import { Layer } from 'effect';
import { createServer } from 'node:http';

// Define the router with a single route for the root URL
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);

// Set up the application server with logging
const app = router.pipe(
  HttpServer.server.serve(),
  HttpServer.server.withLogAddress,
);

// Specify the port
const port = 3000;

// Create a server layer with the specified port
const ServerLive = NodeHttpServer.server.layer(() => createServer(), { port });

// Run the application
NodeRuntime.runMain(Layer.launch(Layer.provide(app, ServerLive)));

/*
Output:
timestamp=... level=INFO fiber=#0 message="Listening on http://localhost:3000"
*/
```

> [!NOTE]
> The `HttpServer.server.withLogAddress` middleware logs the address and port where the server is listening, helping to confirm that the server is running correctly and accessible on the expected endpoint.

Bun Example

```ts
import { HttpServer } from '@effect/platform';
import { BunHttpServer, BunRuntime } from '@effect/platform-bun';
import { Layer } from 'effect';

// Define the router with a single route for the root URL
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);

// Set up the application server with logging
const app = router.pipe(
  HttpServer.server.serve(),
  HttpServer.server.withLogAddress,
);

// Specify the port
const port = 3000;

// Create a server layer with the specified port
const ServerLive = BunHttpServer.server.layer({ port });

// Run the application
BunRuntime.runMain(Layer.launch(Layer.provide(app, ServerLive)));

/*
Output:
timestamp=... level=INFO fiber=#0 message="Listening on http://localhost:3000"
*/
```

To avoid boilerplate code for the final server setup, we'll use a helper function from the `listen.ts` file:

```ts
import type { HttpServer } from '@effect/platform';
import { NodeHttpServer, NodeRuntime } from '@effect/platform-node';
import { Layer } from 'effect';
import { createServer } from 'node:http';

export const listen = (
  app: Layer.Layer<
    never,
    never,
    HttpServer.platform.Platform | HttpServer.server.Server
  >,
  port: number,
) =>
  NodeRuntime.runMain(
    Layer.launch(
      Layer.provide(
        app,
        NodeHttpServer.server.layer(() => createServer(), { port }),
      ),
    ),
  );
```

### Basic routing

Routing refers to determining how an application responds to a client request to a particular endpoint, which is a URI (or path) and a specific HTTP request method (GET, POST, and so on).

Route definition takes the following structure:

```
router.pipe(HttpServer.router.METHOD(PATH, HANDLER))
```

Where:

- **router** is an instance of `Router` (`import type { Router } from "@effect/platform/Http/Router"`).
- **METHOD** is an HTTP request method, in lowercase (e.g., get, post, put, del).
- **PATH** is the path on the server (e.g., "/", "/user").
- **HANDLER** is the action that gets executed when the route is matched.

The following examples illustrate defining simple routes.

Respond with `"Hello World!"` on the homepage:

```ts
router.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);
```

Respond to POST request on the root route (/), the application's home page:

```ts
router.pipe(
  HttpServer.router.post('/', HttpServer.response.text('Got a POST request')),
);
```

Respond to a PUT request to the `/user` route:

```ts
router.pipe(
  HttpServer.router.put(
    '/user',
    HttpServer.response.text('Got a PUT request at /user'),
  ),
);
```

Respond to a DELETE request to the `/user` route:

```ts
router.pipe(
  HttpServer.router.del(
    '/user',
    HttpServer.response.text('Got a DELETE request at /user'),
  ),
);
```

### Serving static files

To serve static files such as images, CSS files, and JavaScript files, use the `HttpServer.response.file` built-in action.

```ts
import { HttpServer } from '@effect/platform';
import { listen } from './listen.js';

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.file('index.html')),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

Create an `index.html` file in your project directory:

```html filename="index.html"
<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>index.html</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
  </head>
  <body>
    index.html
  </body>
</html>
```

## Routing

Routing refers to how an application's endpoints (URIs) respond to client requests.

You define routing using methods of the `HttpServer.router` object that correspond to HTTP methods; for example, `HttpServer.router.get()` to handle GET requests and `HttpServer.router.post` to handle POST requests. You can also use `HttpServer.router.all()` to handle all HTTP methods.

These routing methods specify a `Route.Handler` called when the application receives a request to the specified route (endpoint) and HTTP method. In other words, the application â€œlistensâ€ for requests that match the specified route(s) and method(s), and when it detects a match, it calls the specified handler.

The following code is an example of a very basic route.

```ts
// respond with "hello world" when a GET request is made to the homepage
HttpServer.router.get('/', HttpServer.response.text('Hello World'));
```

### Route methods

A route method is derived from one of the HTTP methods, and is attached to an instance of the `HttpServer.router` object.

The following code is an example of routes that are defined for the GET and the POST methods to the root of the app.

```ts
// GET method route
HttpServer.router.get(
  '/',
  HttpServer.response.text('GET request to the homepage'),
);

// POST method route
HttpServer.router.post(
  '/',
  HttpServer.response.text('POST request to the homepage'),
);
```

`HttpServer.router` supports methods that correspond to all HTTP request methods: `get`, `post`, and so on.

There is a special routing method, `HttpServer.router.all()`, used to load middleware functions at a path for **all** HTTP request methods. For example, the following handler is executed for requests to the route â€œ/secretâ€ whether using GET, POST, PUT, DELETE.

```ts
HttpServer.router.all(
  '/secret',
  HttpServer.response
    .empty()
    .pipe(Effect.tap(Console.log('Accessing the secret section ...'))),
);
```

### Route paths

Route paths, when combined with a request method, define the endpoints where requests can be made. Route paths can be specified as strings according to the following type:

```ts
type PathInput = `/${string}` | '*';
```

> [!NOTE]
> Query strings are not part of the route path.

Here are some examples of route paths based on strings.

This route path will match requests to the root route, /.

```ts
HttpServer.router.get('/', HttpServer.response.text('root'));
```

This route path will match requests to `/user`.

```ts
HttpServer.router.get('/user', HttpServer.response.text('user'));
```

This route path matches requests to any path starting with `/user` (e.g., `/user`, `/users`, etc.)

```ts
HttpServer.router.get(
  '/user*',
  Effect.map(
    HttpServer.request.ServerRequest,
    (req) => HttpServer.response.text(req.url),
  ),
);
```

### Route parameters

Route parameters are named URL segments that are used to capture the values specified at their position in the URL. By using a schema the captured values are populated in an object, with the name of the route parameter specified in the path as their respective keys.

Route parameters are named segments in a URL that capture the values specified at those positions. These captured values are stored in an object, with the parameter names used as keys.

For example:

```
Route path: /users/:userId/books/:bookId
Request URL: http://localhost:3000/users/34/books/8989
params: { "userId": "34", "bookId": "8989" }
```

To define routes with parameters, include the parameter names in the path and use a schema to validate and parse these parameters, as shown below.

```ts
import { HttpServer } from '@effect/platform';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Define the schema for route parameters
const Params = Schema.Struct({
  userId: Schema.String,
  bookId: Schema.String,
});

// Create a router with a route that captures parameters
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/users/:userId/books/:bookId',
    HttpServer.router
      .schemaPathParams(Params)
      .pipe(Effect.flatMap((params) => HttpServer.response.json(params))),
  ),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

### Response methods

The methods on `HttpServer.response` object in the following table can send a response to the client, and terminate the request-response cycle. If none of these methods are called from a route handler, the client request will be left hanging.

| Method       | Description                    |
| ------------ | ------------------------------ |
| **empty**    | Sends an empty response.       |
| **formData** | Sends form data.               |
| **html**     | Sends an HTML response.        |
| **raw**      | Sends a raw response.          |
| **setBody**  | Sets the body of the response. |
| **stream**   | Sends a streaming response.    |
| **text**     | Sends a plain text response.   |

### Router

Use the `HttpServer.router` object to create modular, mountable route handlers. A `Router` instance is a complete middleware and routing system, often referred to as a "mini-app."

The following example shows how to create a router as a module, define some routes, and mount the router module on a path in the main app.

Create a file named `birds.ts` in your app directory with the following content:

```ts
import { HttpServer } from '@effect/platform';

export const birds = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Birds home page')),
  HttpServer.router.get('/about', HttpServer.response.text('About birds')),
);
```

In your main application file, load the router module and mount it.

```ts
import { HttpServer } from '@effect/platform';
import { birds } from './birds.js';
import { listen } from './listen.js';

// Create the main router and mount the birds router
const router = HttpServer.router.empty.pipe(
  HttpServer.router.mount('/birds', birds),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

When you run this code, your application will be able to handle requests to `/birds` and `/birds/about`, serving the respective responses defined in the `birds` router module.

## Writing Middleware

In this section, we'll build a simple "Hello World" application and demonstrate how to add three middleware functions: `myLogger` for logging, `requestTime` for displaying request timestamps, and `validateCookies` for validating incoming cookies.

### Example Application

Here is an example of a basic "Hello World" application with middleware.

### Middleware `myLogger`

This middleware logs "LOGGED" whenever a request passes through it.

```ts
const myLogger = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    console.log('LOGGED');
    return yield* app;
  })
);
```

To use the middleware, add it to the router using `HttpServer.router.use()`:

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

const myLogger = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    console.log('LOGGED');
    return yield* app;
  })
);

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);

const app = router.pipe(
  HttpServer.router.use(myLogger),
  HttpServer.server.serve(),
);

listen(app, 3000);
```

With this setup, every request to the app will log "LOGGED" to the terminal. Middleware execute in the order they are loaded.

### Middleware `requestTime`

Next, we'll create a middleware that records the timestamp of each HTTP request and provides it via a service called `RequestTime`.

```ts
class RequestTime extends Context.Tag('RequestTime')<RequestTime, number>() {}

const requestTime = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    return yield* app.pipe(Effect.provideService(RequestTime, Date.now()));
  })
);
```

Update the app to use this middleware and display the timestamp in the response:

```ts
import { HttpServer } from '@effect/platform';
import { Context, Effect } from 'effect';
import { listen } from './listen.js';

class RequestTime extends Context.Tag('RequestTime')<RequestTime, number>() {}

const requestTime = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    return yield* app.pipe(Effect.provideService(RequestTime, Date.now()));
  })
);

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/',
    Effect.gen(function* () {
      const requestTime = yield* RequestTime;
      const responseText =
        `Hello World<br/><small>Requested at: ${requestTime}</small>`;
      return yield* HttpServer.response.html(responseText);
    }),
  ),
);

const app = router.pipe(
  HttpServer.router.use(requestTime),
  HttpServer.server.serve(),
);

listen(app, 3000);
```

Now, when you make a request to the root path, the response will include the timestamp of the request.

### Middleware `validateCookies`

Finally, we'll create a middleware that validates incoming cookies. If the cookies are invalid, it sends a 400 response.

Here's an example that validates cookies using an external service:

```ts
class CookieError {
  readonly _tag = 'CookieError';
}

const externallyValidateCookie = (testCookie: string | undefined) =>
  testCookie && testCookie.length > 0
    ? Effect.succeed(testCookie)
    : Effect.fail(new CookieError());

const cookieValidator = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    const req = yield* HttpServer.request.ServerRequest;
    yield* externallyValidateCookie(req.cookies.testCookie);
    return yield* app;
  }).pipe(
    Effect.catchTag(
      'CookieError',
      () => HttpServer.response.text('Invalid cookie'),
    ),
  )
);
```

Update the app to use the `cookieValidator` middleware:

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

class CookieError {
  readonly _tag = 'CookieError';
}

const externallyValidateCookie = (testCookie: string | undefined) =>
  testCookie && testCookie.length > 0
    ? Effect.succeed(testCookie)
    : Effect.fail(new CookieError());

const cookieValidator = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    const req = yield* HttpServer.request.ServerRequest;
    yield* externallyValidateCookie(req.cookies.testCookie);
    return yield* app;
  }).pipe(
    Effect.catchTag(
      'CookieError',
      () => HttpServer.response.text('Invalid cookie'),
    ),
  )
);

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);

const app = router.pipe(
  HttpServer.router.use(cookieValidator),
  HttpServer.server.serve(),
);

listen(app, 3000);
```

Test the middleware with the following commands:

```sh
curl -i http://localhost:3000
curl -i http://localhost:3000 --cookie "testCookie=myvalue"
curl -i http://localhost:3000 --cookie "testCookie="
```

This setup validates the `testCookie` and returns "Invalid cookie" if the validation fails, or "Hello World" if it passes.

## Applying Middleware in Your Application

Middleware functions are powerful tools that allow you to modify the request-response cycle. Middlewares can be applied at various levels to achieve different scopes of influence:

- **Route Level**: Apply middleware to individual routes.
- **Router Level**: Apply middleware to a group of routes within a single router.
- **Server Level**: Apply middleware across all routes managed by a server.

### Applying Middleware at the Route Level

At the route level, middlewares are applied to specific endpoints, allowing for targeted modifications or enhancements such as logging, authentication, or parameter validation for a particular route.

**Example**

Hereâ€™s a practical example showing how to apply middleware at the route level:

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Middleware constructor that logs the name of the middleware
const withMiddleware = (name: string) =>
  HttpServer.middleware.make((app) =>
    Effect.gen(function* () {
      console.log(name); // Log the middleware name when the route is accessed
      return yield* app; // Continue with the original application flow
    })
  );

const router = HttpServer.router.empty.pipe(
  // Applying middleware to route "/a"
  HttpServer.router.get(
    '/a',
    HttpServer.response.text('a').pipe(withMiddleware('M1')),
  ),
  // Applying middleware to route "/b"
  HttpServer.router.get(
    '/b',
    HttpServer.response.text('b').pipe(withMiddleware('M2')),
  ),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

**Testing the Middleware**

You can test the middleware by making requests to the respective routes and observing the console output:

```sh
# Test route /a
curl -i http://localhost:3000/a
# Expected console output: M1

# Test route /b
curl -i http://localhost:3000/b
# Expected console output: M2
```

### Applying Middleware at the Router Level

Applying middleware at the router level is an efficient way to manage common functionalities across multiple routes within your application. Middleware can handle tasks such as logging, authentication, and response modifications before reaching the actual route handlers.

**Example**

Hereâ€™s how you can structure and apply middleware across different routers using the `@effect/platform` library:

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Middleware constructor that logs the name of the middleware
const withMiddleware = (name: string) =>
  HttpServer.middleware.make((app) =>
    Effect.gen(function* () {
      console.log(name); // Log the middleware name when a route is accessed
      return yield* app; // Continue with the original application flow
    })
  );

// Define Router1 with specific routes
const router1 = HttpServer.router.empty.pipe(
  HttpServer.router.get('/a', HttpServer.response.text('a')), // Middleware M4, M3, M1 will apply
  HttpServer.router.get('/b', HttpServer.response.text('b')), // Middleware M4, M3, M1 will apply
  // Apply Middleware at the router level
  HttpServer.router.use(withMiddleware('M1')),
  HttpServer.router.get('/c', HttpServer.response.text('c')), // Middleware M4, M3 will apply
);

// Define Router2 with specific routes
const router2 = HttpServer.router.empty.pipe(
  HttpServer.router.get('/d', HttpServer.response.text('d')), // Middleware M4, M2 will apply
  HttpServer.router.get('/e', HttpServer.response.text('e')), // Middleware M4, M2 will apply
  HttpServer.router.get('/f', HttpServer.response.text('f')), // Middleware M4, M2 will apply
  // Apply Middleware at the router level
  HttpServer.router.use(withMiddleware('M2')),
);

// Main router combining Router1 and Router2
const router = HttpServer.router.empty.pipe(
  HttpServer.router.mount('/r1', router1),
  // Apply Middleware affecting all routes under /r1
  HttpServer.router.use(withMiddleware('M3')),
  HttpServer.router.get('/g', HttpServer.response.text('g')), // Only Middleware M4 will apply
  HttpServer.router.mount('/r2', router2),
  // Apply Middleware affecting all routes
  HttpServer.router.use(withMiddleware('M4')),
);

// Configure the application with the server middleware
const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

**Testing the Middleware**

To ensure that the middleware is working as expected, you can test it by making HTTP requests to the defined routes and checking the console output for middleware logs:

```sh
# Test route /a under router1
curl -i http://localhost:3000/r1/a
# Expected console output: M4 M3 M1

# Test route /c under router1
curl -i http://localhost:3000/r1/c
# Expected console output: M4 M3

# Test route /d under router2
curl -i http://localhost:3000/r2/d
# Expected console output: M4 M2

# Test route /g under the main router
curl -i http://localhost:3000/g
# Expected console output: M4
```

### Applying Middleware at the Server Level

Applying middleware at the server level allows you to introduce certain functionalities, such as logging, authentication, or general request processing, that affect every request handled by the server. This ensures that all incoming requests, regardless of the route, pass through the applied middleware, making it an essential feature for global error handling, logging, or authentication.

**Example**

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Middleware constructor that logs the name of the middleware
const withMiddleware = (name: string) =>
  HttpServer.middleware.make((app) =>
    Effect.gen(function* () {
      console.log(name); // Log the middleware name when the route is accessed
      return yield* app; // Continue with the original application flow
    })
  );

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/a',
    HttpServer.response.text('a').pipe(withMiddleware('M1')),
  ),
  HttpServer.router.get('/b', HttpServer.response.text('b')),
  HttpServer.router.use(withMiddleware('M2')),
  HttpServer.router.get('/', HttpServer.response.text('root')),
);

const app = router.pipe(HttpServer.server.serve(withMiddleware('M3')));

listen(app, 3000);
```

**Testing the Middleware**

To confirm the middleware is functioning as intended, you can send HTTP requests to the defined routes and check the console for middleware logs:

```sh
# Test route /a and observe the middleware logs
curl -i http://localhost:3000/a
# Expected console output: M3 M2 M1  - Middleware M3 (server-level), M2 (router-level), and M1 (route-level) apply.

# Test route /b and observe the middleware logs
curl -i http://localhost:3000/b
# Expected console output: M3 M2  - Middleware M3 (server-level) and M2 (router-level) apply.

# Test route / and observe the middleware logs
curl -i http://localhost:3000/
# Expected console output: M3 M2  - Middleware M3 (server-level) and M2 (router-level) apply.
```

### Applying Multiple Middlewares

Middleware functions are simply functions that transform a `Default` app into another `Default` app. This flexibility allows for stacking multiple middleware functions, much like composing functions in functional programming. The `flow` function from the `Effect` library facilitates this by enabling function composition.

**Example**

```ts
import { HttpServer } from '@effect/platform';
import { Effect, flow } from 'effect';
import { listen } from './listen.js';

// Middleware constructor that logs the middleware's name when a route is accessed
const withMiddleware = (name: string) =>
  HttpServer.middleware.make((app) =>
    Effect.gen(function* () {
      console.log(name); // Log the middleware name
      return yield* app; // Continue with the original application flow
    })
  );

// Setup routes and apply multiple middlewares using flow for function composition
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/a',
    HttpServer.response
      .text('a')
      .pipe(flow(withMiddleware('M1'), withMiddleware('M2'))),
  ),
  HttpServer.router.get('/b', HttpServer.response.text('b')),
  // Apply combined middlewares to the entire router
  HttpServer.router.use(flow(withMiddleware('M3'), withMiddleware('M4'))),
  HttpServer.router.get('/', HttpServer.response.text('root')),
);

// Apply combined middlewares at the server level
const app = router.pipe(
  HttpServer.server.serve(flow(withMiddleware('M5'), withMiddleware('M6'))),
);

listen(app, 3000);
```

**Testing the Middleware Composition**

To verify that the middleware is functioning as expected, you can send HTTP requests to the routes and check the console for the expected middleware log output:

```sh
# Test route /a to see the output from multiple middleware layers
curl -i http://localhost:3000/a
# Expected console output: M6 M5 M4 M3 M2 M1

# Test route /b where fewer middleware are applied
curl -i http://localhost:3000/b
# Expected console output: M6 M5 M4 M3

# Test the root route to confirm top-level middleware application
curl -i http://localhost:3000/
# Expected console output: M6 M5
```

## Built-in middleware

### Middleware Summary

| Middleware            | Description                                                                                                                       |
| --------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| **Logger**            | Provides detailed logging of all requests and responses, aiding in debugging and monitoring application activities.               |
| **xForwardedHeaders** | Manages `X-Forwarded-*` headers to accurately maintain client information such as IP addresses and host names in proxy scenarios. |

### logger

The `HttpServer.middleware.logger` middleware enables logging for your entire application, providing insights into each request and response. Hereâ€™s how to set it up:

```ts
import { HttpServer } from '@effect/platform';
import { listen } from './listen.js';

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
);

// Apply the logger middleware globally
const app = router.pipe(HttpServer.server.serve(HttpServer.middleware.logger));

listen(app, 3000);
/*
curl -i http://localhost:3000
timestamp=... level=INFO fiber=#0 message="Listening on http://0.0.0.0:3000"
timestamp=... level=INFO fiber=#19 message="Sent HTTP response" http.span.1=8ms http.status=200 http.method=GET http.url=/
timestamp=... level=INFO fiber=#20 cause="RouteNotFound: GET /favicon.ico not found
    at ...
    at http.server GET" http.span.2=4ms http.status=500 http.method=GET http.url=/favicon.ico
*/
```

To disable the logger for specific routes, you can use `HttpServer.middleware.withLoggerDisabled`:

```ts
import { HttpServer } from '@effect/platform';
import { listen } from './listen.js';

// Create the router with routes that will and will not have logging
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('Hello World')),
  HttpServer.router.get(
    '/no-logger',
    HttpServer.response
      .text('no-logger')
      .pipe(HttpServer.middleware.withLoggerDisabled),
  ),
);

// Apply the logger middleware globally
const app = router.pipe(HttpServer.server.serve(HttpServer.middleware.logger));

listen(app, 3000);
/*
curl -i http://localhost:3000/no-logger
timestamp=2024-05-19T09:53:29.877Z level=INFO fiber=#0 message="Listening on http://0.0.0.0:3000"
*/
```

### xForwardedHeaders

This middleware handles `X-Forwarded-*` headers, useful when your app is behind a reverse proxy or load balancer and you need to retrieve the original client's IP and host information.

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Create a router and a route that logs request headers and remote address
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/',
    Effect.gen(function* () {
      const req = yield* HttpServer.request.ServerRequest;
      console.log(req.headers);
      console.log(req.remoteAddress);
      return yield* HttpServer.response.text('Hello World');
    }),
  ),
);

// Set up the server with xForwardedHeaders middleware
const app = router.pipe(
  HttpServer.server.serve(HttpServer.middleware.xForwardedHeaders),
);

listen(app, 3000);
/*
curl -H "X-Forwarded-Host: 192.168.1.1" -H "X-Forwarded-For: 192.168.1.1" http://localhost:3000
timestamp=... level=INFO fiber=#0 message="Listening on http://0.0.0.0:3000"
{
  host: '192.168.1.1',
  'user-agent': 'curl/8.6.0',
  accept: '*\/*',
  'x-forwarded-host': '192.168.1.1',
  'x-forwarded-for': '192.168.1.1'
}
{ _id: 'Option', _tag: 'Some', value: '192.168.1.1' }
*/
```

## Error Handling

### Catching Errors

Below is an example illustrating how to catch and manage errors that occur during the execution of route handlers:

```ts
import { HttpServer } from '@effect/platform';
import { Effect } from 'effect';
import { listen } from './listen.js';

// Define routes that might throw errors or fail
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/throw',
    Effect.sync(() => {
      throw new Error('BROKEN'); // This will intentionally throw an error
    }),
  ),
  HttpServer.router.get('/fail', Effect.fail('Uh oh!')), // This will intentionally fail
);

// Configure the application to handle different types of errors
const app = router.pipe(
  Effect.catchTags({
    RouteNotFound: () =>
      HttpServer.response.text('Route Not Found', { status: 404 }),
  }),
  Effect.catchAllCause((cause) =>
    HttpServer.response.text(cause.toString(), { status: 500 })
  ),
  HttpServer.server.serve(),
);

listen(app, 3000);
```

You can test the error handling setup with `curl` commands by trying to access routes that trigger errors:

```sh
# Accessing a route that does not exist
curl -i http://localhost:3000/nonexistent

# Accessing the route that throws an error
curl -i http://localhost:3000/throw

# Accessing the route that fails
curl -i http://localhost:3000/fail
```

## Validations

Validation is a critical aspect of handling HTTP requests to ensure that the data your server receives is as expected. We'll explore how to validate headers and cookies using the `@effect/platform` and `@effect/schema` libraries, which provide structured and robust methods for these tasks.

### Headers

Headers often contain important information needed by your application, such as content types, authentication tokens, or session data. Validating these headers ensures that your application can trust and correctly process the information it receives.

```ts
import { HttpServer } from '@effect/platform';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { listen } from './listen.js';

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/',
    Effect.gen(function* () {
      // Define the schema for expected headers and validate them
      const headers = yield* HttpServer.request.schemaHeaders(
        Schema.Struct({ test: Schema.String }),
      );
      return yield* HttpServer.response.text('header: ' + headers.test);
    }).pipe(
      // Handle parsing errors
      Effect.catchTag(
        'ParseError',
        (e) => HttpServer.response.text(`Invalid header: ${e.message}`),
      ),
    ),
  ),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

You can test header validation using the following `curl` commands:

```sh
# Request without the required header
curl -i http://localhost:3000

# Request with the valid header
curl -i -H "test: myvalue" http://localhost:3000
```

### Cookies

Cookies are commonly used to maintain session state or user preferences. Validating cookies ensures that the data they carry is intact and as expected, enhancing security and application integrity.

Hereâ€™s how you can validate cookies received in HTTP requests:

```ts
import { HttpServer } from '@effect/platform';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { listen } from './listen.js';

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/',
    Effect.gen(function* () {
      const cookies = yield* HttpServer.request.schemaCookies(
        Schema.Struct({ test: Schema.String }),
      );
      return yield* HttpServer.response.text('cookie: ' + cookies.test);
    }).pipe(
      Effect.catchTag(
        'ParseError',
        (e) => HttpServer.response.text(`Invalid cookie: ${e.message}`),
      ),
    ),
  ),
);

const app = router.pipe(HttpServer.server.serve());

listen(app, 3000);
```

Validate the cookie handling with the following `curl` commands:

```sh
# Request without any cookies
curl -i http://localhost:3000

# Request with the valid cookie
curl -i http://localhost:3000 --cookie "test=myvalue"
```

## ServerRequest

### How do I get the raw request?

The native request object depends on the platform you are using, and it is not directly modeled in `@effect/platform`. Instead, you need to refer to the specific platform package you are working with, such as `@effect/platform-node` or `@effect/platform-bun`.

Here is an example using Node.js:

```ts
import { HttpServer } from '@effect/platform';
import { NodeHttpServer } from '@effect/platform-node';
import { Effect } from 'effect';
import { listen } from './listen.js';

const router = HttpServer.router.empty.pipe(
  HttpServer.router.get(
    '/',
    Effect.gen(function* () {
      const req = yield* HttpServer.request.ServerRequest;
      const raw = NodeHttpServer.request.toIncomingMessage(req);
      console.log(raw);
      return HttpServer.response.empty();
    }),
  ),
);

listen(HttpServer.server.serve(router), 3000);
```

## Conversions

### toWebHandler

The `toWebHandler` function converts a `Default` (i.e. a type of `HttpApp` that specifically produces a `ServerResponse` as its output) into a web handler that can process `Request` objects and return `Response` objects.

```ts
import * as HttpServer from '@effect/platform/HttpServer';

// Define the router with some routes
const router = HttpServer.router.empty.pipe(
  HttpServer.router.get('/', HttpServer.response.text('content 1')),
  HttpServer.router.get('/foo', HttpServer.response.text('content 2')),
);

// Convert the router to a web handler
// const handler: (request: Request) => Promise<Response>
const handler = HttpServer.app.toWebHandler(router);

// Test the handler with a request
const response = await handler(new Request('http://localhost:3000/foo'));
console.log(await response.text()); // Output: content 2
```

# README.md

# Pretty Printer for Effect-TS

- [Pretty Printer for Effect-TS](#pretty-printer-for-effect-ts)
  - [Installation](#installation)
    - [`@effect/printer`](#effectprinter)
  - [Overview](#overview)
  - [Simple Example](#simple-example)
  - [General Workflow](#general-workflow)
  - [How the Layout Works](#how-the-layout-works)
    - [Available Width](#available-width)
    - [Grouping](#grouping)
  - [Things the Pretty Printer Cannot Do](#things-the-pretty-printer-cannot-do)
  - [Helpful Tips](#helpful-tips)
    - [Which kind of annotation should I use?](#which-kind-of-annotation-should-i-use)
  - [Acknowledgements](#acknowledgements)

## Installation

### `@effect/printer`

```bash
npm install @effect/printer
```

```bash
pnpm install @effect/printer
```

```bash
yarn add @effect/printer
```

## Overview

This module defines a pretty printer to format text in a flexible and convenient way. The idea is to combine a `Doc`ument out of many small components, then using a layouter to convert it to an easily renderable `DocStream`, which can then be rendered to a variety of formats.

The document consists of several parts:

1. Just below is some general information about the library
2. The actual library with extensive documentation and examples

## Simple Example

As a simple demonstration, let's use `@effect/printer` to pretty-print the following simple Haskell type definition.

```haskell
example :: Int -> Bool -> Char -> IO ()
```

First, let's setup the imports we need:

```ts
import * as Doc from '@effect/printer/Doc';
import * as Render from '@effect/printer/Render';
import * as Array from 'effect/Array';
import { pipe } from 'effect/Function';
```

Next, we intersperse the `"->"` character between our types and add a leading `"::"` character:

```ts
const prettyTypes = (types: ReadonlyArray<string>): Doc.Doc<never> => {
  const symbolDocuments = pipe(
    Array.makeBy(types.length - 1, () => Doc.text('->')),
    Array.prepend(Doc.text('::')),
  );
  const typeDocuments = types.map(Doc.text);
  const documents = pipe(
    Array.zipWith(
      symbolDocuments,
      typeDocuments,
      (left, right) => Doc.catWithSpace(left, right),
    ),
  );
  return Doc.align(Doc.seps(documents));
};
```

The `seps` function is one way of concatenating documents, but there are many others (e.g. `vsep`, `cat` and `fillSep`, etc.). In our example, `seps` is used to space-separate all documents if there is space remaining in the current line, and newlines if the remaining line is too short.

Next, we prepend the name to the type,

```ts
const prettyDeclaration = (
  name: string,
  types: ReadonlyArray<string>,
): Doc.Doc<never> => Doc.catWithSpace(Doc.text(name), prettyTypes(types));
```

Now we can define a document that contains some type signature:

```ts
const name = 'example';
const types = ['Int', 'Bool', 'Char', 'IO ()'];
const doc: Doc.Doc<never> = prettyDeclaration(name, types);
```

This document can now be printed! And as a bonus, it automatically adapts to available space.

If the page is wide enough (`80` characters in this case), the definitions are space-separated.

```ts
const rendered = Render.prettyDefault(doc);
console.log(rendered);
// example :: Int -> Bool -> Char -> IO ()
```

If we narrow the page width to only `20` characters, the same document renders vertically aligned:

```ts
const rendered = Render.pretty(doc, { lineWidth: 20 });
console.log(rendered);
// example :: Int
//         -> Bool
//         -> Char
//         -> IO ()
```

Speaking of alignment, had we not used the `align` combinators, the `"->"` would be at the beginning of each line, and not beneath the `"::"`.

## General Workflow

```text
â•”â•â•â•â•â•â•â•â•â•â•â•—
â•‘          â•‘                         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘                         â”‚ vsep, pretty, <+>, â”‚
â•‘          â•‘                         â”‚ nest, align, â€¦     â”‚
â•‘          â•‘                         â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•‘          â•‘                                   â”‚
â•‘  Create  â•‘                                   â”‚
â•‘          â•‘                                   â”‚
â•‘          â•‘                                   â–½
â•‘          â•‘                         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘                         â”‚        Doc        â”‚
â• â•â•â•â•â•â•â•â•â•â•â•£                         â”‚  (rich document)  â”‚
â•‘          â•‘                         â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•‘          â•‘                                   â”‚
â•‘          â•‘                                   â”‚ Layout algorithms
â•‘  Layout  â•‘                                   â”‚ e.g. Layout.pretty
â•‘          â•‘                                   â–½
â•‘          â•‘                         â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘                         â”‚     DocStream     â”‚
â• â•â•â•â•â•â•â•â•â•â•â•£                         â”‚ (simple document) â”‚
â•‘          â•‘                         â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•‘          â•‘                                   â”‚
â•‘          â•‘                                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘                                   â”‚                             â”‚ treeForm
â•‘          â•‘                                   â”‚                             â–½
â•‘          â•‘                                   â”‚                     â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘                                   â”‚                     â”‚    DocTree    â”‚
â•‘  Render  â•‘                                   â”‚                     â•°â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â•¯
â•‘          â•‘                                   â”‚                             â”‚
â•‘          â•‘               â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘               â”‚                   â”‚                 â”‚  â”‚                 â”‚
â•‘          â•‘               â–½                   â–½                 â–½  â–½                 â–½
â•‘          â•‘       â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â•‘          â•‘       â”‚ ANSI terminal â”‚   â”‚  Plain Text   â”‚   â”‚ other/custom  â”‚   â”‚     HTML      â”‚
â•‘          â•‘       â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•‘          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•
```

## How the Layout Works

There are two key concepts to laying a document out: the available width, and grouping.

### Available Width

The layout algorithm will try to avoid exceeding the maximum width of the `Doc`ument by inserting line breaks where possible. The available layout combinators make it fairly straightforward to specify where, and under what circumstances, such a line break may be inserted by the layout algorithm (for example via the `seps` function).

There is also the concept of ribbon width. The ribbon is the part of a line that is printed (i.e. the line length without the leading indentation). The layout algorithms take a ribbon fraction argument, which specifies how much of a line should be filled before trying to break it up. A ribbon width of 0.5 in a document of width 80 will result in the layout algorithm trying to avoid exceeding `0.5 * 80 = 40` (ignoring current indentation depth).

### Grouping

A document can be `group`ed, which tells the layout algorithm that it should attempt to collapse it to a single line. If the result does not fit within the constraints (given by page and ribbon widths), the document is rendered unaltered. This allows fallback renderings, so that we get nice results even when the original document would exceed the layout constraints.

## Things the Pretty Printer Cannot Do

Due to how the Wadler/Leijen algorithm is designed, a couple of things are unsupported right now, with a high possibility of having no sensible implementation without significantly changing the layout algorithm. In particular, this includes:

- Leading symbols instead of just spaces for indentation (as used by the Linux tree tool, for example)
- Multi-column layouts, in particular tables with multiple cells of equal width adjacent to each other

## Helpful Tips

### Which kind of annotation should I use?

TL;DR - Use semantic annotations for `Doc`, and after laying out the `Doc, only then map to backend-specific annotations.

For example, suppose you want to pretty-print some programming language code. If you want keywords to be red, you should annotate the `Doc` with a type that has a `Keyword` field (without any notion of color), and then after laying out the document, convert the annotations to map `Keyword` to `Red` (using `DocStream.reAnnotate`). The alternative (which is not recommended) is directly annotating the `Doc` with `Red`.

While both versions would work equally well, and would create identical output, the recommended way has two significant advantages: modularity and extensibility.

**Modularity**: Changing the color of `Keyword`s after laying out a `Doc`ument means that there is only one modification needed (namely the call to `DocStream.reAnnotate`) should the color of `Keyword`s need to be changed in the future. If you have directly annotated `Doc`uments with the color `Red`, a full text search/replacement would be required should the color need to be changed.

**Extensibility**: Adding a different rendering of a `Keyword` in the recommended version is as simple as adding a variant of `DocStream.reAnnotate` to convert the `Doc` annotation to something else. On the other hand, let's assume you have `Red` as an annotation in the `Doc` and the backend you would like to implement does not have the notion of color (think of plain text or a website where red doesnâ€™t work well with the rest of the style). You now need to worry what to map _redness_ to, which in this case has no canonical answer. Should it be omitted? What does _red_ mean in the context of the new backend? Additionally, consider the case where keywords and variables have already been annotated as red, but you want to change only the color of variables.

## Acknowledgements

This package is a port of https://github.com/quchen/prettyprinter

# README.md

# Introduction

Welcome to the documentation for `@effect/schema`, **a library for defining and using schemas** to validate and transform data in TypeScript.

`@effect/schema` allows you to define a `Schema<Type, Encoded, Context>` that provides a blueprint for describing the structure and data types of your data. Once defined, you can leverage this schema to perform a range of operations, including:

| Operation       | Description                                                                                                    |
| --------------- | -------------------------------------------------------------------------------------------------------------- |
| Decoding        | Transforming data from an input type `Encoded` to an output type `Type`.                                       |
| Encoding        | Converting data from an output type `Type` back to an input type `Encoded`.                                    |
| Asserting       | Verifying that a value adheres to the schema's output type `Type`.                                             |
| Arbitraries     | Generate arbitraries for [fast-check](https://github.com/dubzzz/fast-check) testing.                           |
| Pretty printing | Support pretty printing for data structures.                                                                   |
| JSON Schemas    | Create JSON Schemas based on defined schemas.                                                                  |
| Equivalence     | Create [Equivalences](https://effect-ts.github.io/effect/schema/Equivalence.ts.html) based on defined schemas. |

If you're eager to learn how to define your first schema, jump straight to the [**Basic usage**](#basic-usage) section!

## The Schema Type

The `Schema<Type, Encoded, Context>` type represents an immutable value that describes the structure of your data.

The `Schema` type has three type parameters with the following meanings:

- **Type**. Represents the type of value that a schema can succeed with during decoding.
- **Encoded**. Represents the type of value that a schema can succeed with during encoding. By default, it's equal to `Type` if not explicitly provided.
- **Context**. Similar to the [`Effect`](https://effect.website/docs/guides/essentials/the-effect-type) type, it represents the contextual data required by the schema to execute both decoding and encoding. If this type parameter is `never` (default if not explicitly provided), it means the schema has no requirements.

**Examples**

- `Schema<string>` (defaulted to `Schema<string, string, never>`) represents a schema that decodes to `string`, encodes to `string`, and has no requirements.
- `Schema<number, string>` (defaulted to `Schema<number, string, never>`) represents a schema that decodes to `number` from `string`, encodes a `number` to a `string`, and has no requirements.

> [!NOTE]
> In the Effect ecosystem, you may often encounter the type parameters of `Schema` abbreviated as `A`, `I`, and `R` respectively. This is just shorthand for the type value of type **A**, **I**nput, and **R**equirements.

`Schema` values are immutable, and all `@effect/schema` functions produce new `Schema` values.

`Schema` values do not actually do anything, they are just values that model or describe the structure of your data.

`Schema` values don't perform any actions themselves; they simply describe the structure of your data. A `Schema` can be interpreted by various "compilers" into specific operations, depending on the compiler type (decoding, encoding, pretty printing, arbitraries, etc.).

## Understanding Decoding and Encoding

```mermaid
sequenceDiagram
    participant UA as unknown
    participant A
    participant I
    participant UI as unknown
    UI->>A: decodeUnknown
    I->>A: decode
    A->>I: encode
    UA->>I: encodeUnknown
    UA->>A: validate
    UA->>A: is
    UA->>A: asserts
```

We'll break down these concepts using an example with a `Schema<Date, string, never>`. This schema serves as a tool to transform a `string` into a `Date` and vice versa.

**Encoding**

When we talk about "encoding," we are referring to the process of changing a `Date` into a `string`. To put it simply, it's the act of converting data from one format to another.

**Decoding**

Conversely, "decoding" entails transforming a `string` back into a `Date`. It's essentially the reverse operation of encoding, where data is returned to its original form.

**Decoding From Unknown**

Decoding from `unknown` involves two key steps:

1. **Checking:** Initially, we verify that the input data (which is of the `unknown` type) matches the expected structure. In our specific case, this means ensuring that the input is indeed a `string`.

2. **Decoding:** Following the successful check, we proceed to convert the `string` into a `Date`. This process completes the decoding operation, where the data is both validated and transformed.

**Encoding From Unknown**

Encoding from `unknown` involves two key steps:

1. **Checking:** Initially, we verify that the input data (which is of the `unknown` type) matches the expected structure. In our specific case, this means ensuring that the input is indeed a `Date`.

2. **Encoding:** Following the successful check, we proceed to convert the `Date` into a `string`. This process completes the encoding operation, where the data is both validated and transformed.

> [!NOTE]
> As a general rule, schemas should be defined such that encode + decode return the original value.

### Recap

- **Decoding:** Used for parsing data from external sources where you have no control over the data format.
- **Encoding:** Used when sending data out to external sources, converting it to a format that is expected by those sources.

For instance, when working with forms in the frontend, you often receive untyped data in the form of strings. This data can be tampered with and does not natively support arrays or booleans. Decoding helps you validate and parse this data into more useful types like numbers, dates, and arrays. Encoding allows you to convert these types back into the string format expected by forms.

By understanding these processes, you can ensure that your data handling is robust and reliable, converting data safely between different formats.

## The Rule of Schemas: Keeping Encode and Decode in Sync

When working with schemas, there's an important rule to keep in mind: your schemas should be crafted in a way that when you perform both encoding and decoding operations, you should end up with the original value.

In simpler terms, if you encode a value and then immediately decode it, the result should match the original value you started with. This rule ensures that your data remains consistent and reliable throughout the encoding and decoding process.

# Requirements

- TypeScript 5.0 or newer
- The `strict` flag enabled in your `tsconfig.json` file
- The `exactOptionalPropertyTypes` flag enabled in your `tsconfig.json` file
  ```
  {
    // ...
    "compilerOptions": {
      // ...
      "strict": true,
      "exactOptionalPropertyTypes": true
    }
  }
  ```
- Additionally, make sure to install the following packages, as they are peer dependencies. Note that some package managers might not install peer dependencies by default, so you need to install them manually:
  - `effect` package (peer dependency)
  - [fast-check](https://github.com/dubzzz/fast-check) package (peer dependency)

## Understanding `exactOptionalPropertyTypes`

The `@effect/schema` library takes advantage of the `exactOptionalPropertyTypes` option of `tsconfig.json`. This option affects how optional properties are typed (to learn more about this option, you can refer to the official [TypeScript documentation](https://www.typescriptlang.org/tsconfig#exactOptionalPropertyTypes)).

Let's delve into this with an example.

**With `exactOptionalPropertyTypes` Enabled**

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.optional(Schema.String.pipe(Schema.nonEmpty()), {
    exact: true,
  }),
});

/*
type Type = {
    readonly name?: string; // the type is strict (no `| undefined`)
}
*/
type Type = Schema.Schema.Type<typeof Person>;

Schema.decodeSync(Person)({ name: undefined });
/*
TypeScript Error:
Argument of type '{ name: undefined; }' is not assignable to parameter of type '{ readonly name?: string; }' with 'exactOptionalPropertyTypes: true'. Consider adding 'undefined' to the types of the target's properties.
  Types of property 'name' are incompatible.
    Type 'undefined' is not assignable to type 'string'.ts(2379)
*/
```

Here, notice that the type of `name` is "exact" (`string`), which means the type checker will catch any attempt to assign an invalid value (like `undefined`).

**With `exactOptionalPropertyTypes` Disabled**

If, for some reason, you can't enable the `exactOptionalPropertyTypes` option (perhaps due to conflicts with other third-party libraries), you can still use `@effect/schema`. However, there will be a mismatch between the types and the runtime behavior:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.optional(Schema.String.pipe(Schema.nonEmpty()), {
    exact: true,
  }),
});

/*
type Type = {
    readonly name?: string | undefined; // the type is widened to string | undefined
}
*/
type Type = Schema.Schema.Type<typeof Person>;

Schema.decodeSync(Person)({ name: undefined }); // No type error, but a decoding failure occurs
/*
Error: { name?: a non empty string }
â””â”€ ["name"]
   â””â”€ a non empty string
      â””â”€ From side refinement failure
         â””â”€ Expected a string, actual undefined
*/
```

In this case, the type of `name` is widened to `string | undefined`, which means the type checker won't catch the invalid value (`undefined`). However, during decoding, you'll encounter an error, indicating that `undefined` is not allowed.

# Getting started

To install the **alpha** version:

```
npm install @effect/schema
```

Additionally, make sure to install the following packages, as they are peer dependencies. Note that some package managers might not install peer dependencies by default, so you need to install them manually:

- `effect` package (peer dependency)

> [!WARNING]
> This package is primarily published to receive early feedback and for contributors, during this development phase we cannot guarantee the stability of the APIs, consider each **minor** release to contain breaking changes.

Once you have installed the library, you can import the necessary types and functions from the `@effect/schema/Schema` module.

**Example** (Namespace Import)

```ts
import * as Schema from '@effect/schema/Schema';
```

**Example** (Named Import)

```ts
import { Schema } from '@effect/schema';
```

## Defining a schema

One common way to define a `Schema` is by utilizing the `struct` constructor provided by `@effect/schema`. This function allows you to create a new `Schema` that outlines an object with specific properties. Each property in the object is defined by its own `Schema`, which specifies the data type and any validation rules.

For example, consider the following `Schema` that describes a person object with a `name` property of type `string` and an `age` property of type `number`:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});
```

> [!NOTE]
> It's important to note that by default, most constructors exported by `@effect/schema` return `readonly` types. For instance, in the `Person` schema above, the resulting type would be `{ readonly name: string; readonly age: number; }`.

## Extracting Inferred Types

### Type

Once you've defined a `Schema<A, I, R>`, you can extract the inferred type `A`, which represents the data described by the schema, in two ways:

- Using the `Schema.Schema.Type` utility.
- Using the `Type` field defined on your schema.

For example, you can extract the inferred type of a `Person` object as demonstrated below:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.NumberFromString,
});

// 1. Using the Schema.Type utility
type Person = Schema.Schema.Type<typeof Person>;
/*
Equivalent to:
interface Person {
  readonly name: string;
  readonly age: number;
}
*/

// 2. Using the `Type` field
type Person2 = typeof Person.Type;
```

Alternatively, you can define the `Person` type using the `interface` keyword:

```ts
interface Person extends Schema.Schema.Type<typeof Person> {}
/*
Equivalent to:
type Person {
  readonly name: string;
  readonly age: number;
}
*/
```

Both approaches yield the same result, but using an interface provides benefits such as performance advantages and improved readability.

### Encoded

In cases where in a `Schema<A, I>` the `I` type differs from the `A` type, you can also extract the inferred `I` type using the `Schema.Encoded` utility (or the `Encoded` field defined on your schema).

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.NumberFromString,
});

// 1. Using the Schema.Encoded utility
type PersonEncoded = Schema.Schema.Encoded<typeof Person>;
/*
type PersonEncoded = {
    readonly name: string;
    readonly age: string;
}
*/

// 2. Using the `Encoded` field
type PersonEncoded2 = typeof Person.Encoded;
```

### Context

You can also extract the inferred type `R` that represents the context described by the schema using the `Schema.Context` utility:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.NumberFromString,
});

// type PersonContext = never
type PersonContext = Schema.Schema.Context<typeof Person>;
```

### Advanced extracting Inferred Types

To create a schema with an opaque type, you can use the following technique that re-declares the schema:

```ts
import { Schema } from '@effect/schema';

const _Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

interface Person extends Schema.Schema.Type<typeof _Person> {}

// Re-declare the schema to create a schema with an opaque type
const Person: Schema.Schema<Person> = _Person;
```

Alternatively, you can use the `Class` APIs (see the [Class](#classes) section below for more details).

Note that the technique shown above becomes more complex when the schema is defined such that `A` is different from `I`. For example:

```ts
import { Schema } from '@effect/schema';

const _Person = Schema.Struct({
  name: Schema.String,
  age: Schema.NumberFromString,
});

interface Person extends Schema.Schema.Type<typeof _Person> {}

interface PersonEncoded extends Schema.Schema.Encoded<typeof _Person> {}

// Re-declare the schema to create a schema with an opaque type
const Person: Schema.Schema<Person, PersonEncoded> = _Person;
```

In this case, the field `"age"` is of type `string` in the `Encoded` type of the schema and is of type `number` in the `Type` type of the schema. Therefore, we need to define **two** interfaces (`PersonEncoded` and `Person`) and use both to redeclare our final schema `Person`.

## Decoding From Unknown Values

When working with unknown data types in TypeScript, decoding them into a known structure can be challenging. Luckily, `@effect/schema` provides several functions to help with this process. Let's explore how to decode unknown values using these functions.

### Using `decodeUnknown*` Functions

The `@effect/schema/Schema` module offers a variety of `decodeUnknown*` functions, each tailored for different decoding scenarios:

- `decodeUnknownSync`: Synchronously decodes a value and throws an error if parsing fails.
- `decodeUnknownOption`: Decodes a value and returns an `Option` type.
- `decodeUnknownEither`: Decodes a value and returns an `Either` type.
- `decodeUnknownPromise`: Decodes a value and returns a `Promise`.
- `decodeUnknown`: Decodes a value and returns an `Effect`.

**Example** (Using `decodeUnknownSync`)

Let's begin with an example using the `decodeUnknownSync` function. This function is useful when you want to parse a value and immediately throw an error if the parsing fails.

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

// Simulate an unknown input
const input: unknown = { name: 'Alice', age: 30 };

console.log(Schema.decodeUnknownSync(Person)(input));
// Output: { name: 'Alice', age: 30 }

console.log(Schema.decodeUnknownSync(Person)(null));
/*
throws:
Error: Expected { readonly name: string; readonly age: number }, actual null
*/
```

**Example** (Using `decodeUnknownEither`)

Now, let's see how to use the `decodeUnknownEither` function, which returns an `Either` type representing success or failure.

```ts
import { Schema } from '@effect/schema';
import { Either } from 'effect';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const decode = Schema.decodeUnknownEither(Person);

// Simulate an unknown input
const input: unknown = { name: 'Alice', age: 30 };

const result1 = decode(input);
if (Either.isRight(result1)) {
  console.log(result1.right);
  /*
  Output:
  { name: "Alice", age: 30 }
  */
}

const result2 = decode(null);
if (Either.isLeft(result2)) {
  console.log(result2.left);
  /*
  Output:
  {
    _id: 'ParseError',
    message: 'Expected { readonly name: string; readonly age: number }, actual null'
  }
  */
}
```

The `decode` function returns an `Either<A, ParseError>`, where `ParseError` is defined as follows:

```ts
interface ParseError {
  readonly _tag: 'ParseError';
  readonly issue: ParseIssue;
}
```

Here, `ParseIssue` represents an error that might occur during the parsing process. It is wrapped in a tagged error to make it easier to catch errors using `Effect.catchTag`. The result `Either<A, ParseError>` contains the inferred data type described by the schema. A successful parse yields a `Right` value with the parsed data `A`, while a failed parse results in a `Left` value containing a `ParseError`.

### Handling Async Transformations

When your schema involves asynchronous transformations, neither the `decodeUnknownSync` nor the `decodeUnknownEither` functions will work for you. In such cases, you must turn to the `decodeUnknown` function, which returns an `Effect`.

```ts
import { Schema } from '@effect/schema';
import { Effect } from 'effect';

const PersonId = Schema.Number;

const Person = Schema.Struct({
  id: PersonId,
  name: Schema.String,
  age: Schema.Number,
});

const asyncSchema = Schema.transformOrFail(PersonId, Person, {
  // Simulate an async transformation
  decode: (id) =>
    Effect.succeed({ id, name: 'name', age: 18 }).pipe(
      Effect.delay('10 millis'),
    ),
  encode: (person) => Effect.succeed(person.id).pipe(Effect.delay('10 millis')),
});

const syncParsePersonId = Schema.decodeUnknownEither(asyncSchema);

console.log(JSON.stringify(syncParsePersonId(1), null, 2));
/*
Output:
{
  "_id": "Either",
  "_tag": "Left",
  "left": {
    "_id": "ParseError",
    "message": "(number <-> { readonly id: number; readonly name: string; readonly age: number })\nâ””â”€ cannot be be resolved synchronously, this is caused by using runSync on an effect that performs async work"
  }
}
*/

const asyncParsePersonId = Schema.decodeUnknown(asyncSchema);

Effect.runPromise(asyncParsePersonId(1)).then(console.log);
/*
Output:
{ id: 1, name: 'name', age: 18 }
*/
```

As shown in the code above, the first approach returns a `Forbidden` error, indicating that using `decodeUnknownEither` with an async transformation is not allowed. However, the second approach works as expected, allowing you to handle async transformations and return the desired result.

### Excess properties

When using a `Schema` to parse a value, by default any properties that are not specified in the `Schema` will be stripped out from the output. This is because the `Schema` is expecting a specific shape for the parsed value, and any excess properties do not conform to that shape.

However, you can use the `onExcessProperty` option (default value: `"ignore"`) to trigger a parsing error. This can be particularly useful in cases where you need to detect and handle potential errors or unexpected values.

Here's an example of how you might use `onExcessProperty` set to `"error"`:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

console.log(
  Schema.decodeUnknownSync(Person)({
    name: 'Bob',
    age: 40,
    email: 'bob@example.com',
  }),
);
/*
Output:
{ name: 'Bob', age: 40 }
*/

Schema.decodeUnknownSync(Person)(
  {
    name: 'Bob',
    age: 40,
    email: 'bob@example.com',
  },
  { onExcessProperty: 'error' },
);
/*
throws
Error: { readonly name: string; readonly age: number }
â””â”€ ["email"]
   â””â”€ is unexpected, expected "name" | "age"
*/
```

If you want to allow excess properties to remain, you can use `onExcessProperty` set to `"preserve"`:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

console.log(
  Schema.decodeUnknownSync(Person)(
    {
      name: 'Bob',
      age: 40,
      email: 'bob@example.com',
    },
    { onExcessProperty: 'preserve' },
  ),
);
/*
{ email: 'bob@example.com', name: 'Bob', age: 40 }
*/
```

> [!NOTE]
> The [`onExcessProperty`](#excess-properties) and [`error`](#all-errors) options also affect encoding.

### All errors

The `errors` option allows you to receive all parsing errors when attempting to parse a value using a schema. By default only the first error is returned, but by setting the `errors` option to `"all"`, you can receive all errors that occurred during the parsing process. This can be useful for debugging or for providing more comprehensive error messages to the user.

Here's an example of how you might use `errors`:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

Schema.decodeUnknownSync(Person)(
  {
    name: 'Bob',
    age: 'abc',
    email: 'bob@example.com',
  },
  { errors: 'all', onExcessProperty: 'error' },
);
/*
throws
Error: { readonly name: string; readonly age: number }
â”œâ”€ ["email"]
â”‚  â””â”€ is unexpected, expected "name" | "age"
â””â”€ ["age"]
   â””â”€ Expected a number, actual "abc"
*/
```

> [!NOTE]
> The [`onExcessProperty`](#excess-properties) and [`error`](#all-errors) options also affect encoding.

### Managing Property Order

The `propertyOrder` option provides control over the order of object fields in the output. This feature is particularly useful when the sequence of keys is important for the consuming processes or when maintaining the input order enhances readability and usability.

By default, the `propertyOrder` option is set to `"none"`. This means that the internal system decides the order of keys to optimize parsing speed. The order of keys in this mode should not be considered stable, and it's recommended not to rely on key ordering as it may change in future updates without notice.

Setting `propertyOrder` to `"original"` ensures that the keys are ordered as they appear in the input during the decoding/encoding process.

**Example** (Synchronous Decoding)

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  a: Schema.Number,
  b: Schema.Literal('b'),
  c: Schema.Number,
});

// Decoding an object synchronously without specifying the property order
console.log(Schema.decodeUnknownSync(schema)({ b: 'b', c: 2, a: 1 }));
// Output decided internally: { b: 'b', a: 1, c: 2 }

// Decoding an object synchronously while preserving the order of properties as in the input
console.log(
  Schema.decodeUnknownSync(schema)(
    { b: 'b', c: 2, a: 1 },
    { propertyOrder: 'original' },
  ),
);
// Output preserving input order: { b: 'b', c: 2, a: 1 }
```

**Example** (Asynchronous Decoding)

```ts
import { ParseResult, Schema } from '@effect/schema';
import type { Duration } from 'effect';
import { Effect } from 'effect';

// Function to simulate an asynchronous process within the schema
const effectify = (duration: Duration.DurationInput) =>
  Schema.Number.pipe(
    Schema.transformOrFail(Schema.Number, {
      decode: (x) =>
        Effect.sleep(duration).pipe(Effect.andThen(ParseResult.succeed(x))),
      encode: ParseResult.succeed,
    }),
  );

// Define a structure with asynchronous behavior in each field
const schema = Schema.Struct({
  a: effectify('200 millis'),
  b: effectify('300 millis'),
  c: effectify('100 millis'),
}).annotations({ concurrency: 3 });

// Decoding data asynchronously without preserving order
Schema.decode(schema)({ a: 1, b: 2, c: 3 })
  .pipe(Effect.runPromise)
  .then(console.log);
// Output decided internally: { c: 3, a: 1, b: 2 }

// Decoding data asynchronously while preserving the original input order
Schema.decode(schema)({ a: 1, b: 2, c: 3 }, { propertyOrder: 'original' })
  .pipe(Effect.runPromise)
  .then(console.log);
// Output preserving input order: { a: 1, b: 2, c: 3 }
```

### Managing Missing Properties

When using the `@effect/schema` library to handle data structures, it's important to understand how missing properties are processed. By default, if a property is not present in the input, it is treated as if it were present with an `undefined` value.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({ a: Schema.Unknown });
const input = {};

console.log(Schema.decodeUnknownSync(schema)(input)); // Output: { a: undefined }
```

In this example, although the key `"a"` is not present in the input, it is treated as `{ a: undefined }` by default.

If your validation logic needs to distinguish between truly missing properties and those that are explicitly undefined, you can enable the `exact` option:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({ a: Schema.Unknown });
const input = {};

console.log(Schema.decodeUnknownSync(schema)(input, { exact: true }));
/*
throws
Error: { readonly a: unknown }
â””â”€ ["a"]
   â””â”€ is missing
*/
```

For the APIs `is` and `asserts`, however, the default behavior is to treat missing properties strictly, where the default for `exact` is `true`:

```ts
import type { AST } from '@effect/schema';
import { Schema } from '@effect/schema';

const schema = Schema.Struct({ a: Schema.Unknown });
const input = {};

console.log(Schema.is(schema)(input)); // Output: false
console.log(Schema.is(schema)(input, { exact: false })); // Output: true

const asserts: (
  u: unknown,
  overrideOptions?: AST.ParseOptions,
) => asserts u is {
  readonly a: unknown;
} = Schema.asserts(schema);

try {
  asserts(input);
  console.log('asserts passed');
} catch (e: any) {
  console.error('asserts failed');
  console.error(e.message);
}
/*
Output:
asserts failed
{ readonly a: unknown }
â””â”€ ["a"]
  â””â”€ is missing
*/

try {
  asserts(input, { exact: false });
  console.log('asserts passed');
} catch (e: any) {
  console.error('asserts failed');
  console.error(e.message);
}
// Output: asserts passed
```

## Encoding

The `@effect/schema/Schema` module provides several `encode*` functions to encode data according to a schema:

- `encodeSync`: Synchronously encodes data and throws an error if encoding fails.
- `encodeOption`: Encodes data and returns an `Option` type.
- `encodeEither`: Encodes data and returns an `Either` type representing success or failure.
- `encodePromise`: Encodes data and returns a `Promise`.
- `encode`: Encodes data and returns an `Effect`.

Let's consider an example where we have a schema for a `Person` object with a `name` property of type `string` and an `age` property of type `number`.

```ts
import * as S from '@effect/schema/Schema';

import { Schema } from '@effect/schema';

// Age is a schema that can decode a string to a number and encode a number to a string
const Age = Schema.NumberFromString;

const Person = Schema.Struct({
  name: Schema.NonEmpty,
  age: Age,
});

console.log(Schema.encodeSync(Person)({ name: 'Alice', age: 30 }));
// Output: { name: 'Alice', age: '30' }

console.log(Schema.encodeSync(Person)({ name: '', age: 30 }));
/*
throws:
Error: { readonly name: NonEmpty; readonly age: NumberFromString }
â””â”€ ["name"]
   â””â”€ NonEmpty
      â””â”€ Predicate refinement failure
         â””â”€ Expected NonEmpty (a non empty string), actual ""
*/
```

Note that during encoding, the number value `30` was converted to a string `"30"`.

> [!NOTE]
> The [`onExcessProperty`](#excess-properties) and [`error`](#all-errors) options also affect encoding.

### Handling Unsupported Encoding

Although it is generally recommended to define schemas that support both decoding and encoding, there are situations where encoding support might be impossible. In such cases, the `Forbidden` error can be used to handle unsupported encoding.

Here is an example of a transformation that never fails during decoding. It returns an `Either` containing either the decoded value or the original input. For encoding, it is reasonable to not support it and use `Forbidden` as the result.

```ts
import { ParseResult, Schema } from '@effect/schema';
import { Either } from 'effect';

// Define a schema that safely decodes to Either type
export const SafeDecode = <A, I>(self: Schema.Schema<A, I, never>) => {
  const decodeUnknownEither = Schema.decodeUnknownEither(self);
  return Schema.transformOrFail(
    Schema.Unknown,
    Schema.EitherFromSelf({
      left: Schema.Unknown,
      right: Schema.typeSchema(self),
    }),
    {
      strict: true,
      decode: (input) =>
        ParseResult.succeed(
          Either.mapLeft(decodeUnknownEither(input), () => input),
        ),
      encode: (actual, _, ast) =>
        Either.match(actual, {
          onLeft: () =>
            ParseResult.fail(
              new ParseResult.Forbidden(ast, actual, 'cannot encode a Left'),
            ),
          onRight: ParseResult.succeed,
        }),
    },
  );
};
```

**Explanation**

- **Decoding**: The `SafeDecode` function ensures that decoding never fails. It wraps the decoded value in an `Either`, where a successful decoding results in a `Right` and a failed decoding results in a `Left` containing the original input.

- **Encoding**: The encoding process uses the `Forbidden` error to indicate that encoding a `Left` value is not supported. Only `Right` values are successfully encoded.

## Formatting Errors

When you're working with Effect Schema and encounter errors during decoding, or encoding functions, you can format these errors in two different ways: using the `TreeFormatter` or the `ArrayFormatter`.

### TreeFormatter (default)

The `TreeFormatter` is the default method for formatting errors. It organizes errors in a tree structure, providing a clear hierarchy of issues.

Here's an example of how it works:

```ts
import { Schema, TreeFormatter } from '@effect/schema';
import { Either } from 'effect';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const decode = Schema.decodeUnknownEither(Person);

const result = decode({});
if (Either.isLeft(result)) {
  console.error('Decoding failed:');
  console.error(TreeFormatter.formatErrorSync(result.left));
}
/*
Decoding failed:
{ readonly name: string; readonly age: number }
â””â”€ ["name"]
   â””â”€ is missing
*/
```

In this example, the tree error message is structured as follows:

- `{ name: string; age: number }` represents the schema, providing a visual representation of the expected structure. This can be customized using annotations, such as setting the `identifier` annotation.
- `["name"]` indicates the offending property, in this case, the `"name"` property.
- `is missing` represents the specific error for the `"name"` property.

**Handling Multiple Errors**

By default, decoding functions like `decodeUnknownEither` return only the first encountered error. If you require a comprehensive list of all errors, you can modify the behavior by passing the `{ errors: "all" }` option:

```ts
import { Schema, TreeFormatter } from '@effect/schema';
import { Either } from 'effect';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const decode = Schema.decodeUnknownEither(Person, { errors: 'all' });

const result = decode({});
if (Either.isLeft(result)) {
  console.error('Decoding failed:');
  console.error(TreeFormatter.formatErrorSync(result.left));
}
/*
Decoding failed:
{ readonly name: string; readonly age: number }
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["age"]
   â””â”€ is missing
*/
```

This adjustment ensures that the formatter displays all errors related to the input, providing a more detailed diagnostic of what went wrong.

#### ParseIssueTitle Annotation

When a decoding or encoding operation fails, it's useful to have additional details in the default error message returned by `TreeFormatter` to understand exactly which value caused the operation to fail. To achieve this, you can set an annotation that depends on the value undergoing the operation and can return an excerpt of it, making it easier to identify the problematic value. A common scenario is when the entity being validated has an `id` field. The `ParseIssueTitle` annotation facilitates this kind of analysis during error handling.

The type of the annotation is:

```ts
export type ParseIssueTitleAnnotation = (
  issue: ParseIssue,
) => string | undefined;
```

If you set this annotation on a schema and the provided function returns a `string`, then that string is used as the title by `TreeFormatter`, unless a `message` annotation (which has the highest priority) has also been set. If the function returns `undefined`, then the default title used by `TreeFormatter` is determined with the following priorities:

- `identifier`
- `title`
- `description`
- `ast.toString()`

**Example**

```ts
import type { ParseResult } from '@effect/schema';
import { Schema } from '@effect/schema';

const getOrderItemId = ({ actual }: ParseResult.ParseIssue) => {
  if (Schema.is(Schema.Struct({ id: Schema.String }))(actual)) {
    return `OrderItem with id: ${actual.id}`;
  }
};

const OrderItem = Schema.Struct({
  id: Schema.String,
  name: Schema.String,
  price: Schema.Number,
}).annotations({
  identifier: 'OrderItem',
  parseIssueTitle: getOrderItemId,
});

const getOrderId = ({ actual }: ParseResult.ParseIssue) => {
  if (Schema.is(Schema.Struct({ id: Schema.Number }))(actual)) {
    return `Order with id: ${actual.id}`;
  }
};

const Order = Schema.Struct({
  id: Schema.Number,
  name: Schema.String,
  items: Schema.Array(OrderItem),
}).annotations({
  identifier: 'Order',
  parseIssueTitle: getOrderId,
});

const decode = Schema.decodeUnknownSync(Order, { errors: 'all' });

// No id available, so the `identifier` annotation is used as the title
decode({});
/*
throws
Error: Order
â”œâ”€ ["id"]
â”‚  â””â”€ is missing
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["items"]
   â””â”€ is missing
*/

// An id is available, so the `parseIssueTitle` annotation is used as the title
decode({ id: 1 });
/*
throws
Error: Order with id: 1
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["items"]
   â””â”€ is missing
*/

decode({ id: 1, items: [{ id: '22b', price: '100' }] });
/*
throws
Error: Order with id: 1
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["items"]
   â””â”€ ReadonlyArray<OrderItem>
      â””â”€ [0]
         â””â”€ OrderItem with id: 22b
            â”œâ”€ ["name"]
            â”‚  â””â”€ is missing
            â””â”€ ["price"]
               â””â”€ Expected a number, actual "100"
*/
```

In the examples above, we can see how the `parseIssueTitle` annotation helps provide meaningful error messages when decoding fails.

### ArrayFormatter

The `ArrayFormatter` offers an alternative method for formatting errors within `@effect/schema`, organizing them into a more structured and easily navigable array format. This formatter is especially useful when you need a clear overview of all issues detected during the decoding or encoding processes.

The `ArrayManager` formats errors as an array of objects, where each object represents a distinct issue and includes properties such as `_tag`, `path`, and `message`. This structured format can help developers quickly identify and address multiple issues in data processing.

Here's an example of how it works:

```ts
import { ArrayFormatter, Schema } from '@effect/schema';
import { Either } from 'effect';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const decode = Schema.decodeUnknownEither(Person);

const result = decode({});
if (Either.isLeft(result)) {
  console.error('Decoding failed:');
  console.error(ArrayFormatter.formatErrorSync(result.left));
}
/*
Decoding failed:
[ { _tag: 'Missing', path: [ 'name' ], message: 'is missing' } ]
*/
```

Each error is formatted as an object in an array, making it clear what the error is (`is missing`), where it occurred (`name`), and its type (`Missing`).

**Handling Multiple Errors**

By default, decoding functions like `decodeUnknownEither` return only the first encountered error. If you require a comprehensive list of all errors, you can modify the behavior by passing the `{ errors: "all" }` option:

```ts
import { ArrayFormatter, Schema } from '@effect/schema';
import { Either } from 'effect';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const decode = Schema.decodeUnknownEither(Person, { errors: 'all' });

const result = decode({});
if (Either.isLeft(result)) {
  console.error('Decoding failed:');
  console.error(ArrayFormatter.formatErrorSync(result.left));
}
/*
Decoding failed:
[
  { _tag: 'Missing', path: [ 'name' ], message: 'is missing' },
  { _tag: 'Missing', path: [ 'age' ], message: 'is missing' }
]
*/
```

### React Hook Form

If you are working with React and need form validation, `@hookform/resolvers` offers an adapter for `@effect/schema`, which can be integrated with React Hook Form for enhanced form validation processes. This integration allows you to leverage the powerful features of `@effect/schema` within your React applications.

For more detailed instructions and examples on how to integrate `@effect/schema` with React Hook Form using `@hookform/resolvers`, you can visit the official npm package page:
[React Hook Form Resolvers](https://www.npmjs.com/package/@hookform/resolvers#effect-ts)

## Type Guards

The `Schema.is` function provided by the `@effect/schema/Schema` module represents a way of verifying that a value conforms to a given `Schema`. It functions as a [type guard](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#using-type-predicates), taking a value of type `unknown` and determining if it matches the structure and type constraints defined in the schema.

Here's how the `Schema.is` function works

1. **Schema Definition**: Define a schema to describe the structure and constraints of the data type you expect. For instance, `Schema<A, I, R>` where `A` is the desired type.

2. **Type Guard Creation**: Convert the schema into a user-defined type guard `(u: unknown) => u is A`. This allows you to assert at runtime whether a value meets the specified schema.

The type `I`, typically used in schema transformations, does not influence the generation of the type guard. The primary focus is on ensuring that the input conforms to the desired type `A`.

**Example Usage**:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

/*
const isPerson: (a: unknown, options?: number | ParseOptions) => a is {
    readonly name: string;
    readonly age: number;
}
*/
const isPerson = Schema.is(Person);

console.log(isPerson({ name: 'Alice', age: 30 })); // true
console.log(isPerson(null)); // false
console.log(isPerson({})); // false
```

## Assertions

While type guards verify and inform about type conformity, the `Schema.asserts` function takes it a step further by asserting that an input matches the schema `A` type (from `Schema<A, I, R>`). If the input does not match, it throws a detailed error.

**Example Usage**:

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

// equivalent to: (input: unknown, options?: ParseOptions) => asserts input is { readonly name: string; readonly age: number; }
const assertsPerson: Schema.Schema.ToAsserts<typeof Person> = Schema.asserts(
  Person,
);

try {
  assertsPerson({ name: 'Alice', age: '30' });
} catch (e) {
  console.error('The input does not match the schema:');
  console.error(e);
}
/*
The input does not match the schema:
Error: { readonly name: string; readonly age: number }
â””â”€ ["age"]
   â””â”€ Expected a number, actual "30"
*/

// this will not throw an error
assertsPerson({ name: 'Alice', age: 30 });
```

## Generating Arbitraries

The `make` function within the `@effect/schema/Arbitrary` module allows for the creation of random values that align with a specific `Schema<A, I, R>`. This utility returns an `Arbitrary<A>` from the [fast-check](https://github.com/dubzzz/fast-check) library, which is particularly useful for generating random test data that adheres to the defined schema constraints.

```ts
import { Arbitrary, FastCheck, Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.NumberFromString.pipe(Schema.int(), Schema.between(0, 200)),
});

/*
FastCheck.Arbitrary<{
    readonly name: string;
    readonly age: number;
}>
*/
const PersonArbitraryType = Arbitrary.make(Person);

console.log(FastCheck.sample(PersonArbitraryType, 2));
/*
Example Output:
[ { name: 'q r', age: 1 }, { name: '&|', age: 133 } ]
*/

/*
Arbitrary for the "Encoded" type:
FastCheck.Arbitrary<{
    readonly name: string;
    readonly age: string;
}>
*/
const PersonArbitraryEncoded = Arbitrary.make(Schema.encodedSchema(Person));

console.log(FastCheck.sample(PersonArbitraryEncoded, 2));
/*
Example Output:
[ { name: 'key', age: '' }, { name: 'Gm', age: 'q' } ]
*/
```

### Understanding Schema Transformations and Arbitrary Generation

The generation of arbitrary data requires a clear understanding of how transformations and filters are applied within a schema:

- **Transformations and Filters**: Only the filters applied after the last transformation in the transformation chain are considered during arbitrary generation.

```ts
import { Arbitrary, FastCheck, Schema } from '@effect/schema';

const schema1 = Schema.compose(Schema.NonEmpty, Schema.Trim).pipe(
  Schema.maxLength(500),
);
// Might output empty strings despite `NonEmpty` due to filter order.
console.log(FastCheck.sample(Arbitrary.make(schema1), 10));

const schema2 = Schema.Trim.pipe(Schema.nonEmpty(), Schema.maxLength(500));
// Ensures no empty strings, correctly applying `nonEmpty()`.
console.log(FastCheck.sample(Arbitrary.make(schema2), 10));
```

**Explanation:**

- **Schema 1**: Considers the `Schema.maxLength(500)` because it follows the `Schema.Trim` transformation but disregards `Schema.NonEmpty` as it comes before any transformations.
- **Schema 2**: Properly adheres to all applied filters by ensuring they follow transformations, thus avoiding the generation of undesired data.

**Best Practices**

Organize transformations and filters to ensure clarity and effectiveness in data generation. Follow the pattern: `(I filters) -> (transformations) -> (A filters)` where "I" and "A" stand for the initial and transformed types in the schema.

"I" and "A" represent the initial and final types in the schema, ensuring that each stage of data processing is clearly defined.

Instead of indiscriminately combining transformations and filters:

```ts
import { Schema } from '@effect/schema';

// Less optimal mixing of transformations and filters
const schema = Schema.compose(
  // transformation + filter
  Schema.Lowercase,
  // transformation + filter
  Schema.Trim,
);
```

Prefer separating transformation steps from filter applications:

```ts
import { Schema } from '@effect/schema';

// Recommended approach: Separate transformations from filters
const schema = Schema.transform(
  Schema.String,
  Schema.String.pipe(Schema.trimmed(), Schema.lowercased()),
  {
    decode: (s) => s.trim().toLowerCase(),
    encode: (s) => s,
  },
);
```

### Customizations

You can customize the output by using the `arbitrary` annotation:

```ts
import { Arbitrary, FastCheck, Schema } from '@effect/schema';

const schema = Schema.Number.annotations({
  arbitrary: () => (fc) => fc.nat(),
});

const arb = Arbitrary.make(schema);

console.log(FastCheck.sample(arb, 2));
// Output: [ 1139348969, 749305462 ]
```

> [!WARNING]
> Customizing a schema can disrupt previously applied filters. Filters set after the customization will remain effective, while those applied before will be disregarded.

**Example**

```ts
import { Arbitrary, FastCheck, Schema } from '@effect/schema';

// Here, the 'positive' filter is overridden by the custom arbitrary definition
const problematic = Schema.Number.pipe(Schema.positive()).annotations({
  arbitrary: () => (fc) => fc.integer(),
});

console.log(FastCheck.sample(Arbitrary.make(problematic), 2));
// Example Output: [ -1600163302, -6 ]

// Here, the 'positive' filter is applied after the arbitrary customization, ensuring it is considered
const improved = Schema.Number.annotations({
  arbitrary: () => (fc) => fc.integer(),
}).pipe(Schema.positive());

console.log(FastCheck.sample(Arbitrary.make(improved), 2));
// Example Output: [ 7, 1518247613 ]
```

## Pretty print

The `make` function provided by the `@effect/schema/Pretty` module represents a way of pretty-printing values that conform to a given `Schema`.

You can use the `make` function to create a human-readable string representation of a value that conforms to a `Schema`. This can be useful for debugging or logging purposes, as it allows you to easily inspect the structure and data types of the value.

```ts
import { Pretty, Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

const PersonPretty = Pretty.make(Person);

// returns a string representation of the object
console.log(PersonPretty({ name: 'Alice', age: 30 }));
/*
Output:
'{ "name": "Alice", "age": 30 }'
*/
```

### Customizations

You can customize the output using the `pretty` annotation:

```ts
import { Pretty, Schema } from '@effect/schema';

const schema = Schema.Number.annotations({
  pretty: () => (n) => `my format: ${n}`,
});

console.log(Pretty.make(schema)(1)); // my format: 1
```

## Generating JSON Schemas

The `make` function from the `@effect/schema/JSONSchema` module enables you to create a JSON Schema based on a defined schema:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number,
});

const jsonSchema = JSONSchema.make(Person);

console.log(JSON.stringify(jsonSchema, null, 2));
/*
Output:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [
    "age",
    "name"
  ],
  "properties": {
    "age": {
      "type": "number",
      "description": "a number",
      "title": "number"
    },
    "name": {
      "type": "string",
      "description": "a non empty string",
      "title": "NonEmpty",
      "minLength": 1
    }
  },
  "additionalProperties": false
}
*/
```

In this example, we have created a schema for a "Person" with a name (a non-empty string) and an age (a number). We then use the `JSONSchema.make` function to generate the corresponding JSON Schema.

Note that `JSONSchema.make` attempts to produce the optimal JSON Schema for the input part of the decoding phase. This means that starting from the most nested schema, it traverses the chain, including each refinement, and stops at the first transformation found.

For instance, if we modify the schema of the `age` field:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number.pipe(
    // refinement, will be included in the generated JSON Schema
    Schema.int(),
    // transformation, will be excluded in the generated JSON Schema
    Schema.clamp(1, 10),
  ),
});

const jsonSchema = JSONSchema.make(Person);

console.log(JSON.stringify(jsonSchema, null, 2));
```

We can see that the new JSON Schema generated for the `age` field is of type `"integer"`, retaining the useful refinement (being an integer) and excluding the transformation (clamping between `1` and `10`):

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": ["name", "age"],
  "properties": {
    "name": {
      "type": "string",
      "description": "a non empty string",
      "title": "NonEmpty",
      "minLength": 1
    },
    "age": {
      "type": "integer",
      "description": "an integer",
      "title": "integer"
    }
  },
  "additionalProperties": false
}
```

### Identifier Annotations

You can enhance your schemas with `identifier` annotations. If you do, your schema will be included within a "definitions" object property on the root and referenced from there:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const Name = Schema.String.annotations({ identifier: 'Name' });
const Age = Schema.Number.annotations({ identifier: 'Age' });
const Person = Schema.Struct({
  name: Name,
  age: Age,
});

const jsonSchema = JSONSchema.make(Person);

console.log(JSON.stringify(jsonSchema, null, 2));
/*
Output:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [
    "name",
    "age"
  ],
  "properties": {
    "name": {
      "$ref": "#/$defs/Name"
    },
    "age": {
      "$ref": "#/$defs/Age"
    }
  },
  "additionalProperties": false,
  "$defs": {
    "Name": {
      "type": "string",
      "description": "a string",
      "title": "string"
    },
    "Age": {
      "type": "number",
      "description": "a number",
      "title": "number"
    }
  }
}
*/
```

This technique helps organize your JSON Schema by creating separate definitions for each identifier annotated schema, making it more readable and maintainable.

### Standard JSON Schema Annotations

Standard JSON Schema annotations such as `title`, `description`, `default`, and `Examples` are supported:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const schema = Schema.Struct({
  foo: Schema.optional(
    Schema.String.annotations({
      description: 'an optional string field',
      title: 'foo',
      examples: ['a', 'b'],
    }).pipe(Schema.compose(Schema.Trim)),
    {
      default: () => '',
    },
  ).annotations({ description: 'a required, trimmed string field' }),
});

// Generate a JSON Schema for the input part
console.log(JSON.stringify(JSONSchema.make(schema), null, 2));
/*
Output:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [],
  "properties": {
    "foo": {
      "type": "string",
      "description": "an optional string field",
      "title": "foo",
      "examples": [
        "a",
        "b"
      ]
    }
  },
  "additionalProperties": false,
  "title": "Struct (Encoded side)"
}
*/

// Generate a JSON Schema for the output part
console.log(
  JSON.stringify(JSONSchema.make(Schema.typeSchema(schema)), null, 2),
);
/*
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [
    "foo"
  ],
  "properties": {
    "foo": {
      "type": "string",
      "description": "a required string field",
      "title": "Trimmed",
      "pattern": "^.*[a-zA-Z0-9]+.*$"
    }
  },
  "additionalProperties": false,
  "title": "Struct (Type side)"
}
*/
```

### Recursive and Mutually Recursive Schemas

Recursive and mutually recursive schemas are supported, but in these cases, identifier annotations are **required**:

```ts
import { JSONSchema, Schema } from '@effect/schema';

interface Category {
  readonly name: string;
  readonly categories: ReadonlyArray<Category>;
}

const schema = Schema.Struct({
  name: Schema.String,
  categories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => schema),
  ),
}).annotations({ identifier: 'Category' });

const jsonSchema = JSONSchema.make(schema);

console.log(JSON.stringify(jsonSchema, null, 2));
/*
Output:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$ref": "#/$defs/Category",
  "$defs": {
    "Category": {
      "type": "object",
      "required": [
        "name",
        "categories"
      ],
      "properties": {
        "name": {
          "type": "string",
          "description": "a string",
          "title": "string"
        },
        "categories": {
          "type": "array",
          "items": {
            "$ref": "#/$defs/Category"
          }
        }
      },
      "additionalProperties": false
    }
  }
}
*/
```

In the example above, we define a schema for a "Category" that can contain a "name" (a string) and an array of nested "categories." To support recursive definitions, we use the `S.suspend` function and identifier annotations to name our schema.

This ensures that the JSON Schema properly handles the recursive structure and creates distinct definitions for each annotated schema, improving readability and maintainability.

### Custom JSON Schema Annotations

When working with JSON Schema in the `@effect/schema` library, certain data types, such as `bigint`, lack a direct representation because JSON Schema does not natively support them. This absence typically leads to an error when the schema is generated:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const schema = Schema.Struct({
  a_bigint_field: Schema.BigIntFromSelf,
});

// Attempt to generate JSON Schema throws an error due to unsupported type
console.log('%o', JSONSchema.make(schema));
/*
throws:
Error: cannot build a JSON Schema for `bigint` without a JSON Schema annotation (path ["a_bigint_field"])
*/
```

To address this, you can enhance the schema with a custom annotation, defining how you intend to represent such types in JSON Schema:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const schema = Schema.Struct({
  a_bigint_field: Schema.BigIntFromSelf.annotations({
    jsonSchema: { type: 'some custom way to encode a bigint in JSON Schema' },
  }),
});

// Now the JSON Schema generation will include the custom representation
console.log('%o', JSONSchema.make(schema));
/*
Output:
{
  '$schema': 'http://json-schema.org/draft-07/schema#',
  type: 'object',
  required: [ 'a_bigint_field', [length]: 1 ],
  properties: {
    a_bigint_field: { type: 'some custom way to encode a bigint in JSON Schema' }
  },
  additionalProperties: false
}
*/
```

When defining a **refinement** (e.g., through the `filter` function), you can attach a JSON Schema annotation to your schema containing a JSON Schema "fragment" related to this particular refinement. This fragment will be used to generate the corresponding JSON Schema. Note that if the schema consists of more than one refinement, the corresponding annotations will be merged.

> Note:
>
> The `jsonSchema` property is intentionally defined as a generic object. This allows it to describe non-standard extensions.
> As a result, the responsibility of enforcing type constraints is left to you, the user.
> If you prefer stricter type enforcement or need to support non-standard extensions, you can introduce a `satisfies` constraint on the object literal. This constraint should be used in conjunction with the typing library of your choice.
>
> In the following example, we've used the `@types/json-schema` package to provide TypeScript definitions for JSON Schema. This approach not only ensures type correctness but also enables autocomplete suggestions in your IDE.

```ts
import { JSONSchema, Schema } from '@effect/schema';
import type { JSONSchema7 } from 'json-schema';

// Simulate one or more refinements
const Positive = Schema.Number.pipe(
  Schema.filter((n) => n > 0, {
    jsonSchema: { minimum: 0 }, // `jsonSchema` is a generic object; you can add any key-value pair without type errors or autocomplete suggestions.
  }),
);

const schema = Positive.pipe(
  Schema.filter((n) => n <= 10, {
    jsonSchema: { maximum: 10 } satisfies JSONSchema7, //  Now `jsonSchema` is constrained to fulfill the JSONSchema7 type; incorrect properties will trigger type errors, and you'll get autocomplete suggestions.
  }),
);

const jsonSchema = JSONSchema.make(schema);

console.log(JSON.stringify(jsonSchema, null, 2));
/*
Output:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "number",
  "description": "a number",
  "title": "number",
  "minimum": 0,
  "maximum": 10
}
*/
```

For all other types of schema that are not refinements, the content of the annotation is used and overrides anything the system would have generated by default:

```ts
import { JSONSchema, Schema } from '@effect/schema';

const schema = Schema.Struct({ foo: Schema.String }).annotations({
  jsonSchema: { type: 'object' },
});

const jsonSchema = JSONSchema.make(schema);

console.log(JSON.stringify(jsonSchema, null, 2));
/*
Output
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object"
}
the default would be:
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "required": [
    "foo"
  ],
  "properties": {
    "foo": {
      "type": "string",
      "description": "a string",
      "title": "string"
    }
  },
  "additionalProperties": false
}
*/
```

## Generating Equivalences

The `make` function, which is part of the `@effect/schema/Equivalence` module, allows you to generate an [Equivalence](https://effect-ts.github.io/effect/schema/Equivalence.ts.html) based on a schema definition:

```ts
import { Equivalence, Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

// $ExpectType Equivalence<{ readonly name: string; readonly age: number; }>
const PersonEquivalence = Equivalence.make(Person);

const john = { name: 'John', age: 23 };
const alice = { name: 'Alice', age: 30 };

console.log(PersonEquivalence(john, { name: 'John', age: 23 })); // Output: true
console.log(PersonEquivalence(john, alice)); // Output: false
```

### Customizations

You can customize the output using the `equivalence` annotation:

```ts
import { Equivalence, Schema } from '@effect/schema';

const schema = Schema.String.annotations({
  equivalence: () => (a, b) => a.at(0) === b.at(0),
});

console.log(Equivalence.make(schema)('aaa', 'abb')); // Output: true
```

# Basic Usage

## Cheatsheet

| Typescript Type                              | Description / Notes                      | Schema / Combinator                                       |
| -------------------------------------------- | ---------------------------------------- | --------------------------------------------------------- |
| `null`                                       |                                          | `S.Null`                                                  |
| `undefined`                                  |                                          | `S.Undefined`                                             |
| `string`                                     |                                          | `S.String`                                                |
| `number`                                     |                                          | `S.Number`                                                |
| `boolean`                                    |                                          | `S.Boolean`                                               |
| `symbol`                                     |                                          | `S.SymbolFromSelf` / `S.Symbol`                           |
| `BigInt`                                     |                                          | `S.BigIntFromSelf` / `S.BigInt`                           |
| `unknown`                                    |                                          | `S.Unknown`                                               |
| `any`                                        |                                          | `S.Any`                                                   |
| `never`                                      |                                          | `S.Never`                                                 |
| `object`                                     |                                          | `S.Object`                                                |
| `unique symbol`                              |                                          | `S.UniqueSymbolFromSelf`                                  |
| `"a"`, `1`, `true`                           | type literals                            | `S.Literal("a")`, `S.Literal(1)`, `S.Literal(true)`       |
| `a${string}`                                 | template literals                        | `S.TemplateLiteral("a", S.String)`                        |
| `{ readonly a: string, readonly b: number }` | structs                                  | `S.Struct({ a: S.String, b: S.Number })`                  |
| `{ readonly a?: string \| undefined }`       | optional fields                          | `S.Struct({ a: S.optional(S.String) })`                   |
| `{ readonly a?: string }`                    | optional fields                          | `S.Struct({ a: S.optional(S.String, { exact: true }) })`  |
| `Record<A, B>`                               | records                                  | `S.Record(A, B)`                                          |
| `readonly [string, number]`                  | tuples                                   | `S.Tuple(S.String, S.Number)`                             |
| `ReadonlyArray<string>`                      | arrays                                   | `S.Array(S.String)`                                       |
| `A \| B`                                     | unions                                   | `S.Union(A, B)`                                           |
| `A & B`                                      | intersections of non-overlapping structs | `S.extend(A, B)`                                          |
| `Record<A, B> & Record<C, D>`                | intersections of non-overlapping records | `S.extend(S.Record(A, B), S.Record(C, D))`                |
| `type A = { readonly a: A \| null }`         | recursive types                          | `S.Struct({ a: S.Union(S.Null, S.suspend(() => self)) })` |
| `keyof A`                                    |                                          | `S.keyof(A)`                                              |
| `partial<A>`                                 |                                          | `S.partial(A)`                                            |
| `required<A>`                                |                                          | `S.required(A)`                                           |

## Primitives

Here are the primitive schemas provided by the `@effect/schema/Schema` module:

```ts
import { Schema } from '@effect/schema';

Schema.String; // Schema<string>
Schema.Number; // Schema<number>
Schema.Boolean; // Schema<boolean>
Schema.BigIntFromSelf; // Schema<BigInt>
Schema.SymbolFromSelf; // Schema<symbol>
Schema.Object; // Schema<object>
Schema.Undefined; // Schema<undefined>
Schema.Void; // Schema<void>
Schema.Any; // Schema<any>
Schema.Unknown; // Schema<unknown>
Schema.Never; // Schema<never>
```

These primitive schemas are building blocks for creating more complex schemas to describe your data structures.

## Literals

Literals in schemas represent specific values that are directly specified. Here are some examples of literal schemas provided by the `@effect/schema/Schema` module:

```ts
import { Schema } from '@effect/schema';

Schema.Null; // same as S.Literal(null)
Schema.Literal('a');
Schema.Literal('a', 'b', 'c'); // union of literals
Schema.Literal(1);
Schema.Literal(2n); // BigInt literal
Schema.Literal(true);
```

We can also use `pickLiteral` with a literal schema to narrow down the possible values:

```ts
import { Schema } from '@effect/schema';

Schema.Literal('a', 'b', 'c').pipe(Schema.pickLiteral('a', 'b')); // same as S.Literal("a", "b")
```

Sometimes, we need to reuse a schema literal in other parts of our code. Let's see an example:

```ts
import { Schema } from '@effect/schema';

const FruitId = Schema.Number;
// the source of truth regarding the Fruit category
const FruitCategory = Schema.Literal('sweet', 'citrus', 'tropical');

const Fruit = Schema.Struct({
  id: FruitId,
  category: FruitCategory,
});

// Here, we want to reuse our FruitCategory definition to create a subtype of Fruit
const SweetAndCitrusFruit = Schema.Struct({
  fruitId: FruitId,
  category: FruitCategory.pipe(Schema.pickLiteral('sweet', 'citrus')),
  /*
    By using pickLiteral from the FruitCategory, we ensure that the values selected
    are those defined in the category definition above.
    If we remove "sweet" from the FruitCategory definition, TypeScript will notify us.
    */
});
```

In this example, `FruitCategory` serves as the source of truth for the categories of fruits. We reuse it to create a subtype of `Fruit` called `SweetAndCitrusFruit`, ensuring that only the categories defined in `FruitCategory` are allowed.

### Exposed Values

You can access the literals of a literal schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Literal('a', 'b');

// Accesses the literals
const literals = schema.literals; // readonly ["a", "b"]
```

## Template literals

In TypeScript, template literals allow you to embed expressions within string literals. The `@effect/schema` library provides a `TemplateLiteral` constructor that you can use to create a schema for these template literal types.

Here's how you can use it:

```ts
import { Schema } from '@effect/schema';

// This creates a TemplateLiteral of type `a${string}`
Schema.TemplateLiteral('a', Schema.String);

// This creates a TemplateLiteral of type `https://${string}.com` or `https://${string}.net`
Schema.TemplateLiteral(
  'https://',
  Schema.String,
  '.',
  Schema.Literal('com', 'net'),
);
```

Let's look at a more complex example. Suppose you have two sets of locale IDs for emails and footers:

```ts
// example from https://www.typescriptlang.org/docs/handbook/2/template-literal-types.html
const EmailLocaleIDs = Schema.Literal('welcome_email', 'email_heading');
const FooterLocaleIDs = Schema.Literal('footer_title', 'footer_sendoff');
```

You can use the `TemplateLiteral` constructor to create a schema that combines these IDs:

```ts
// This creates a TemplateLiteral of type "welcome_email_id" | "email_heading_id" | "footer_title_id" | "footer_sendoff_id"
Schema.TemplateLiteral(Schema.Union(EmailLocaleIDs, FooterLocaleIDs), '_id');
```

The `TemplateLiteral` constructor supports the following types of spans:

- `Schema.String`
- `Schema.Number`
- Literals: `string | number | boolean | null | bigint`. These can be either wrapped by `Schema.Literal` or used directly
- Unions of the above types

## Unique Symbols

```ts
import { Schema } from '@effect/schema';

const mySymbol = Symbol.for('mysymbol');

// const mySymbolSchema: S.Schema<typeof mySymbol>
const mySymbolSchema = Schema.UniqueSymbolFromSelf(mySymbol);
```

## Filters

Using the `Schema.filter` function, developers can define custom validation logic that goes beyond basic type checks, allowing for in-depth control over the data conformity process. This function applies a predicate to data, and if the data fails the predicate's condition, a custom error message can be returned.

**Simple Validation Example**:

```ts
import { Schema } from '@effect/schema';

const LongString = Schema.String.pipe(
  Schema.filter((s) =>
    s.length >= 10 ? undefined : 'a string at least 10 characters long'
  ),
);

console.log(Schema.decodeUnknownSync(LongString)('a'));
/*
throws:
Error: { string | filter }
â””â”€ Predicate refinement failure
   â””â”€ a string at least 10 characters long
*/
```

> [!WARNING]
> Please note that the use of filters do not alter the type of the `Schema`. They only serve to add additional constraints to the parsing process. If you intend to modify the `Type`, consider using [Branded types](#branded-types).

### Predicate Function Structure

The predicate for a filter is defined as follows:

```ts
type Predicate = (
  a: A,
  options: ParseOptions,
  self: AST.Refinement,
) => FilterReturnType;
```

where

```ts
export interface FilterIssue {
  readonly path: ReadonlyArray<PropertyKey>;
  readonly issue: string | ParseResult.ParseIssue;
}

export type FilterOutput =
  | undefined
  | boolean
  | string
  | ParseResult.ParseIssue
  | FilterIssue;

type FilterReturnType = FilterOutput | ReadonlyArray<FilterOutput>;
```

Filter predicates can return several types of values, each with specific implications:

- `true`: The data satisfies the filter's condition.
- `false` or `undefined`: The filter is not satisfied, and no specific error message is provided.
- `string`: The filter fails, and the provided string is used as the **default** error message.
- `ParseResult.ParseIssue`: The filter fails with a detailed error structure.
- `FilterIssue`: Allows specifying detailed error paths and messages, enhancing error specificity.

An array can be returned if multiple issues need to be reported, allowing for complex validations that may have multiple points of failure.

### Schema Metadata

It's beneficial to embed as much metadata as possible within the schema. This metadata can include identifiers, JSON schema specifications, and descriptive text to facilitate later analysis and understanding of the schema's purpose and constraints.

```ts
import { Schema } from '@effect/schema';

const LongString = Schema.String.pipe(
  Schema.filter(
    (s) => s.length >= 10 ? undefined : 'a string at least 10 characters long',
    {
      identifier: 'LongString',
      jsonSchema: { minLength: 10 },
      description:
        'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua',
    },
  ),
);

console.log(Schema.decodeUnknownSync(LongString)('a'));
/*
throws:
Error: LongString
â””â”€ Predicate refinement failure
   â””â”€ a string at least 10 characters long
*/
```

### Specifying Error Paths

It's possible to specify an error path along with the message, which enhances error specificity and is particularly beneficial for integration with tools like `react-hook-form`.

```ts
import { ArrayFormatter, Schema } from '@effect/schema';
import { Either } from 'effect';

const Password = Schema.Trim.pipe(Schema.minLength(1));

const MyForm = Schema.Struct({
  password: Password,
  confirm_password: Password,
}).pipe(
  Schema.filter((input) => {
    if (input.password !== input.confirm_password) {
      return {
        path: ['confirm_password'],
        message: 'Passwords do not match',
      };
    }
  }),
);

console.log(
  '%o',
  Schema.decodeUnknownEither(MyForm)({
    password: 'abc',
    confirm_password: 'd',
  }).pipe(Either.mapLeft((error) => ArrayFormatter.formatErrorSync(error))),
);
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: [
    {
      _tag: 'Type',
      path: [ 'confirm_password' ],
      message: 'Passwords do not match'
    }
  ]
}
*/
```

This allows the error to be directly associated with the `confirm_password` field, improving clarity for the end-user.

### Multiple Error Reporting

The `filter` API also supports reporting multiple issues at once, which is useful in forms where several validation checks might fail simultaneously.

```ts
import { ArrayFormatter, Schema } from '@effect/schema';
import { Either } from 'effect';

const Password = Schema.Trim.pipe(Schema.minLength(1));
const OptionalString = Schema.optional(Schema.String);

const MyForm = Schema.Struct({
  password: Password,
  confirm_password: Password,
  name: OptionalString,
  surname: OptionalString,
}).pipe(
  Schema.filter((input) => {
    const issues: Array<Schema.FilterIssue> = [];
    // passwords must match
    if (input.password !== input.confirm_password) {
      issues.push({
        path: ['confirm_password'],
        message: 'Passwords do not match',
      });
    }
    // either name or surname must be present
    if (!input.name && !input.surname) {
      issues.push({
        path: ['surname'],
        message: 'Surname must be present if name is not present',
      });
    }
    return issues;
  }),
);

console.log(
  '%o',
  Schema.decodeUnknownEither(MyForm)({
    password: 'abc',
    confirm_password: 'd',
  }).pipe(Either.mapLeft((error) => ArrayFormatter.formatErrorSync(error))),
);
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: [
    {
      _tag: 'Type',
      path: [ 'confirm_password' ],
      message: 'Passwords do not match'
    },
    {
      _tag: 'Type',
      path: [ 'surname' ],
      message: 'Surname must be present if name is not present'
    }
  ]
}
*/
```

### Exposed Values

You can access the base schema for which the filter has been defined:

```ts
import { Schema } from '@effect/schema';

const LongString = Schema.String.pipe(Schema.filter((s) => s.length >= 10));

// const From: typeof Schema.String
const From = LongString.from;
```

In this example, you're able to access the original schema (`Schema.String`) for which the filter (`LongString`) has been defined. The `from` property provides access to this base schema.

### String Filters

```ts
import { Schema } from '@effect/schema';

Schema.String.pipe(Schema.maxLength(5)); // Specifies maximum length of a string
Schema.String.pipe(Schema.minLength(5)); // Specifies minimum length of a string
Schema.NonEmpty; // Equivalent to ensuring the string has a minimum length of 1
Schema.String.pipe(Schema.length(5)); // Specifies exact length of a string
Schema.String.pipe(Schema.length({ min: 2, max: 4 })); // Specifies a range for the length of a string
Schema.String.pipe(Schema.pattern(regex)); // Matches a string against a regular expression pattern
Schema.String.pipe(Schema.startsWith(string)); // Ensures a string starts with a specific substring
Schema.String.pipe(Schema.endsWith(string)); // Ensures a string ends with a specific substring
Schema.String.pipe(Schema.includes(searchString)); // Checks if a string includes a specific substring
Schema.String.pipe(Schema.trimmed()); // Validates that a string has no leading or trailing whitespaces
Schema.String.pipe(Schema.lowercased()); // Validates that a string is entirely in lowercase
```

> [!NOTE]
> The `trimmed` combinator does not make any transformations, it only validates. If what you were looking for was a combinator to trim strings, then check out the `trim` combinator ot the `Trim` schema.

### Number Filters

```ts
import { Schema } from '@effect/schema';

Schema.Number.pipe(Schema.greaterThan(5)); // Specifies a number greater than 5
Schema.Number.pipe(Schema.greaterThanOrEqualTo(5)); // Specifies a number greater than or equal to 5
Schema.Number.pipe(Schema.lessThan(5)); // Specifies a number less than 5
Schema.Number.pipe(Schema.lessThanOrEqualTo(5)); // Specifies a number less than or equal to 5
Schema.Number.pipe(Schema.between(-2, 2)); // Specifies a number between -2 and 2, inclusive

Schema.Number.pipe(Schema.int()); // Specifies that the value must be an integer

Schema.Number.pipe(Schema.nonNaN()); // Ensures the value is not NaN
Schema.Number.pipe(Schema.finite()); // Ensures the value is finite and not Infinity or -Infinity

Schema.Number.pipe(Schema.positive()); // Specifies a positive number (> 0)
Schema.Number.pipe(Schema.nonNegative()); // Specifies a non-negative number (>= 0)
Schema.Number.pipe(Schema.negative()); // Specifies a negative number (< 0)
Schema.Number.pipe(Schema.nonPositive()); // Specifies a non-positive number (<= 0)

Schema.Number.pipe(Schema.multipleOf(5)); // Specifies a number that is evenly divisible by 5
```

### BigInt Filters

```ts
import { Schema } from '@effect/schema';

Schema.BigInt.pipe(Schema.greaterThanBigInt(5n)); // Specifies a BigInt greater than 5
Schema.BigInt.pipe(Schema.greaterThanOrEqualToBigInt(5n)); // Specifies a BigInt greater than or equal to 5
Schema.BigInt.pipe(Schema.lessThanBigInt(5n)); // Specifies a BigInt less than 5
Schema.BigInt.pipe(Schema.lessThanOrEqualToBigInt(5n)); // Specifies a BigInt less than or equal to 5
Schema.BigInt.pipe(Schema.betweenBigInt(-2n, 2n)); // Specifies a BigInt between -2 and 2, inclusive

Schema.BigInt.pipe(Schema.positiveBigInt()); // Specifies a positive BigInt (> 0n)
Schema.BigInt.pipe(Schema.nonNegativeBigInt()); // Specifies a non-negative BigInt (>= 0n)
Schema.BigInt.pipe(Schema.negativeBigInt()); // Specifies a negative BigInt (< 0n)
Schema.BigInt.pipe(Schema.nonPositiveBigInt()); // Specifies a non-positive BigInt (<= 0n)
```

### BigDecimal Filters

```ts
import { Schema } from '@effect/schema';
import { BigDecimal } from 'effect';

Schema.BigDecimal.pipe(Schema.greaterThanBigDecimal(BigDecimal.fromNumber(5))); // Specifies a BigDecimal greater than 5
Schema.BigDecimal.pipe(
  Schema.greaterThanOrEqualToBigDecimal(BigDecimal.fromNumber(5)),
); // Specifies a BigDecimal greater than or equal to 5
Schema.BigDecimal.pipe(Schema.lessThanBigDecimal(BigDecimal.fromNumber(5))); // Specifies a BigDecimal less than 5
Schema.BigDecimal.pipe(
  Schema.lessThanOrEqualToBigDecimal(BigDecimal.fromNumber(5)),
); // Specifies a BigDecimal less than or equal to 5
Schema.BigDecimal.pipe(
  Schema.betweenBigDecimal(BigDecimal.fromNumber(-2), BigDecimal.fromNumber(2)),
); // Specifies a BigDecimal between -2 and 2, inclusive

Schema.BigDecimal.pipe(Schema.positiveBigDecimal()); // Specifies a positive BigDecimal (> 0)
Schema.BigDecimal.pipe(Schema.nonNegativeBigDecimal()); // Specifies a non-negative BigDecimal (>= 0)
Schema.BigDecimal.pipe(Schema.negativeBigDecimal()); // Specifies a negative BigDecimal (< 0)
Schema.BigDecimal.pipe(Schema.nonPositiveBigDecimal()); // Specifies a non-positive BigDecimal (<= 0)
```

### Duration Filters

```ts
import { Schema } from '@effect/schema';

Schema.Duration.pipe(Schema.greaterThanDuration('5 seconds')); // Specifies a duration greater than 5 seconds
Schema.Duration.pipe(Schema.greaterThanOrEqualToDuration('5 seconds')); // Specifies a duration greater than or equal to 5 seconds
Schema.Duration.pipe(Schema.lessThanDuration('5 seconds')); // Specifies a duration less than 5 seconds
Schema.Duration.pipe(Schema.lessThanOrEqualToDuration('5 seconds')); // Specifies a duration less than or equal to 5 seconds
Schema.Duration.pipe(Schema.betweenDuration('5 seconds', '10 seconds')); // Specifies a duration between 5 seconds and 10 seconds, inclusive
```

### Array Filters

```ts
import { Schema } from '@effect/schema';

Schema.Array(Schema.Number).pipe(Schema.maxItems(2)); // Specifies the maximum number of items in the array
Schema.Array(Schema.Number).pipe(Schema.minItems(2)); // Specifies the minimum number of items in the array
Schema.Array(Schema.Number).pipe(Schema.itemsCount(2)); // Specifies the exact number of items in the array
```

## Branded types

TypeScript's type system is structural, which means that any two types that are structurally equivalent are considered the same. This can cause issues when types that are semantically different are treated as if they were the same.

```ts
type UserId = string
type Username = string

const getUser = (id: UserId) => { ... }

const myUsername: Username = "gcanti"

getUser(myUsername) // works fine
```

In the above example, `UserId` and `Username` are both aliases for the same type, `string`. This means that the `getUser` function can mistakenly accept a `Username` as a valid `UserId`, causing bugs and errors.

To avoid these kinds of issues, the `@effect` ecosystem provides a way to create custom types with a unique identifier attached to them. These are known as "branded types".

```ts
import { Brand } from "effect"

type UserId = string & Brand.Brand<"UserId">
type Username = string

const getUser = (id: UserId) => { ... }

const myUsername: Username = "gcanti"

getUser(myUsername) // error
```

By defining `UserId` as a branded type, the `getUser` function can accept only values of type `UserId`, and not plain strings or other types that are compatible with strings. This helps to prevent bugs caused by accidentally passing the wrong type of value to the function.

There are two ways to define a schema for a branded type, depending on whether you:

- want to define the schema from scratch
- have already defined a branded type via `effect/Brand` and want to reuse it to define a schema

### Defining a schema from scratch

To define a schema for a branded type from scratch, you can use the `brand` combinator exported by the `@effect/schema/Schema` module. Here's an example:

```ts
import { Schema } from '@effect/schema';

const UserId = Schema.String.pipe(Schema.brand('UserId'));
type UserId = Schema.Schema.Type<typeof UserId>; // string & Brand<"UserId">
```

Note that you can use `unique symbol`s as brands to ensure uniqueness across modules / packages:

```ts
import { Schema } from '@effect/schema';

const UserIdBrand = Symbol.for('UserId');
const UserId = Schema.String.pipe(Schema.brand(UserIdBrand));

// string & Brand<typeof UserIdBrand>
type UserId = Schema.Schema.Type<typeof UserId>;
```

### Reusing an existing branded type

If you have already defined a branded type using the `effect/Brand` module, you can reuse it to define a schema using the `fromBrand` combinator exported by the `@effect/schema/Schema` module. Here's an example:

```ts
import { Schema } from '@effect/schema';
import { Brand } from 'effect';

// the existing branded type
type UserId = string & Brand.Brand<'UserId'>;
const UserId = Brand.nominal<UserId>();

// Define a schema for the branded type
const UserIdSchema = Schema.String.pipe(Schema.fromBrand(UserId));
```

## Native enums

```ts
import { Schema } from '@effect/schema';

enum Fruits {
  Apple,
  Banana,
}

// Schema.Enums<typeof Fruits>
const schema = Schema.Enums(Fruits);
```

### Accessing Enum Members

Enums are exposed under an `enums` property of the schema:

```ts
// Access the enum members
Schema.Enums(Fruits).enums; // Returns all enum members
Schema.Enums(Fruits).enums.Apple; // Access the Apple member
Schema.Enums(Fruits).enums.Banana; // Access the Banana member
```

## Nullables

```ts
import { Schema } from '@effect/schema';

// Represents a schema for a string or null value
Schema.NullOr(Schema.String);

// Represents a schema for a string, null, or undefined value
Schema.NullishOr(Schema.String);

// Represents a schema for a string or undefined value
Schema.UndefinedOr(Schema.String);
```

## Unions

`@effect/schema/Schema` includes a built-in `union` combinator for composing "OR" types.

```ts
import { Schema } from '@effect/schema';

// Schema<string | number>
Schema.Union(S.String, S.Number);
```

### Union of Literals

While the following is perfectly acceptable:

```ts
import { Schema } from '@effect/schema';

// Schema<"a" | "b" | "c">
const schema = Schema.Union(
  Schema.Literal('a'),
  Schema.Literal('b'),
  Schema.Literal('c'),
);
```

It is possible to use `Literal` and pass multiple literals, which is less cumbersome:

```ts
import { Schema } from '@effect/schema';

// Schema<"a" | "b" | "c">
const schema = Schema.Literal('a', 'b', 'c');
```

Under the hood, they are the same, as `Literal(...literals)` will be converted into a union.

### Discriminated unions

TypeScript reference: https://www.typescriptlang.org/docs/handbook/2/narrowing.html#discriminated-unions

Discriminated unions in TypeScript are a way of modeling complex data structures that may take on different forms based on a specific set of conditions or properties. They allow you to define a type that represents multiple related shapes, where each shape is uniquely identified by a shared discriminant property.

In a discriminated union, each variant of the union has a common property, called the discriminant. The discriminant is a literal type, which means it can only have a finite set of possible values. Based on the value of the discriminant property, TypeScript can infer which variant of the union is currently in use.

Here is an example of a discriminated union in TypeScript:

```ts
type Circle = {
  readonly kind: 'circle';
  readonly radius: number;
};

type Square = {
  readonly kind: 'square';
  readonly sideLength: number;
};

type Shape = Circle | Square;
```

This code defines a discriminated union using the `@effect/schema` library:

```ts
import { Schema } from '@effect/schema';

const Circle = Schema.Struct({
  kind: Schema.Literal('circle'),
  radius: Schema.Number,
});

const Square = Schema.Struct({
  kind: Schema.Literal('square'),
  sideLength: Schema.Number,
});

const Shape = Schema.Union(Circle, Square);
```

The `Literal` combinator is used to define the discriminant property with a specific string literal value.

Two structs are defined for `Circle` and `Square`, each with their own properties. These structs represent the variants of the union.

Finally, the `union` combinator is used to create a schema for the discriminated union `Shape`, which is a union of `Circle` and `Square`.

### How to transform a simple union into a discriminated union

If you're working on a TypeScript project and you've defined a simple union to represent a particular input, you may find yourself in a situation where you're not entirely happy with how it's set up. For example, let's say you've defined a `Shape` union as a combination of `Circle` and `Square` without any special property:

```ts
import { Schema } from '@effect/schema';

const Circle = Schema.Struct({
  radius: Schema.Number,
});

const Square = Schema.Struct({
  sideLength: Schema.Number,
});

const Shape = Schema.Union(Circle, Square);
```

To make your code more manageable, you may want to transform the simple union into a discriminated union. This way, TypeScript will be able to automatically determine which member of the union you're working with based on the value of a specific property.

To achieve this, you can add a special property to each member of the union, which will allow TypeScript to know which type it's dealing with at runtime. Here's how you can transform the `Shape` schema into another schema that represents a discriminated union:

```ts
import { Schema } from '@effect/schema';
import * as assert from 'node:assert';

const Circle = Schema.Struct({
  radius: Schema.Number,
});

const Square = Schema.Struct({
  sideLength: Schema.Number,
});

const DiscriminatedShape = Schema.Union(
  Circle.pipe(
    Schema.transform(
      Schema.Struct({ ...Circle.fields, kind: Schema.Literal('circle') }), // Add a "kind" property with the literal value "circle" to Circle
      {
        decode: (circle) => ({ ...circle, kind: 'circle' as const }), // Add the discriminant property to Circle
        encode: ({ kind: _kind, ...rest }) => rest, // Remove the discriminant property
      },
    ),
  ),
  Square.pipe(
    Schema.transform(
      Schema.Struct({ ...Square.fields, kind: Schema.Literal('square') }), // Add a "kind" property with the literal value "square" to Square
      {
        decode: (square) => ({ ...square, kind: 'square' as const }), // Add the discriminant property to Square
        encode: ({ kind: _kind, ...rest }) => rest, // Remove the discriminant property
      },
    ),
  ),
);

assert.deepStrictEqual(
  Schema.decodeUnknownSync(DiscriminatedShape)({ radius: 10 }),
  {
    kind: 'circle',
    radius: 10,
  },
);

assert.deepStrictEqual(
  Schema.decodeUnknownSync(DiscriminatedShape)({ sideLength: 10 }),
  {
    kind: 'square',
    sideLength: 10,
  },
);
```

The previous solution works perfectly and shows how we can add properties to our schema at will, making it easier to consume the result within our domain model. However, it requires a lot of boilerplate. Fortunately, there is an API called `attachPropertySignature` designed specifically for this use case, which allows us to achieve the same result with much less effort:

```ts
import { Schema } from '@effect/schema';
import * as assert from 'node:assert';

const Circle = Schema.Struct({ radius: Schema.Number });
const Square = Schema.Struct({ sideLength: Schema.Number });
const DiscriminatedShape = Schema.Union(
  Circle.pipe(Schema.attachPropertySignature('kind', 'circle')),
  Square.pipe(Schema.attachPropertySignature('kind', 'square')),
);

// decoding
assert.deepStrictEqual(
  Schema.decodeUnknownSync(DiscriminatedShape)({ radius: 10 }),
  {
    kind: 'circle',
    radius: 10,
  },
);

// encoding
assert.deepStrictEqual(
  Schema.encodeSync(DiscriminatedShape)({
    kind: 'circle',
    radius: 10,
  }),
  { radius: 10 },
);
```

> [!NOTE]
> Please note that with `attachPropertySignature`, you can only add a property, it cannot override an existing one.

### Exposed Values

You can access the members of a union schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Union(Schema.String, Schema.Number);

// Accesses the members of the union
const members = schema.members; // [typeof Schema.String, typeof Schema.Number]
```

## Tuples

### Required Elements

To define a tuple with required elements, you simply specify the list of elements:

```ts
import { Schema } from '@effect/schema';

// const opaque: Schema.Tuple<[typeof Schema.String, typeof Schema.Number]>
const opaque = Schema.Tuple(Schema.String, Schema.Number);

// const nonOpaque: Schema.Schema<readonly [string, number], readonly [string, number], never>
const nonOpaque = Schema.asSchema(opaque);
```

### Append a Required Element

```ts
import { Schema } from '@effect/schema';

// Schema.Tuple<[typeof Schema.String, typeof Schema.Number]>
const tuple1 = Schema.Tuple(Schema.String, Schema.Number);

// Schema.Tuple<[typeof Schema.String, typeof Schema.Number, typeof Schema.Boolean]>
const tuple2 = Schema.Tuple(...tuple1.elements, Schema.Boolean);
```

### Optional Elements

To define an optional element, wrap the schema of the element with the `OptionalElement` modifier:

```ts
import { Schema } from '@effect/schema';

// Schema.Tuple<[typeof Schema.String, Schema.OptionalElement<typeof Schema.Number>]>
const opaque = Schema.Tuple(
  Schema.String,
  Schema.optionalElement(Schema.Number),
);

// Schema.Schema<readonly [string, number?], readonly [string, number?], never>
const nonOpaque = Schema.asSchema(opaque);
```

### Rest Element

To define rest elements, follow the list of elements (required or optional) with an element for the rest:

```ts
import { Schema } from '@effect/schema';

// Schema.TupleType<readonly [typeof Schema.String, Schema.OptionalElement<typeof Schema.Number>], [typeof Schema.Boolean]>
const opaque = Schema.Tuple(
  [Schema.String, Schema.optionalElement(Schema.Number)],
  Schema.Boolean,
);

// Schema.Schema<readonly [string, number?, ...boolean[]], readonly [string, number?, ...boolean[]], never>
const nonOpaque = Schema.asSchema(opaque);
```

Optionally, you can include other elements after the rest:

```ts
import { Schema } from '@effect/schema';

// Schema.TupleType<readonly [typeof Schema.String, Schema.OptionalElement<typeof Schema.Number>], [typeof Schema.Boolean, typeof Schema.String]>
const opaque = Schema.Tuple(
  [Schema.String, Schema.optionalElement(Schema.Number)],
  Schema.Boolean,
  Schema.String,
);

// Schema.Schema<readonly [string, number | undefined, ...boolean[], string], readonly [string, number | undefined, ...boolean[], string], never>
const nonOpaque = Schema.asSchema(opaque);
```

### Exposed Values

You can access the elements and rest elements of a tuple schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Tuple(
  [Schema.String, Schema.optionalElement(Schema.Number)],
  Schema.Boolean,
  Schema.Number,
);

// Accesses the elements of the tuple
const tupleElements = schema.elements; // readonly [typeof Schema.String, Schema.OptionalElement<typeof Schema.Number>]

// Accesses the rest elements of the tuple
const restElements = schema.rest; // readonly [typeof Schema.Boolean, typeof Schema.Number]
```

### Annotations

Annotations are used to add metadata to tuple elements, which can describe the purpose or requirements of each element more clearly. This can be particularly useful when generating documentation or JSON schemas from your schemas.

```ts
import { JSONSchema, Schema } from '@effect/schema';

// Defining a tuple with annotations for each coordinate in a point
const Point = Schema.Tuple(
  Schema.element(Schema.Number).annotations({
    title: 'X',
    description: 'X coordinate',
  }),
  Schema.optionalElement(Schema.Number).annotations({
    title: 'Y',
    description: 'optional Y coordinate',
  }),
);

// Generating a JSON Schema from the tuple
console.log(JSONSchema.make(Point));
/*
Output:
{
  '$schema': 'http://json-schema.org/draft-07/schema#',
  type: 'array',
  minItems: 1,
  items: [
    { type: 'number', description: 'X coordinate', title: 'X' },
    {
      type: 'number',
      description: 'optional Y coordinate',
      title: 'Y'
    }
  ],
  additionalItems: false
}
*/
```

## Arrays

```ts
import { Schema } from '@effect/schema';

// Schema.Array$<typeof Schema.Number>
const opaque = Schema.Array(Schema.Number);

// Schema.Schema<readonly number[], readonly number[], never>
const schema = Schema.asSchema(opaque);
```

### Exposed Values

You can access the value of an array schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Array(Schema.String);

// Accesses the value
const value = schema.value; // typeof Schema.String
```

### Mutable Arrays

By default, when you use `S.Array`, it generates a type marked as readonly. The `mutable` combinator is a useful function for creating a new schema with a mutable type in a **shallow** manner:

```ts
import { Schema } from '@effect/schema';

// Schema.mutable<Schema.Array$<typeof Schema.Number>>
const opaque = Schema.mutable(Schema.Array(Schema.Number));

// Schema.Schema<number[], number[], never>
const schema = Schema.asSchema(opaque);
```

### Non empty arrays

```ts
import { Schema } from '@effect/schema';

// Schema.NonEmptyArray<typeof Schema.Number>
const opaque = Schema.NonEmptyArray(Schema.Number);

// Schema.Schema<readonly [number, ...number[]], readonly [number, ...number[]], never>
const schema = Schema.asSchema(opaque);
```

#### Exposed Values

You can access the value of a non-empty array schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.NonEmptyArray(Schema.String);

// Accesses the value
const value = schema.value; // typeof Schema.String
```

## Records

### String keys

```ts
import { Schema } from '@effect/schema';

// Schema.Record$<typeof Schema.String, typeof Schema.Number>
const opaque1 = Schema.Record(Schema.String, Schema.Number);

// Schema.Schema<{ readonly [x: string]: number; }>
const schema1 = Schema.asSchema(opaque1);

// Schema.Record$<Schema.Union<[Schema.Literal<["a"]>, Schema.Literal<["b"]>]>, typeof Schema.Number>
const opaque2 = Schema.Record(
  Schema.Union(Schema.Literal('a'), Schema.Literal('b')),
  Schema.Number,
);

// Schema.Schema<{ readonly a: number; readonly b: number; }>
const schema2 = Schema.asSchema(opaque2);
```

### Keys refinements

```ts
import { Schema } from '@effect/schema';

// Schema.Record$<Schema.filter<Schema.Schema<string, string, never>>, typeof Schema.Number>
const opaque = Schema.Record(
  Schema.String.pipe(Schema.minLength(2)),
  Schema.Number,
);

// Schema.Schema<{ readonly [x: string]: number; }>
const schema = Schema.asSchema(opaque);
```

### Symbol keys

```ts
import { Schema } from '@effect/schema';

// Schema.Record$<typeof Schema.SymbolFromSelf, typeof Schema.Number>
const opaque = Schema.Record(Schema.SymbolFromSelf, Schema.Number);

// Schema.Schema<{ readonly [x: symbol]: number; }>
const schema = Schema.asSchema(opaque);
```

### Template literal keys

```ts
import { Schema } from '@effect/schema';

// Schema.Record$<Schema.Schema<`a${string}`, `a${string}`, never>, typeof Schema.Number>
const opaque = Schema.Record(
  Schema.TemplateLiteral(Schema.Literal('a'), Schema.String),
  Schema.Number,
);

// Schema.Schema<{ readonly [x: `a${string}`]: number; }>
const schema = Schema.asSchema(opaque);
```

### Mutable Records

By default, when you use `S.Record`, it generates a type marked as readonly. The `mutable` combinator is a useful function for creating a new schema with a mutable type in a **shallow** manner:

```ts
import { Schema } from '@effect/schema';

// Schema.mutable<Schema.Record$<typeof Schema.String, typeof Schema.Number>>
const opaque = Schema.mutable(Schema.Record(Schema.String, Schema.Number));

// Schema.Schema<{ [x: string]: number; }>
const schema = Schema.asSchema(opaque);
```

### Exposed Values

You can access the key and the value of a record schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Record(Schema.String, Schema.Number);

// Accesses the key
const key = schema.key; // typeof Schema.String

// Accesses the value
const value = schema.value; // typeof Schema.Number
```

## Structs

In `@effect/schema`, structs are used to define schemas for objects with specific properties. Here's how you can create and use a struct schema:

```ts
import { Schema } from '@effect/schema';

// Define a struct schema for an object with properties a (string) and b (number)
const MyStruct = Schema.Struct({ a: Schema.String, b: Schema.Number });
```

The `MyStruct` constant will have the type `Schema.Struct<{ a: typeof Schema.String; b: typeof Schema.Number; }>`, representing the structure of the object.

To view the detailed type of `MyStruct`, you can use the `Schema.asSchema` function:

```ts
/*
const schema: Schema.Schema<{
    readonly a: string;
    readonly b: number;
}, {
    readonly a: string;
    readonly b: number;
}, never>
*/
const schema = Schema.asSchema(MyStruct);
```

> [!NOTE]
> Note that `Schema.Struct({})` models the TypeScript type `{}`, which is similar to `unknown`. This means that the schema will allow any type of data to pass through without validation.

### Index Signatures

The `Struct` constructor optionally accepts a list of key/value pairs representing index signatures:

```ts
(props, ...indexSignatures) => Struct<...>
```

**Example**

```ts
import { Schema } from '@effect/schema';

/*
Schema.TypeLiteral<{
    a: typeof Schema.Number;
}, readonly [{
    readonly key: typeof Schema.String;
    readonly value: typeof Schema.Number;
}]>
*/
const opaque = Schema.Struct(
  {
    a: Schema.Number,
  },
  { key: Schema.String, value: Schema.Number },
);

/*
Schema.Schema<{
    readonly [x: string]: number;
    readonly a: number;
}, {
    readonly [x: string]: number;
    readonly a: number;
}, never>
*/
const nonOpaque = Schema.asSchema(opaque);
```

Since the `Record` constructor returns a schema that exposes both the `key` and the `value`, instead of passing a bare object `{ key, value }`, you can use the `Record` constructor:

```ts
import { Schema } from '@effect/schema';

/*
Schema.TypeLiteral<{
    a: typeof Schema.Number;
}, readonly [Schema.Record$<typeof Schema.String, typeof Schema.Number>]>
*/
const opaque = Schema.Struct(
  { a: Schema.Number },
  Schema.Record(Schema.String, Schema.Number),
);

/*
Schema.Schema<{
    readonly [x: string]: number;
    readonly a: number;
}, {
    readonly [x: string]: number;
    readonly a: number;
}, never>
*/
const nonOpaque = Schema.asSchema(opaque);
```

### Exposed Values

You can access the fields and the records of a struct schema:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct(
  { a: Schema.Number },
  Schema.Record(Schema.String, Schema.Number),
);

// Accesses the fields
const fields = schema.fields; // { readonly a: typeof Schema.Number; }

// Accesses the records
const records = schema.records; // readonly [Schema.Record$<typeof Schema.String, typeof Schema.Number>]
```

### Mutable Properties

By default, when you use `S.struct`, it generates a type with properties that are marked as readonly. The `mutable` combinator is a useful function for creating a new schema with properties made mutable in a **shallow** manner:

```ts
import { Schema } from '@effect/schema';

/*
Schema.mutable<Schema.Struct<{
    a: typeof Schema.String;
    b: typeof Schema.Number;
}>>
*/
const opaque = Schema.mutable(
  Schema.Struct({ a: Schema.String, b: Schema.Number }),
);

// Schema.Schema<{ a: string; b: number; }>
const schema = Schema.asSchema(opaque);
```

## Property Signatures

A `PropertySignature` generally represents a transformation from a "From" field:

```ts
{
  fromKey: fromType;
}
```

to a "To" field:

```ts
{
  toKey: toType;
}
```

Let's start with the simple definition of a property signature that can be used to add annotations:

```ts
import { Schema } from '@effect/schema';

/*
Schema.Struct<{
    name: typeof Schema.String;
    age: Schema.PropertySignature<":", number, never, ":", string, false, never>;
}>
*/
const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.propertySignature(Schema.NumberFromString).annotations({
    title: 'Age',
  }),
});
```

Let's delve into the details of all the information contained in the type of a `PropertySignature`:

```ts
age: PropertySignature<
  ToToken,
  ToType,
  FromKey,
  FromToken,
  FromType,
  HasDefault,
  Context
>;
```

- `age`: is the key of the "To" field
- `ToToken`: either `"?:"` or `":"`, `"?:"` indicates that the "To" field is optional, `":"` indicates that the "To" field is required
- `ToType`: the type of the "To" field
- `FromKey` (optional, default = `never`): indicates the key from the field from which the transformation starts, by default it is equal to the key of the "To" field (i.e., `"age"` in this case)
- `FormToken`: either `"?:"` or `":"`, `"?:"` indicates that the "From" field is optional, `":"` indicates that the "From" field is required
- `FromType`: the type of the "From" field
- `HasDefault`: indicates whether it has a constructor default value.

In our case, the type

```ts
PropertySignature<':', number, never, ':', string, false, never>;
```

indicates that there is the following transformation:

- `age` is the key of the "To" field
- `ToToken = ":"` indicates that the `age` field is required
- `ToType = number` indicates that the type of the `age` field is `number`
- `FromKey = never` indicates that the decoding occurs from the same field named `age`
- `FormToken = "."` indicates that the decoding occurs from a required `age` field
- `FromType = string` indicates that the decoding occurs from a `string` type `age` field
- `HasDefault = false`: no default.

Let's see an example of decoding:

```ts
console.log(Schema.decodeUnknownSync(Person)({ name: 'name', age: '18' }));
// Output: { name: 'name', age: 18 }
```

Now, suppose the field from which decoding occurs is named `"AGE"`, but for our model, we want to keep the name in lowercase `"age"`. To achieve this result, we need to map the field key from `"AGE"` to `"age"`, and to do that, we can use the `fromKey` combinator:

```ts
import { Schema } from '@effect/schema';

/*
Schema.Struct<{
    name: typeof Schema.String;
    age: Schema.PropertySignature<":", number, "AGE", ":", string, false, never>;
}>
*/
const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.propertySignature(Schema.NumberFromString).pipe(
    Schema.fromKey('AGE'),
  ),
});
```

This modification is represented in the type of the created `PropertySignature`:

```ts
// fromKey ----------------------v
PropertySignature<':', number, 'AGE', ':', string, false, never>;
```

Now, let's see an example of decoding:

```ts
console.log(Schema.decodeUnknownSync(Person)({ name: 'name', AGE: '18' }));
// Output: { name: 'name', age: 18 }
```

### Optional Fields

**Cheatsheet**

| Combinator | From                                                 | To                                                                                                      |
| ---------- | ---------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| `optional` | `Schema<A, I, R>`                                    | `PropertySignature<"?:", string \| undefined, never, "?:", string \| undefined, never>`                 |
| `optional` | `Schema<A, I, R>`, `{ nullable: true }`              | `PropertySignature<"?:", string \| null \| undefined, never, "?:", string \| null \| undefined, never>` |
| `optional` | `Schema<A, I, R>`, `{ exact: true }`                 | `PropertySignature<"?:", string, never, "?:", string, never>`                                           |
| `optional` | `Schema<A, I, R>`, `{ exact: true, nullable: true }` | `PropertySignature<"?:", string \| null, never, "?:", string \| null, never>`                           |

#### optional(schema)

- decoding
  - `<missing value>` -> `<missing value>`
  - `undefined` -> `undefined`
  - `i` -> `a`
- encoding
  - `<missing value>` -> `<missing value>`
  - `undefined` -> `undefined`
  - `a` -> `i`

#### optional(schema, { nullable: true })

- decoding
  - `<missing value>` -> `<missing value>`
  - `undefined` -> `undefined`
  - `null` -> `<missing value>`
  - `i` -> `a`
- encoding
  - `<missing value>` -> `<missing value>`
  - `undefined` -> `undefined`
  - `a` -> `i`

#### optional(schema, { exact: true })

- decoding
  - `<missing value>` -> `<missing value>`
  - `i` -> `a`
- encoding
  - `<missing value>` -> `<missing value>`
  - `a` -> `i`

#### optional(schema, { exact: true, nullable: true })

- decoding
  - `<missing value>` -> `<missing value>`
  - `null` -> `<missing value>`
  - `i` -> `a`
- encoding
  - `<missing value>` -> `<missing value>`
  - `a` -> `i`

### Default Values

The `default` option allows you to set a default value for both the decoding phase and the default constructor.

**Example**

Let's see how default values work in both the decoding and constructing phases, illustrating how the default value is applied when certain properties are not provided.

```ts
import { Schema } from '@effect/schema';

const Product = Schema.Struct({
  name: Schema.String,
  price: Schema.NumberFromString,
  quantity: Schema.optional(Schema.NumberFromString, { default: () => 1 }),
});

// Applying defaults in the decoding phase
console.log(
  Schema.decodeUnknownSync(Product)({ name: 'Laptop', price: '999' }),
); // { name: 'Laptop', price: 999, quantity: 1 }
console.log(
  Schema.decodeUnknownSync(Product)({
    name: 'Laptop',
    price: '999',
    quantity: '2',
  }),
); // { name: 'Laptop', price: 999, quantity: 2 }

// Applying defaults in the constructor
console.log(Product.make({ name: 'Laptop', price: 999 })); // { name: 'Laptop', price: 999, quantity: 1 }
console.log(Product.make({ name: 'Laptop', price: 999, quantity: 2 })); // { name: 'Laptop', price: 999, quantity: 2 }
```

| Combinator | From                                                                   | To                                                                                |
| ---------- | ---------------------------------------------------------------------- | --------------------------------------------------------------------------------- |
| `optional` | `Schema<A, I, R>`, `{ default: () => A }`                              | `PropertySignature<":", string, never, "?:", string \| undefined, never>`         |
| `optional` | `Schema<A, I, R>`, `{ exact: true, default: () => A }`                 | `PropertySignature<":", string, never, "?:", string, never>`                      |
| `optional` | `Schema<A, I, R>`, `{ nullable: true, default: () => A }`              | `PropertySignature<":", string, never, "?:", string \| null \| undefined, never>` |
| `optional` | `Schema<A, I, R>`, `{ exact: true, nullable: true, default: () => A }` | `PropertySignature<":", string, never, "?:", string \| null, never>`              |

#### optional(schema, { default: () => A })

- decoding
  - `<missing value>` -> `<default value>`
  - `undefined` -> `<default value>`
  - `i` -> `a`
- encoding
  - `a` -> `i`

#### optional(schema, { exact: true, default: () => A })

- decoding
  - `<missing value>` -> `<default value>`
  - `i` -> `a`
- encoding
  - `a` -> `i`

#### optional(schema, { nullable: true, default: () => A })

- decoding
  - `<missing value>` -> `<default value>`
  - `undefined` -> `<default value>`
  - `null` -> `<default value>`
  - `i` -> `a`
- encoding
  - `a` -> `i`

#### optional(schema, { exact: true, nullable: true, default: () => A })

- decoding
  - `<missing value>` -> `<default value>`
  - `null` -> `<default value>`
  - `i` -> `a`
- encoding
  - `a` -> `i`

### Optional Fields as `Option`s

| Combinator | From                                                               | To                                                                                        |
| ---------- | ------------------------------------------------------------------ | ----------------------------------------------------------------------------------------- |
| `optional` | `Schema<A, I, R>`, `{ as: "Option" }`                              | `PropertySignature<":", Option<string>, never, "?:", string \| undefined, never>`         |
| `optional` | `Schema<A, I, R>`, `{ exact: true, as: "Option" }`                 | `PropertySignature<":", Option<string>, never, "?:", string, never>`                      |
| `optional` | `Schema<A, I, R>`, `{ nullable: true, as: "Option" }`              | `PropertySignature<":", Option<string>, never, "?:", string \| null \| undefined, never>` |
| `optional` | `Schema<A, I, R>`, `{ exact: true, nullable: true, as: "Option" }` | `PropertySignature<":", Option<string>, never, "?:", string \| null, never>`              |

#### optional(schema, { as: "Option" })

- decoding
  - `<missing value>` -> `Option.none()`
  - `undefined` -> `Option.none()`
  - `i` -> `Option.some(a)`
- encoding
  - `Option.none()` -> `<missing value>`
  - `Option.some(a)` -> `i`

#### optional(schema, { exact: true, as: "Option" })

- decoding
  - `<missing value>` -> `Option.none()`
  - `i` -> `Option.some(a)`
- encoding
  - `Option.none()` -> `<missing value>`
  - `Option.some(a)` -> `i`

#### optional(schema, { nullable: true, as: "Option" })

- decoding
  - `<missing value>` -> `Option.none()`
  - `undefined` -> `Option.none()`
  - `null` -> `Option.none()`
  - `i` -> `Option.some(a)`
- encoding
  - `Option.none()` -> `<missing value>`
  - `Option.some(a)` -> `i`

#### optional(schema, { exact: true, nullable: true, as: "Option" })

- decoding
  - `<missing value>` -> `Option.none()`
  - `null` -> `Option.none()`
  - `i` -> `Option.some(a)`
- encoding
  - `Option.none()` -> `<missing value>`
  - `Option.some(a)` -> `i`

### Optional Fields Primitives

The `optional` API is based on two primitives: `optionalToOptional` and `optionalToRequired`. These primitives are incredibly useful for defining property signatures with more precision.

#### optionalToOptional

The `optionalToOptional` API is used to manage the transformation from an optional field to another optional field. With this, we can control both the output type and the presence or absence of the field.

For example a common use case is to equate a specific value in the source field with the absence of value in the destination field.

Here's the signature of the `optionalToOptional` API:

```ts
export const optionalToOptional = <FA, FI, FR, TA, TI, TR>(
  from: Schema<FA, FI, FR>,
  to: Schema<TA, TI, TR>,
  options: {
    readonly decode: (o: Option.Option<FA>) => Option.Option<TI>,
    readonly encode: (o: Option.Option<TI>) => Option.Option<FA>
  }
): PropertySignature<"?:", TA, never, "?:", FI, false, FR | TR>
```

As you can see, we can transform the type by specifying a schema for `to`, which can be different from the schema of `from`. Additionally, we can control the presence or absence of the field using `decode` and `encode`, with the following meanings:

- `decode`:
  - `none` as an argument means the value is missing in the input
  - `none` as a return value means the value will be missing in the output
- `encode`:
  - `none` as an argument means the value is missing in the input
  - `none` as a return value means the value will be missing in the output

**Example**

Suppose we have an optional field of type `string`, and we want to exclude empty strings from the output. In other words, if the input contains an empty string, we want the field to be absent in the output.

```ts
import { Schema } from '@effect/schema';
import { identity, Option } from 'effect';

const schema = Schema.Struct({
  a: Schema.optionalToOptional(Schema.String, Schema.String, {
    decode: (input) => {
      if (Option.isNone(input)) {
        // If the field is absent in the input, returning `Option.none()` will make it absent in the output too
        return Option.none();
      }
      const value = input.value;
      if (value === '') {
        // If the field is present in the input but is an empty string, returning `Option.none()` will make it absent in the output
        return Option.none();
      }
      // If the field is present in the input and is not an empty string, returning `Option.some` will make it present in the output
      return Option.some(value);
    },
    // Here in the encoding part, we can decide to handle things in the same way as in the decoding phase
    // or handle them differently. For example, we can leave everything unchanged and use the identity function
    encode: identity,
  }),
});

const decode = Schema.decodeUnknownSync(schema);

console.log(decode({})); // Output: {}
console.log(decode({ a: '' })); // Output: {}
console.log(decode({ a: 'a non-empty string' })); // Output: { a: 'a non-empty string' }

const encode = Schema.encodeSync(schema);

console.log(encode({})); // Output: {}
console.log(encode({ a: '' })); // Output: { a: '' }
console.log(encode({ a: 'foo' })); // Output: { a: 'foo' }
```

#### optionalToRequired

The `optionalToRequired` API allows us to transform an optional field into a required one, applying custom logic if the field is absent in the input.

```ts
export const optionalToRequired = <FA, FI, FR, TA, TI, TR>(
  from: Schema<FA, FI, FR>,
  to: Schema<TA, TI, TR>,
  options: {
    readonly decode: (o: Option.Option<FA>) => TI,
    readonly encode: (ti: TI) => Option.Option<FA>
  }
): PropertySignature<":", TA, never, "?:", FI, false, FR | TR>
```

For instance, a common use case is to assign a default value to the field in the output if it's missing in the input. Let's see an example:

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.Struct({
  a: Schema.optionalToRequired(Schema.String, Schema.String, {
    decode: (input) => {
      if (Option.isNone(input)) {
        // If the field is absent in the input, we can return the default value for the field in the output
        return 'default value';
      }
      // If the field is present in the input, return its value as it is in the output
      return input.value;
    },
    // During encoding, we can choose to handle things differently, or simply return the same value present in the input for the output
    encode: (a) => Option.some(a),
  }),
});

const decode = Schema.decodeUnknownSync(schema);

console.log(decode({})); // Output: { a: 'default value' }
console.log(decode({ a: 'foo' })); // Output: { a: 'foo' }

const encode = Schema.encodeSync(schema);

console.log(encode({ a: 'foo' })); // Output: { a: 'foo' }
```

#### requiredToOptional

This API allows developers to specify how a field that is normally required can be treated as optional based on custom logic.

```ts
export const requiredToOptional = <FA, FI, FR, TA, TI, TR>(
  from: Schema<FA, FI, FR>,
  to: Schema<TA, TI, TR>,
  options: {
    readonly decode: (fa: FA) => Option.Option<TI>
    readonly encode: (o: Option.Option<TI>) => FA
  }
): PropertySignature<"?:", TA, never, ":", FI, false, FR | TR>
```

- **`from` and `to` Schemas**: Define the starting and ending schemas for the transformation.
- **`decode`**: Custom logic for transforming the required input into an optional output.
- **`encode`**: Defines how to handle the potentially optional input when encoding it back to a required output.

**Example**

Let's look at a practical example where a field `name` that is typically required can be considered optional if it's an empty string during decoding, and ensure there is always a value during encoding by providing a default.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.Struct({
  name: Schema.requiredToOptional(Schema.String, Schema.String, {
    decode: Option.liftPredicate((s) => s !== ''), // empty string is considered as absent
    encode: Option.getOrElse(() => ''),
  }),
});

const decode = Schema.decodeUnknownSync(schema);

console.log(decode({ name: 'John' })); // Output: { name: 'John' }
console.log(decode({ name: '' })); // Output: {}

const encode = Schema.encodeSync(schema);

console.log(encode({ name: 'John' })); // { name: 'John' }
console.log(encode({})); // Output: { name: '' }
```

### Renaming a Property During Definition

To rename a property directly during schema creation, you can utilize the `Schema.fromKey` function. This function is particularly useful when you want to map properties from the input object to different names in the resulting schema object.

**Example: Renaming a Required Property**

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  a: Schema.propertySignature(Schema.String).pipe(Schema.fromKey('c')),
  b: Schema.Number,
});

console.log(Schema.decodeUnknownSync(schema)({ c: 'c', b: 1 }));
// Output: { a: "c", b: 1 }
```

**Example: Renaming an Optional Property**

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  a: Schema.optional(Schema.String).pipe(Schema.fromKey('c')),
  b: Schema.Number,
});

console.log(Schema.decodeUnknownSync(schema)({ c: 'c', b: 1 }));
// Output: { b: 1, a: "c" }

console.log(Schema.decodeUnknownSync(schema)({ b: 1 }));
// Output: { b: 1 }
```

Note that `Schema.optional` returns a `PropertySignature`, which simplifies the process by eliminating the need for explicit `Schema.propertySignature` usage as required in previous versions.

### Renaming Properties of an Existing Schema

For existing schemas, the `rename` API offers a way to systematically change property names across a schema, even within complex structures like unions.

**Example: Renaming Properties in a Struct Schema**

```ts
import { Schema } from '@effect/schema';

// Original Schema
const originalSchema = Schema.Struct({
  c: Schema.String,
  b: Schema.Number,
});

// Renaming the "c" property to "a"
const renamedSchema = Schema.rename(originalSchema, { c: 'a' });

console.log(Schema.decodeUnknownSync(renamedSchema)({ c: 'c', b: 1 }));
// Output: { a: "c", b: 1 }
```

**Example: Renaming Properties in Union Schemas**

```ts
import { Schema } from '@effect/schema';

const originalSchema = Schema.Union(
  Schema.Struct({
    c: Schema.String,
    b: Schema.Number,
  }),
  Schema.Struct({
    c: Schema.String,
    d: Schema.Boolean,
  }),
);

// Renaming the "c" property to "a" for all members
const renamedSchema = Schema.rename(originalSchema, { c: 'a' });

console.log(Schema.decodeUnknownSync(renamedSchema)({ c: 'c', b: 1 }));
// Output: { a: "c", b: 1 }

console.log(Schema.decodeUnknownSync(renamedSchema)({ c: 'c', d: false }));
// Output: { d: false, a: 'c' }
```

## Tagged Structs

In TypeScript tags help to enhance type discrimination and pattern matching by providing a simple yet powerful way to define and recognize different data types.

### What is a Tag?

A tag is a literal value added to data structures, commonly used in structs, to distinguish between various object types or variants within tagged unions. This literal acts as a discriminator, making it easier to handle and process different types of data correctly and efficiently.

### Using the `tag` Constructor

The `tag` constructor is specifically designed to create a property signature that holds a specific literal value, serving as the discriminator for object types. Here's how you can define a schema with a tag:

```ts
import { Schema } from '@effect/schema';

const User = Schema.Struct({
  _tag: Schema.tag('User'),
  name: Schema.String,
  age: Schema.Number,
});

assert.deepStrictEqual(User.make({ name: 'John', age: 44 }), {
  _tag: 'User',
  name: 'John',
  age: 44,
});
```

In the example above, `Schema.tag("User")` attaches a `_tag` property to the `User` struct schema, effectively labeling objects of this struct type as "User". This label is automatically applied when using the `make` method to create new instances, simplifying object creation and ensuring consistent tagging.

### Simplifying Tagged Structs with `TaggedStruct`

The `TaggedStruct` constructor streamlines the process of creating tagged structs by directly integrating the tag into the struct definition. This method provides a clearer and more declarative approach to building data structures with embedded discriminators.

```ts
import { Schema } from '@effect/schema';

const User = Schema.TaggedStruct('User', {
  name: Schema.String,
  age: Schema.Number,
});

// `_tag` is optional
const userInstance = User.make({ name: 'John', age: 44 });

assert.deepStrictEqual(userInstance, {
  _tag: 'User',
  name: 'John',
  age: 44,
});
```

### Multiple Tags

While a primary tag is often sufficient, TypeScript allows you to define multiple tags for more complex data structuring needs. Here's an example demonstrating the use of multiple tags within a single struct:

```ts
import { Schema } from '@effect/schema';

const Product = Schema.TaggedStruct('Product', {
  category: Schema.tag('Electronics'),
  name: Schema.String,
  price: Schema.Number,
});

// `_tag` and `category` are optional
const productInstance = Product.make({ name: 'Smartphone', price: 999 });

assert.deepStrictEqual(productInstance, {
  _tag: 'Product',
  category: 'Electronics',
  name: 'Smartphone',
  price: 999,
});
```

This example showcases a product schema that not only categorizes each product under a general tag (`"Product"`) but also specifies a category tag (`"Electronics"`), enhancing the clarity and specificity of the data model.

## instanceOf

When you need to define a schema for your custom data type defined through a `class`, the most convenient and fast way is to use the `Schema.instanceOf` constructor. Let's see an example:

```ts
import { Schema } from '@effect/schema';

class MyData {
  constructor(readonly name: string) {}
}

// Schema.instanceOf<MyData>
const MyDataSchema = Schema.instanceOf(MyData);

console.log(Schema.decodeUnknownSync(MyDataSchema)(new MyData('name')));
// MyData { name: 'name' }
console.log(Schema.decodeUnknownSync(MyDataSchema)({ name: 'name' }));
/*
throws
Error: Expected an instance of MyData, actual {"name":"name"}
*/
```

The `Schema.instanceOf` constructor is just a lightweight wrapper of the `Schema.declare` API, which is the primitive in `@effect/schema` for declaring new custom data types.

However, note that `instanceOf` can only be used for classes that expose a **public constructor**. If you try to use it with classes that, for some reason, have marked the constructor as `private`, you'll receive a TypeScript error:

```ts
import { Schema } from '@effect/schema';

class MyData {
  static make = (name: string) => new MyData(name);
  private constructor(readonly name: string) {}
}

/*
Argument of type 'typeof MyData' is not assignable to parameter of type 'abstract new (...args: any) => any'.
  Cannot assign a 'private' constructor type to a 'public' constructor type.ts(2345)
*/
const MyDataSchema = Schema.instanceOf(MyData);
```

In such cases, you cannot use `Schema.instanceOf`, and you must rely on `Schema.declare` like this:

```ts
import { Schema } from '@effect/schema';

class MyData {
  static make = (name: string) => new MyData(name);
  private constructor(readonly name: string) {}
}

const MyDataSchema = Schema.declare(
  (input: unknown): input is MyData => input instanceof MyData,
);

console.log(Schema.decodeUnknownSync(MyDataSchema)(MyData.make('name')));
// MyData { name: 'name' }
console.log(Schema.decodeUnknownSync(MyDataSchema)({ name: 'name' }));
/*
throws
Error: Expected <declaration schema>, actual {"name":"name"}
*/
```

To improve the error message in case of failed decoding, remember to add annotations:

```ts
const MyDataSchema = Schema.declare(
  (input: unknown): input is MyData => input instanceof MyData,
  {
    identifier: 'MyData',
    description: 'an instance of MyData',
  },
);

console.log(Schema.decodeUnknownSync(MyDataSchema)({ name: 'name' }));
/*
throws
Error: Expected MyData (an instance of MyData), actual {"name":"name"}
*/
```

## pick

The `pick` operation is used to select specific properties from a schema.

```ts
import { Schema } from '@effect/schema';

// Schema<{ readonly a: string; }>
Schema.Struct({ a: Schema.String, b: Schema.Number, c: Schema.Boolean }).pipe(
  Schema.pick('a'),
);

// Schema<{ readonly a: string; readonly c: boolean; }>
Schema.Struct({ a: Schema.String, b: Schema.Number, c: Schema.Boolean }).pipe(
  Schema.pick('a', 'c'),
);
```

## omit

The `omit` operation is employed to exclude certain properties from a schema.

```ts
import { Schema } from '@effect/schema';

// Schema<{ readonly b: number; readonly c: boolean; }>
Schema.Struct({ a: Schema.String, b: Schema.Number, c: Schema.Boolean }).pipe(
  Schema.omit('a'),
);

// Schema<{ readonly b: number; }>
Schema.Struct({ a: Schema.String, b: Schema.Number, c: Schema.Boolean }).pipe(
  Schema.omit('a', 'c'),
);
```

## partial

The `partial` operation makes all properties within a schema optional.

By default, the `partial` operation adds a union with `undefined` to the types. If you wish to avoid this, you can opt-out by passing a `{ exact: true }` argument to the `partial` operation.

**Example**

```ts
import { Schema } from '@effect/schema';

/*
Schema.Schema<{
    readonly a?: string | undefined;
}, {
    readonly a?: string | undefined;
}, never>
*/
const schema = Schema.partial(Schema.Struct({ a: Schema.String }));

Schema.decodeUnknownSync(schema)({ a: 'a' }); // ok
Schema.decodeUnknownSync(schema)({ a: undefined }); // ok

/*
Schema.Schema<{
    readonly a?: string;
}, {
    readonly a?: string;
}, never>
*/
const exactSchema = Schema.partial(Schema.Struct({ a: Schema.String }), {
  exact: true,
});

Schema.decodeUnknownSync(exactSchema)({ a: 'a' }); // ok
Schema.decodeUnknownSync(exactSchema)({ a: undefined });
/*
throws:
Error: { readonly a?: string }
â””â”€ ["a"]
   â””â”€ Expected a string, actual undefined
*/
```

## required

The `required` operation ensures that all properties in a schema are mandatory.

```ts
import { Schema } from '@effect/schema';

// Schema<{ readonly a: string; readonly b: number; }>
Schema.required(
  Schema.Struct({
    a: Schema.optional(Schema.String, { exact: true }),
    b: Schema.optional(Schema.Number, { exact: true }),
  }),
);
```

## Extending Schemas

The `extend` combinator allows you to add **additional** fields or index signatures to an existing `Schema`.

Example

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  a: Schema.String,
  b: Schema.String,
});

/*
const extended: S.Schema<{
    readonly [x: string]: string;
    readonly a: string;
    readonly b: string;
    readonly c: string;
}>
*/
const extended = Schema.asSchema(
  schema.pipe(
    Schema.extend(Schema.Struct({ c: Schema.String })), // <= you can add more fields
    Schema.extend(Schema.Record(Schema.String, Schema.String)), // <= you can add index signatures
  ),
);
```

Alternatively, you can utilize the `fields` property of structs:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({ a: Schema.String, b: Schema.String });

const extended = Schema.Struct(
  {
    ...schema.fields,
    c: Schema.String,
  },
  { key: Schema.String, value: Schema.String },
);
```

> [!NOTE]
> Note that there are strict limitations on the schemas that can be handled by `extend`:

1. It only supports **structs**, refinements of structs, unions of structs, suspensions of structs (informally `Supported = Struct | Refinement of Supported | Union of Supported | suspend(() => Supported)`)
2. The arguments must represent disjoint types (e.g., `extend(Struct({ a: String }), Struct({ a: String })))` raises an error)

## Composition

Combining and reusing schemas is a common requirement, the `compose` combinator allows you to do just that. It enables you to combine two schemas, `Schema<B, A, R1>` and `Schema<C, B, R2>`, into a single schema `Schema<C, A, R1 | R2>`:

```ts
import { Schema } from '@effect/schema';

// Schema<readonly string[], string>
const schema1 = Schema.split(',');

// Schema<readonly number[], readonly string[]>
const schema2 = Schema.Array(Schema.NumberFromString);

// Schema<readonly number[], string>
const ComposedSchema = Schema.compose(schema1, schema2);
```

In this example, we have two schemas, `schema1` and `schema2`. The first schema, `schema1`, takes a string and splits it into an array using a comma as the delimiter. The second schema, `schema2`, transforms an array of strings into an array of numbers.

Now, by using the `compose` combinator, we can create a new schema, `ComposedSchema`, that combines the functionality of both `schema1` and `schema2`. This allows us to parse a string and directly obtain an array of numbers as a result.

### Non-strict Option

If you need to be less restrictive when composing your schemas, i.e., when you have something like `Schema<R1, A, B>` and `Schema<R2, C, D>` where `C` is different from `B`, you can make use of the `{ strict: false }` option:

```ts
declare const compose: <A, B, R1, D, C, R2>(
  from: Schema<B, A, R1>,
  to: Schema<D, C, R2>,
  options: { readonly strict: false } // Less strict constraint
  ,
) => Schema<D, A, R1 | R2>;
```

This is useful when you want to relax the type constraints imposed by the `decode` and `encode` functions, making them more permissive:

```ts
import { Schema } from '@effect/schema';

// error: Type 'string | null' is not assignable to type 'string'
Schema.compose(
  Schema.Union(Schema.Null, Schema.String),
  Schema.NumberFromString,
);

// ok
Schema.compose(
  Schema.Union(Schema.Null, Schema.String),
  Schema.NumberFromString,
  { strict: false },
);
```

## Projections

### typeSchema

The `typeSchema` function allows you to extract the `Type` portion of a schema, creating a new schema that conforms to the properties defined in the original schema without considering the initial encoding or transformation processes.

**Function Signature:**

```ts
export const typeSchema = <A, I, R>(schema: Schema<A, I, R>): Schema<A>
```

**Example Usage:**

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  foo: Schema.NumberFromString.pipe(Schema.greaterThanOrEqualTo(2)),
});

// This creates a schema where 'foo' is strictly a number that must be greater than or equal to 2.
const resultingTypeSchema = Schema.typeSchema(schema);

// resultingTypeSchema is the same as:
Schema.Struct({
  foo: Schema.Number.pipe(Schema.greaterThanOrEqualTo(2)),
});
```

In this example:

- **Original Schema**: The schema for `foo` is initially defined to accept a number from a string and enforce that it is greater than or equal to 2.
- **Resulting Type Schema**: The `typeSchema` extracts only the type-related information from `foo`, simplifying it to just a number while still maintaining the constraint that it must be greater than or equal to 2.

### encodedSchema

The `encodedSchema` function allows you to extract the `Encoded` portion of a schema, creating a new schema that conforms to the properties defined in the original schema without retaining any refinements or transformations that were applied previously.

**Function Signature:**

```ts
export const encodedSchema = <A, I, R>(schema: Schema<A, I, R>): Schema<I>
```

**Example Usage:**

Attenzione che `encodedSchema` non preserva i refinements:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  foo: Schema.String.pipe(Schema.minLength(3)),
});

// resultingEncodedSchema simplifies 'foo' to just a string, disregarding the minLength refinement.
const resultingEncodedSchema = Schema.encodedSchema(schema);

// resultingEncodedSchema is the same as:
Schema.Struct({
  foo: Schema.String,
});
```

In this example:

- **Original Schema Definition**: The `foo` field in the schema is defined as a string with a minimum length of three characters.
- **Resulting Encoded Schema**: The `encodedSchema` function simplifies the `foo` field to just a string type, effectively stripping away the `minLength` refinement.

### encodedBoundSchema

The `encodedBoundSchema` function is similar to `encodedSchema` but preserves the refinements up to the first transformation point in the
original schema.

**Function Signature:**

```ts
export const encodedBoundSchema = <A, I, R>(schema: Schema<A, I, R>): Schema<I>
```

The term "bound" in this context refers to the boundary up to which refinements are preserved when extracting the encoded form of a schema. It essentially marks the limit to which initial validations and structure are maintained before any transformations are applied.

**Example Usage:**

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  foo: Schema.String.pipe(Schema.minLength(3), Schema.compose(Schema.Trim)),
});

// The resultingEncodedBoundSchema preserves the minLength(3) refinement,
// ensuring the string length condition is enforced but omits the Trim transformation.
const resultingEncodedBoundSchema = Schema.encodedBoundSchema(schema);

// resultingEncodedBoundSchema is the same as:
Schema.Struct({
  foo: Schema.String.pipe(Schema.minLength(3)),
});
```

In the provided example:

- **Initial Schema**: The schema for `foo` includes a refinement to ensure strings have a minimum length of three characters and a transformation to trim the string.
- **Resulting Schema**: `resultingEncodedBoundSchema` maintains the `minLength(3)` condition, ensuring that this validation persists. However, it excludes the trimming transformation, focusing solely on the length requirement without altering the string's formatting.

# Declaring New Data Types

Creating schemas for new data types is crucial to defining the expected structure of information in your application. This guide explores how to declare schemas for new data types. We'll cover two important concepts: declaring schemas for primitive data types and type constructors.

## Declaring Schemas for Primitive Data Types

A primitive data type represents simple values. To declare a schema for a primitive data type, like the `File` type in TypeScript, we use the `S.declare` constructor along with a type guard. Let's go through an example:

```ts
import { Schema } from '@effect/schema';

// Schema.SchemaClass<File, File, never>
const FileFromSelf = Schema.declare(
  (input: unknown): input is File => input instanceof File,
);

const decode = Schema.decodeUnknownSync(FileFromSelf);

console.log(decode(new File([], ''))); // File { size: 0, type: '', name: '', lastModified: 1705595977234 }

decode(null);
/*
throws
Error: Expected <declaration schema>, actual null
*/
```

As you can see, the error message describes what went wrong but doesn't provide much information about which schema caused the error (`"Expected <declaration schema>"`). To enhance the default error message, you can add annotations, particularly the `identifier`, `title`, and `description` annotations (none of these annotations are required, but they are encouraged for good practice and can make your schema "self-documenting"). These annotations will be utilized by the messaging system to return more meaningful messages.

A "title" should be concise, while a "description" provides a more detailed explanation of the purpose of the data described by the schema.

```ts
import { Schema } from '@effect/schema';

const FileFromSelf = Schema.declare(
  (input: unknown): input is File => input instanceof File,
  {
    identifier: 'FileFromSelf',
    description: 'The `File` type in JavaScript',
  },
);

const decode = Schema.decodeUnknownSync(FileFromSelf);

console.log(decode(new File([], ''))); // File { size: 0, type: '', name: '', lastModified: 1705595977234 }

decode(null);
/*
throws
Error: Expected FileFromSelf (The File type in JavaScript), actual null
*/
```

## Declaring Schemas for Type Constructors

Type constructors are generic types that take one or more types as arguments and return a new type. If you need to define a schema for a type constructor, you can use the `S.declare` constructor. Let's illustrate this with a schema for `ReadonlySet<A>`:

```ts
import { ParseResult, Schema } from '@effect/schema';

export const MyReadonlySet = <A, I, R>(
  // Schema for the elements of the Set
  item: Schema.Schema<A, I, R>,
): Schema.Schema<ReadonlySet<A>, ReadonlySet<I>, R> =>
  Schema.declare(
    // Store the schema for the elements
    [item],
    {
      // Decoding function
      decode: (item) => (input, parseOptions, ast) => {
        if (input instanceof Set) {
          // Decode the elements
          const elements = ParseResult.decodeUnknown(Schema.Array(item))(
            Array.from(input.values()),
            parseOptions,
          );
          // Return a Set containing the parsed elements
          return ParseResult.map(elements, (as): ReadonlySet<A> => new Set(as));
        }
        return ParseResult.fail(new ParseResult.Type(ast, input));
      },
      // Encoding function
      encode: (item) => (input, parseOptions, ast) => {
        if (input instanceof Set) {
          // Encode the elements
          const elements = ParseResult.encodeUnknown(Schema.Array(item))(
            Array.from(input.values()),
            parseOptions,
          );
          // Return a Set containing the parsed elements
          return ParseResult.map(elements, (is): ReadonlySet<I> => new Set(is));
        }
        return ParseResult.fail(new ParseResult.Type(ast, input));
      },
    },
    {
      description: `ReadonlySet<${Schema.format(item)}>`,
    },
  );

// const setOfNumbers: S.Schema<ReadonlySet<string>, ReadonlySet<number>>
const setOfNumbers = MyReadonlySet(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(setOfNumbers);

console.log(decode(new Set(['1', '2', '3']))); // Set(3) { 1, 2, 3 }

decode(null);
/*
throws
Error: Expected ReadonlySet<NumberFromString>, actual null
*/

decode(new Set(['1', null, '3']));
/*
throws
Error: ReadonlySet<NumberFromString>
â””â”€ ReadonlyArray<NumberFromString>
   â””â”€ [1]
      â””â”€ NumberFromString
         â””â”€ From side transformation failure
            â””â”€ Expected a string, actual null
*/
```

> [!WARNING]
> The decoding and encoding functions cannot use context (the `R` type parameter) and cannot use async effects.

## Adding Annotations

When you define a new data type, some compilers like `Arbitrary` or `Pretty` may not know how to handle the newly defined data. For instance:

```ts
import { Arbitrary, Schema } from '@effect/schema';

const FileFromSelf = Schema.declare(
  (input: unknown): input is File => input instanceof File,
  {
    identifier: 'FileFromSelf',
  },
);

// Create an Arbitrary instance for FileFromSelf schema
const arb = Arbitrary.make(FileFromSelf);
/*
throws:
Error: cannot build an Arbitrary for a declaration without annotations (FileFromSelf)
*/
```

In such cases, you need to provide annotations to ensure proper functionality:

```ts
import { Arbitrary, FastCheck, Pretty, Schema } from '@effect/schema';

const FileFromSelf = Schema.declare(
  (input: unknown): input is File => input instanceof File,
  {
    identifier: 'FileFromSelf',
    // Provide an arbitrary function to generate random File instances
    arbitrary: () => (fc) =>
      fc
        .tuple(fc.string(), fc.string())
        .map(([path, content]) => new File([content], path)),
    // Provide a pretty function to generate human-readable representation of File instances
    pretty: () => (file) => `File(${file.name})`,
  },
);

// Create an Arbitrary instance for FileFromSelf schema
const arb = Arbitrary.make(FileFromSelf);

// Generate sample files using the Arbitrary instance
const files = FastCheck.sample(arb, 2);
console.log(files);
/*
Output:
[
  File { size: 5, type: '', name: 'C', lastModified: 1706435571176 },
  File { size: 1, type: '', name: '98Ggmc', lastModified: 1706435571176 }
]
*/

// Create a Pretty instance for FileFromSelf schema
const pretty = Pretty.make(FileFromSelf);

// Print human-readable representation of a file
console.log(pretty(files[0])); // "File(C)"
```

# Transformations

Transformations are a crucial aspect of working with schemas, especially when you need to convert data from one type to another, such as parsing a string into a number or converting a date string into a `Date` object.

## transform

The `transform` combinator is designed to facilitate these conversions by linking two schemas together: one for the input type and one for the output type.

The `transform` combinator takes four key parameters:

- **from**: This is the source schema, denoted as `Schema<B, A, R1>`, where `A` is the input type and `B` is the intermediate type after initial validation.
- **to**: This is the target schema, denoted as `Schema<D, C, R2>`, where `C` is the transformed type from `B`, and `D` is the final output type.
- **decode**: A function that transforms an intermediate value of type `B` into another value of type `C`.
- **encode**: A function that reverses the transformation, converting type `C` back to type `B`.

The resulting schema from using `transform` will be `Schema<D, A, R1 | R2>`, indicating it integrates the dependencies and transformations specified in both the `from` and `to` schemas.

**Flowchart Explanation**

```mermaid
flowchart TD
  schema1["from: Schema<B, A>"]
  schema2["to: Schema<D, C>"]
  schema1--"decode: B -> C"-->schema2
  schema2--"encode: C -> B"-->schema1
```

This flowchart illustrates how the data flows through the `transform` combinator, starting from the `from` schema, passing through the transformation functions, and finally through the `to` schema.

**Practical Example: Doubling a Number**

Here's how you might define a simple schema transformation that doubles an input number:

```ts
import { Schema } from '@effect/schema';

// Define a transformation that doubles the input number
export const transformedSchema = Schema.transform(
  Schema.Number, // Source schema
  Schema.Number, // Target schema
  {
    decode: (n) => n * 2, // Transformation function to double the number
    encode: (n) => n / 2, // Reverse transformation to revert to the original number
  },
);
```

In this example, if you provide the input value `2`, the transformation schema will decode it to `4` and encode it back to `2`.

Here's a simple example of how you might use the `transform` combinator to trim whitespace from string inputs:

```ts
import { Schema } from '@effect/schema';

export const transformedSchema = Schema.transform(
  Schema.String, // Source schema: accepts any string
  Schema.String, // Target schema: also accepts any string
  {
    decode: (s) => s.trim(), // Trim the string during decoding
    encode: (s) => s, // No change during encoding
  },
);
```

In this example, the `transform` function is used to create a schema that automatically trims leading and trailing whitespace from a string when decoding. During encoding, it simply returns the string as is, assuming it's already trimmed.

### Improving the Transformation with a Filter

While the basic example ensures that strings are trimmed during the decoding process, it doesn't enforce that only trimmed strings are accepted or returned by the schema. To enhance this, you can restrict the target schema to only accept strings that are already trimmed:

```ts
import { Schema } from '@effect/schema';

export const transformedSchema = Schema.transform(
  Schema.String, // Source schema: accepts any string
  Schema.String.pipe(Schema.filter((s) => s === s.trim())), // Target schema now only accepts strings that are trimmed
  {
    decode: (s) => s.trim(), // Trim the string during decoding
    encode: (s) => s, // No change during encoding
  },
);
```

In this improved example, the target schema is piped through a `filter` function. This function checks that the string is equal to its trimmed version, effectively ensuring that only strings without leading or trailing whitespace are considered valid. This is particularly useful for maintaining data integrity and can help prevent errors or inconsistencies in data processing.

### Non-strict option

Sometimes the strict type checking can impede certain operations where types might slightly deviate during the transformation process. For such cases, `transform` provides an option, `strict: false`, to relax type constraints and allow for more flexible data manipulation.

**Example: Clamping Constructor**

Let's consider the scenario where you need to define a constructor `clamp` that ensures a number falls within a specific range. This function returns a schema that "clamps" a number to a specified minimum and maximum range:

```ts
import { Schema } from '@effect/schema';
import { Number } from 'effect';

const clamp =
  (minimum: number, maximum: number) =>
  <A extends number, I, R>(self: Schema.Schema<A, I, R>) =>
    Schema.transform(
      self,
      self.pipe(
        Schema.typeSchema,
        Schema.filter((a) => a <= minimum || a >= maximum),
      ),
      {
        decode: (a) => Number.clamp(a, { minimum, maximum }),
        encode: (a) => a,
      },
    );
```

In this code, `Number.clamp` is a function that adjusts the given number to stay within the specified range. However, the return type of `Number.clamp` may not strictly be of type `A` but just a `number`, which can lead to type mismatches according to TypeScript's strict type-checking.

There are two ways to resolve the type mismatch:

1. **Using Type Assertion**:
   Adding a type cast can enforce the return type to be treated as type `A`:

   ```ts
   decode: ((a) => Number.clamp(a, { minimum, maximum }) as A);
   ```

2. **Using the Non-Strict Option**:
   Setting `strict: false` in the transformation options allows the schema to bypass some of TypeScript's type-checking rules, accommodating the type discrepancy:

   ```ts
   import { Schema } from '@effect/schema';
   import { Number } from 'effect';

   export const clamp =
     (minimum: number, maximum: number) =>
     <A extends number, I, R>(self: Schema.Schema<A, I, R>) =>
       Schema.transform(
         self,
         self.pipe(
           Schema.typeSchema,
           Schema.filter((a) => a >= minimum && a <= maximum),
         ),
         {
           strict: false,
           decode: (a) => Number.clamp(a, { minimum, maximum }),
           encode: (a) => a,
         },
       );
   ```

## transformOrFail

In data transformation processes, handling transformations that may fail is crucial. While the `transform` combinator is suitable for error-free transformations, the `transformOrFail` combinator is designed for more complex scenarios where transformations can fail during the decoding or encoding stages.

The `transformOrFail` combinator extends the capabilities of the `transform` combinator by allowing for potential failures in the transformation functions. This combinator enables functions to return either a successful result or an error, making it particularly useful for validating and processing data that might not always conform to expected formats.

### Error Handling with ParseResult

The `transformOrFail` combinator utilizes the `ParseResult` module to manage potential errors:

- **`ParseResult.succeed`**: This function is used to indicate a successful transformation, where no errors occurred.
- **`ParseResult.fail(issue)`**: This function signals a failed transformation, creating a new `ParseError` based on the provided `ParseIssue`.

Additionally, the `ParseError` module provides APIs for dealing with various types of parse issues, such as `Declaration`, `Refinement`, `TupleType`, `TypeLiteral`, `Union`, `Transformation`, `Type`, and `Forbidden`. These tools allow for detailed and specific error handling, enhancing the reliability of data processing operations.

**Example: Converting a String to a Number**

A common use case for `transformOrFail` is converting string representations of numbers into actual numeric types. This scenario is typical when dealing with user inputs or data from external sources.

```ts
import { ParseResult, Schema } from '@effect/schema';

export const NumberFromString = Schema.transformOrFail(
  Schema.String, // Source schema: accepts any string
  Schema.Number, // Target schema: expects a number
  {
    decode: (input, options, ast) => {
      const parsed = parseFloat(input);
      if (isNaN(parsed)) {
        return ParseResult.fail(
          new ParseResult.Type(
            ast,
            input,
            'Failed to convert string to number',
          ),
        );
      }
      return ParseResult.succeed(parsed);
    },
    encode: (input, options, ast) => ParseResult.succeed(input.toString()),
  },
);
```

In this example:

- **Decoding:** Attempts to parse the input string into a number. If the parsing results in `NaN` (indicating that the string is not a valid number), it fails with a descriptive error.
- **Encoding:** Converts the number back to a string, assuming that the input number is valid.

Both `decode` and `encode` functions not only receive the value to transform (`input`), but also the parse `options` that the user sets when using the resulting schema, and the `ast`, which represents the `AST` of the schema you're transforming.

### Async Operations

In modern applications, especially those interacting with external APIs, you might need to transform data asynchronously

**Example: Asynchronously Converting a String to a Number Using an API**

Consider a situation where you need to validate a person's ID by fetching data from an external API. Here's how you can implement it:

```ts
import { ParseResult, Schema, TreeFormatter } from '@effect/schema';
import { Effect } from 'effect';

// Define an API call function
const api = (url: string): Effect.Effect<unknown, Error> =>
  Effect.tryPromise({
    try: () =>
      fetch(url).then((res) => {
        if (res.ok) {
          return res.json() as Promise<unknown>;
        }
        throw new Error(String(res.status));
      }),
    catch: (e) => new Error(String(e)),
  });

const PeopleId = Schema.String.pipe(Schema.brand('PeopleId'));

// Define a schema with async transformation
const PeopleIdFromString = Schema.transformOrFail(Schema.String, PeopleId, {
  decode: (s, _, ast) =>
    Effect.mapBoth(api(`https://swapi.dev/api/people/${s}`), {
      onFailure: (e) => new ParseResult.Type(ast, s, e.message),
      onSuccess: () => s,
    }),
  encode: ParseResult.succeed,
});

const decode = (id: string) =>
  Effect.mapError(
    Schema.decodeUnknown(PeopleIdFromString)(id),
    (e) => TreeFormatter.formatError(e),
  );

Effect.runPromiseExit(decode('1')).then(console.log);
/*
Output:
{ _id: 'Exit', _tag: 'Success', value: '1' }
*/

Effect.runPromiseExit(decode('fail')).then(console.log);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Fail',
    failure: '(string <-> string)\nâ””â”€ Transformation process failure\n   â””â”€ Error: 404'
  }
}
*/
```

### Declaring Dependencies

For more complex scenarios where your transformation might depend on external services like a fetching function, you can declare these dependencies explicitly. This approach ensures that your schema transformations are not only testable but also modular.

**Example: Injecting Dependencies**

Here's how to inject a fetch dependency into your transformation process:

```ts
import { ParseResult, Schema, TreeFormatter } from '@effect/schema';
import { Context, Effect, Layer } from 'effect';

const Fetch = Context.GenericTag<'Fetch', typeof fetch>('Fetch');

// API call function with dependency
const api = (url: string): Effect.Effect<unknown, Error, 'Fetch'> =>
  Fetch.pipe(
    Effect.flatMap((fetch) =>
      Effect.tryPromise({
        try: () =>
          fetch(url).then((res) => {
            if (res.ok) {
              return res.json() as Promise<unknown>;
            }
            throw new Error(String(res.status));
          }),
        catch: (e) => new Error(String(e)),
      })
    ),
  );

const PeopleId = Schema.String.pipe(Schema.brand('PeopleId'));

const PeopleIdFromString = Schema.transformOrFail(Schema.String, PeopleId, {
  decode: (s, _, ast) =>
    Effect.mapBoth(api(`https://swapi.dev/api/people/${s}`), {
      onFailure: (e) => new ParseResult.Type(ast, s, e.message),
      onSuccess: () => s,
    }),
  encode: ParseResult.succeed,
});

const decode = (id: string) =>
  Effect.mapError(
    Schema.decodeUnknown(PeopleIdFromString)(id),
    (e) => TreeFormatter.formatError(e),
  );

const FetchLive = Layer.succeed(Fetch, fetch);

Effect.runPromiseExit(decode('1').pipe(Effect.provide(FetchLive))).then(
  console.log,
);
/*
Output:
{ _id: 'Exit', _tag: 'Success', value: '1' }
*/

Effect.runPromiseExit(decode('fail').pipe(Effect.provide(FetchLive))).then(
  console.log,
);
/*
Output:
{
  _id: 'Exit',
  _tag: 'Failure',
  cause: {
    _id: 'Cause',
    _tag: 'Fail',
    failure: '(string <-> string)\nâ””â”€ Transformation process failure\n   â””â”€ Error: 404'
  }
}
*/
```

## String Transformations

### split

The `split` combinator allows splitting a string into an array of strings.

```ts
import { Schema } from '@effect/schema';

// Schema<string[], string>
const schema = Schema.split(',');
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('')); // [""]
console.log(decode(',')); // ["", ""]
console.log(decode('a,')); // ["a", ""]
console.log(decode('a,b')); // ["a", "b"]
```

### Trim

The `Trim` schema allows removing whitespaces from the beginning and end of a string.

```ts
import { Schema } from '@effect/schema';

// Schema<string>
const schema = Schema.Trim;
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('a')); // "a"
console.log(decode(' a')); // "a"
console.log(decode('a ')); // "a"
console.log(decode(' a ')); // "a"
```

**Note**. If you were looking for a combinator to check if a string is trimmed, check out the `trimmed` filter.

### Lowercase

The `Lowercase` schema converts a string to lowercase.

```ts
import { Schema } from '@effect/schema';

const decode = Schema.decodeUnknownSync(Schema.Lowercase);

console.log(decode('A')); // "a"
console.log(decode(' AB')); // " ab"
console.log(decode('Ab ')); // "ab "
console.log(decode(' ABc ')); // " abc "
```

**Note**. If you were looking for a combinator to check if a string is lowercased, check out the `Lowercased` schema or the `lowercased` filter.

### Uppercase

The `Uppercase` schema converts a string to uppercase.

```ts
import { Schema } from '@effect/schema';

const decode = Schema.decodeUnknownSync(Schema.Uppercase);

console.log(decode('a')); // "A"
console.log(decode(' ab')); // " AB"
console.log(decode('aB ')); // "AB "
console.log(decode(' abC ')); // " ABC "
```

**Note**. If you were looking for a combinator to check if a string is uppercased, check out the `Uppercased` schema or the `uppercased` filter.

### parseJson

The `parseJson` constructor offers a method to convert JSON strings into the `unknown` type using the underlying functionality of `JSON.parse`. It also employs `JSON.stringify` for encoding.

```ts
import { Schema } from '@effect/schema';

// Schema<unknown, string>
const schema = Schema.parseJson();
const decode = Schema.decodeUnknownSync(schema);

// Parse valid JSON strings
console.log(decode('{}')); // Output: {}
console.log(decode(`{"a":"b"}`)); // Output: { a: "b" }

// Attempting to decode an empty string results in an error
decode('');
/*
throws:
Error: (JsonString <-> unknown)
â””â”€ Transformation process failure
   â””â”€ Unexpected end of JSON input
*/
```

Additionally, you can refine the parsing result by providing a schema to the `parseJson` constructor:

```ts
import { Schema } from '@effect/schema';

/*
Schema.Schema<{
    readonly a: number;
}, string, never>
*/
const schema = Schema.parseJson(Schema.Struct({ a: Schema.Number }));
```

In this example, we've used `parseJson` with a struct schema to ensure that the parsed result has a specific structure, including an object with a numeric property "a". This helps in handling JSON data with predefined shapes.

## Number Transformations

### NumberFromString

Transforms a `string` into a `number` by parsing the string using `parseFloat`.

The following special string values are supported: "NaN", "Infinity", "-Infinity".

```ts
import { Schema } from '@effect/schema';

// Schema<number, string>
const schema = Schema.NumberFromString;
const decode = Schema.decodeUnknownSync(schema);

// success cases
console.log(decode('1')); // 1
console.log(decode('-1')); // -1
console.log(decode('1.5')); // 1.5
console.log(decode('NaN')); // NaN
console.log(decode('Infinity')); // Infinity
console.log(decode('-Infinity')); // -Infinity

// failure cases
decode('a');
/*
throws:
Error: NumberFromString
â””â”€ Transformation process failure
   â””â”€ Expected NumberFromString, actual "a"
*/
```

### clamp

Clamps a `number` between a minimum and a maximum value.

```ts
import { Schema } from '@effect/schema';

// Schema<number>
const schema = Schema.Number.pipe(Schema.clamp(-1, 1)); // clamps the input to -1 <= x <= 1

const decode = Schema.decodeUnknownSync(schema);

console.log(decode(-3)); // -1
console.log(decode(0)); // 0
console.log(decode(3)); // 1
```

### parseNumber

Transforms a `string` into a `number` by parsing the string using the `parse` function of the `effect/Number` module.

It returns an error if the value can't be converted (for example when non-numeric characters are provided).

The following special string values are supported: "NaN", "Infinity", "-Infinity".

```ts
import { Schema } from '@effect/schema';

const schema = Schema.String.pipe(Schema.parseNumber);

const decode = Schema.decodeUnknownSync(schema);

console.log(decode('1')); // 1
console.log(decode('Infinity')); // Infinity
console.log(decode('NaN')); // NaN
console.log(decode('-'));
/*
throws
Error: (string <-> number)
â””â”€ Transformation process failure
   â””â”€ Expected (string <-> number), actual "-"
*/
```

## Boolean Transformations

### Not

Negates a boolean value.

```ts
import { Schema } from '@effect/schema';

// Schema<boolean>
const schema = Schema.Not;

const decode = Schema.decodeUnknownSync(schema);

console.log(decode(true)); // false
console.log(decode(false)); // true
```

## Symbol transformations

### Symbol

Transforms a `string` into a `symbol` by parsing the string using `Symbol.for`.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Symbol; // Schema<symbol, string>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('a')); // Symbol(a)
```

## BigInt transformations

### BigInt

Transforms a `string` into a `BigInt` by parsing the string using `BigInt`.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.BigInt; // Schema<BigInt, string>
const decode = Schema.decodeUnknownSync(schema);

// success cases
console.log(decode('1')); // 1n
console.log(decode('-1')); // -1n

// failure cases
decode('a');
/*
throws:
Error: BigInt
â””â”€ Transformation process failure
   â””â”€ Expected BigInt, actual "a"
*/
decode('1.5'); // throws
decode('NaN'); // throws
decode('Infinity'); // throws
decode('-Infinity'); // throws
```

### BigIntFromNumber

Transforms a `number` into a `BigInt` by parsing the number using `BigInt`.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.BigIntFromNumber; // Schema<BigInt, number>
const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

// success cases
console.log(decode(1)); // 1n
console.log(decode(-1)); // -1n
console.log(encode(1n)); // 1
console.log(encode(-1n)); // -1

// failure cases
decode(1.5);
/*
throws:
Error: BigIntFromNumber
â””â”€ Transformation process failure
   â””â”€ Expected BigIntFromNumber, actual 1.5
*/
decode(NaN); // throws
decode(Infinity); // throws
decode(-Infinity); // throws
encode(BigInt(Number.MAX_SAFE_INTEGER) + 1n); // throws
encode(BigInt(Number.MIN_SAFE_INTEGER) - 1n); // throws
```

### clamp

Clamps a `BigInt` between a minimum and a maximum value.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.BigIntFromSelf.pipe(Schema.clampBigInt(-1n, 1n)); // clamps the input to -1n <= x <= 1n

const decode = Schema.decodeUnknownSync(schema);

console.log(decode(-3n)); // -1n
console.log(decode(0n)); // 0n
console.log(decode(3n)); // 1n
```

## Date transformations

### Date

Transforms a `string` into a **valid** `Date`, ensuring that invalid dates, such as `new Date("Invalid Date")`, are rejected.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Date; // Schema<Date, string>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('1970-01-01T00:00:00.000Z')); // 1970-01-01T00:00:00.000Z

decode('a');
/*
throws:
Error: Date
â””â”€ Predicate refinement failure
   â””â”€ Expected Date (a valid Date), actual Invalid Date
*/

const validate = Schema.validateSync(schema);

console.log(validate(new Date(0))); // 1970-01-01T00:00:00.000Z
validate(new Date('Invalid Date'));
/*
throws:
Error: Date
â””â”€ Predicate refinement failure
   â””â”€ Expected Date (a valid Date), actual Invalid Date
*/
```

## BigDecimal Transformations

### BigDecimal

Transforms a `string` into a `BigDecimal`.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.BigDecimal; // Schema<BigDecimal, string>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('.124')); // { _id: 'BigDecimal', value: '124', scale: 3 }
```

### BigDecimalFromNumber

Transforms a `number` into a `BigDecimal`.

> [!WARNING]
> Warning: When encoding, this Schema will produce incorrect results if the BigDecimal exceeds the 64-bit range of a number.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.BigDecimalFromNumber; // Schema<BigDecimal, number>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode(0.111)); // { _id: 'BigDecimal', value: '111', scale: 3 }
```

### clampBigDecimal

Clamps a `BigDecimal` between a minimum and a maximum value.

```ts
import { Schema } from '@effect/schema';
import { BigDecimal } from 'effect';

const schema = Schema.BigDecimal.pipe(
  Schema.clampBigDecimal(BigDecimal.fromNumber(-1), BigDecimal.fromNumber(1)),
);

const decode = Schema.decodeUnknownSync(schema);

console.log(decode('-2')); // { _id: 'BigDecimal', value: '-1', scale: 0 }
console.log(decode('0')); // { _id: 'BigDecimal', value: '0', scale: 0 }
console.log(decode('3')); // { _id: 'BigDecimal', value: '1', scale: 0 }
```

# Advanced Usage

## Annotations

One of the fundamental requirements in the design of `@effect/schema` is that it is extensible and customizable. Customizations are achieved through "annotations". Each node contained in the AST of `@effect/schema/AST` contains an `annotations: Record<symbol, unknown>` field that can be used to attach additional information to the schema.
You can manage these annotations using the `annotations` method.

Let's see some examples:

```ts
import { Schema } from '@effect/schema';

const Password =
  // initial schema, a string
  Schema.String
    // add an error message for non-string values
    .annotations({ message: () => 'not a string' })
    .pipe(
      // add a constraint to the schema, only non-empty strings are valid
      // and add an error message for empty strings
      Schema.nonEmpty({ message: () => 'required' }),
      // add a constraint to the schema, only strings with a length less or equal than 10 are valid
      // and add an error message for strings that are too long
      Schema.maxLength(10, { message: (s) => `${s} is too long` }),
      // add an identifier to the schema
    )
    .annotations({
      // add an identifier to the schema
      identifier: 'Password',
      // add a title to the schema
      title: 'password',
      // add a description to the schema
      description:
        'A password is a string of characters used to verify the identity of a user during the authentication process',
      // add examples to the schema
      examples: ['1Ki77y', 'jelly22fi$h'],
      // add documentation to the schema
      documentation: `jsDoc documentation...`,
    });
```

The example shows some built-in combinators to add meta information, but users can easily add their own meta information by defining a custom annotation.

Here's an example of how to add a `deprecated` annotation:

```ts
import { AST, Schema } from '@effect/schema';

const DeprecatedId = Symbol.for(
  'some/unique/identifier/for/the/custom/annotation',
);

const deprecated = <A, I, R>(
  self: Schema.Schema<A, I, R>,
): Schema.Schema<A, I, R> =>
  Schema.make(AST.annotations(self.ast, { [DeprecatedId]: true }));

const schema = deprecated(Schema.String);

console.log(schema);
/*
Output:
{
  ast: {
    _tag: 'StringKeyword',
    annotations: {
      [Symbol(@effect/schema/annotation/Title)]: 'string',
      [Symbol(@effect/schema/annotation/Description)]: 'a string',
      [Symbol(some/unique/identifier/for/the/custom/annotation)]: true
    }
  }
  ...
}
*/
```

Annotations can be read using the `getAnnotation` helper, here's an example:

```ts
import { AST, Schema } from '@effect/schema';
import { Option } from 'effect';

const DeprecatedId = Symbol.for(
  'some/unique/identifier/for/the/custom/annotation',
);

const deprecated = <A, I, R>(
  self: Schema.Schema<A, I, R>,
): Schema.Schema<A, I, R> =>
  Schema.make(AST.annotations(self.ast, { [DeprecatedId]: true }));

const schema = deprecated(Schema.String);

const isDeprecated = <A, I, R>(schema: Schema.Schema<A, I, R>): boolean =>
  AST.getAnnotation<boolean>(DeprecatedId)(schema.ast).pipe(
    Option.getOrElse(() => false),
  );

console.log(isDeprecated(Schema.String)); // false
console.log(isDeprecated(schema)); // true
```

## Recursive Schemas

The `suspend` combinator is useful when you need to define a `Schema` that depends on itself, like in the case of recursive data structures. In this example, the `Category` schema depends on itself because it has a field `subcategories` that is an array of `Category` objects.

```ts
import { Schema } from '@effect/schema';

interface Category {
  readonly name: string;
  readonly subcategories: ReadonlyArray<Category>;
}

const Category = Schema.Struct({
  name: Schema.String,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => Category),
  ),
});
```

> [!NOTE]
> It is necessary to define the `Category` type and add an explicit type annotation (`const Category: S.Schema<Category>`) because otherwise TypeScript would struggle to infer types correctly. Without this annotation, you might encounter the error message: "'Category' implicitly has type 'any' because it does not have a type annotation and is referenced directly or indirectly in its own initializer.ts(7022)"

### A Helpful Pattern to Simplify Schema Definition

As we've observed, it's necessary to define an interface for the `Type` of the schema to enable recursive schema definition, which can complicate things and be quite tedious. One pattern to mitigate this is to **separate the field responsible for recursion** from all other fields.

```ts
import { Schema } from '@effect/schema';

const fields = {
  name: Schema.String,
  // ...possibly other fields
};

// Define an interface for the Category schema, extending the Type of the defined fields
interface Category extends Schema.Struct.Type<typeof fields> {
  readonly subcategories: ReadonlyArray<Category>; // Define `subcategories` using recursion
}

const Category = Schema.Struct({
  ...fields, // Include the fields
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => Category),
  ), // Define `subcategories` using recursion
});
```

### Mutually Recursive Schemas

Here's an example of two mutually recursive schemas, `Expression` and `Operation`, that represent a simple arithmetic expression tree.

```ts
import { Schema } from '@effect/schema';

interface Expression {
  readonly type: 'expression';
  readonly value: number | Operation;
}

interface Operation {
  readonly type: 'operation';
  readonly operator: '+' | '-';
  readonly left: Expression;
  readonly right: Expression;
}

const Expression = Schema.Struct({
  type: Schema.Literal('expression'),
  value: Schema.Union(
    Schema.Number,
    Schema.suspend((): Schema.Schema<Operation> => Operation),
  ),
});

const Operation = Schema.Struct({
  type: Schema.Literal('operation'),
  operator: Schema.Literal('+', '-'),
  left: Expression,
  right: Expression,
});
```

### Recursive Types with Different Encoded and Type

Defining a recursive schema where the `Encoded` type differs from the `Type` type adds another layer of complexity. In such cases, we need to define two interfaces: one for the `Type` type, as seen previously, and another for the `Encoded` type.

Let's consider an example: suppose we want to add an `id` field to the `Category` schema, where the schema for `id` is `NumberFromString`. It's important to note that `NumberFromString` is a schema that transforms a string into a number, so the `Type` and `Encoded` types of `NumberFromString` differ, being `number` and `string` respectively. When we add this field to the `Category` schema, TypeScript raises an error:

```ts
import { Schema } from '@effect/schema';

const fields = {
  id: Schema.NumberFromString,
  name: Schema.String,
};

interface Category extends Schema.Struct.Type<typeof fields> {
  readonly subcategories: ReadonlyArray<Category>;
}

/*
TypeScript error:
Type 'Struct<{ subcategories: Array$<suspend<Category, Category, never>>; id: typeof NumberFromString; name: typeof String$; }>' is not assignable to type 'Schema<Category, Category, never>'.
  The types of 'Encoded.id' are incompatible between these types.
    Type 'string' is not assignable to type 'number'.ts(2322)
*/
const Category = Schema.Struct({
  ...fields,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => Category),
  ),
});
```

This error occurs because the explicit annotation `const Category: S.Schema<Category>` is no longer sufficient and needs to be adjusted by explicitly adding the `Encoded` type:

```ts
import { Schema } from '@effect/schema';

const fields = {
  id: Schema.NumberFromString,
  name: Schema.String,
};

interface Category extends Schema.Struct.Type<typeof fields> {
  readonly subcategories: ReadonlyArray<Category>;
}

interface CategoryEncoded extends Schema.Struct.Encoded<typeof fields> {
  readonly subcategories: ReadonlyArray<CategoryEncoded>;
}

const Category = Schema.Struct({
  ...fields,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category, CategoryEncoded> => Category),
  ),
});
```

## Error messages

### Default Error Messages

When a parsing, decoding, or encoding process encounters a failure, a default error message is automatically generated for you. Let's explore some examples:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

Schema.decodeUnknownSync(schema)(null);
/*
throws:
Error: Expected { readonly name: string; readonly age: number }, actual null
*/

Schema.decodeUnknownSync(schema)({}, { errors: 'all' });
/*
throws:
Error: { readonly name: string; readonly age: number }
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["age"]
   â””â”€ is missing
*/
```

#### Identifiers in Error Messages

When you include an identifier annotation, it will be incorporated into the default error message, followed by a description if provided:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  name: Schema.String.annotations({ identifier: 'Name' }),
  age: Schema.Number.annotations({ identifier: 'Age' }),
}).annotations({ identifier: 'Person' });

Schema.decodeUnknownSync(schema)(null);
/*
throws:
Error: Expected Person, actual null
*/

Schema.decodeUnknownSync(schema)({}, { errors: 'all' });
/*
throws:
Error: Person
â”œâ”€ ["name"]
â”‚  â””â”€ is missing
â””â”€ ["age"]
   â””â”€ is missing
*/

Schema.decodeUnknownSync(schema)({ name: null, age: null }, { errors: 'all' });
/*
throws:
Error: Person
â”œâ”€ ["name"]
â”‚  â””â”€ Expected Name (a string), actual null
â””â”€ ["age"]
   â””â”€ Expected Age (a number), actual null
*/
```

#### Refinements

When a refinement fails, the default error message indicates whether the failure occurred in the "from" part or within the predicate defining the refinement:

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Struct({
  name: Schema.NonEmpty.annotations({ identifier: 'Name' }), // refinement
  age: Schema.Positive.pipe(Schema.int({ identifier: 'Age' })), // refinement
}).annotations({ identifier: 'Person' });

// "from" failure
Schema.decodeUnknownSync(schema)({ name: null, age: 18 });
/*
throws:
Error: Person
â””â”€ ["name"]
   â””â”€ Name
      â””â”€ From side refinement failure
         â””â”€ Expected a string, actual null
*/

// predicate failure
Schema.decodeUnknownSync(schema)({ name: '', age: 18 });
/*
throws:
Error: Person
â””â”€ ["name"]
   â””â”€ Name
      â””â”€ Predicate refinement failure
         â””â”€ Expected Name (a non empty string), actual ""
*/
```

In the first example, the error message indicates a "from" side refinement failure in the "Name" property, specifying that a string was expected but received null. In the second example, a predicate refinement failure is reported, indicating that a non-empty string was expected for "Name," but an empty string was provided.

### Custom Error Messages

Custom messages can be set using the `message` annotation:

```ts
type MessageAnnotation = (issue: ParseIssue) =>
  | string
  | Effect<string>
  | {
    readonly message: string | Effect<string>;
    readonly override: boolean;
  };
```

Here's a simple example of how to set a custom message for the built-in `String` schema:

```ts
import { Schema } from '@effect/schema';

const MyString = Schema.String.annotations({
  message: () => 'my custom message',
});
```

#### General Guidelines for Messages

The general logic followed to determine the messages is as follows:

1. If no custom messages are set, the default message related to the innermost schema where the operation (i.e., decoding or encoding) failed is used.

2. If custom messages are set, then the message corresponding to the **first** failed schema is used, starting from the innermost schema to the outermost. However, if the failing schema does not have a custom message, then **the default message is used**.

3. As an opt-in feature, **you can override guideline 2** by setting the `overwrite` flag to `true`. This allows the custom message to take precedence over all other custom messages from inner schemas. This is to address the scenario where a user wants to define a single cumulative custom message describing the properties that a valid value must have and does not want to see default messages.

Let's see some practical examples.

#### Scalar Schemas

```ts
import { Schema } from '@effect/schema';

const MyString = Schema.String.annotations({
  message: () => 'my custom message',
});

const decode = Schema.decodeUnknownEither(MyString);

console.log(decode(null)); // "my custom message"
```

#### Refinements

This example demonstrates setting a custom message on the last refinement in a chain of refinements. As you can see, the custom message is only used if the refinement related to `maxLength` fails; otherwise, default messages are used.

```ts
import { Schema } from '@effect/schema';

const MyString = Schema.String.pipe(
  Schema.minLength(1),
  Schema.maxLength(2),
).annotations({
  // This message is displayed only if the last filter (`maxLength`) fails
  message: () => 'my custom message',
});

const decode = Schema.decodeUnknownEither(MyString);

console.log(decode(null)); // "Expected a string, actual null"
console.log(decode('')); // `Expected a string at least 1 character(s) long, actual ""`
console.log(decode('abc')); // "my custom message"
```

When setting multiple override messages, the one corresponding to the **first** failed predicate is used, starting from the innermost refinement to the outermost:

```ts
import { Schema } from '@effect/schema';

const MyString = Schema.String
  // This message is displayed only if a non-String is passed as input
  .annotations({ message: () => 'String custom message' })
  .pipe(
    // This message is displayed only if the filter `minLength` fails
    Schema.minLength(1, { message: () => 'minLength custom message' }),
    // This message is displayed only if the filter `maxLength` fails
    Schema.maxLength(2, { message: () => 'maxLength custom message' }),
  );

const decode = Schema.decodeUnknownEither(MyString);

console.log(decode(null)); // "String custom message"
console.log(decode('')); // "minLength custom message"
console.log(decode('abc')); // "maxLength custom message"
```

You have the option to change the default behavior by setting the `override` flag to `true`. This is useful when you want to create a single comprehensive custom message that describes the required properties of a valid value without displaying default messages.

```ts
import { Schema } from '@effect/schema';

const MyString = Schema.String.pipe(
  Schema.minLength(1),
  Schema.maxLength(2),
).annotations({
  // By setting the `override` flag to `true`, this message will always be shown for any error
  message: () => ({ message: 'my custom message', override: true }),
});

const decode = Schema.decodeUnknownEither(MyString);

console.log(decode(null)); // "my custom message"
console.log(decode('')); // "my custom message"
console.log(decode('abc')); // "my custom message"
```

#### Transformations

In this example, `IntFromString` is a transformation schema that converts strings to integers. It applies specific validation messages based on different scenarios.

```ts
import { ParseResult, Schema } from '@effect/schema';

const IntFromString = Schema.transformOrFail(
  // This message is displayed only if the input is not a string
  Schema.String.annotations({ message: () => 'please enter a string' }),
  // This message is displayed only if the input can be converted to a number but it's not an integer
  Schema.Int.annotations({ message: () => 'please enter an integer' }),
  {
    decode: (s, _, ast) => {
      const n = Number(s);
      return Number.isNaN(n)
        ? ParseResult.fail(new ParseResult.Type(ast, s))
        : ParseResult.succeed(n);
    },
    encode: (n) => ParseResult.succeed(String(n)),
  },
)
  // This message is displayed only if the input cannot be converted to a number
  .annotations({ message: () => 'please enter a parseable string' });

const decode = Schema.decodeUnknownEither(IntFromString);

console.log(decode(null)); // "please enter a string"
console.log(decode('1.2')); // "please enter an integer"
console.log(decode('not a number')); // "please enter a parseable string"
```

#### Compound Schemas

The custom message system becomes especially handy when dealing with complex schemas, unlike simple scalar values like `string` or `number`. For instance, consider a schema comprising nested structures, such as a struct containing an array of other structs. Let's explore an example demonstrating the advantage of default messages in handling decoding errors within such nested structures:

```ts
import { Schema } from '@effect/schema';
import { pipe } from 'effect';

const schema = Schema.Struct({
  outcomes: pipe(
    Schema.Array(
      Schema.Struct({
        id: Schema.String,
        text: pipe(
          Schema.String,
          Schema.message(() => 'error_invalid_outcome_type'),
          Schema.minLength(1, { message: () => 'error_required_field' }),
          Schema.maxLength(50, { message: () => 'error_max_length_field' }),
        ),
      }),
    ),
    Schema.minItems(1, { message: () => 'error_min_length_field' }),
  ),
});

Schema.decodeUnknownSync(schema, { errors: 'all' })({
  outcomes: [],
});
/*
throws
Error: { outcomes: an array of at least 1 items }
â””â”€ ["outcomes"]
   â””â”€ error_min_length_field
*/

Schema.decodeUnknownSync(schema, { errors: 'all' })({
  outcomes: [
    { id: '1', text: '' },
    { id: '2', text: 'this one is valid' },
    { id: '3', text: '1234567890'.repeat(6) },
  ],
});
/*
throws
Error: { outcomes: an array of at least 1 items }
â””â”€ ["outcomes"]
   â””â”€ an array of at least 1 items
      â””â”€ From side refinement failure
         â””â”€ ReadonlyArray<{ id: string; text: a string at most 50 character(s) long }>
            â”œâ”€ [0]
            â”‚  â””â”€ { id: string; text: a string at most 50 character(s) long }
            â”‚     â””â”€ ["text"]
            â”‚        â””â”€ error_required_field
            â””â”€ [2]
               â””â”€ { id: string; text: a string at most 50 character(s) long }
                  â””â”€ ["text"]
                     â””â”€ error_max_length_field
*/
```

#### Effectful messages

Messages are not only of type `string` but can return an `Effect` so that they can have dependencies (for example, from an internationalization service). Let's see the outline of a similar situation with a very simplified example for demonstration purposes:

```ts
import { Schema, TreeFormatter } from '@effect/schema';
import { Context, Effect, Either, Option } from 'effect';

// internationalization service
class Messages extends Context.Tag('Messages')<
  Messages,
  {
    NonEmpty: string;
  }
>() {}

const Name = Schema.NonEmpty.pipe(
  Schema.message(() =>
    Effect.gen(function* (_) {
      const service = yield* _(Effect.serviceOption(Messages));
      return Option.match(service, {
        onNone: () => 'Invalid string',
        onSome: (messages) => messages.NonEmpty,
      });
    })
  ),
);

Schema.decodeUnknownSync(Name)(''); // => throws "Invalid string"

const result = Schema.decodeUnknownEither(Name)('').pipe(
  Either.mapLeft((error) =>
    TreeFormatter.formatError(error).pipe(
      Effect.provideService(Messages, { NonEmpty: 'should be non empty' }),
      Effect.runSync,
    )
  ),
);

console.log(result); // => { _id: 'Either', _tag: 'Left', left: 'should be non empty' }
```

#### Missing messages

You can provide custom messages for missing fields or elements using the `missingMessage` annotation.

Example (missing field)

```ts
import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.propertySignature(Schema.String).annotations({
    missingMessage: () => 'Name is required',
  }),
});

Schema.decodeUnknownSync(Person)({});
/*
Output:
Error: { readonly name: string }
â””â”€ ["name"]
   â””â”€ Name is required
*/
```

Example (missing element)

```ts
import { Schema } from '@effect/schema';

const Point = Schema.Tuple(
  Schema.element(Schema.Number).annotations({
    missingMessage: () => 'X coordinate is required',
  }),
  Schema.element(Schema.Number).annotations({
    missingMessage: () => 'Y coordinate is required',
  }),
);

Schema.decodeUnknownSync(Point)([], { errors: 'all' });
/*
Output:
Error: readonly [number, number]
â”œâ”€ [0]
â”‚  â””â”€ X coordinate is required
â””â”€ [1]
   â””â”€ Y coordinate is required
*/
```

## Classes

When working with schemas, you have a choice beyond the `S.Struct` constructor. You can leverage the power of classes through the `Class` utility, which comes with its own set of advantages tailored to common use cases:

Classes offer several features that simplify the schema creation process:

- **All-in-One Definition**: With classes, you can define both a schema and an opaque type simultaneously.
- **Shared Functionality**: You can incorporate shared functionality using class methods or getters.
- **Value Hashing and Equality**: Utilize the built-in capability for checking value equality and applying hashing (thanks to `Class` implementing [Data.Class](https://effect.website/docs/other/data-types/data#class)).

### Definition

To define a `Class` in `@effect/schema`, you need to provide:

- The type of the class being created.
- A unique identifier for the class.
- The desired fields, or any schema that has an exposed `fields` property.

```ts
import { Schema } from '@effect/schema';

// Define your schema by providing the type, a unique identifier and the desired fields
class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {}
```

In this setup, `Person` is a class where `id` is a number and `name` is a non-empty string. The constructor for the class creates instances with these specified properties.

#### Classes Without Arguments

If your schema does not require any fields, you can define a class with an empty object:

```ts
import { Schema } from '@effect/schema';

class NoArgs extends Schema.Class<NoArgs>('NoArgs')({}) {}

const noargs = new NoArgs();
```

### Class Constructor as a Validator

When you define a class using `Schema.Class`, the constructor automatically checks that the provided properties adhere to the schema's rules. Here's how you can define and instantiate a `Person` class:

```ts
import { Schema } from '@effect/schema';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {}

const john = new Person({ id: 1, name: 'John' });

john.id;
john.name;
```

This ensures that each property of the `Person` instance, like `id` and `name`, meets the conditions specified in the schema, such as `id` being a number and `name` being a non-empty string.

If an instance is created with invalid properties, the constructor throws an error detailing what went wrong:

```ts
try {
  new Person({ id: 1, name: '' }); // Attempting to instantiate with an invalid name
} catch (error) {
  console.error(error);
}
/*
Error output:
Error: Person (Constructor)
â””â”€ ["name"]
   â””â”€ a non empty string
      â””â”€ Predicate refinement failure
         â””â”€ Expected a non empty string, actual ""

    ...stack...
*/
```

This error message clearly states that the `name` field failed the non-empty string predicate, providing precise feedback on why the validation failed.

There are scenarios where you might want to bypass validation during instantiation. Although not typically recommended, `@effect/schema` allows for this flexibility:

```ts
const john = new Person({ id: 1, name: '' }, true); // Bypasses validation and creates the instance without errors
// or more explicitly
new Person({ id: 1, name: '' }, { disableValidation: true }); // Bypasses validation and creates the instance without errors
```

### Hashing and Equality

Thanks to the implementation of [`Data.Class`](https://effect.website/docs/other/data-types/data#class), instances of your classes automatically support the [`Equal`](https://effect.website/docs/other/trait/equal) trait, which allows for easy comparison:

```ts
import { Schema } from '@effect/schema';
import { Equal } from 'effect';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {}

const john1 = new Person({ id: 1, name: 'John' });
const john2 = new Person({ id: 1, name: 'John' });

console.log(Equal.equals(john1, john2)); // Output: true
```

However, be aware that the `Equal` trait checks for equality only at the first level. If, for instance, a field is an array, the returned instances will not be considered equal:

```ts
import { Schema } from '@effect/schema';
import { Equal } from 'effect';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
  hobbies: Schema.Array(Schema.String),
}) {}

const john1 = new Person({
  id: 1,
  name: 'John',
  hobbies: ['reading', 'coding'],
});
const john2 = new Person({
  id: 1,
  name: 'John',
  hobbies: ['reading', 'coding'],
});

console.log(Equal.equals(john1, john2)); // Output: false
```

To ensure deep equality for arrays, use `Schema.Data` combined with `Data.array`:

```ts
import { Schema } from '@effect/schema';
import { Data, Equal } from 'effect';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
  hobbies: Schema.Data(Schema.Array(Schema.String)),
}) {}

const john1 = new Person({
  id: 1,
  name: 'John',
  hobbies: Data.array(['reading', 'coding']),
});
const john2 = new Person({
  id: 1,
  name: 'John',
  hobbies: Data.array(['reading', 'coding']),
});

console.log(Equal.equals(john1, john2)); // Output: true
```

### Custom Getters and Methods

You have the flexibility to enhance schema classes with custom getters and methods.

Let's look at how you can add a custom getter to a class:

```ts
import { Schema } from '@effect/schema';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {
  // Custom getter to return the name in uppercase
  get upperName() {
    return this.name.toUpperCase();
  }
}

const john = new Person({ id: 1, name: 'John' });

console.log(john.upperName); // Output: "JOHN"
```

### Using Classes as Schemas

When you define a class using `Schema.Class`, it not only creates a new class but also treats this class as a schema. This means the class can be utilized wherever a schema is expected.

```ts
import { Schema } from '@effect/schema';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {}

// Person can be used as a normal schema
const Persons = Schema.Array(Person);
```

#### The `.fields` Property

The class also includes a `.fields` static property, which outlines the fields defined during the class creation.

```ts
/*
{
    readonly id: typeof Schema.Number;
    readonly name: Schema.filter<Schema.Schema<string, string, never>>;
}
*/
Person.fields;
```

### Recursive Schemas

The `suspend` combinator is useful when you need to define a `Schema` that depends on itself, like in the case of recursive data structures. In this example, the `Category` schema depends on itself because it has a field `subcategories` that is an array of `Category` objects.

```ts
import { Schema } from '@effect/schema';

class Category extends Schema.Class<Category>('Category')({
  name: Schema.String,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => Category),
  ),
}) {}
```

> [!NOTE]
> It is necessary to add an explicit type annotation (`S.suspend((): S.Schema<Category> => Category`) because otherwise TypeScript would struggle to infer types correctly. Without this annotation, you might encounter the error message: "Type 'typeof Category' is missing the following properties from type 'Schema<unknown, unknown, unknown>': ast, annotations, [TypeId], pipets(2739)"

#### Mutually Recursive Schemas

Here's an example of two mutually recursive schemas, `Expression` and `Operation`, that represent a simple arithmetic expression tree.

```ts
import { Schema } from '@effect/schema';

class Expression extends Schema.Class<Expression>('Expression')({
  type: Schema.Literal('expression'),
  value: Schema.Union(
    Schema.Number,
    Schema.suspend((): Schema.Schema<Operation> => Operation),
  ),
}) {}

class Operation extends Schema.Class<Operation>('Operation')({
  type: Schema.Literal('operation'),
  operator: Schema.Literal('+', '-'),
  left: Expression,
  right: Expression,
}) {}
```

#### Recursive Types with Different Encoded and Type

Defining a recursive schema where the `Encoded` type differs from the `Type` type adds another layer of complexity. In such cases, we need to define an interface for the `Encoded` type.

Let's consider an example: suppose we want to add an `id` field to the `Category` schema, where the schema for `id` is `NumberFromString`. It's important to note that `NumberFromString` is a schema that transforms a string into a number, so the `Type` and `Encoded` types of `NumberFromString` differ, being `number` and `string` respectively. When we add this field to the `Category` schema, TypeScript raises an error:

```ts
import { Schema } from '@effect/schema';

/*
TypeScript error:
Type 'Category' is not assignable to type '{ readonly id: string; readonly name: string; readonly subcategories: readonly Category[]; }'.
  Types of property 'id' are incompatible.
    Type 'number' is not assignable to type 'string'.ts(2322)
*/
class Category extends Schema.Class<Category>('Category')({
  id: Schema.NumberFromString,
  name: Schema.String,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category> => Category),
  ),
}) {}
```

This error occurs because the explicit annotation `S.suspend((): S.Schema<Category> => Category` is no longer sufficient and needs to be adjusted by explicitly adding the `Encoded` type:

```ts
import { Schema } from '@effect/schema';

interface CategoryEncoded {
  readonly id: string;
  readonly name: string;
  readonly subcategories: ReadonlyArray<CategoryEncoded>;
}

class Category extends Schema.Class<Category>('Category')({
  id: Schema.NumberFromString,
  name: Schema.String,
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category, CategoryEncoded> => Category),
  ),
}) {}
```

As we've observed, it's necessary to define an interface for the `Encoded` of the schema to enable recursive schema definition, which can complicate things and be quite tedious. One pattern to mitigate this is to **separate the field responsible for recursion** from all other fields.

```ts
import { Schema } from '@effect/schema';

const fields = {
  id: Schema.NumberFromString,
  name: Schema.String,
  // ...possibly other fields
};

interface CategoryEncoded extends Schema.Struct.Encoded<typeof fields> {
  readonly subcategories: ReadonlyArray<CategoryEncoded>; // Define `subcategories` using recursion
}

class Category extends Schema.Class<Category>('Category')({
  ...fields, // Include the fields
  subcategories: Schema.Array(
    Schema.suspend((): Schema.Schema<Category, CategoryEncoded> => Category),
  ), // Define `subcategories` using recursion
}) {}
```

### Tagged Class variants

You can also create classes that extend `TaggedClass` & `TaggedError` from the `effect/Data` module:

```ts
import { Schema } from '@effect/schema';

class TaggedPerson extends Schema.TaggedClass<TaggedPerson>()('TaggedPerson', {
  name: Schema.String,
}) {}

class HttpError extends Schema.TaggedError<HttpError>()('HttpError', {
  status: Schema.Number,
}) {}

const joe = new TaggedPerson({ name: 'Joe' });
console.log(joe._tag); // "TaggedPerson"

const error = new HttpError({ status: 404 });
console.log(error._tag); // "HttpError"
console.log(error.stack); // access the stack trace
```

### Extending existing Classes

In situations where you need to augment your existing class with more fields, the built-in `extend` utility comes in handy:

```ts
import { Schema } from '@effect/schema';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String.pipe(Schema.nonEmpty()),
}) {
  get upperName() {
    return this.name.toUpperCase();
  }
}

class PersonWithAge extends Person.extend<PersonWithAge>('PersonWithAge')({
  age: Schema.Number,
}) {
  get isAdult() {
    return this.age >= 18;
  }
}
```

### Transformations

You have the option to enhance a class with (effectful) transformations. This becomes valuable when you want to enrich or validate an entity sourced from a data store.

```ts
import { Schema } from '@effect/schema';
import { Effect, Option } from 'effect';

export class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String,
}) {}

console.log(Schema.decodeUnknownSync(Person)({ id: 1, name: 'name' }));
/*
Output:
Person { id: 1, name: 'name' }
*/

function getAge(id: number): Effect.Effect<number, Error> {
  return Effect.succeed(id + 2);
}

export class PersonWithTransform
  extends Person.transformOrFail<PersonWithTransform>(
    'PersonWithTransform',
  )(
    {
      age: Schema.optional(Schema.Number, { exact: true, as: 'Option' }),
    },
    {
      decode: (input) =>
        Effect.mapBoth(getAge(input.id), {
          onFailure: (e) =>
            new ParseResult.Type(Schema.String.ast, input.id, e.message),
          // must return { age: Option<number> }
          onSuccess: (age) => ({ ...input, age: Option.some(age) }),
        }),
      encode: ParseResult.succeed,
    },
  ) {}

Schema.decodeUnknownPromise(PersonWithTransform)({ id: 1, name: 'name' }).then(
  console.log,
);
/*
Output:
PersonWithTransform {
  id: 1,
  name: 'name',
  age: { _id: 'Option', _tag: 'Some', value: 3 }
}
*/

export class PersonWithTransformFrom
  extends Person.transformOrFailFrom<PersonWithTransformFrom>(
    'PersonWithTransformFrom',
  )(
    {
      age: Schema.optional(Schema.Number, { exact: true, as: 'Option' }),
    },
    {
      decode: (input) =>
        Effect.mapBoth(getAge(input.id), {
          onFailure: (e) =>
            new ParseResult.Type(Schema.String.ast, input, e.message),
          // must return { age?: number }
          onSuccess: (age) => (age > 18 ? { ...input, age } : { ...input }),
        }),
      encode: ParseResult.succeed,
    },
  ) {}

Schema.decodeUnknownPromise(PersonWithTransformFrom)({
  id: 1,
  name: 'name',
}).then(console.log);
/*
Output:
PersonWithTransformFrom {
  id: 1,
  name: 'name',
  age: { _id: 'Option', _tag: 'None' }
}
*/
```

The decision of which API to use, either `transformOrFail` or `transformOrFailFrom`, depends on when you wish to execute the transformation:

1. Using `transformOrFail`:

   - The transformation occurs at the end of the process.
   - It expects you to provide a value of type `{ age: Option<number> }`.
   - After processing the initial input, the new transformation comes into play, and you need to ensure the final output adheres to the specified structure.

2. Using `transformOrFailFrom`:
   - The new transformation starts as soon as the initial input is handled.
   - You should provide a value `{ age?: number }`.
   - Based on this fresh input, the subsequent transformation `{ age: S.optionalToOption(S.Number, { exact: true }) }` is executed.
   - This approach allows for immediate handling of the input, potentially influencing the subsequent transformations.

## Default Constructors

When dealing with data, creating values that match a specific schema is crucial. To simplify this process, we've introduced **default constructors** for various types of schemas: `Struct`s, `Record`s, `filter`s, and `brand`s. Let's dive into each of them with some examples to understand better how they work.

> [!NOTE]
> Default constructors associated with a schema `Schema<A, I, R>` are specifically related to the `A` type, not the `I` type.

Example (`Struct`)

```ts
import { Schema } from '@effect/schema';

const Struct = Schema.Struct({
  name: Schema.NonEmpty,
});

Struct.make({ name: 'a' }); // ok
Struct.make({ name: '' });
/*
throws
Error: { name: NonEmpty }
â””â”€ ["name"]
   â””â”€ NonEmpty
      â””â”€ Predicate refinement failure
         â””â”€ Expected NonEmpty (a non empty string), actual ""
*/
```

There are scenarios where you might want to bypass validation during instantiation. Although not typically recommended, `@effect/schema` allows for this flexibility:

```ts
Struct.make({ name: '' }, true); // Bypasses validation and creates the instance without errors
// or more explicitly
Struct.make({ name: '' }, { disableValidation: true }); // Bypasses validation and creates the instance without errors
```

Example (`Record`)

```ts
import { Schema } from '@effect/schema';

const Record = Schema.Record(Schema.String, Schema.NonEmpty);

Record.make({ a: 'a', b: 'b' }); // ok
Record.make({ a: 'a', b: '' });
/*
throws
Error: { [x: string]: NonEmpty }
â””â”€ ["b"]
   â””â”€ NonEmpty
      â””â”€ Predicate refinement failure
         â””â”€ Expected NonEmpty (a non empty string), actual ""
*/
Record.make({ a: 'a', b: '' }, { disableValidation: true }); // no errors
```

Example (`filter`)

```ts
import { Schema } from '@effect/schema';

const MyNumber = Schema.Number.pipe(Schema.between(1, 10));

// const n: number
const n = MyNumber.make(5); // ok
MyNumber.make(20);
/*
throws
Error: a number between 1 and 10
â””â”€ Predicate refinement failure
  â””â”€ Expected a number between 1 and 10, actual 20
*/
MyNumber.make(20, { disableValidation: true }); // no errors
```

Example (`brand`)

```ts
import { Schema } from '@effect/schema';

const BrandedNumberSchema = Schema.Number.pipe(
  Schema.between(1, 10),
  Schema.brand('MyNumber'),
);

// const n: number & Brand<"MyNumber">
const n = BrandedNumberSchema.make(5); // ok
BrandedNumberSchema.make(20);
/*
throws
Error: a number between 1 and 10
â””â”€ Predicate refinement failure
  â””â”€ Expected a number between 1 and 10, actual 20
*/
BrandedNumberSchema.make(20, { disableValidation: true }); // no errors
```

When utilizing our default constructors, it's important to grasp the type of value they generate. In the `BrandedNumberSchema` example, the return type of the constructor is `number & Brand<"MyNumber">`, indicating that the resulting value is a number with the added branding "MyNumber".

This differs from the filter example where the return type is simply `number`. The branding offers additional insights about the type, facilitating the identification and manipulation of your data.

Note that default constructors are "unsafe" in the sense that if the input does not conform to the schema, the constructor throws an error containing a description of what is wrong. This is because the goal of default constructors is to provide a quick way to create compliant values (for example, for writing tests or configurations, or in any situation where it is assumed that the input passed to the constructors is valid and the opposite situation is exceptional). To have a "safe" constructor, you can use `Schema.validateEither`:

```ts
import { Schema } from '@effect/schema';

const MyNumber = Schema.Number.pipe(Schema.between(1, 10));

const ctor = Schema.validateEither(MyNumber);

console.log(ctor(5));
/*
{ _id: 'Either', _tag: 'Right', right: 5 }
*/

console.log(ctor(20));
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: {
    _id: 'ParseError',
    message: 'a number between 1 and 10\n' +
      'â””â”€ Predicate refinement failure\n' +
      '   â””â”€ Expected a number between 1 and 10, actual 20'
  }
}
*/
```

### Introduction to Setting Default Values

When constructing objects, it's common to want to assign default values to certain fields to simplify the creation of new instances. Our new `withConstructorDefault` combinator allows you to effortlessly manage the optionality of a field in your default constructor.

Example Without Default

```ts
import { Schema } from '@effect/schema';

const PersonSchema = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number,
});

// Both name and age are required
PersonSchema.make({ name: 'John', age: 30 });
```

Example With Default

```ts
import { Schema } from '@effect/schema';

const PersonSchema = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => 0),
  ),
});

// The age field is optional and defaults to 0
console.log(PersonSchema.make({ name: 'John' })); // Output: { age: 0, name: 'John' }
```

In the second example, notice how the `age` field is now optional and defaults to `0` when not provided.

Defaults are **lazily evaluated**, meaning that a new instance of the default is generated every time the constructor is called:

```ts
import { Schema } from '@effect/schema';

const PersonSchema = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => 0),
  ),
  timestamp: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => new Date().getTime()),
  ),
});

console.log(PersonSchema.make({ name: 'name1' })); // { age: 0, timestamp: 1714232909221, name: 'name1' }
console.log(PersonSchema.make({ name: 'name2' })); // { age: 0, timestamp: 1714232909227, name: 'name2' }
```

Note how the `timestamp` field varies.

Default values are also "portable", meaning that if you reuse the same property signature in another schema, the default is carried over:

```ts
import { Schema } from '@effect/schema';

const PersonSchema = Schema.Struct({
  name: Schema.NonEmpty,
  age: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => 0),
  ),
  timestamp: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => new Date().getTime()),
  ),
});

const AnotherSchema = Schema.Struct({
  foo: Schema.String,
  age: PersonSchema.fields.age,
});

console.log(AnotherSchema.make({ foo: 'bar' })); // => { foo: 'bar', age: 0 }
```

Defaults can also be applied using the `Class` API:

```ts
import { Schema } from '@effect/schema';

class Person extends Schema.Class<Person>('Person')({
  name: Schema.NonEmpty,
  age: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => 0),
  ),
  timestamp: Schema.Number.pipe(
    Schema.propertySignature,
    Schema.withConstructorDefault(() => new Date().getTime()),
  ),
}) {}

console.log(new Person({ name: 'name1' })); // Person { age: 0, timestamp: 1714400867208, name: 'name1' }
console.log(new Person({ name: 'name2' })); // Person { age: 0, timestamp: 1714400867215, name: 'name2' }
```

## API Interfaces

### What's an API Interface?

An "API Interface" is an `interface` specifically defined for a schema exported from `@effect/schema` or for a particular API exported from `@effect/schema`. Let's see an example with a simple schema:

**Example** (an `Age` schema)

```ts
import { Schema } from '@effect/schema';

// API interface
interface Age extends Schema.Schema<number> {}

const Age: Age = Schema.Number.pipe(Schema.between(0, 100));

// type AgeType = number
type AgeType = Schema.Schema.Type<typeof Age>;
// type AgeEncoded = number
type AgeEncoded = Schema.Schema.Encoded<typeof Age>;
```

The benefit is that when we hover over the `Age` schema, we see `Age` instead of `Schema<number, number, never>`. This is a small improvement if we only think about the `Age` schema, but as we'll see shortly, these improvements in schema visualization add up, resulting in a significant improvement in the readability of our schemas.

Many of the built-in schemas exported from `@effect/schema` have been equipped with API interfaces, for example `number` or `never`.

```ts
import { Schema } from '@effect/schema';

// const number: S.Number$
Schema.Number;

// const never: S.Never
Schema.Never;
```

> [!NOTE]
> Notice that we had to add a `$` suffix to the API interface name because we couldn't simply use "Number" since it's a reserved name for the TypeScript `Number` type.

Now let's see an example with a combinator that, given an input schema for a certain type `A`, returns the schema of the pair `readonly [A, A]`:

**Example** (a `pair` combinator)

```ts
import { Schema } from '@effect/schema';

// API interface
export interface pair<S extends Schema.Schema.Any> extends
  Schema.Schema<
    readonly [Schema.Schema.Type<S>, Schema.Schema.Type<S>],
    readonly [Schema.Schema.Encoded<S>, Schema.Schema.Encoded<S>],
    Schema.Schema.Context<S>
  > {}

// API
export const pair = <S extends Schema.Schema.Any>(schema: S): pair<S> =>
  Schema.Tuple(Schema.asSchema(schema), Schema.asSchema(schema));
```

> [!NOTE]
> The `Schema.Schema.Any` helper represents any schema, except for `never`. For more information on the `asSchema` helper, refer to the following section "Understanding Opaque Names".

If we try to use our `pair` combinator, we see that readability is also improved in this case:

```ts
// const Coords: pair<typeof Schema.Number>
const Coords = pair(Schema.Number);
```

In hover, we simply see `pair<typeof Schema.Number>` instead of the verbose:

```ts
// const Coords: Schema.Tuple<[typeof Schema.Number, typeof Schema.Number]>
const Coords = Schema.Tuple(Schema.Number, Schema.Number);
```

The new name is not only shorter and more readable but also carries along the origin of the schema, which is a call to the `pair` combinator.

### Understanding Opaque Names

Opaque names generated in this way are very convenient, but sometimes there's a need to see what the underlying types are, perhaps for debugging purposes while you declare your schemas. At any time, you can use the `asSchema` function, which returns an `Schema<A, I, R>` compatible with your opaque definition:

```ts
// const Coords: pair<typeof Schema.Number>
const Coords = pair(Schema.Number);

// const NonOpaqueCoords: Schema.Schema<readonly [number, number], readonly [number, number], never>
const NonOpaqueCoords = Schema.asSchema(Coords);
```

> [!NOTE]
> The call to `asSchema` is negligible in terms of overhead since it's nothing more than a glorified identity function.

Many of the built-in combinators exported from `@effect/schema` have been equipped with API interfaces, for example `struct`:

```ts
import { Schema } from '@effect/schema';

/*
const Person: Schema.Struct<{
    name: typeof Schema.String;
    age: typeof Schema.Number;
}>
*/
const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});
```

In hover, we simply see:

```ts
const Person: Schema.Struct<{
  name: typeof Schema.String;
  age: typeof Schema.Number;
}>;
```

instead of the verbose:

```ts
const Person: Schema.Schema<
  {
    readonly name: string;
    readonly age: number;
  },
  {
    readonly name: string;
    readonly age: number;
  },
  never
>;
```

### Exposing Arguments

The benefits of API interfaces don't end with better readability; in fact, the driving force behind the introduction of API interfaces arises more from the need to expose some important information about the schemas that users generate. Let's see some examples related to literals and structs:

**Example** (exposed literals)

Now when we define literals, we can retrieve them using the `literals` field exposed by the generated schema:

```ts
import { Schema } from '@effect/schema';

// const myliterals: Schema.Literal<["A", "B"]>
const myliterals = Schema.Literal('A', 'B');

// literals: readonly ["A", "B"]
myliterals.literals;

console.log(myliterals.literals); // Output: [ 'A', 'B' ]
```

**Example** (exposed fields)

Similarly to what we've seen for literals, when we define a struct, we can retrieve its `fields`:

```ts
import { Schema } from '@effect/schema';

/*
const Person: Schema.Struct<{
    name: typeof Schema.String;
    age: typeof Schema.Number;
}>
*/
const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

/*
fields: {
    readonly name: typeof Schema.String;
    readonly age: typeof Schema.Number;
}
*/
Person.fields;

console.log(Person.fields);
/*
{
  name: Schema {
    ast: StringKeyword { _tag: 'StringKeyword', annotations: [Object] },
    ...
  },
  age: Schema {
    ast: NumberKeyword { _tag: 'NumberKeyword', annotations: [Object] },
    ...
  }
}
*/
```

Being able to retrieve the `fields` is particularly advantageous when you want to extend a struct with new fields; now you can do it simply using the spread operator:

```ts
import * as S from '@effect/schema/Schema';

import { Schema } from '@effect/schema';

const Person = Schema.Struct({
  name: Schema.String,
  age: Schema.Number,
});

/*
const PersonWithId: Schema.Struct<{
    id: typeof Schema.Number;
    name: typeof Schema.String;
    age: typeof Schema.Number;
}>
*/
const PersonWithId = Schema.Struct({
  ...Person.fields,
  id: Schema.Number,
});
```

The list of APIs equipped with API interfaces is extensive; here we provide only the main ones just to give you an idea of the new development possibilities that have opened up:

```ts
import { Schema } from '@effect/schema';

// ------------------------
// array value
// ------------------------

// value: typeof Schema.String
Schema.Array(Schema.String).value;

// ------------------------
// record key and value
// ------------------------

// key: typeof Schema.String
Schema.Record(Schema.String, Schema.Number).key;
// value: typeof Schema.Number
Schema.Record(Schema.String, Schema.Number).value;

// ------------------------
// union members
// ------------------------

// members: readonly [typeof Schema.String, typeof Schema.Number]
Schema.Union(Schema.String, Schema.Number).members;

// ------------------------
// tuple elements
// ------------------------

// elements: readonly [typeof Schema.String, typeof Schema.Number]
Schema.Tuple(Schema.String, Schema.Number).elements;
```

### Troubleshooting When Working With Generic Schemas

Sometimes, while working with functions that handle generic schemas, you may encounter the issue where TypeScript fails to fully resolve the schema type, making it unusable within the function body. Let's see an example:

```ts
import { Schema } from '@effect/schema';

// A function that uses a generic schema
const MyStruct = <X extends Schema.Schema.All>(x: X) => Schema.Struct({ x });

// Helper type that returns the return type of the `MyStruct` function
type MyStructReturnType<X extends Schema.Schema.All> = Schema.Schema.Type<
  ReturnType<typeof MyStruct<X>>
>;

// In the function body, `obj` has type `Simplify<Schema.Struct.Type<{ x: X; }>>`
// so it's not possible to access the `x` field
function test<X extends Schema.Schema.All>(obj: MyStructReturnType<X>) {
  obj.x; // error: Property 'x' does not exist on type 'Simplify<Type<{ x: X; }>>'.ts(2339)
}
```

In the function body, `obj` has type

```ts
Simplify<Schema.Struct.Type<{ x: X }>>;
```

so it's not possible to access the `x` field.

To solve the problem, you need to force TypeScript to resolve the type of `obj`, and you can do this with the type-level helper `Schema.Schema.AsSchema`, which is the type-level counterpart of the function `Schema.asSchema`:

```ts
function test<X extends Schema.Schema.All>(
  obj: MyStructReturnType<Schema.Schema.AsSchema<X>>,
) {
  obj.x; // Schema.Schema.Type<X>
}
```

Now the type of `obj` is resolved to

```ts
{
    readonly x: Schema.Schema.Type<X>;
}
```

and therefore, we can access its `x` field.

# Effect Data Types

## Interop With Data

The `effect/Data` module in the Effect ecosystem serves as a utility module that simplifies the process of comparing values for equality without the need for explicit implementations of the `Equal` and `Hash` interfaces. It provides convenient APIs that automatically generate default implementations for equality checks, making it easier for developers to perform equality comparisons in their applications.

```ts
import { Data, Equal } from 'effect';

const person1 = Data.struct({ name: 'Alice', age: 30 });
const person2 = Data.struct({ name: 'Alice', age: 30 });

console.log(Equal.equals(person1, person2)); // true
```

You can use the `Schema.Data(schema)` combinator to build a schema from an existing schema that can decode a value `A` to a value with `Equal` and `Hash` traits added:

```ts
import { Schema } from '@effect/schema';
import { Equal } from 'effect';

/*
Schema.Schema<{
    readonly name: string;
    readonly age: number;
}, {
    readonly name: string;
    readonly age: number;
}, never>
*/
const schema = Schema.Data(
  Schema.Struct({
    name: Schema.String,
    age: Schema.Number,
  }),
);

const decode = Schema.decode(schema);

const person1 = decode({ name: 'Alice', age: 30 });
const person2 = decode({ name: 'Alice', age: 30 });

console.log(Equal.equals(person1, person2)); // true
```

## Config

The `Config` API in the `@effect/schema` library is specifically designed to enhance configuration validation in software applications. This feature empowers developers to seamlessly integrate structured schema validation with configuration settings, ensuring that the configuration data is consistent with predefined schemas and providing detailed feedback when discrepancies are found.

The `Config` function is defined as follows:

```ts
Config: (<A>(name: string, schema: Schema<A, string>) => Config<A>);
```

This function requires two parameters:

- **name**: The identifier for the configuration setting.
- **schema**: A schema object that describes the expected data type and structure.

The function returns a [`Config`](https://effect.website/docs/guides/configuration) object that is directly integrated with your application's configuration management system.

The `Config` function operates through the following steps:

1. **Fetching Configuration**: The configuration value is retrieved based on its name.
2. **Validation**: The value is then validated against the schema. If the value does not conform to the schema, the function formats and returns detailed validation errors.
3. **Error Formatting**: Errors are formatted using `TreeFormatter.formatErrorSync` to provide clear, actionable error messages.

**Example**

Below is a practical example illustrating how to use the `Config` API:

```ts
// config.ts
import { Schema } from '@effect/schema';
import { Effect } from 'effect';

// const myconfig: Config<string>
const myconfig = Schema.Config('Foo', Schema.String.pipe(Schema.minLength(4)));

const program = Effect.gen(function* () {
  const foo = yield* myconfig;
  console.log(`ok: ${foo}`);
});

Effect.runSync(program);
```

To test the configuration, execute the following commands:

- **Test with Missing Configuration Data**:
  ```sh
  npx tsx config.ts
  # Output:
  # [(Missing data at Foo: "Expected Foo to exist in the process context")]
  ```
- **Test with Invalid Data**:
  ```sh
  Foo=bar npx tsx config.ts
  # Output:
  # [(Invalid data at Foo: "a string at least 4 character(s) long
  # â””â”€ Predicate refinement failure
  #    â””â”€ Expected a string at least 4 character(s) long, actual "bar"")]
  ```
- **Test with Valid Data**:
  ```sh
  Foo=foobar npx tsx config.ts
  # Output:
  # ok: foobar
  ```

## Option

**Cheatsheet**

| Combinator              | From                                   | To                                             |
| ----------------------- | -------------------------------------- | ---------------------------------------------- |
| `Option`                | `Schema<A, I, R>`                      | `Schema<Option<A>, OptionFrom<I>, R>`          |
| `OptionFromSelf`        | `Schema<A, I, R>`                      | `Schema<Option<A>, Option<I>, R>`              |
| `OptionFromUndefinedOr` | `Schema<A, I, R>`                      | `Schema<Option<A>, I \| undefined, R>`         |
| `OptionFromNullOr`      | `Schema<A, I, R>`                      | `Schema<Option<A>, I \| null, R>`              |
| `OptionFromNullishOr`   | `Schema<A, I, R>`, `null \| undefined` | `Schema<Option<A>, I \| null \| undefined, R>` |

where

```ts
type OptionFrom<I> =
  | {
    readonly _tag: 'None';
  }
  | {
    readonly _tag: 'Some';
    readonly value: I;
  };
```

### Option

- **Decoding**
  - `{ _tag: "None" }` is converted to `Option.none()`.
  - `{ _tag: "Some", value: i }` is converted to `Option.some(a)`, where `i` is decoded into `a` using the inner schema.
- **Encoding**
  - `Option.none()` is converted to `{ _tag: "None" }`.
  - `Option.some(a)` is converted to `{ _tag: "Some", value: i }`, where `a` is encoded into `i` using the inner schema.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.Option(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode({ _tag: 'None' })); // { _id: 'Option', _tag: 'None' }
console.log(decode({ _tag: 'Some', value: '1' })); // { _id: 'Option', _tag: 'Some', value: 1 }

console.log(encode(Option.none())); // { _tag: 'None' }
console.log(encode(Option.some(1))); // { _tag: 'Some', value: '1' }
```

### OptionFromSelf

- **Decoding**
  - `Option.none()` remains as `Option.none()`.
  - `Option.some(i)` is converted to `Option.some(a)`, where `i` is decoded into `a` using the inner schema.
- **Encoding**
  - `Option.none()` remains as `Option.none()`.
  - `Option.some(a)` is converted to `Option.some(i)`, where `a` is encoded into `i` using the inner schema.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.OptionFromSelf(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(Option.none())); // { _id: 'Option', _tag: 'None' }
console.log(decode(Option.some('1'))); // { _id: 'Option', _tag: 'Some', value: 1 }

console.log(encode(Option.none())); // { _id: 'Option', _tag: 'None' }
console.log(encode(Option.some(1))); // { _id: 'Option', _tag: 'Some', value: '1' }
```

### OptionFromUndefinedOr

- **Decoding**
  - `undefined` is converted to `Option.none()`.
  - `i` is converted to `Option.some(a)`, where `i` is decoded into `a` using the inner schema.
- **Encoding**
  - `Option.none()` is converted to `undefined`.
  - `Option.some(a)` is converted to `i`, where `a` is encoded into `i` using the inner schema.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.OptionFromUndefinedOr(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(undefined)); // { _id: 'Option', _tag: 'None' }
console.log(decode('1')); // { _id: 'Option', _tag: 'Some', value: 1 }

console.log(encode(Option.none())); // undefined
console.log(encode(Option.some(1))); // "1"
```

### OptionFromNullOr

- **Decoding**
  - `null` is converted to `Option.none()`.
  - `i` is converted to `Option.some(a)`, where `i` is decoded into `a` using the inner schema.
- **Encoding**
  - `Option.none()` is converted to `null`.
  - `Option.some(a)` is converted to `i`, where `a` is encoded into `i` using the inner schema.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.OptionFromNullOr(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(null)); // { _id: 'Option', _tag: 'None' }
console.log(decode('1')); // { _id: 'Option', _tag: 'Some', value: 1 }

console.log(encode(Option.none())); // null
console.log(encode(Option.some(1))); // "1"
```

### OptionFromNullishOr

- **Decoding**

  - `null` is converted to `Option.none()`.
  - `undefined` is converted to `Option.none()`.
  - `i` is converted to `Option.some(a)`, where `i` is decoded into `a` using the inner schema.

- **Encoding**
  - `Option.none()` is converted to a specified value (`undefined` or `null` based on user choice).
  - `Option.some(a)` is converted to `i`, where `a` is encoded into `i` using the inner schema.

```ts
import { Schema } from '@effect/schema';
import { Option } from 'effect';

const schema = Schema.OptionFromNullishOr(Schema.NumberFromString, undefined);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(null)); // { _id: 'Option', _tag: 'None' }
console.log(decode(undefined)); // { _id: 'Option', _tag: 'None' }
console.log(decode('1')); // { _id: 'Option', _tag: 'Some', value: 1 }

console.log(encode(Option.none())); // undefined
console.log(encode(Option.some(1))); // "1"
```

## Either

### Either

- decoding
  - `{ _tag: "Left", left: li }` -> `Either.left(la)`
  - `{ _tag: "Right", right: ri }` -> `Either.right(ra)`
- encoding
  - `Either.left(la)` -> `{ _tag: "Left", left: li }`
  - `Either.right(ra)` -> `{ _tag: "Right", right: ri }`

```ts
import { Schema } from '@effect/schema';
import { Either } from 'effect';

const schema = Schema.Either({
  left: Schema.Trim,
  right: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode({ _tag: 'Left', left: ' a ' })); // { _id: 'Either', _tag: 'Left', left: 'a' }
console.log(decode({ _tag: 'Right', right: '1' })); // { _id: 'Either', _tag: 'Right', right: 1 }

console.log(encode(Either.left('a'))); // { _tag: 'Left', left: 'a' }
console.log(encode(Either.right(1))); // { _tag: 'Right', right: '1' }
```

### EitherFromSelf

- decoding
  - `Either.left(li)` -> `Either.left(la)`
  - `Either.right(ri)` -> `Either.right(ra)`
- encoding
  - `Either.left(la)` -> `Either.left(li)`
  - `Either.right(ra)` -> `Either.right(ri)`

```ts
import { Schema } from '@effect/schema';
import { Either } from 'effect';

const schema = Schema.EitherFromSelf({
  left: Schema.Trim,
  right: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(Either.left(' a '))); // { _id: 'Either', _tag: 'Left', left: 'a' }
console.log(decode(Either.right('1'))); // { _id: 'Either', _tag: 'Right', right: 1 }

console.log(encode(Either.left('a'))); // { _id: 'Either', _tag: 'Left', left: 'a' }
console.log(encode(Either.right(1))); // { _id: 'Either', _tag: 'Right', right: '1' }
```

### EitherFromUnion

- decoding
  - `li` -> `Either.left(la)`
  - `ri` -> `Either.right(ra)`
- encoding
  - `Either.left(la)` -> `li`
  - `Either.right(ra)` -> `ri`

```ts
import { Schema } from '@effect/schema';
import { Either } from 'effect';

const schema = Schema.EitherFromUnion({
  left: Schema.Boolean,
  right: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(true)); // { _id: 'Either', _tag: 'Left', left: true }
console.log(decode('1')); // { _id: 'Either', _tag: 'Right', right: 1 }

console.log(encode(Either.left(true))); // true
console.log(encode(Either.right(1))); // "1"
```

## ReadonlySet

### ReadonlySet

- decoding
  - `ReadonlyArray<I>` -> `ReadonlySet<A>`
- encoding
  - `ReadonlySet<A>` -> `ReadonlyArray<I>`

```ts
import { Schema } from '@effect/schema';

const schema = Schema.ReadonlySet(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(['1', '2', '3'])); // Set(3) { 1, 2, 3 }
console.log(encode(new Set([1, 2, 3]))); // [ '1', '2', '3' ]
```

### ReadonlySetFromSelf

- decoding
  - `ReadonlySet<I>` -> `ReadonlySet<A>`
- encoding
  - `ReadonlySet<A>` -> `ReadonlySet<I>`

```ts
import { Schema } from '@effect/schema';

const schema = Schema.ReadonlySetFromSelf(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(new Set(['1', '2', '3']))); // Set(3) { 1, 2, 3 }
console.log(encode(new Set([1, 2, 3]))); // Set(3) { '1', '2', '3' }
```

## ReadonlyMap

### ReadonlyMap

- decoding
  - `ReadonlyArray<readonly [KI, VI]>` -> `ReadonlyMap<KA, VA>`
- encoding
  - `ReadonlyMap<KA, VA>` -> `ReadonlyArray<readonly [KI, VI]>`

```ts
import { Schema } from '@effect/schema';

const schema = Schema.ReadonlyMap({
  key: Schema.String,
  value: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(
  decode([
    ['a', '2'],
    ['b', '2'],
    ['c', '3'],
  ]),
); // Map(3) { 'a' => 2, 'b' => 2, 'c' => 3 }
console.log(
  encode(
    new Map([
      ['a', 1],
      ['b', 2],
      ['c', 3],
    ]),
  ),
); // [ [ 'a', '1' ], [ 'b', '2' ], [ 'c', '3' ] ]
```

### ReadonlyMapFromSelf

- decoding
  - `ReadonlyMap<KI, VI>` -> `ReadonlyMap<KA, VA>`
- encoding
  - `ReadonlyMap<KA, VA>` -> `ReadonlyMap<KI, VI>`

```ts
import { Schema } from '@effect/schema';

const schema = Schema.ReadonlyMapFromSelf({
  key: Schema.String,
  value: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(
  decode(
    new Map([
      ['a', '2'],
      ['b', '2'],
      ['c', '3'],
    ]),
  ),
); // Map(3) { 'a' => 2, 'b' => 2, 'c' => 3 }
console.log(
  encode(
    new Map([
      ['a', 1],
      ['b', 2],
      ['c', 3],
    ]),
  ),
); // Map(3) { 'a' => '1', 'b' => '2', 'c' => '3' }
```

## HashSet

### HashSet

- decoding
  - `ReadonlyArray<I>` -> `HashSet<A>`
- encoding
  - `HashSet<A>` -> `ReadonlyArray<I>`

```ts
import { Schema } from '@effect/schema';
import { HashSet } from 'effect';

const schema = Schema.HashSet(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(['1', '2', '3'])); // { _id: 'HashSet', values: [ 1, 2, 3 ] }
console.log(encode(HashSet.fromIterable([1, 2, 3]))); // [ '1', '2', '3' ]
```

### HashSetFromSelf

- decoding
  - `HashSet<I>` -> `HashSet<A>`
- encoding
  - `HashSet<A>` -> `HashSet<I>`

```ts
import { Schema } from '@effect/schema';
import { HashSet } from 'effect';

const schema = Schema.HashSetFromSelf(Schema.NumberFromString);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(HashSet.fromIterable(['1', '2', '3']))); // { _id: 'HashSet', values: [ 1, 2, 3 ] }
console.log(encode(HashSet.fromIterable([1, 2, 3]))); // { _id: 'HashSet', values: [ '1', '3', '2' ] }
```

## HashMap

### HashMap

- decoding
  - `ReadonlyArray<readonly [KI, VI]>` -> `HashMap<KA, VA>`
- encoding
  - `HashMap<KA, VA>` -> `ReadonlyArray<readonly [KI, VI]>`

```ts
import { Schema } from '@effect/schema';
import { HashMap } from 'effect';

const schema = Schema.HashMap({
  key: Schema.String,
  value: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(
  decode([
    ['a', '2'],
    ['b', '2'],
    ['c', '3'],
  ]),
); // { _id: 'HashMap', values: [ [ 'a', 2 ], [ 'c', 3 ], [ 'b', 2 ] ] }
console.log(
  encode(
    HashMap.fromIterable([
      ['a', 1],
      ['b', 2],
      ['c', 3],
    ]),
  ),
); // [ [ 'a', '1' ], [ 'c', '3' ], [ 'b', '2' ] ]
```

### HashMapFromSelf

- decoding
  - `HashMap<KI, VI>` -> `HashMap<KA, VA>`
- encoding
  - `HashMap<KA, VA>` -> `HashMap<KI, VI>`

```ts
import { Schema } from '@effect/schema';
import { HashMap } from 'effect';

const schema = Schema.HashMapFromSelf({
  key: Schema.String,
  value: Schema.NumberFromString,
});

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(
  decode(
    HashMap.fromIterable([
      ['a', '2'],
      ['b', '2'],
      ['c', '3'],
    ]),
  ),
); // { _id: 'HashMap', values: [ [ 'a', 2 ], [ 'c', 3 ], [ 'b', 2 ] ] }
console.log(
  encode(
    HashMap.fromIterable([
      ['a', 1],
      ['b', 2],
      ['c', 3],
    ]),
  ),
); // { _id: 'HashMap', values: [ [ 'a', '1' ], [ 'c', '3' ], [ 'b', '2' ] ] }
```

## SortedSet

### SortedSet

- decoding
  - `ReadonlyArray<I>` -> `SortedSet<A>`
- encoding
  - `SortedSet<A>` -> `ReadonlyArray<I>`

```ts
import { Schema } from '@effect/schema';
import { Number, SortedSet } from 'effect';

const schema = Schema.SortedSet(Schema.NumberFromString, Number.Order);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(['1', '2', '3'])); // { _id: 'SortedSet', values: [ 1, 2, 3 ] }
console.log(encode(SortedSet.fromIterable(Number.Order)([1, 2, 3]))); // [ '1', '2', '3' ]
```

### SortedSetFromSelf

- decoding
  - `SortedSet<I>` -> `SortedSet<A>`
- encoding
  - `SortedSet<A>` -> `SortedSet<I>`

```ts
import { Schema } from '@effect/schema';
import { Number, SortedSet, String } from 'effect';

const schema = Schema.SortedSetFromSelf(
  Schema.NumberFromString,
  Number.Order,
  String.Order,
);

const decode = Schema.decodeUnknownSync(schema);
const encode = Schema.encodeSync(schema);

console.log(decode(SortedSet.fromIterable(String.Order)(['1', '2', '3']))); // { _id: 'SortedSet', values: [ 1, 2, 3 ] }
console.log(encode(SortedSet.fromIterable(Number.Order)([1, 2, 3]))); // { _id: 'SortedSet', values: [ '1', '2', '3' ] }
```

## Duration

### Duration

Converts an hrtime(i.e. `[seconds: number, nanos: number]`) into a `Duration`.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.Duration; // Schema<Duration, number>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode([0, 0])); // { _id: 'Duration', _tag: 'Millis', millis: 0 }
console.log(decode([5000, 0])); // { _id: 'Duration', _tag: 'Nanos', hrtime: [ 5000, 0 ] }
```

### DurationFromSelf

The `DurationFromSelf` schema is designed to validate that a given value conforms to the `Duration` type from the `effect` library.

```ts
import { Schema } from '@effect/schema';
import { Duration } from 'effect';

const schema = Schema.DurationFromSelf;
const decode = Schema.decodeUnknownSync(schema);

console.log(decode(Duration.seconds(2))); // { _id: 'Duration', _tag: 'Millis', millis: 2000 }
console.log(decode(null)); // throws Error: Expected DurationFromSelf, actual null
```

### DurationFromMillis

Converts a `number` into a `Duration` where the number represents the number of milliseconds.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.DurationFromMillis; // Schema<Duration, number>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode(0)); // { _id: 'Duration', _tag: 'Millis', millis: 0 }
console.log(decode(5000)); // { _id: 'Duration', _tag: 'Millis', millis: 5000 }
```

### DurationFromNanos

Converts a `BigInt` into a `Duration` where the number represents the number of nanoseconds.

```ts
import { Schema } from '@effect/schema';

const schema = Schema.DurationFromNanos; // Schema<Duration, BigInt>
const decode = Schema.decodeUnknownSync(schema);

console.log(decode(0n)); // { _id: 'Duration', _tag: 'Millis', millis: 0 }
console.log(decode(5000000000n)); // { _id: 'Duration', _tag: 'Nanos', hrtime: [ 5, 0 ] }
```

### clampDuration

Clamps a `Duration` between a minimum and a maximum value.

```ts
import { Schema } from '@effect/schema';
import { Duration } from 'effect';

const schema = Schema.DurationFromSelf.pipe(
  Schema.clampDuration('5 seconds', '10 seconds'),
);

const decode = Schema.decodeUnknownSync(schema);

console.log(decode(Duration.decode('2 seconds'))); // { _id: 'Duration', _tag: 'Millis', millis: 5000 }
console.log(decode(Duration.decode('6 seconds'))); // { _id: 'Duration', _tag: 'Millis', millis: 6000 }
console.log(decode(Duration.decode('11 seconds'))); // { _id: 'Duration', _tag: 'Millis', millis: 10000 }
```

## Redacted

### Redacted

The `Redacted` schema in `@effect/schema` is specifically designed to handle sensitive information by converting a `string` into a `Redacted` object. This transformation ensures that the sensitive data is not exposed in the application's output.

```ts
import { Schema } from '@effect/schema';

// Schema.Redacted<typeof Schema.String>
const schema = Schema.Redacted(Schema.String);
const decode = Schema.decodeUnknownSync(schema);

console.log(decode('keep it secret, keep it safe')); // {}
```

**Note on Logging**

It's important to note that when successfully decoding a `Redacted`, the output is intentionally obscured (`{}`) to prevent the actual secret from being revealed in logs or console outputs.

#### Warning on Schema Composition

When composing the `Redacted` schema with other schemas, care must be taken as decoding or encoding errors could potentially expose sensitive information.

**Practical Example Showing Potential Data Exposure**

```ts
import { Schema } from '@effect/schema';
import { Redacted } from 'effect';

const schema = Schema.Trimmed.pipe(
  Schema.compose(Schema.Redacted(Schema.String)),
);

console.log(Schema.decodeUnknownEither(schema)(' 123'));
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: {
    _id: 'ParseError',
    message: '(Trimmed <-> (string <-> Redacted(<redacted>)))\n' +
      'â””â”€ Encoded side transformation failure\n' +
      '   â””â”€ Trimmed\n' +
      '      â””â”€ Predicate refinement failure\n' +
      '         â””â”€ Expected Trimmed (a string with no leading or trailing whitespace), actual " 123"'
  }
}
*/
console.log(Schema.encodeEither(schema)(Redacted.make(' 123')));
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: {
    _id: 'ParseError',
    message: '(Trimmed <-> (string <-> Redacted(<redacted>)))\n' +
      'â””â”€ Encoded side transformation failure\n' +
      '   â””â”€ Trimmed\n' +
      '      â””â”€ Predicate refinement failure\n' +
      '         â””â”€ Expected Trimmed (a string with no leading or trailing whitespace), actual " 123"'
  }
}
*/
```

In the example above, if the input string does not meet the criteria (e.g., contains spaces), the error message generated might inadvertently expose sensitive information included in the input.

#### Mitigating Exposure Risks

To reduce the risk of sensitive information leakage in error messages, you can customize the error messages to obscure sensitive details:

```ts
import { Schema } from '@effect/schema';
import { Redacted } from 'effect';

const schema = Schema.Trimmed.annotations({
  message: () => 'Expected Trimmed, actual <redacted>',
}).pipe(Schema.compose(Schema.Redacted(Schema.String)));

console.log(Schema.decodeUnknownEither(schema)(' 123'));
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: {
    _id: 'ParseError',
    message: '(Trimmed <-> (string <-> Redacted(<redacted>)))\n' +
      'â””â”€ Encoded side transformation failure\n' +
      '   â””â”€ Expected Trimmed, actual <redacted>'
  }
}
*/
console.log(Schema.encodeEither(schema)(Redacted.make(' 123')));
/*
{
  _id: 'Either',
  _tag: 'Left',
  left: {
    _id: 'ParseError',
    message: '(Trimmed <-> (string <-> Redacted(<redacted>)))\n' +
      'â””â”€ Encoded side transformation failure\n' +
      '   â””â”€ Expected Trimmed, actual <redacted>'
  }
}
*/
```

### RedactedFromSelf

The `RedactedFromSelf` schema is designed to validate that a given value conforms to the `Redacted` type from the `effect` library.

```ts
import { Schema } from '@effect/schema';
import { Redacted } from 'effect';

const schema = Schema.RedactedFromSelf(Schema.String);
const decode = Schema.decodeUnknownSync(schema);

console.log(decode(Redacted.make('mysecret'))); // {}
console.log(decode(null)); // throws Error: Expected Redacted(<redacted>), actual <redacted>
```

**Note on Logging**

It's important to note that when successfully decoding a `Redacted`, the output is intentionally obscured (`{}`) to prevent the actual secret from being revealed in logs or console outputs.

# Useful Examples

## Email

Since there are various different definitions of what constitutes a valid email address depending on the environment and use case, `@effect/schema` does not provide a built-in combinator for parsing email addresses. However, it is easy to define a custom combinator that can be used to parse email addresses.

```ts
import { Schema } from '@effect/schema';

// see https://stackoverflow.com/questions/46155/how-can-i-validate-an-email-address-in-javascript/46181#46181
const Email = Schema.pattern(
  /^(?!\.)(?!.*\.\.)([A-Z0-9_+-.]*)[A-Z0-9_+-]@([A-Z0-9][A-Z0-9-]*\.)+[A-Z]{2,}$/i,
);
```

## Url

Multiple environments like the Browser or Node provide a built-in `URL` class that can be used to validate URLs. Here we demonstrate how to leverage it to validate if a string is a valid URL.

```ts
import { Schema } from '@effect/schema';

const UrlString = Schema.String.pipe(
  Schema.filter((value) => {
    try {
      new URL(value);
      return true;
    } catch (_) {
      return false;
    }
  }),
);

const decode = Schema.decodeUnknownSync(UrlString);

console.log(decode('https://www.effect.website')); // https://www.effect.website
```

In case you prefer to normalize URLs you can combine `transformOrFail` with `URL`:

```ts
import { ParseResult, Schema } from '@effect/schema';

const NormalizedUrlString = Schema.String.pipe(
  Schema.filter((value) => {
    try {
      return new URL(value).toString() === value;
    } catch (_) {
      return false;
    }
  }),
);

const NormalizeUrlString = Schema.transformOrFail(
  Schema.String,
  NormalizedUrlString,
  {
    decode: (value, _, ast) =>
      ParseResult.try({
        try: () => new URL(value).toString(),
        catch: (err) =>
          new ParseResult.Type(
            ast,
            value,
            err instanceof Error ? err.message : undefined,
          ),
      }),
    encode: ParseResult.succeed,
  },
);

const decode = Schema.decodeUnknownSync(NormalizeUrlString);

console.log(decode('https://www.effect.website')); // "https://www.effect.website/"
```

# Technical overview: Understanding Schemas

A schema is a description of a data structure that can be used to generate various artifacts from a single declaration.

From a technical point of view a schema is just a typed wrapper of an `AST` value:

```ts
interface Schema<A, I, R> {
  readonly ast: AST;
}
```

The `AST` type represents a tiny portion of the TypeScript AST, roughly speaking the part describing ADTs (algebraic data types),
i.e. products (like structs and tuples) and unions, plus a custom transformation node.

This means that you can define your own schema constructors / combinators as long as you are able to manipulate the `AST` value accordingly, let's see an example.

Say we want to define a `pair` schema constructor, which takes a `Schema<A, I, R>` as input and returns a `Schema<readonly [A, A], readonly [I, I], R>` as output.

First of all we need to define the signature of `pair`

```ts
import type { Schema } from '@effect/schema';

declare const pair: <A, I, R>(
  schema: Schema.Schema<A, I, R>,
) => Schema.Schema<readonly [A, A], readonly [I, I], R>;
```

Then we can implement the body using the APIs exported by the `@effect/schema/AST` module:

```ts
import { AST, Schema } from '@effect/schema';

const pair = <A, I, R>(
  schema: Schema.Schema<A, I, R>,
): Schema.Schema<readonly [A, A], readonly [I, I], R> => {
  const element = new AST.Element(
    schema.ast, // <= the element type
    false, // <= is optional?
  );
  const tuple = new AST.TupleType(
    [element, element], // <= elements definitions
    [], // <= rest element
    true, // <= is readonly?
  );
  return Schema.make(tuple); // <= wrap the AST value in a Schema
};
```

This example demonstrates the use of the low-level APIs of the `AST` module, however, the same result can be achieved more easily and conveniently by using the high-level APIs provided by the `Schema` module.

```ts
import { Schema } from '@effect/schema';

const pair = <A, I, R>(
  schema: Schema.Schema<A, I, R>,
): Schema.Schema<readonly [A, A], readonly [I, I], R> =>
  Schema.Tuple(schema, schema);
```

# Comparisons

## Zod

Feature-wise, `schema` can do practically everything that `zod` can do.

The main differences are:

1. `schema` transformations are bidirectional, so it not only decodes like `zod` but also encodes.
2. `schema` is integrated with `Effect` and inherits some benefits from it (such as dependency tracking in transformations).
3. `schema` is highly customizable through annotations, allowing users to attach meta-information.
4. `schema` uses a functional programming style with combinators and transformations (while `zod` provides a chainable API).

### Basic usage

Zod

```ts
import { z } from 'zod';

// creating a schema for strings
const mySchema = z.string();

// parsing
mySchema.parse('tuna'); // => "tuna"
mySchema.parse(12); // => throws ZodError

// "safe" parsing (doesn't throw error if validation fails)
mySchema.safeParse('tuna'); // => { success: true; data: "tuna" }
mySchema.safeParse(12); // => { success: false; error: ZodError }
```

Schema

```ts
import { Schema as S } from '@effect/schema';

// creating a schema for strings
const mySchema = S.String;

// parsing
S.decodeUnknownSync(mySchema)('tuna'); // => "tuna"
S.decodeUnknownSync(mySchema)(12); // => throws ParseError

// "safe" parsing (doesn't throw error if validation fails)
S.decodeUnknownEither(mySchema)('tuna'); // => right("tuna")
S.decodeUnknownEither(mySchema)(12); // => left(ParseError)
```

Creating an object schema

Zod

```ts
import { z } from 'zod';

const User = z.object({
  username: z.string(),
});

User.parse({ username: 'Ludwig' });

// extract the inferred type
type User = z.infer<typeof User>;
// { username: string }
```

Schema

```ts
import { Schema as S } from '@effect/schema';

const User = S.Struct({
  username: S.String,
});

S.decodeUnknownSync(User)({ username: 'Ludwig' });

// extract the inferred type
type User = S.Schema.Type<typeof User>;
// { readonly username: string }
```

### Primitives

Zod

```ts
import { z } from 'zod';

// primitive values
z.string();
z.number();
z.bigint();
z.boolean();
z.date();
z.symbol();

// empty types
z.undefined();
z.null();
z.void(); // accepts undefined

// catch-all types
// allows any value
z.any();
z.unknown();

// never type
// allows no values
z.never();
```

Schema

```ts
import { Schema as S } from '@effect/schema';

// primitive values
S.String;
S.Number;
S.BigInt;
S.Boolean;
S.Date;
S.Symbol;

// empty types
S.Undefined;
S.Null;
S.Void; // accepts undefined

// catch-all types
// allows any value
S.Any;
S.Unknown;

// never type
// allows no values
S.Never;
```

### Coercion for primitives

No equivalent.

### Literals

Zod

```ts
const tuna = z.literal('tuna');
const twelve = z.literal(12);
const twobig = z.literal(2n); // bigint literal
const tru = z.literal(true);

const terrificSymbol = Symbol('terrific');
const terrific = z.literal(terrificSymbol);

// retrieve literal value
tuna.value; // "tuna"
```

Schema

```ts
import { Schema as S } from '@effect/schema';

const tuna = S.Literal('tuna');
const twelve = S.Literal(12);
const twobig = S.Literal(2n); // bigint literal
const tru = S.Literal(true);

const terrificSymbol = Symbol('terrific');
const terrific = S.UniqueSymbolFromSelf(terrificSymbol);

// retrieve literal value
tuna.literals; // ["tuna"]
```

### Strings

Zod

```ts
// validations
z.string().max(5);
z.string().min(5);
z.string().length(5);
z.string().email();
z.string().url();
z.string().emoji();
z.string().uuid();
z.string().nanoid();
z.string().cuid();
z.string().cuid2();
z.string().ulid();
z.string().regex(regex);
z.string().includes(string);
z.string().startsWith(string);
z.string().endsWith(string);
z.string().datetime(); // ISO 8601; by default only `Z` timezone allowed
z.string().date(); // ISO date format (YYYY-MM-DD)
z.string().time(); // ISO time format (HH:mm:ss[.SSSSSS])
z.string().duration(); // ISO 8601 duration
z.string().ip(); // defaults to allow both IPv4 and IPv6
z.string().base64();

// transforms
z.string().trim(); // trim whitespace
z.string().toLowerCase(); // toLowerCase
z.string().toUpperCase(); // toUpperCase
```

Schema

```ts
import { Schema as S } from '@effect/schema';

// validations
S.String.pipe(S.maxLength(5));
S.String.pipe(S.minLength(5));
S.String.pipe(S.length(5));
// S.string().email() // No equivalent
// S.string().url() // No equivalent
// S.string().emoji() // No equivalent
S.UUID;
// S.string().nanoid() // No equivalent
// S.string().cuid() // No equivalent
// S.string().cuid2() // No equivalent
S.ULID;
S.String.pipe(S.pattern(regex));
S.String.pipe(S.includes(string));
S.String.pipe(S.startsWith(string));
S.String.pipe(S.endsWith(string));
// S.string().datetime() // No equivalent
// S.string().date() // No equivalent
// S.string().time() // No equivalent
// S.string().duration() // No equivalent
// S.string().ip() // No equivalent
S.Base64;

// transforms
S.Trim; // trim whitespace
S.Lowercase; // toLowerCase
S.Uppercase; // toUpperCase
```

You can customize some common error messages when creating a string schema.

Zod

```ts
const name = z.string({
  required_error: 'Name is required',
  invalid_type_error: 'Name must be a string',
});
```

Schema

```ts
const name = S.String.annotations({
  message: () => 'Name must be a string',
});
```

When using validation methods, you can pass in an additional argument to provide a custom error message.

Zod

```ts
z.string().min(5, { message: 'Must be 5 or more characters long' });
```

Schema

```ts
S.String.pipe(
  S.minLength(5, { message: () => 'Must be 5 or more characters long' }),
);
```

### Datetimes

No equivalent.

### Dates

Zod

```ts
const date = z.string().date();

date.parse('2020-01-01'); // pass
date.parse('2020-1-1'); // fail
date.parse('2020-01-32'); // fail
```

Schema

```ts
import { Schema as S } from '@effect/schema';

S.decodeUnknownSync(S.Date)('2020-01-01'); // pass
S.decodeUnknownSync(S.Date)('2020-1-1'); // pass
S.decodeUnknownSync(S.Date)('2020-01-32'); // fail
```

### Times

No equivalent.

### IP addresses

No equivalent.

### Numbers

Zod

```ts
z.number().gt(5);
z.number().gte(5); // alias .min(5)
z.number().lt(5);
z.number().lte(5); // alias .max(5)

z.number().int(); // value must be an integer

z.number().positive(); //     > 0
z.number().nonnegative(); //  >= 0
z.number().negative(); //     < 0
z.number().nonpositive(); //  <= 0

z.number().multipleOf(5); // Evenly divisible by 5. Alias .step(5)

z.number().finite(); // value must be finite, not Infinity or -Infinity
z.number().safe(); // value must be between Number.MIN_SAFE_INTEGER and Number.MAX_SAFE_INTEGER
```

Schema

```ts
import { Schema as S } from '@effect/schema';

S.Number.pipe(S.greaterThan(5));
S.Number.pipe(S.greaterThanOrEqualTo(5));
S.Number.pipe(S.lessThan(5));
S.Number.pipe(S.lessThanOrEqualTo(5));

S.Number.pipe(S.int());

S.Number.pipe(S.positive());
S.Number.pipe(S.nonNegative());
S.Number.pipe(S.negative());
S.Number.pipe(S.nonPositive());

S.Number.pipe(S.multipleOf(5));

S.Number.pipe(S.finite());
// z.number().safe(); // No equivalent
```

Optionally, you can pass in a second argument to provide a custom error message.

Zod

```ts
z.number().lte(5, { message: 'thisðŸ‘isðŸ‘tooðŸ‘big' });
```

Schema

```ts
S.Number.pipe(S.lessThanOrEqualTo(5, { message: () => 'thisðŸ‘isðŸ‘tooðŸ‘big' }));
```

### BigInts

Zod

```ts
z.bigint().gt(5n);
z.bigint().gte(5n); // alias `.min(5n)`
z.bigint().lt(5n);
z.bigint().lte(5n); // alias `.max(5n)`

z.bigint().positive(); // > 0n
z.bigint().nonnegative(); // >= 0n
z.bigint().negative(); // < 0n
z.bigint().nonpositive(); // <= 0n

z.bigint().multipleOf(5n); // Evenly divisible by 5n.
```

Schema

```ts
import { Schema as S } from '@effect/schema';

S.BigInt.pipe(S.greaterThanBigInt(5n));
S.BigInt.pipe(S.greaterThanOrEqualToBigInt(5n));
S.BigInt.pipe(S.lessThanBigInt(5n));
S.BigInt.pipe(S.lessThanOrEqualToBigInt(5n));

S.BigInt.pipe(S.positiveBigInt());
S.BigInt.pipe(S.nonNegativeBigInt());
S.BigInt.pipe(S.negativeBigInt());
S.BigInt.pipe(S.nonPositiveBigInt());

// S.BigInt.pipe().multipleOf(5n);  // No equivalent
```

### Booleans

Zod

```ts
const isActive = z.boolean({
  required_error: 'isActive is required',
  invalid_type_error: 'isActive must be a boolean',
});
```

Schema

```ts
const isActive = S.Boolean.annotations({
  message: () => 'isActive must be a boolean',
});
```

### Native enums

Zod

```ts
enum Fruits {
  Apple,
  Banana,
}

const FruitEnum = z.nativeEnum(Fruits);
type FruitEnum = z.infer<typeof FruitEnum>; // Fruits

FruitEnum.parse(Fruits.Apple); // passes
FruitEnum.parse(Fruits.Banana); // passes
FruitEnum.parse(0); // passes
FruitEnum.parse(1); // passes
FruitEnum.parse(3); // fails
```

Schema

```ts
enum Fruits {
  Apple,
  Banana,
}

const FruitEnum = S.Enums(Fruits);
type FruitEnum = S.Schema.Type<typeof FruitEnum>; // Fruits

S.decodeUnknownSync(FruitEnum)(Fruits.Apple); // passes
S.decodeUnknownSync(FruitEnum)(Fruits.Banana); // passes
S.decodeUnknownSync(FruitEnum)(0); // passes
S.decodeUnknownSync(FruitEnum)(1); // passes
S.decodeUnknownSync(FruitEnum)(3); // fails
```

### Optionals

Zod

```ts
const user = z.object({
  username: z.string().optional(),
});
type C = z.infer<typeof user>; // { username?: string | undefined };
```

Schema

```ts
const user = S.Struct({
  username: S.optional(S.String),
});
type C = S.Schema.Type<typeof user>; // { readonly username?: string | undefined };
```

### Nullables

Zod

```ts
const nullableString = z.nullable(z.string());
nullableString.parse('asdf'); // => "asdf"
nullableString.parse(null); // => null
```

Schema

```ts
const nullableString = S.NullOr(S.String);
S.decodeUnknownSync(nullableString)('asdf'); // => "asdf"
S.decodeUnknownSync(nullableString)(null); // => null
```

### Objects

Zod

```ts
// all properties are required by default
const Dog = z.object({
  name: z.string(),
  age: z.number(),
});

// extract the inferred type like this
type Dog = z.infer<typeof Dog>;

// equivalent to:
type Dog = {
  name: string;
  age: number;
};
```

Schema

```ts
// all properties are required by default
const Dog = S.Struct({
  name: S.String,
  age: S.Number,
});

// extract the inferred type like this
type Dog = S.Schema.Type<typeof Dog>;

// equivalent to:
type Dog = {
  readonly name: string;
  readonly age: number;
};
```

#### shape

Zod

```ts
Dog.shape.name; // => string schema
Dog.shape.age; // => number schema
```

Schema

```ts
Dog.fields.name; // => String schema
Dog.fields.age; // => Number schema
```

#### keyof

Zod

```ts
const keySchema = Dog.keyof();
keySchema; // ZodEnum<["name", "age"]>
```

Schema

```ts
// const keySchema: S.Schema<"name" | "age", "name" | "age", never>
const keySchema = S.keyof(Dog);
```

#### extend

Zod

```ts
const DogWithBreed = Dog.extend({
  breed: z.string(),
});
```

Schema

```ts
const DogWithBreed = Dog.pipe(
  S.extend(
    S.Struct({
      breed: S.String,
    }),
  ),
);

// or simply

const DogWithBreed = S.Struct({
  ...Dog.fields,
  breed: S.String,
});
```

#### pick / omit

Zod

```ts
const Recipe = z.object({
  id: z.string(),
  name: z.string(),
  ingredients: z.array(z.string()),
});

const JustTheName = Recipe.pick({ name: true });

const NoIDRecipe = Recipe.omit({ id: true });
```

Schema

```ts
const Recipe = S.Struct({
  id: S.String,
  name: S.String,
  ingredients: S.Array(S.String),
});

const JustTheName = Recipe.pipe(S.pick('name'));

const NoIDRecipe = Recipe.pipe(S.omit('id'));
```

#### partial

Zod

```ts
const user = z.object({
  email: z.string(),
  username: z.string(),
});

const partialUser = user.partial();
```

Schema

```ts
const user = S.Struct({
  email: S.String,
  username: S.String,
});

const partialUser = S.partial(user);
```

#### deepPartial

No equivalent

#### required

Zod

```ts
const user = z
  .object({
    email: z.string(),
    username: z.string(),
  })
  .partial();

const requiredUser = user.required();
```

Schema

```ts
const user = S.partial(
  S.Struct({
    email: S.String,
    username: S.String,
  }),
);

const requiredUser = S.required(user);
```

#### passthrough

Zod

```ts
const person = z.object({
  name: z.string(),
});

person.parse({
  name: 'bob dylan',
  extraKey: 61,
});
// => { name: "bob dylan" }
// extraKey has been stripped

person.passthrough().parse({
  name: 'bob dylan',
  extraKey: 61,
});
// => { name: "bob dylan", extraKey: 61 }
```

Schema

```ts
const person = S.Struct({
  name: S.String,
});

S.decodeUnknownSync(person)(
  {
    name: 'bob dylan',
    extraKey: 61,
  },
  { onExcessProperty: 'preserve' },
);
// => { name: "bob dylan", extraKey: 61 }
```

#### strict

Zod

```ts
const person = z
  .object({
    name: z.string(),
  })
  .strict();

person.parse({
  name: 'bob dylan',
  extraKey: 61,
});
// => throws ZodError
```

Schema

```ts
const person = S.Struct({
  name: S.String,
});

S.decodeUnknownSync(person)(
  {
    name: 'bob dylan',
    extraKey: 61,
  },
  { onExcessProperty: 'error' },
);
// => throws ParseError
```

#### catchall

Zod

````ts
const person = z
  .object({
    name: z.string(),
  })
  .catchall(z.string());

person.parse({
  name: 'bob dylan',
  validExtraKey: 'foo', // works fine
});

person.parse({
  name: 'bob dylan',
  validExtraKey: false, // fails
});
// => throws ZodError```
````

Schema

```ts
const person = S.Struct(
  {
    name: S.String,
  },
  S.Record(S.String, S.String),
);

S.decodeUnknownSync(person)({
  name: 'bob dylan',
  validExtraKey: 'foo', // works fine
});

S.decodeUnknownSync(person)({
  name: 'bob dylan',
  validExtraKey: true, // fails
});
// => throws ParseError
```

### Arrays

Zod

```ts
const stringArray = z.array(z.string());
```

Schema

```ts
const stringArray = S.Array(S.String);
```

#### element

Zod

```ts
stringArray.element; // => string schema
```

Schema

```ts
stringArray.value; // => String schema
```

#### nonempty

Zod

```ts
const nonEmptyStrings = z.string().array().nonempty();
// the inferred type is now
// [string, ...string[]]

nonEmptyStrings.parse([]); // throws: "Array cannot be empty"
nonEmptyStrings.parse(['Ariana Grande']); // passes
```

Schema

```ts
const nonEmptyStrings = S.NonEmptyArray(S.String);
// the inferred type is now
// [string, ...string[]]

S.decodeUnknownSync(nonEmptyStrings)([]);
/* throws:
Error: readonly [string, ...string[]]
â””â”€ [0]
   â””â”€ is missing
*/
S.decodeUnknownSync(nonEmptyStrings)(['Ariana Grande']); // passes
```

#### min / max / length

Zod

```ts
z.string().array().min(5); // must contain 5 or more items
z.string().array().max(5); // must contain 5 or fewer items
z.string().array().length(5); // must contain 5 items exactly
```

Schema

```ts
S.Array(S.String).pipe(S.minItems(5)); // must contain 5 or more items
S.Array(S.String).pipe(S.maxItems(5)); // must contain 5 or fewer items
S.Array(S.String).pipe(S.itemsCount(5)); // must contain 5 items exactly
```

### Tuples

Zod

```ts
const athleteSchema = z.tuple([
  z.string(), // name
  z.number(), // jersey number
  z.object({
    pointsScored: z.number(),
  }), // statistics
]);

type Athlete = z.infer<typeof athleteSchema>;
// type Athlete = [string, number, { pointsScored: number }]
```

Schema

```ts
const athleteSchema = S.Tuple(
  S.String, // name
  S.Number, // jersey number
  S.Struct({
    pointsScored: S.Number,
  }), // statistics
);

type Athlete = S.Schema.Type<typeof athleteSchema>;
// type Athlete = readonly [string, number, { readonly pointsScored: number }]
```

A variadic ("rest") argument can be added with the .rest method.

Zod

```ts
const variadicTuple = z.tuple([z.string()]).rest(z.number());
const result = variadicTuple.parse(['hello', 1, 2, 3]);
// => [string, ...number[]];
```

Schema

```ts
const variadicTuple = S.Tuple([S.String], S.Number);
const result = S.decodeUnknownSync(variadicTuple)(['hello', 1, 2, 3]);
// => readonly [string, ...number[]];
```

### Unions

Zod

```ts
const stringOrNumber = z.union([z.string(), z.number()]);

stringOrNumber.parse('foo'); // passes
stringOrNumber.parse(14); // passes
```

Schema

```ts
const stringOrNumber = S.Union(S.String, S.Number);

S.decodeUnknownSync(stringOrNumber)('foo'); // passes
S.decodeUnknownSync(stringOrNumber)(14); // passes
```

### Discriminated unions

No equivalent needed as discriminated unions are automatically detected.

### Records

Zod

```ts
const User = z.object({ name: z.string() });

const UserStore = z.record(z.string(), User);
type UserStore = z.infer<typeof UserStore>;
// => Record<string, { name: string }>
```

Schema

```ts
const User = S.Struct({ name: S.String });

const UserStore = S.Record(S.String, User);
type UserStore = S.Schema.Type<typeof UserStore>;
// => type UserStore = { readonly [x: string]: { readonly name: string; }; }
```

### Maps

Zod

```ts
const stringNumberMap = z.map(z.string(), z.number());

type StringNumberMap = z.infer<typeof stringNumberMap>;
// type StringNumberMap = Map<string, number>
```

Schema

```ts
const stringNumberMap = S.Map({ key: S.String, value: S.Number });

type StringNumberMap = S.Schema.Type<typeof stringNumberMap>;
// type StringNumberMap = Map<string, number>
```

### Sets

Zod

```ts
const numberSet = z.set(z.number());
type NumberSet = z.infer<typeof numberSet>;
// type NumberSet = Set<number>
```

Schema

```ts
const numberSet = S.Set(S.Number);

type NumberSet = S.Schema.Type<typeof numberSet>;
// type NumberSet = Set<number>
```

### Intersections

No equivalent.

### Recursive types

Zod

```ts
const baseCategorySchema = z.object({
  name: z.string(),
});

type Category = z.infer<typeof baseCategorySchema> & {
  subcategories: Category[];
};

const categorySchema: z.ZodType<Category> = baseCategorySchema.extend({
  subcategories: z.lazy(() => categorySchema.array()),
});
```

Schema

```ts
const baseCategorySchema = S.Struct({
  name: S.String,
});

type Category = S.Schema.Type<typeof baseCategorySchema> & {
  readonly subcategories: ReadonlyArray<Category>;
};

const categorySchema: S.Schema<Category> = S.Struct({
  ...baseCategorySchema.fields,
  subcategories: S.suspend(() => S.Array(categorySchema)),
});
```

### Promises

No equivalent.

### Instanceof

Zod

```ts
class Test {
  name: string = 'name';
}

const TestSchema = z.instanceof(Test);

const blob: any = 'whatever';
TestSchema.parse(new Test()); // passes
TestSchema.parse(blob); // throws
```

Schema

```ts
class Test {
  name: string = 'name';
}

const TestSchema = S.instanceOf(Test);

const blob: any = 'whatever';

S.decodeUnknownSync(TestSchema)(new Test()); // passes
S.decodeUnknownSync(TestSchema)(blob); // throws
```

### Functions

No equivalent.

### Preprocess

No equivalent.

### Custom schemas

Zod

```ts
z.custom;
```

Schema

```ts
S.declare;
```

### refine / superRefine

Zod

`.refine()` / `.superRefine()` methods

Schema

`S.filter` / `S.transformOrFail` functions

### transform

Zod

`.transform()` method

Schema

`S.transform` function

### describe

Zod

```ts
const documentedString = z
  .string()
  .describe('A useful bit of text, if you know what to do with it.');
documentedString.description; // A useful bit of textâ€¦
```

Schema

```ts
import { AST, Schema as S } from '@effect/schema';

const documentedString = S.String.annotations({
  description: 'A useful bit of text, if you know what to do with it.',
});

console.log(AST.getDescriptionAnnotation(documentedString.ast));
/*
Output:
{
  _id: 'Option',
  _tag: 'Some',
  value: 'A useful bit of text, if you know what to do with it.'
}
*/
```

### nullish

Zod

```ts
const nullishString = z.string().nullish(); // string | null | undefined
```

Schema

```ts
const nullishString = S.NullishOr(S.String); // string | null | undefined
```

### brand

Zod

```ts
const Cat = z.object({ name: z.string() }).brand<'Cat'>();
```

Schema

```ts
const Cat = S.Struct({ name: S.String }).pipe(S.brand('Cat'));
```

### readonly

No equivalent as it's the default behavior.

# API Reference

- [API Reference](https://effect-ts.github.io/effect/docs/schema)

# License

The MIT License (MIT)

# Contributing Guidelines

Thank you for considering contributing to our project! Here are some guidelines to help you get started:

## Reporting Bugs

If you have found a bug, please open an issue on our [issue tracker](https://github.com/Effect-TS/effect/issues) and provide as much detail as possible. This should include:

- A clear and concise description of the problem
- Steps to reproduce the problem
- The expected behavior
- The actual behavior
- Any relevant error messages or logs

## Suggesting Enhancements

If you have an idea for an enhancement or a new feature, please open an issue on our [issue tracker](https://github.com/Effect-TS/effect/issues) and provide as much detail as possible. This should include:

- A clear and concise description of the enhancement or feature
- Any potential benefits or use cases
- Any potential drawbacks or trade-offs

## Pull Requests

We welcome contributions via pull requests! Here are some guidelines to help you get started:

1. Fork the repository and clone it to your local machine.
2. Create a new branch for your changes: `git checkout -b my-new-feature`
3. Ensure you have the required dependencies installed by running: `pnpm install` (assuming pnpm version `8.x`).
4. Make your desired changes and, if applicable, include tests to validate your modifications.
5. Run the following commands to ensure the integrity of your changes:
   - `pnpm check`: Verify that the code compiles.
   - `pnpm test`: Execute the tests.
   - `pnpm circular`: Confirm there are no circular imports.
   - `pnpm lint`: Check for code style adherence (if you happen to encounter any errors during this process, you can add the `--fix` option to automatically fix some of these style issues).
   - `pnpm dtslint`: Run type-level tests.
   - `pnpm docgen`: Update the automatically generated documentation.
6. Create a changeset for your changes: before committing your changes, create a changeset to document the modifications. This helps in tracking and communicating the changes effectively. To create a changeset, run the following command: `pnpm changeset`.
7. Commit your changes: after creating the changeset, commit your changes with a descriptive commit message: `git commit -am 'Add some feature'`.
8. Push your changes to your fork: `git push origin my-new-feature`.
9. Open a pull request against our `main` branch.

### Pull Request Guidelines

- Please make sure your changes are consistent with the project's existing style and conventions.
- Please write clear commit messages and include a summary of your changes in the pull request description.
- Please make sure all tests pass and add new tests as necessary.
- If your change requires documentation, please update the relevant documentation.
- Please be patient! We will do our best to review your pull request as soon as possible.

# Credits

This library was inspired by the following projects:

- [io-ts](https://github.com/gcanti/io-ts)
- [zod](https://github.com/colinhacks/zod)
- [zio-schema](https://github.com/zio/zio-schema)

## License

By contributing to this project, you agree that your contributions will be licensed under the project's [MIT License](./LICENSE).

# README.md

# Effect SQL

A SQL toolkit for Effect.

## Basic example

```ts
import { Config, Effect, pipe, Struct } from 'effect';
import * as Sql from '@effect/sql';
import * as Pg from '@effect/sql-pg';

const SqlLive = Pg.client.layer({
  database: Config.succeed('effect_pg_dev'),
});

const program = Effect.gen(function* (_) {
  const sql = yield* _(Sql.client.Client);

  const people = yield* _(
    sql<{
      readonly id: number;
      readonly name: string;
    }>`SELECT id, name FROM people`,
  );

  yield* _(Effect.log(`Got ${people.length} results!`));
});

pipe(program, Effect.provide(SqlLive), Effect.runPromise);
```

## Migrating from `sqlfx`

If you are coming from the `sqlfx` package, here are some differences that should be noted:

#### All the modules are now re-exported from the top level for easy access

For example, to create the client Layer, instead of:

```ts
import { Config } from 'effect';
import * as Pg from '@sqlfx/pg';

const SqlLive = Pg.makeLayer({
  database: Config.succeed('effect_pg_dev'),
});
```

You now do:

```ts
import { Config } from 'effect';
import * as Pg from '@effect/sql-pg';

const SqlLive = Pg.client.layer({
  database: Config.succeed('effect_pg_dev'),
});
```

#### The default table name for migrations has changed

To continue using your `sqlfx` migrations table, you can setup your migrator Layer as below:

```ts
import { Config } from 'effect';
import * as Pg from '@effect/sql-pg';

const MigratorLive = Layer.provide(
  Pg.migrator.layer({
    loader: Pg.migrator.fromFileSystem(
      fileURLToPath(new URL('migrations', import.meta.url)),
    ),
    table: 'sqlfx_migrations',
  }),
  SqlLive,
);
```

Or you can rename the `sqlfx_migrations` table to `effect_sql_migrations`.

#### The resolver & schema apis have moved

- `sql.resolver` -> `Sql.resolver.ordered`
- `sql.resolverVoid` -> `Sql.resolver.void`
- `sql.resolverId` -> `Sql.resolver.findById`
- `sql.resolverIdMany` -> `Sql.resolver.grouped`
- `sql.resolverSingle*` has been removed in favour of using the `effect/Cache` module with the schema apis
- `sql.schema` -> `Sql.schema.findAll`
- `sql.schemaSingle` -> `Sql.schema.single`
- `sql.schemaSingleOption` -> `Sql.schema.findOne`
- `sql.schemaVoid` -> `Sql.schema.void`

#### The array helper has moved

In `sqlfx` you could pass an array to the `sql(array)` function to pass an list of items to a SQL `IN` clause. Now you have to use `sql.in(array)`.

## INSERT resolver

```ts
import { Effect, pipe } from "effect"
import * as Schema from "@effect/schema/Schema"
import * as Sql from "@effect/sql"

class Person extends Schema.Class<Person>("Person")({
  id: Schema.Number,
  name: Schema.Strin/*  */g,
  createdAt: Schema.DateFromSelf,
  updatedAt: Schema.DateFromSelf
}) {}

const InsertPersonSchema = Schema.Struct(
  Struct.omit(Person.fields, "id", "createdAt", "updatedAt")
)

export const makePersonService = Effect.gen(function* (_) {
  const sql = yield* _(Sql.client.Client)

  const InsertPerson = yield* _(
    Sql.resolver.ordered("InsertPerson", {
      Request: InsertPersonSchema,
      Result: Person,
      execute: (requests) =>
        sql`
        INSERT INTO people
        ${sql.insert(requests)}
        RETURNING people.*
      `
    })
  )
  const insert = InsertPerson.execute

  return { insert }
})
```

## SELECT resolver

```ts
import { Effect, pipe } from 'effect';
import * as Schema from '@effect/schema/Schema';
import * as Sql from '@effect/sql';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String,
  createdAt: Schema.DateFromSelf,
  updatedAt: Schema.DateFromSelf,
}) {}

export const makePersonService = Effect.gen(function* (_) {
  const sql = yield* _(Sql.client.Client);

  const GetById = yield* _(
    Sql.resolver.findById('GetPersonById', {
      Id: Schema.Number,
      Result: Person,
      ResultId: (_) => _.id,
      execute: (ids) => sql`SELECT * FROM people WHERE ${sql.in('id', ids)}`,
    }),
  );

  const getById = (id: number) =>
    Effect.withRequestCaching('on')(GetById.execute(id));

  return { getById };
});
```

## Building queries

### Safe interpolation

```ts
import { Effect } from 'effect';
import * as Sql from '@effect/sql';

export const make = (limit: number) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM people LIMIT ${limit}`;
    // e.g. SELECT * FROM people LIMIT ?
  });
```

### Identifiers

```ts
import { Effect } from 'effect';
import * as Sql from '@effect/sql';

const table = 'people';

export const make = (limit: number) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM ${sql(table)} LIMIT ${limit}`;
    // e.g. SELECT * FROM "people" LIMIT ?
  });
```

### Unsafe interpolation

```ts
import * as Effect from 'effect/Effect';
import * as Sql from '@effect/sql';

type OrderBy = 'id' | 'created_at' | 'updated_at';
type SortOrder = 'ASC' | 'DESC';

export const make = (orderBy: OrderBy, sortOrder: SortOrder) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM people ORDER BY ${sql(orderBy)} ${
      sql.unsafe(sortOrder)
    }`;
    // e.g. SELECT * FROM people ORDER BY `id` ASC
  });
```

### Where clause combinators

#### AND

```ts
import { Effect } from 'effect';
import * as Sql from '@effect/sql';

export const make = (names: string[], cursor: string) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM people WHERE ${
      sql.and([
        sql.in('name', names),
        sql`created_at < ${cursor}`,
      ])
    }`;
    // SELECT * FROM people WHERE ("name" IN (?,?,?) AND created_at < ?)
  });
```

#### OR

```ts
import { Effect } from 'effect';
import * as Sql from '@effect/sql';

export const make = (names: string[], cursor: Date) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM people WHERE ${
      sql.or([
        sql.in('name', names),
        sql`created_at < ${cursor}`,
      ])
    }`;
    // SELECT * FROM people WHERE ("name" IN (?,?,?) OR created_at < ?)
  });
```

#### Mixed

```ts
import { Effect } from 'effect';
import * as Sql from '@effect/sql';

export const make = (names: string[], afterCursor: Date, beforeCursor: Date) =>
  Effect.gen(function* (_) {
    const sql = yield* _(Sql.client.Client);

    const statement = sql`SELECT * FROM people WHERE ${
      sql.or([
        sql.in('name', names),
        sql.and([
          `created_at > ${afterCursor}`,
          `created_at < ${beforeCursor}`,
        ]),
      ])
    }`;
    // SELECT * FROM people WHERE ("name" IN (?,?,?) OR (created_at > ? AND created_at < ?))
  });
```

## Migrations

A `Migrator` module is provided, for running migrations.

Migrations are forward-only, and are written in Typescript as Effect's.

Here is an example migration:

```ts
// src/migrations/0001_add_users.ts

import { Effect } from 'effect';
import * as Sql from '@effect/sql';

export default Effect.flatMap(
  Sql.client.Client,
  (sql) =>
    sql`
    CREATE TABLE users (
      id serial PRIMARY KEY,
      name varchar(255) NOT NULL,
      created_at TIMESTAMP NOT NULL DEFAULT NOW(),
      updated_at TIMESTAMP NOT NULL DEFAULT NOW()
    )
  `,
);
```

To run your migrations:

```ts
// src/main.ts

import { Config, Effect, Layer, pipe } from 'effect';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import * as Sql from '@effect/sql';
import * as Pg from '@effect/sql-pg';
import { fileURLToPath } from 'node:url';

const program = Effect.gen(function* (_) {
  // ...
});

const SqlLive = Pg.client.layer({
  database: Config.succeed('example_database'),
});

const MigratorLive = Pg.migrator
  .layer({
    loader: Sql.migrator.fromFileSystem(
      fileURLToPath(new URL('migrations', import.meta.url)),
    ),
    // Where to put the `_schema.sql` file
    schemaDirectory: 'src/migrations',
  })
  .pipe(Layer.provide(SqlLive));

const EnvLive = Layer.mergeAll(SqlLive, MigratorLive).pipe(
  Layer.provide(NodeContext.layer),
);

pipe(program, Effect.provide(EnvLive), NodeRuntime.runMain);
```

# README.md

# Introduction

Welcome to the documentation for `@effect/typeclass`, **a collection of re-usable typeclasses for the Effect ecosystem**.

The functional abstractions in `@effect/typeclass` can be broadly divided into two categories.

- Abstractions For Concrete Types - These abstractions define properties of concrete types, such as `number` and `string`, as well as ways of combining those values.
- Abstractions For Parameterized Types - These abstractions define properties of parameterized types such as `ReadonlyArray` and `Option` and ways of combining them.

# Concrete Types

## Members and derived functions

Note: members are in bold.

### Bounded

A type class used to name the lower limit and the upper limit of a type.

Extends:

- `Order`

| Name         | Given        | To           |
| ------------ | ------------ | ------------ |
| **maxBound** |              | `A`          |
| **minBound** |              | `A`          |
| reverse      | `Bounded<A>` | `Bounded<A>` |
| clamp        | `A`          | `A`          |

### Monoid

A `Monoid` is a `Semigroup` with an identity. A `Monoid` is a specialization of a
`Semigroup`, so its operation must be associative. Additionally,
`x |> combine(empty) == empty |> combine(x) == x`. For example, if we have `Monoid<String>`,
with `combine` as string concatenation, then `empty = ""`.

Extends:

- `Semigroup`

| Name           | Given                                 | To                            |
| -------------- | ------------------------------------- | ----------------------------- |
| **empty**      |                                       | `A`                           |
| **combineAll** | `Iterable<A>`                         | `A`                           |
| reverse        | `Monoid<A>`                           | `Monoid<A>`                   |
| tuple          | `[Monoid<A>, Monoid<B>, ...]`         | `Monoid<[A, B, ...]>`         |
| struct         | `{ a: Monoid<A>, b: Monoid<B>, ... }` | `Monoid<{ a: A, b: B, ... }>` |
| min            | `Bounded<A>`                          | `Monoid<A>`                   |
| max            | `Bounded<A>`                          | `Monoid<A>`                   |

### Semigroup

A `Semigroup` is any set `A` with an associative operation (`combine`):

`x |> combine(y) |> combine(z) == x |> combine(y |> combine(z))`

| Name            | Given                                       | To                               |
| --------------- | ------------------------------------------- | -------------------------------- |
| **combine**     | `A`, `A`                                    | `A`                              |
| **combineMany** | `A`, `Iterable<A>`                          | `A`                              |
| reverse         | `Semigroup<A>`                              | `Semigroup<A>`                   |
| tuple           | `[Semigroup<A>, Semigroup<B>, ...]`         | `Semigroup<[A, B, ...]>`         |
| struct          | `{ a: Semigroup<A>, b: Semigroup<B>, ... }` | `Semigroup<{ a: A, b: B, ... }>` |
| min             | `Order<A>`                                  | `Semigroup<A>`                   |
| max             | `Order<A>`                                  | `Semigroup<A>`                   |
| constant        | `A`                                         | `Semigroup<A>`                   |
| intercalate     | `A`, `Semigroup<A>`                         | `Semigroup<A>`                   |
| first           |                                             | `Semigroup<A>`                   |
| last            |                                             | `Semigroup<A>`                   |

# Parameterized Types

**Parameterized Types Hierarchy**

```mermaid
flowchart TD
    Alternative --> SemiAlternative
    Alternative --> Coproduct
    Applicative --> Product
    Coproduct --> SemiCoproduct
    SemiAlternative --> Covariant
    SemiAlternative --> SemiCoproduct
    SemiApplicative --> SemiProduct
    SemiApplicative --> Covariant
    Applicative --> SemiApplicative
    Chainable --> FlatMap
    Chainable ---> Covariant
    Monad --> FlatMap
    Monad --> Pointed
    Pointed --> Of
    Pointed --> Covariant
    Product --> SemiProduct
    Product --> Of
    SemiProduct --> Invariant
    Covariant --> Invariant
    SemiCoproduct --> Invariant
```

## Members and derived functions

Note: members are in bold.

### Alternative

Extends:

- `SemiAlternative`
- `Coproduct`

### Applicative

Extends:

- `SemiApplicative`
- `Product`

| Name       | Given       | To             |
| ---------- | ----------- | -------------- |
| liftMonoid | `Monoid<A>` | `Monoid<F<A>>` |

### Bicovariant

A type class of types which give rise to two independent, covariant
functors.

| Name      | Given                            | To         |
| --------- | -------------------------------- | ---------- |
| **bimap** | `F<E1, A>`, `E1 => E2`, `A => B` | `F<E2, B>` |
| mapLeft   | `F<E1, A>`, `E1 => E2`           | `F<E2, A>` |
| map       | `F<A>`, `A => B`                 | `F<B>`     |

### Chainable

Extends:

- `FlatMap`
- `Covariant`

| Name           | Given                               | To                     |
| -------------- | ----------------------------------- | ---------------------- |
| tap            | `F<A>`, `A => F<B>`                 | `F<A>`                 |
| andThenDiscard | `F<A>`, `F<B>`                      | `F<A>`                 |
| bind           | `F<A>`, `name: string`, `A => F<B>` | `F<A & { [name]: B }>` |

### Contravariant

Contravariant functors.

Extends:

- `Invariant`

| Name                 | Given               | To        |
| -------------------- | ------------------- | --------- |
| **contramap**        | `F<A>`, `B => A`    | `F<B>`    |
| contramapComposition | `F<G<A>>`, `A => B` | `F<G<B>>` |
| imap                 | `contramap`         | `imap`    |

### Coproduct

`Coproduct` is a universal monoid which operates on kinds.

This type class is useful when its type parameter `F<_>` has a
structure that can be combined for any particular type, and which
also has a "zero" representation. Thus, `Coproduct` is like a `Monoid`
for kinds (i.e. parametrized types).

A `Coproduct<F>` can produce a `Monoid<F<A>>` for any type `A`.

Here's how to distinguish `Monoid` and `Coproduct`:

- `Monoid<A>` allows `A` values to be combined, and also means there
  is an "empty" `A` value that functions as an identity.

- `Coproduct<F>` allows two `F<A>` values to be combined, for any `A`. It
  also means that for any `A`, there is an "zero" `F<A>` value. The
  combination operation and zero value just depend on the
  structure of `F`, but not on the structure of `A`.

Extends:

- `SemiCoproduct`

| Name             | Given            | To             |
| ---------------- | ---------------- | -------------- |
| **zero**         |                  | `F<A>`         |
| **coproductAll** | `Iterable<F<A>>` | `F<A>`         |
| getMonoid        |                  | `Monoid<F<A>>` |

### Covariant

Covariant functors.

Extends:

- `Invariant`

| Name           | Given               | To        |
| -------------- | ------------------- | --------- |
| **map**        | `F<A>`, `A => B`    | `F<B>`    |
| mapComposition | `F<G<A>>`, `A => B` | `F<G<B>>` |
| imap           | `map`               | `imap`    |
| flap           | `A`, `F<A => B>`    | `F<B>`    |
| as             | `F<A>`, `B`         | `F<B>`    |
| asUnit         | `F<A>`              | `F<void>` |

### Filterable

`Filterable<F>` allows you to `map` and filter out elements simultaneously.

| Name                    | Given                          | To                   |
| ----------------------- | ------------------------------ | -------------------- |
| **partitionMap**        | `F<A>`, `A => Either<B, C>`    | `[F<B>, F<C>]`       |
| **filterMap**           | `F<A>`, `A => Option<B>`       | `F<B>`               |
| compact                 | `F<Option<A>>`                 | `F<A>`               |
| separate                | `F<Either<A, B>>`              | `[F<A>, F<B>]`       |
| filter                  | `F<A>`, `A => boolean`         | `F<A>`               |
| partition               | `F<A>`, `A => boolean`         | `[F<A>, F<A>]`       |
| partitionMapComposition | `F<G<A>>`, `A => Either<B, C>` | `[F<G<B>>, F<G<C>>]` |
| filterMapComposition    | `F<G<A>>`, `A => Option<B>`    | `F<G<B>>`            |

### FlatMap

| Name                | Given                    | To          |
| ------------------- | ------------------------ | ----------- |
| **flatMap**         | `F<A>`, `A => F<B>`      | `F<B>`      |
| flatten             | `F<F<A>>`                | `F<A>`      |
| andThen             | `F<A>`, `F<B>`           | `F<B>`      |
| composeKleisliArrow | `A => F<B>`, `B => F<C>` | `A => F<C>` |

### Foldable

Data structures that can be folded to a summary value.

In the case of a collection (such as `ReadonlyArray`), these
methods will fold together (combine) the values contained in the
collection to produce a single result. Most collection types have
`reduce` methods, which will usually be used by the associated
`Foldable<F>` instance.

| Name                | Given                                     | To                 |
| ------------------- | ----------------------------------------- | ------------------ |
| **reduce**          | `F<A>`, `B`, `(B, A) => B`                | `B`                |
| reduceComposition   | `F<G<A>>`, `B`, `(B, A) => B`             | `B`                |
| reduceRight         | `F<A>`, `B`, `(B, A) => B`                | `B`                |
| foldMap             | `F<A>`, `Monoid<M>`, `A => M`             | `M`                |
| toReadonlyArray     | `F<A>`                                    | `ReadonlyArray<A>` |
| toReadonlyArrayWith | `F<A>`, `A => B`                          | `ReadonlyArray<B>` |
| reduceKind          | `Monad<G>`, `F<A>`, `B`, `(B, A) => G<B>` | `G<B>`             |
| reduceRightKind     | `Monad<G>`, `F<A>`, `B`, `(B, A) => G<B>` | `G<B>`             |
| foldMapKind         | `Coproduct<G>`, `F<A>`, `(A) => G<B>`     | `G<B>`             |

### Invariant

Invariant functors.

| Name            | Given                         | To                 |
| --------------- | ----------------------------- | ------------------ |
| **imap**        | `F<A>`, `A => B`, `B => A`    | `F<B>`             |
| imapComposition | `F<G<A>>`, `A => B`, `B => A` | `F<G<B>>`          |
| bindTo          | `F<A>`, `name: string`        | `F<{ [name]: A }>` |
| tupled          | `F<A>`                        | `F<[A]>`           |

### Monad

Allows composition of dependent effectful functions.

Extends:

- `FlatMap`
- `Pointed`

### Of

| Name          | Given | To        |
| ------------- | ----- | --------- |
| **of**        | `A`   | `F<A>`    |
| ofComposition | `A`   | `F<G<A>>` |
| unit          |       | `F<void>` |
| Do            |       | `F<{}>`   |

### Pointed

Extends:

- `Covariant`
- `Of`

### Product

Extends:

- `SemiProduct`
- `Of`

| Name           | Given                       | To                       |
| -------------- | --------------------------- | ------------------------ |
| **productAll** | `Iterable<F<A>>`            | `F<ReadonlyArray<A>>`    |
| tuple          | `[F<A>, F<B>, ...]`         | `F<[A, B, ...]>`         |
| struct         | `{ a: F<A>, b: F<B>, ... }` | `F<{ a: A, b: B, ... }>` |

### SemiAlternative

Extends:

- `SemiCoproduct`
- `Covariant`

### SemiApplicative

Extends:

- `SemiProduct`
- `Covariant`

| Name           | Given               | To                           |
| -------------- | ------------------- | ---------------------------- |
| liftSemigroup  | `Semigroup<A>`      | `Semigroup<F<A>>`            |
| ap             | `F<A => B>`, `F<A>` | `F<B>`                       |
| andThenDiscard | `F<A>`, `F<B>`      | `F<A>`                       |
| andThen        | `F<A>`, `F<B>`      | `F<B>`                       |
| lift2          | `(A, B) => C`       | `(F<A>, F<B>) => F<C>`       |
| lift3          | `(A, B, C) => D`    | `(F<A>, F<B>, F<C>) => F<D>` |

### SemiCoproduct

`SemiCoproduct` is a universal semigroup which operates on kinds.

This type class is useful when its type parameter `F<_>` has a
structure that can be combined for any particular type. Thus,
`SemiCoproduct` is like a `Semigroup` for kinds (i.e. parametrized
types).

A `SemiCoproduct<F>` can produce a `Semigroup<F<A>>` for any type A.

Here's how to distinguish `Semigroup` and `SemiCoproduct`:

- `Semigroup<A>` allows two `A` values to be combined.

- `SemiCoproduct<F>` allows two `F<A>` values to be combined, for any `A`.
  The combination operation just depends on the structure of `F`,
  but not the structure of `A`.

Extends:

- `Invariant`

| Name              | Given            | To                |
| ----------------- | ---------------- | ----------------- |
| **coproduct**     | `F<A>`, `F<B>`   | `F<A \| B>`       |
| **coproductMany** | `Iterable<F<A>>` | `F<A>`            |
| getSemigroup      |                  | `Semigroup<F<A>>` |
| coproductEither   | `F<A>`, `F<B>`   | `F<Either<A, B>>` |

### SemiProduct

Extends:

- `Invariant`

| Name                   | Given                          | To                               |
| ---------------------- | ------------------------------ | -------------------------------- |
| **product**            | `F<A>`, `F<B>`                 | `F<[A, B]>`                      |
| **productMany**        | `F<A>`, `Iterable<F<A>>`       | `F<[A, ...ReadonlyArray<A>]>`    |
| productComposition     | `F<G<A>>`, `F<G<B>>`           | `F<G<[A, B]>>`                   |
| productManyComposition | `F<G<A>>`, `Iterable<F<G<A>>>` | `F<G<[A, ...ReadonlyArray<A>]>>` |
| nonEmptyTuple          | `[F<A>, F<B>, ...]`            | `F<[A, B, ...]>`                 |
| nonEmptyStruct         | `{ a: F<A>, b: F<B>, ... }`    | `F<{ a: A, b: B, ... }>`         |
| andThenBind            | `F<A>`, `name: string`, `F<B>` | `F<A & { [name]: B }>`           |
| productFlatten         | `F<A>`, `F<B>`                 | `F<[...A, B]>`                   |

### Traversable

Traversal over a structure with an effect.

| Name                | Given                                    | To           |
| ------------------- | ---------------------------------------- | ------------ |
| **traverse**        | `Applicative<F>`, `T<A>`, `A => F<B>`    | `F<T<B>>`    |
| traverseComposition | `Applicative<F>`, `T<G<A>>`, `A => F<B>` | `F<T<G<B>>>` |
| sequence            | `Applicative<F>`, `T<F<A>>`              | `F<T<A>>`    |
| traverseTap         | `Applicative<F>`, `T<A>`, `A => F<B>`    | `F<T<A>>`    |

### TraversableFilterable

`TraversableFilterable`, also known as `Witherable`, represents list-like structures
that can essentially have a `traverse` and a `filter` applied as a single
combined operation (`traverseFilter`).

| Name                     | Given                                            | To                |
| ------------------------ | ------------------------------------------------ | ----------------- |
| **traversePartitionMap** | `Applicative<F>`, `T<A>`, `A => F<Either<B, C>>` | `F<[T<B>, T<C>]>` |
| **traverseFilterMap**    | `Applicative<F>`, `T<A>`, `A => F<Option<B>>`    | `F<T<B>>`         |
| traverseFilter           | `Applicative<F>`, `T<A>`, `A => F<boolean>`      | `F<T<A>>`         |
| traversePartition        | `Applicative<F>`, `T<A>`, `A => F<boolean>`      | `F<[T<A>, T<A>]>` |

---

Adapted from:

- [cats](https://github.com/typelevel/cats)
- [zio-prelude](https://github.com/zio/zio-prelude)
- [zio-cheatsheet](https://github.com/ghostdogpr/zio-cheatsheet)

# README.md

# Introduction

Welcome to your guide on testing Effect applications using `vitest` and the `@effect/vitest` package! `@effect/vitest` is designed to help simplify running Effect-based tests through `vitest`.

In the guide below, we will first start by setting up the required dependencies. Then, we will dive into a few examples of how to use `@effect/vitest` to create some Effect-based test cases.

# Requirements

First, install [`vitest`](https://vitest.dev/guide/) (version `1.6.0` or newer)

```sh
pnpm add -D vitest
```

Next, install the `@effect/vitest` package which facilitates running Effect-based tests through `vitest`.

```sh
pnpm add -D @effect/vitest
```

# Overview

The main entry point is the following import:

```ts
import { it } from '@effect/vitest';
```

This import enhances the standard `it` function from `vitest` with several powerful features, including:

| Feature         | Description                                                                                            |
| --------------- | ------------------------------------------------------------------------------------------------------ |
| `it.effect`     | Automatically injects a `TestContext` (e.g., `TestClock`) when running a test.                         |
| `it.live`       | Runs the test with the live Effect environment.                                                        |
| `it.scoped`     | Allows running an Effect program that requires a `Scope`.                                              |
| `it.scopedLive` | Combines the features of `scoped` and `live`, using a live Effect environment that requires a `Scope`. |
| `it.flakyTest`  | Facilitates the execution of tests that might occasionally fail.                                       |

# Writing Tests with `it.effect`

Here's how to use `it.effect` to write your tests:

```ts
import { it } from "@effect/vitest"

it.effect("test name", () => EffectContainingAssertions, timeout: number | TestOptions = 5_000)
```

When using `it.effect`, the `TestContext` is automatically injected, which allows tests to have access to services designed to facilitate testing (such as the [`TestClock`](#using-the-testclock)).

## Testing Successful Operations

Let's create a test for a function that divides two numbers but fails if the divisor is zero:

```ts
import { it } from '@effect/vitest';
import { Effect } from 'effect';
import { expect } from 'vitest';

function divide(a: number, b: number) {
  if (b === 0) return Effect.fail('Cannot divide by zero');
  return Effect.succeed(a / b);
}

it.effect('test success', () =>
  Effect.gen(function* () {
    const result = yield* divide(4, 2);
    expect(result).toBe(2);
  }));
```

## Testing Successes and Failures as `Exit`

To test both success and failure scenarios, convert the outcomes into an `Exit` object using `Effect.exit`:

```ts
import { it } from '@effect/vitest';
import { Effect, Exit } from 'effect';
import { expect } from 'vitest';

function divide(a: number, b: number) {
  if (b === 0) return Effect.fail('Cannot divide by zero');
  return Effect.succeed(a / b);
}

it.effect('test success as Exit', () =>
  Effect.gen(function* () {
    const result = yield* divide(4, 2).pipe(Effect.exit);
    expect(result).toStrictEqual(Exit.succeed(2));
  }));

it.effect('test failure as Exit', () =>
  Effect.gen(function* () {
    const result = yield* divide(4, 0).pipe(Effect.exit);
    expect(result).toStrictEqual(Exit.fail('Cannot divide by zero'));
  }));
```

## Using the TestClock

When using `it.effect`, a `TestContext` is provided to your program which provides access to several services designed to facilitate testing. One such service is the `[TestClock`](https://effect.website/docs/guides/testing/testclock) which is designed to simulate the passage of time.

**Note**: To utilize the default, non-testing services in your tests you can use `it.live`.

Below, you'll find examples illustrating different ways to use time in your tests:

1. **Using `it.live` to show the current time:** This mode uses the real-time clock of your system, reflecting the actual current time.

2. **Using `it.effect` with no adjustments:** By default, this test starts the clock at a time of `0`, effectively simulating a starting point without any elapsed time.

3. **Using `it.effect` and adjusting time forward:** Here, we advance the clock by 1000 milliseconds to test scenarios that depend on the passing of time.

```ts
import { it } from '@effect/vitest';
import { Clock, Effect, TestClock } from 'effect';

const logNow = Effect.gen(function* () {
  const now = yield* Clock.currentTimeMillis;
  console.log(now);
});

it.live('runs the test with the live Effect environment', () =>
  Effect.gen(function* () {
    yield* logNow; // prints the actual time
  }));

it.effect('run the test with the test environment', () =>
  Effect.gen(function* () {
    yield* logNow; // prints 0
  }));

it.effect('run the test with the test environment and the time adjusted', () =>
  Effect.gen(function* () {
    yield* TestClock.adjust('1000 millis');
    yield* logNow; // prints 1000
  }));
```

## Skipping Tests

You can skip a test using `it.effect.skip`, which is useful when you want to temporarily disable a test without deleting any code.

```ts
it.effect.skip('test failure as Exit', () =>
  Effect.gen(function* () {
    const result = yield* divide(4, 0).pipe(Effect.exit);
    expect(result).toStrictEqual(Exit.fail('Cannot divide by zero'));
  }));
```

## Running a Single Test

To run only a specific test and ignore all others, use `it.effect.only`. This is helpful during development to focus on a single test case.

```ts
it.effect.only('test failure as Exit', () =>
  Effect.gen(function* () {
    const result = yield* divide(4, 0).pipe(Effect.exit);
    expect(result).toStrictEqual(Exit.fail('Cannot divide by zero'));
  }));
```

# Writing Tests with `it.scoped`

The `it.scoped` method allows you to run tests that involve Effect programs requiring a `Scope`. A `Scope` is essential when your Effect needs to manage resources that must be acquired before the test and released after it completes. This ensures that all resources are properly cleaned up, preventing leaks and ensuring test isolation.

Hereâ€™s a simple example to demonstrate how `it.scoped` can be used in your tests:

```ts
import { it } from '@effect/vitest';
import { Console, Effect } from 'effect';

// Simulate acquiring and releasing a resource with console logging
const acquire = Console.log('acquire resource');
const release = Console.log('release resource');

// Define a resource that needs to be managed
const resource = Effect.acquireRelease(acquire, () => release);

// Incorrect usage: This will result in a type error because it lacks a scope
it.effect('run with scope', () =>
  Effect.gen(function* () {
    yield* resource;
  }));

// Correct usage: Using 'it.scoped' to properly manage the scope
it.scoped('run with scope', () =>
  Effect.gen(function* () {
    yield* resource;
  }));
```

# Writing Tests with `it.flakyTest`

`it.flakyTest` is a function from the `@effect/vitest` package designed to handle tests that might not succeed on the first try. These tests are often called "flaky" tests because their outcome can vary (e.g., due to timing issues, external dependencies, or randomness). `it.flakyTest` allows these tests to be retried until they succeed or until a specified timeout period expires.

Here's how you can use `it.flakyTest` in your test suite:

First, letâ€™s set up a basic test scenario that could potentially fail randomly:

```ts
import { it } from '@effect/vitest';
import { Effect, Random } from 'effect';

// Define a flaky test effect
const flaky = Effect.gen(function* () {
  const random = yield* Random.nextBoolean;
  if (random) {
    return yield* Effect.fail('Failed due to randomness');
  }
});

// Standard test, which may fail intermittently
it.effect('possibly failing test', () => flaky);
```

To address the flakiness, we apply `it.flakyTest` which will retry the test until it succeeds or the specified timeout is reached:

```ts
// Retrying the flaky test with a timeout
it.effect('retrying until success or timeout', () =>
  it.flakyTest(flaky, '5 seconds'));
```

# examples Examples

## examples

### 0001_create_people.ts

```typescript
import * as Sql from '@effect/sql-mssql';
import { Effect } from 'effect';

export default Effect.flatMap(
  Sql.client.MssqlClient,
  (sql) =>
    sql`CREATE TABLE people (
      id INT IDENTITY(1,1) PRIMARY KEY,
      name NVARCHAR(255) NOT NULL,
      created_at DATETIME NOT NULL DEFAULT GETDATE()
    )`,
);
```

### migrations.ts

```typescript
import * as DevTools from '@effect/experimental/DevTools';
import { NodeFileSystem } from '@effect/platform-node';
import * as Mssql from '@effect/sql-mssql';
import {
  Config,
  Effect,
  Layer,
  Logger,
  LogLevel,
  Redacted,
  String,
} from 'effect';
import { pipe } from 'effect/Function';
import { fileURLToPath } from 'node:url';

const peopleProcedure = pipe(
  Mssql.procedure.make('people_proc'),
  Mssql.procedure.param<string>()('name', Mssql.types.VarChar),
  Mssql.procedure.withRows<{ readonly id: number; readonly name: string }>(),
  Mssql.procedure.compile,
);

const program = Effect.gen(function* (_) {
  const sql = yield* _(Mssql.client.MssqlClient);

  yield* _(
    sql`
      CREATE OR ALTER PROC people_proc
        @name VARCHAR(255)
      AS
      BEGIN
        SELECT * FROM people WHERE name = @name
      END
    `,
  );

  // Insert
  const [inserted] = yield* _(
    sql`INSERT INTO ${sql('people')} ${
      sql.insert({
        name: 'Tim',
        createdAt: new Date(),
      }).returning('*')
    }`,
  );
  console.log(inserted);

  console.log(
    yield* _(
      Effect.all(
        [
          sql`SELECT TOP(3) * FROM ${sql('people')}`,
          sql`SELECT TOP(3) * FROM ${sql('people')}`.values,
          sql`SELECT TOP(3) * FROM ${sql('people')}`.withoutTransform,
          sql.call(peopleProcedure({ name: 'Tim' })),
        ],
        { concurrency: 'unbounded' },
      ),
    ),
  );

  console.log(
    yield* sql`
      UPDATE people
      SET name = data.name
      ${
      sql.updateValues([{ ...inserted, name: 'New name' }], 'data').returning(
        '*',
      )
    }
      WHERE people.id = data.id
    `,
  );

  console.log(
    yield* _(
      sql`SELECT TOP(3) * FROM ${sql('people')}`,
      Effect.zipRight(
        Effect.catchAllCause(
          sql.withTransaction(Effect.die('fail')),
          (_) => Effect.void,
        ),
      ),
      Effect.zipRight(
        sql.withTransaction(sql`SELECT TOP(3) * FROM ${sql('people')}`),
      ),
      sql.withTransaction,
    ),
  );
});

const SqlLive = Mssql.migrator.layer({
  loader: Mssql.migrator.fromFileSystem(
    fileURLToPath(new URL('./migrations', import.meta.url)),
  ),
}).pipe(
  Layer.provideMerge(
    Mssql.client.layer({
      database: Config.succeed('msdb'),
      server: Config.succeed('localhost'),
      username: Config.succeed('sa'),
      password: Config.succeed(Redacted.make('Sq1Fx_password')),
      transformQueryNames: Config.succeed(String.camelToSnake),
      transformResultNames: Config.succeed(String.snakeToCamel),
    }),
  ),
  Layer.provide(NodeFileSystem.layer),
  Layer.provide(DevTools.layer()),
  Layer.provide(Logger.minimumLogLevel(LogLevel.All)),
);

pipe(
  program,
  Effect.provide(SqlLive),
  Effect.tapErrorCause(Effect.logError),
  Effect.runFork,
);
```

# examples Examples

## examples

### resolver.ts

```typescript
import * as Redis from '@effect/experimental/Persistence/Redis';
import { persisted } from '@effect/experimental/RequestResolver';
import * as TimeToLive from '@effect/experimental/TimeToLive';
import { runMain } from '@effect/platform-node/NodeRuntime';
import { Schema } from '@effect/schema';
import { Array, Effect, Exit, PrimaryKey, RequestResolver } from 'effect';

class User extends Schema.Class<User>('User')({
  id: Schema.Number,
  name: Schema.String,
}) {}

class GetUserById extends Schema.TaggedRequest<GetUserById>()(
  'GetUserById',
  Schema.String,
  User,
  {
    id: Schema.Number,
  },
) {
  [PrimaryKey.symbol]() {
    return `GetUserById:${this.id}`;
  }
  [TimeToLive.symbol](exit: Exit.Exit<User, string>) {
    return Exit.isSuccess(exit) ? 30000 : 0;
  }
}

Effect.gen(function* (_) {
  const resolver = yield* _(
    RequestResolver.fromEffectTagged<GetUserById>()({
      GetUserById: (reqs) => {
        console.log('uncached requests', reqs.length);
        return Effect.forEach(
          reqs,
          (req) => Effect.succeed(new User({ id: req.id, name: 'John' })),
        );
      },
    }),
    persisted('users'),
  );

  const users = yield* _(
    Effect.forEach(
      Array.range(1, 5),
      (id) => Effect.request(new GetUserById({ id }), resolver),
      {
        batching: true,
      },
    ),
  );

  console.log(users);
}).pipe(
  Effect.scoped,
  Effect.provide(Redis.layerResult({})),
  runMain,
);
```

### dev-tools.ts

```typescript
import * as DevTools from '@effect/experimental/DevTools';
import { runMain } from '@effect/platform-node/NodeRuntime';
import { Effect } from 'effect';

const program = Effect.log('Hello!').pipe(
  Effect.delay(2000),
  Effect.withSpan('Hi', { attributes: { foo: 'bar' } }),
  Effect.forever,
);

program.pipe(
  Effect.provide(DevTools.layer()),
  runMain,
);
```

### machine.ts

```typescript
import { Machine } from '@effect/experimental';
import { runMain } from '@effect/platform-node/NodeRuntime';
import { Data, Effect, List, Request, Schedule } from 'effect';

class SendError extends Data.TaggedError('SendError')<{
  readonly email: string;
  readonly reason: string;
}> {}

class SendEmail extends Request.TaggedClass('SendEmail')<
  void,
  SendError,
  {
    readonly email: string;
    readonly message: string;
  }
> {}

class ProcessEmail extends Request.TaggedClass('ProcessEmail')<
  void,
  never,
  {}
> {}

class Shutdown extends Request.TaggedClass('Shutdown')<
  void,
  never,
  {}
> {}

const mailer = Machine.makeWith<List.List<SendEmail>>()((_, previous) =>
  Effect.gen(function* (_) {
    const ctx = yield* _(Machine.MachineContext);
    const state = previous ?? List.empty();

    if (List.isCons(state)) {
      yield* _(
        ctx.unsafeSend(new ProcessEmail()),
        Effect.replicateEffect(List.size(state)),
      );
    }

    return Machine.procedures.make(state).pipe(
      Machine.procedures.addPrivate<ProcessEmail>()(
        'ProcessEmail',
        ({ state }) =>
          Effect.gen(function* (_) {
            if (List.isNil(state)) {
              return [void 0, state];
            }
            const req = state.head;
            yield* _(
              Effect.log(`Sending email to ${req.email}`),
              Effect.delay(500),
            );
            return [void 0, state.tail];
          }),
      ),
      Machine.procedures.add<SendEmail>()(
        'SendEmail',
        (ctx) =>
          ctx.send(new ProcessEmail()).pipe(
            Effect.as([void 0, List.append(ctx.state, ctx.request)]),
          ),
      ),
      Machine.procedures.add<Shutdown>()(
        'Shutdown',
        () =>
          Effect.log('Shutting down').pipe(
            Effect.zipRight(Effect.interrupt),
          ),
      ),
    );
  })
).pipe(
  Machine.retry(Schedule.forever),
);

Effect.gen(function* (_) {
  const actor = yield* _(Machine.boot(mailer));
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(actor.send(new Shutdown()));
}).pipe(
  Effect.scoped,
  runMain,
);
```

### serializable-machine.ts

```typescript
import { Machine } from '@effect/experimental';
import { runMain } from '@effect/platform-node/NodeRuntime';
import { Schema } from '@effect/schema';
import { Effect, List, Schedule } from 'effect';

class SendError extends Schema.TaggedError<SendError>()(
  'SendError',
  {
    email: Schema.String,
    reason: Schema.String,
  },
) {}

class SendEmail extends Schema.TaggedRequest<SendEmail>()(
  'SendEmail',
  SendError,
  Schema.Void,
  {
    email: Schema.String,
    message: Schema.String,
  },
) {}

class ProcessEmail extends Schema.TaggedRequest<ProcessEmail>()(
  'ProcessEmail',
  Schema.Never,
  Schema.Void,
  {},
) {}

class Shutdown extends Schema.TaggedRequest<Shutdown>()(
  'Shutdown',
  Schema.Never,
  Schema.Void,
  {},
) {}

const mailer = Machine.makeSerializable({
  state: Schema.List(SendEmail),
}, (_, previous) =>
  Effect.gen(function* (_) {
    const ctx = yield* _(Machine.MachineContext);
    const state = previous ?? List.empty();

    if (List.isCons(state)) {
      yield* _(
        ctx.unsafeSend(new ProcessEmail()),
        Effect.replicateEffect(List.size(state)),
      );
    }

    return Machine.serializable.make(state).pipe(
      Machine.serializable.addPrivate(ProcessEmail, ({ state }) =>
        Effect.gen(function* (_) {
          if (List.isNil(state)) {
            return [void 0, state];
          }
          const req = state.head;
          yield* _(
            Effect.log(`Sending email to ${req.email}`),
            Effect.delay(500),
          );
          return [void 0, state.tail];
        })),
      Machine.serializable.add(SendEmail, (ctx) =>
        ctx.send(new ProcessEmail()).pipe(
          Effect.as([void 0, List.append(ctx.state, ctx.request)]),
        )),
      Machine.serializable.add(Shutdown, () =>
        Effect.log('Shutting down').pipe(
          Effect.zipRight(Effect.interrupt),
        )),
    );
  })).pipe(
    Machine.retry(Schedule.forever),
  );

Effect.gen(function* (_) {
  const actor = yield* _(Machine.boot(mailer));
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(
    actor.send(
      new SendEmail({ email: 'test@example.com', message: 'Hello, World!' }),
    ),
  );
  yield* _(actor.send(new Shutdown()));
}).pipe(
  Effect.scoped,
  runMain,
);
```

# examples Examples

## examples

### resolver.ts

```typescript
import * as DevTools from '@effect/experimental/DevTools';
import * as Schema from '@effect/schema/Schema';
import * as Sql from '@effect/sql';
import * as Pg from '@effect/sql-pg';
import { Config, Effect, Layer, String } from 'effect';

class Person extends Schema.Class<Person>('Person')({
  id: Schema.Number,
  name: Schema.String,
  createdAt: Schema.DateFromSelf,
}) {}

const InsertPersonSchema = Schema.Struct(Person.fields).pipe(
  Schema.omit('id', 'createdAt'),
);

const program = Effect.gen(function* (_) {
  const sql = yield* Sql.client.Client;

  yield* sql`TRUNCATE TABLE people RESTART IDENTITY CASCADE`;

  const Insert = yield* Sql.resolver.ordered('InsertPerson', {
    Request: InsertPersonSchema,
    Result: Person,
    execute: (requests) =>
      sql`INSERT INTO people ${sql.insert(requests)} RETURNING people.*`,
  });

  const GetById = yield* Sql.resolver.findById('GetPersonById', {
    Id: Schema.Number,
    Result: Person,
    ResultId: (result) => result.id,
    execute: (ids) => sql`SELECT * FROM people WHERE id IN ${sql.in(ids)}`,
  });

  const GetByName = yield* Sql.resolver.grouped('GetPersonByName', {
    Request: Schema.String,
    RequestGroupKey: (_) => _,
    Result: Person,
    ResultGroupKey: (_) => _.name,
    execute: (ids) =>
      sql<{}>`SELECT * FROM people WHERE name IN ${sql.in(ids)}`,
  });

  const inserted = yield* sql.withTransaction(
    Effect.all(
      [
        Insert.execute({ name: 'John Doe' }),
        Insert.execute({ name: 'Joe Bloggs' }),
      ],
      { batching: true },
    ),
  );

  yield* sql`SELECT * FROM people`.pipe(
    Effect.andThen(Effect.fail('boom')),
    sql.withTransaction,
    Effect.ignore,
  );

  console.log(
    yield* Effect.all(
      [GetById.execute(inserted[0].id), GetById.execute(inserted[1].id)],
      { batching: true },
    ),
  );

  console.log(
    yield* Effect.forEach(
      ['John Doe', 'Joe Bloggs', 'John Doe'],
      (id) => GetByName.execute(id),
      { batching: true },
    ),
  );
});

const PgLive = Pg.client.layer({
  database: Config.succeed('effect_pg_dev'),
  transformQueryNames: Config.succeed(String.camelToSnake),
  transformResultNames: Config.succeed(String.snakeToCamel),
});

program.pipe(
  Effect.provide(PgLive.pipe(
    Layer.provide(DevTools.layer()),
  )),
  Effect.tapErrorCause(Effect.logError),
  Effect.runFork,
);
```

# examples Examples

## examples

### http-router.ts

```typescript
import { NodeHttpServer, NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpServer';
import * as Schema from '@effect/schema/Schema';
import { Effect, Layer, Schedule, Stream } from 'effect';
import { createServer } from 'node:http';

const ServerLive = NodeHttpServer.server.layer(() => createServer(), {
  port: 3000,
});

const HttpLive = Http.router.empty.pipe(
  Http.router.get(
    '/',
    Effect.map(
      Http.request.ServerRequest,
      (req) => Http.response.text(req.url),
    ),
  ),
  Http.router.get(
    '/healthz',
    Http.response.text('ok').pipe(
      Http.middleware.withLoggerDisabled,
    ),
  ),
  Http.router.post(
    '/upload',
    Effect.gen(function* (_) {
      const data = yield* _(Http.request.schemaBodyForm(Schema.Struct({
        files: Http.multipart.FilesSchema,
      })));
      console.log('got files', data.files);
      return Http.response.empty();
    }).pipe(Effect.scoped),
  ),
  Http.router.get(
    '/ws',
    Stream.fromSchedule(Schedule.spaced(1000)).pipe(
      Stream.map(JSON.stringify),
      Stream.encodeText,
      Stream.pipeThroughChannel(Http.request.upgradeChannel()),
      Stream.decodeText(),
      Stream.runForEach((_) => Effect.log(_)),
      Effect.annotateLogs('ws', 'recv'),
      Effect.as(Http.response.empty()),
    ),
  ),
  Http.server.serve(Http.middleware.logger),
  Http.server.withLogAddress,
  Layer.provide(ServerLive),
);

NodeRuntime.runMain(Layer.launch(HttpLive));
```

### fs-watch.ts

```typescript
import { FileSystem } from '@effect/platform';
import { NodeFileSystem, NodeRuntime } from '@effect/platform-node';
import * as ParcelWatcher from '@effect/platform-node/NodeFileSystem/ParcelWatcher';
import { Console, Effect, Layer, Stream } from 'effect';

const EnvLive = NodeFileSystem.layer.pipe(Layer.provide(ParcelWatcher.layer));

Effect.gen(function* (_) {
  const fs = yield* _(FileSystem.FileSystem);

  yield* _(
    fs.watch('src'),
    Stream.runForEach(Console.log),
  );
}).pipe(Effect.provide(EnvLive), NodeRuntime.runMain);
```

### http-server.ts

```typescript
import { NodeHttpServer, NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpServer';
import { Effect, Layer } from 'effect';
import { createServer } from 'node:http';

const ServerLive = NodeHttpServer.server.layer(() => createServer(), {
  port: 3000,
});

const HttpLive = Http.server.serve(
  Effect.succeed(Http.response.text('Hello World')),
)
  .pipe(
    Layer.provide(ServerLive),
  );

NodeRuntime.runMain(Layer.launch(HttpLive));
```

### terminal.ts

```typescript
import { Terminal } from '@effect/platform';
import { NodeRuntime, NodeTerminal } from '@effect/platform-node';
import { Console, Effect } from 'effect';

const program = Effect.gen(function* (_) {
  const terminal = yield* _(Terminal.Terminal);

  const line1 = yield* _(terminal.readLine);
  yield* _(Console.log(`First line: ${line1}`));

  const line2 = yield* _(terminal.readLine);
  yield* _(Console.log(`Second line: ${line2}`));

  const line3 = yield* _(terminal.readLine);
  yield* _(Console.log(`Third line: ${line3}`));
});

const MainLive = NodeTerminal.layer;

program.pipe(
  Effect.provide(MainLive),
  NodeRuntime.runMain,
);
```

### range.ts

```typescript
import { WorkerRunner } from '@effect/platform';
import { NodeRuntime, NodeWorkerRunner } from '@effect/platform-node';
import { Effect, Layer, Stream } from 'effect';

const WorkerLive = Effect.gen(function* (_) {
  yield* _(WorkerRunner.make((n: number) => Stream.range(0, n)));
  yield* _(Effect.log('worker started'));
  yield* _(Effect.addFinalizer(() => Effect.log('worker closed')));
}).pipe(Layer.scopedDiscard, Layer.provide(NodeWorkerRunner.layer));

NodeRuntime.runMain(Layer.launch(WorkerLive));
```

### http-client.ts

```typescript
import { runMain } from '@effect/platform-node/NodeRuntime';
import * as Http from '@effect/platform/HttpClient';
import type * as ParseResult from '@effect/schema/ParseResult';
import * as Schema from '@effect/schema/Schema';
import * as Context from 'effect/Context';
import * as Effect from 'effect/Effect';
import * as Layer from 'effect/Layer';

class Todo extends Schema.Class<Todo>('Todo')({
  userId: Schema.Number,
  id: Schema.Number,
  title: Schema.String,
  completed: Schema.Boolean,
}) {
  static decodeResponse = Http.response.schemaBodyJsonScoped(Todo);
}

const TodoWithoutId = Schema.Struct(Todo.fields).pipe(Schema.omit('id'));
type TodoWithoutId = Schema.Schema.Type<typeof TodoWithoutId>;

interface TodoService {
  readonly create: (
    _: TodoWithoutId,
  ) => Effect.Effect<
    Todo,
    Http.error.HttpClientError | Http.body.BodyError | ParseResult.ParseError
  >;
}
const TodoService = Context.GenericTag<TodoService>(
  '@effect/platform-node/examples/TodoService',
);

const makeTodoService = Effect.gen(function* (_) {
  const defaultClient = yield* _(Http.client.Client);
  const clientWithBaseUrl = defaultClient.pipe(
    Http.client.filterStatusOk,
    Http.client.mapRequest(
      Http.request.prependUrl('https://jsonplaceholder.typicode.com'),
    ),
  );

  const addTodoWithoutIdBody = Http.request.schemaBody(TodoWithoutId);
  const create = (todo: TodoWithoutId) =>
    addTodoWithoutIdBody(
      Http.request.post('/todos'),
      todo,
    ).pipe(
      Effect.flatMap(clientWithBaseUrl),
      Todo.decodeResponse,
    );

  return TodoService.of({ create });
});

const TodoServiceLive = Layer.effect(TodoService, makeTodoService).pipe(
  Layer.provide(Http.client.layer),
);

Effect.flatMap(
  TodoService,
  (todos) => todos.create({ userId: 1, title: 'test', completed: false }),
).pipe(
  Effect.tap(Effect.log),
  Effect.provide(TodoServiceLive),
  runMain,
);
```

### worker.ts

```typescript
import { Worker } from '@effect/platform';
import { NodeRuntime, NodeWorker } from '@effect/platform-node';
import { Console, Context, Effect, Layer, Stream } from 'effect';
import * as WT from 'node:worker_threads';

interface MyWorkerPool {
  readonly _: unique symbol;
}
const Pool = Context.GenericTag<
  MyWorkerPool,
  Worker.WorkerPool<number, never, number>
>('@app/MyWorkerPool');
const PoolLive = Worker.makePoolLayer(Pool, { size: 3 }).pipe(
  Layer.provide(
    NodeWorker.layer(() => new WT.Worker('./examples/worker/range.ts')),
  ),
);

Effect.gen(function* (_) {
  const pool = yield* _(Pool);
  yield* _(
    Effect.all([
      pool.execute(5).pipe(
        Stream.runForEach((_) => Console.log('worker 1', _)),
      ),
      pool.execute(10).pipe(
        Stream.runForEach((_) => Console.log('worker 2', _)),
      ),
      pool.execute(15).pipe(
        Stream.runForEach((_) => Console.log('worker 3', _)),
      ),
    ], { concurrency: 'inherit' }),
  );
}).pipe(Effect.provide(PoolLive), NodeRuntime.runMain);
```

# examples Examples

## examples

### otlp-exporter.ts

```typescript
import * as NodeSdk from '@effect/opentelemetry/NodeSdk';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';
import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';
import { seconds } from 'effect/Duration';
import * as Effect from 'effect/Effect';
import { pipe } from 'effect/Function';

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: {
    serviceName: 'example',
  },
  spanProcessor: new BatchSpanProcessor(
    new OTLPTraceExporter({
      url: 'http://localhost:4318/v1/traces',
    }),
  ),
}));

const program = pipe(
  Effect.log('Hello'),
  Effect.withSpan('c'),
  Effect.withSpan('b'),
  Effect.withSpan('a'),
  Effect.repeatN(50),
  Effect.annotateSpans('working', true),
);

pipe(
  Effect.delay(program, seconds(1)),
  Effect.provide(NodeSdkLive),
  Effect.catchAllCause(Effect.logError),
  Effect.runFork,
);
```

### index.ts

```typescript
import * as NodeSdk from '@effect/opentelemetry/NodeSdk';
import {
  ConsoleSpanExporter,
  SimpleSpanProcessor,
} from '@opentelemetry/sdk-trace-base';
import * as Effect from 'effect/Effect';
import { pipe } from 'effect/Function';

const NodeSdkLive = NodeSdk.layer(() => ({
  resource: {
    serviceName: 'example',
  },
  spanProcessor: new SimpleSpanProcessor(new ConsoleSpanExporter()),
}));

const program = pipe(
  Effect.log('Hello'),
  Effect.withSpan('c'),
  Effect.withSpan('b'),
  Effect.withSpan('a'),
);

pipe(
  program,
  Effect.provide(NodeSdkLive),
  Effect.catchAllCause(Effect.logError),
  Effect.runFork,
);
```

### metrics.ts

```typescript
import * as NodeSdk from '@effect/opentelemetry/NodeSdk';
import { PrometheusExporter } from '@opentelemetry/exporter-prometheus';
import { millis, seconds } from 'effect/Duration';
import * as Effect from 'effect/Effect';
import { pipe } from 'effect/Function';
import * as Metric from 'effect/Metric';

const counter = Metric.counter('count', {
  description: 'An example counter',
});

const incrementCounter = pipe(
  Metric.increment(counter),
  Effect.delay(seconds(1)),
  Effect.forever,
);

const timer = Metric.timer('timer');

const timerLoop = pipe(
  Effect.randomWith((_) => _.nextRange(1, 1000)),
  Effect.flatMap((_) => Effect.sleep(millis(_))),
  Metric.trackDuration(timer),
  Effect.forever,
);

const freq = Metric.frequency('freq');
const labels = [
  'cake',
  'pie',
  'cookie',
  'brownie',
  'muffin',
];

const freqLoop = Effect.randomWith((_) => _.nextIntBetween(0, labels.length))
  .pipe(
    Effect.flatMap((_) => Metric.update(freq, labels[_])),
    Effect.zipRight(Effect.sleep('1 seconds')),
    Effect.forever,
  );

const summary = Metric.summary({
  name: 'summary',
  maxAge: '1 days',
  maxSize: 1000,
  error: 0.01,
  quantiles: [0.1, 0.5, 0.9],
});

const summaryLoop = Effect.randomWith((_) => _.nextRange(100, 1000)).pipe(
  Metric.trackSuccess(summary),
  Effect.zipRight(Effect.sleep('10 millis')),
  Effect.forever,
);

const spawner = Effect.randomWith((_) => _.nextIntBetween(500, 1500)).pipe(
  Effect.flatMap((_) => Effect.fork(Effect.sleep(_))),
  Effect.flatMap((_) => _.await),
  Effect.forever,
);

const program = Effect.gen(function* (_) {
  yield* _(Effect.fork(incrementCounter));
  yield* _(Effect.fork(timerLoop));
  yield* _(Effect.fork(freqLoop));
  yield* _(Effect.fork(summaryLoop));
  yield* _(Effect.fork(spawner));
});

const MetricsLive = NodeSdk.layer(() => ({
  resource: {
    serviceName: 'example',
  },
  metricReader: new PrometheusExporter({ port: 9464 }),
}));

pipe(
  program,
  Effect.awaitAllChildren,
  Effect.provide(MetricsLive),
  Effect.catchAllCause(Effect.logError),
  Effect.runFork,
);
```

# examples Examples

## examples

### main.ts

```typescript
import * as Doc from '@effect/printer/Doc';
import * as Array from 'effect/Array';
import { pipe } from 'effect/Function';

const prettyTypes = (types: ReadonlyArray<string>): Doc.Doc<never> => {
  const symbolDocuments = pipe(
    Array.makeBy(types.length - 1, () => Doc.text('->')),
    Array.prepend(Doc.text('::')),
  );
  const typeDocuments = types.map(Doc.text);
  const documents = Array.zipWith(
    symbolDocuments,
    typeDocuments,
    (left, right) => Doc.catWithSpace(left, right),
  );
  return Doc.align(Doc.seps(documents));
};

const prettyDeclaration = (
  name: string,
  types: ReadonlyArray<string>,
): Doc.Doc<never> => Doc.catWithSpace(Doc.text(name), prettyTypes(types));

const doc: Doc.Doc<never> = prettyDeclaration('example', [
  'Int',
  'Bool',
  'Char',
  'IO ()',
]);

console.log(Doc.render(doc, {
  style: 'pretty',
  options: { lineWidth: 20 },
}));
```

# examples Examples

## examples

### naval-fate.ts

```typescript
import { Args, Command, Options } from '@effect/cli';
import {
  NodeContext,
  NodeKeyValueStore,
  NodeRuntime,
} from '@effect/platform-node';
import * as Console from 'effect/Console';
import * as Effect from 'effect/Effect';
import * as Layer from 'effect/Layer';
import * as NavalFateStore from './naval-fate/store.js';

const { createShip, moveShip, removeMine, setMine, shoot } = Effect
  .serviceFunctions(
    NavalFateStore.NavalFateStore,
  );

// naval_fate [-h | --help] [--version]
// naval_fate ship new <name>...
// naval_fate ship move [--speed=<kn>] <name> <x> <y>
// naval_fate ship shoot <x> <y>
// naval_fate mine set <x> <y> [--moored]
// naval_fate mine remove <x> <y> [--moored]

const nameArg = Args.text({ name: 'name' }).pipe(
  Args.withDescription('The name of the ship'),
);
const xArg = Args.integer({ name: 'x' }).pipe(
  Args.withDescription('The x coordinate'),
);
const yArg = Args.integer({ name: 'y' }).pipe(
  Args.withDescription('The y coordinate'),
);
const coordinatesArg = { x: xArg, y: yArg };
const nameAndCoordinatesArg = { name: nameArg, ...coordinatesArg };

const mooredOption = Options.boolean('moored').pipe(
  Options.withDescription('Whether the mine is moored (anchored) or drifting'),
);
const speedOption = Options.integer('speed').pipe(
  Options.withDescription('Speed in knots'),
  Options.withDefault(10),
);

const shipCommand = Command.make('ship', {
  verbose: Options.boolean('verbose'),
}).pipe(Command.withDescription('Controls a ship in Naval Fate'));

const newShipCommand = Command.make('new', {
  name: nameArg,
}, ({ name }) =>
  Effect.gen(function* (_) {
    const { verbose } = yield* _(shipCommand);
    yield* _(createShip(name));
    yield* _(Console.log(`Created ship: '${name}'`));
    if (verbose) {
      yield* _(Console.log(`Verbose mode enabled`));
    }
  })).pipe(Command.withDescription('Create a new ship'));

const moveShipCommand = Command.make('move', {
  ...nameAndCoordinatesArg,
  speed: speedOption,
}, ({ name, speed, x, y }) =>
  Effect.gen(function* (_) {
    yield* _(moveShip(name, x, y));
    yield* _(
      Console.log(
        `Moving ship '${name}' to coordinates (${x}, ${y}) at ${speed} knots`,
      ),
    );
  })).pipe(Command.withDescription('Move a ship'));

const shootShipCommand = Command.make(
  'shoot',
  { ...coordinatesArg },
  ({ x, y }) =>
    Effect.gen(function* (_) {
      yield* _(shoot(x, y));
      yield* _(Console.log(`Shot cannons at coordinates (${x}, ${y})`));
    }),
).pipe(Command.withDescription('Shoot from a ship'));

const mineCommand = Command.make('mine').pipe(
  Command.withDescription('Controls mines in Naval Fate'),
);

const setMineCommand = Command.make('set', {
  ...coordinatesArg,
  moored: mooredOption,
}, ({ moored, x, y }) =>
  Effect.gen(function* (_) {
    yield* _(setMine(x, y));
    yield* _(
      Console.log(
        `Set ${
          moored ? 'moored' : 'drifting'
        } mine at coordinates (${x}, ${y})`,
      ),
    );
  })).pipe(Command.withDescription('Set a mine at specific coordinates'));

const removeMineCommand = Command.make('remove', {
  ...coordinatesArg,
}, ({ x, y }) =>
  Effect.gen(function* (_) {
    yield* _(removeMine(x, y));
    yield* _(
      Console.log(`Removing mine at coordinates (${x}, ${y}), if present`),
    );
  })).pipe(Command.withDescription('Remove a mine at specific coordinates'));

const command = Command.make('naval_fate').pipe(
  Command.withDescription(
    'An implementation of the Naval Fate CLI application.',
  ),
  Command.withSubcommands([
    shipCommand.pipe(Command.withSubcommands([
      newShipCommand,
      moveShipCommand,
      shootShipCommand,
    ])),
    mineCommand.pipe(Command.withSubcommands([
      setMineCommand,
      removeMineCommand,
    ])),
  ]),
);

const MainLayer = NavalFateStore.layer.pipe(
  Layer.provide(NodeKeyValueStore.layerFileSystem('naval-fate-store')),
  Layer.merge(NodeContext.layer),
);

const cli = Command.run(command, {
  name: 'Naval Fate',
  version: '1.0.0',
});

Effect.suspend(() => cli(process.argv)).pipe(
  Effect.provide(MainLayer),
  Effect.tapErrorCause(Effect.logError),
  NodeRuntime.runMain,
);
```

### prompt.ts

```typescript
import * as Command from '@effect/cli/Command';
import * as Prompt from '@effect/cli/Prompt';
import * as NodeContext from '@effect/platform-node/NodeContext';
import * as Runtime from '@effect/platform-node/NodeRuntime';
import * as Effect from 'effect/Effect';

const colorPrompt = Prompt.select({
  message: 'Pick your favorite color',
  choices: [
    {
      title: 'Red',
      value: '#ff0000',
      description: 'This option has a description',
    },
    { title: 'Green', value: '#00ff00', description: 'So does this one' },
    { title: 'Blue', value: '#0000ff', disabled: true },
  ],
});

const confirmPrompt = Prompt.confirm({
  message: 'Can you please confirm?',
});

const datePrompt = Prompt.date({
  message: "What's your birth day?",
  dateMask:
    '"Year:" YYYY, "Month:" MM, "Day:" DD \\\\\\\\||// \\Hour: HH, \\Minute: mm, "Seconds:" ss',
  validate: (date) =>
    date.getTime() > Date.now()
      ? Effect.fail("Your birth day can't be in the future")
      : Effect.succeed(date),
});

const numberPrompt = Prompt.float({
  message: `What is your favorite number?`,
  validate: (n) =>
    n > 0 ? Effect.succeed(n) : Effect.fail('must be greater than 0'),
});

const passwordPrompt = Prompt.password({
  message: 'Enter your password: ',
  validate: (value) =>
    value.length === 0
      ? Effect.fail('Password cannot be empty')
      : Effect.succeed(value),
});

const togglePrompt = Prompt.toggle({
  message: 'Yes or no?',
  active: 'yes',
  inactive: 'no',
});

const prompt = Prompt.all([
  colorPrompt,
  confirmPrompt,
  datePrompt,
  numberPrompt,
  passwordPrompt,
  togglePrompt,
]);

const command = Command.prompt('favorites', prompt, Effect.log);

const cli = Command.run(command, {
  name: 'Prompt Examples',
  version: '0.0.1',
});

Effect.suspend(() => cli(process.argv)).pipe(
  Effect.provide(NodeContext.layer),
  Runtime.runMain,
);
```

### domain.ts

```typescript
import * as Schema from '@effect/schema/Schema';
import * as Data from 'effect/Data';

/**
 * An error that occurs when attempting to create a Naval Fate ship that already
 * exists.
 */
export class ShipExistsError extends Data.TaggedError('ShipExistsError')<{
  readonly name: string;
}> {
  toString(): string {
    return `ShipExistsError: ship with name '${this.name}' already exists`;
  }
}

/**
 * An error that occurs when attempting to move a Naval Fate ship that does not
 * exist.
 */
export class ShipNotFoundError extends Data.TaggedError('ShipNotFoundError')<{
  readonly name: string;
  readonly x: number;
  readonly y: number;
}> {
  toString(): string {
    return `ShipNotFoundError: ship with name '${this.name}' does not exist`;
  }
}

/**
 * An error that occurs when attempting to move a Naval Fate ship to coordinates
 * already occupied by another ship.
 */
export class CoordinatesOccupiedError
  extends Data.TaggedError('CoordinatesOccupiedError')<{
    readonly name: string;
    readonly x: number;
    readonly y: number;
  }> {
  toString(): string {
    return `CoordinatesOccupiedError: ship with name '${this.name}' already occupies coordinates (${this.x}, ${this.y})`;
  }
}

/**
 * Represents a Naval Fate ship.
 */
export class Ship extends Schema.Class<Ship>('Ship')({
  name: Schema.String,
  x: Schema.Number,
  y: Schema.Number,
  status: Schema.Literal('sailing', 'destroyed'),
}) {
  static readonly create = (name: string) =>
    new Ship({ name, x: 0, y: 0, status: 'sailing' });

  hasCoordinates(x: number, y: number): boolean {
    return this.x === x && this.y === y;
  }

  move(x: number, y: number): Ship {
    return new Ship({ name: this.name, x, y, status: this.status });
  }

  destroy(): Ship {
    return new Ship({
      name: this.name,
      x: this.x,
      y: this.y,
      status: 'destroyed',
    });
  }
}

/**
 * Represents a Naval Fate mine.
 */
export class Mine extends Schema.Class<Mine>('Mine')({
  x: Schema.Number,
  y: Schema.Number,
}) {
  static readonly create = (x: number, y: number) => new Mine({ x, y });

  hasCoordinates(x: number, y: number): boolean {
    return this.x === x && this.y === y;
  }
}
```

### store.ts

```typescript
import * as KeyValueStore from '@effect/platform/KeyValueStore';
import * as Schema from '@effect/schema/Schema';
import * as Arr from 'effect/Array';
import * as Context from 'effect/Context';
import * as Effect from 'effect/Effect';
import { pipe } from 'effect/Function';
import * as Layer from 'effect/Layer';
import * as Option from 'effect/Option';
import {
  CoordinatesOccupiedError,
  Mine,
  Ship,
  ShipExistsError,
  ShipNotFoundError,
} from './domain.js';

/**
 * Represents the storage layer for the Naval Fate command-line application.
 */
export interface NavalFateStore {
  createShip(name: string): Effect.Effect<Ship, ShipExistsError>;
  moveShip(
    name: string,
    x: number,
    y: number,
  ): Effect.Effect<Ship, CoordinatesOccupiedError | ShipNotFoundError>;
  shoot(x: number, y: number): Effect.Effect<void>;
  setMine(x: number, y: number): Effect.Effect<void>;
  removeMine(x: number, y: number): Effect.Effect<void>;
}

export const NavalFateStore = Context.GenericTag<NavalFateStore>(
  'NavalFateStore',
);

export const make = Effect.gen(function* ($) {
  const shipsStore = yield* $(Effect.map(
    KeyValueStore.KeyValueStore,
    (store) =>
      store.forSchema(Schema.ReadonlyMap({ key: Schema.String, value: Ship })),
  ));
  const minesStore = yield* $(Effect.map(
    KeyValueStore.KeyValueStore,
    (store) => store.forSchema(Schema.Array(Mine)),
  ));

  const getShips = shipsStore.get('ships').pipe(
    Effect.map(Option.getOrElse<ReadonlyMap<string, Ship>>(() => new Map())),
    Effect.orDie,
  );
  const getMines = minesStore.get('mines').pipe(
    Effect.map(Option.getOrElse<ReadonlyArray<Mine>>(() => [])),
    Effect.orDie,
  );
  const setShips = (ships: ReadonlyMap<string, Ship>) =>
    shipsStore.set('ships', ships).pipe(Effect.orDie);
  const setMines = (mines: ReadonlyArray<Mine>) =>
    minesStore.set('mines', mines).pipe(Effect.orDie);

  const createShip: NavalFateStore['createShip'] = (name) =>
    Effect.gen(function* ($) {
      const oldShips = yield* $(getShips);
      const foundShip = Option.fromNullable(oldShips.get(name));
      if (Option.isSome(foundShip)) {
        return yield* $(Effect.fail(new ShipExistsError({ name })));
      }
      const ship = Ship.create(name);
      const newShips = new Map(oldShips).set(name, ship);
      yield* $(setShips(newShips));
      return ship;
    });

  const moveShip: NavalFateStore['moveShip'] = (name, x, y) =>
    Effect.gen(function* ($) {
      const oldShips = yield* $(getShips);
      const foundShip = Option.fromNullable(oldShips.get(name));
      if (Option.isNone(foundShip)) {
        return yield* $(Effect.fail(new ShipNotFoundError({ name, x, y })));
      }
      const shipAtCoords = pipe(
        Arr.fromIterable(oldShips.values()),
        Arr.findFirst((ship) => ship.hasCoordinates(x, y)),
      );
      if (Option.isSome(shipAtCoords)) {
        return yield* $(Effect.fail(
          new CoordinatesOccupiedError({ name: shipAtCoords.value.name, x, y }),
        ));
      }
      const mines = yield* $(getMines);
      const mineAtCoords = Arr.findFirst(
        mines,
        (mine) => mine.hasCoordinates(x, y),
      );
      const ship = Option.isSome(mineAtCoords)
        ? foundShip.value.move(x, y).destroy()
        : foundShip.value.move(x, y);
      const newShips = new Map(oldShips).set(name, ship);
      yield* $(setShips(newShips));
      return ship;
    });

  const shoot: NavalFateStore['shoot'] = (x, y) =>
    Effect.gen(function* ($) {
      const oldShips = yield* $(getShips);
      const shipAtCoords = pipe(
        Arr.fromIterable(oldShips.values()),
        Arr.findFirst((ship) => ship.hasCoordinates(x, y)),
      );
      if (Option.isSome(shipAtCoords)) {
        const ship = shipAtCoords.value.destroy();
        const newShips = new Map(oldShips).set(ship.name, ship);
        yield* $(setShips(newShips));
      }
    });

  const setMine: NavalFateStore['setMine'] = (x, y) =>
    Effect.gen(function* ($) {
      const mines = yield* $(getMines);
      const mineAtCoords = Arr.findFirst(
        mines,
        (mine) => mine.hasCoordinates(x, y),
      );
      if (Option.isNone(mineAtCoords)) {
        const mine = Mine.create(x, y);
        const newMines = Arr.append(mines, mine);
        yield* $(setMines(newMines));
      }
    });

  const removeMine: NavalFateStore['removeMine'] = (x, y) =>
    Effect.gen(function* ($) {
      const mines = yield* $(getMines);
      const mineAtCoords = Arr.findFirstIndex(
        mines,
        (mine) => mine.hasCoordinates(x, y),
      );
      if (Option.isSome(mineAtCoords)) {
        const newMines = Arr.remove(mines, mineAtCoords.value);
        yield* $(setMines(newMines));
      }
    });

  return NavalFateStore.of({
    createShip,
    moveShip,
    shoot,
    setMine,
    removeMine,
  });
});

export const layer = Layer.effect(NavalFateStore, make);
```

### minigit.ts

```typescript
import { Args, Command, Options } from '@effect/cli';
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Array, Config, ConfigProvider, Console, Effect, Option } from 'effect';

// minigit [--version] [-h | --help] [-c <name>=<value>]
const configs = Options.keyValueMap('c').pipe(Options.optional);
const minigit = Command.make(
  'minigit',
  { configs },
  ({ configs }) =>
    Option.match(configs, {
      onNone: () => Console.log("Running 'minigit'"),
      onSome: (configs) => {
        const keyValuePairs = Array.fromIterable(configs)
          .map(([key, value]) => `${key}=${value}`)
          .join(', ');
        return Console.log(
          `Running 'minigit' with the following configs: ${keyValuePairs}`,
        );
      },
    }),
);

// minigit add   [-v | --verbose] [--] [<pathspec>...]
const pathspec = Args.text({ name: 'pathspec' }).pipe(Args.repeated);
const verbose = Options.boolean('verbose').pipe(
  Options.withAlias('v'),
  Options.withFallbackConfig(Config.boolean('VERBOSE')),
);
const minigitAdd = Command.make(
  'add',
  { pathspec, verbose },
  ({ pathspec, verbose }) => {
    const paths = Array.match(pathspec, {
      onEmpty: () => '',
      onNonEmpty: (paths) => ` ${Array.join(paths, ' ')}`,
    });
    return Console.log(
      `Running 'minigit add${paths}' with '--verbose ${verbose}'`,
    );
  },
);

// minigit clone [--depth <depth>] [--] <repository> [<directory>]
const repository = Args.text({ name: 'repository' });
const directory = Args.directory().pipe(Args.optional);
const depth = Options.integer('depth').pipe(
  Options.withFallbackConfig(Config.integer('DEPTH')),
  Options.optional,
);
const minigitClone = Command.make(
  'clone',
  { repository, directory, depth },
  (subcommandConfig) =>
    Effect.flatMap(minigit, (parentConfig) => {
      const depth = Option.map(subcommandConfig.depth, (depth) =>
        `--depth ${depth}`);
      const repository = Option.some(subcommandConfig.repository);
      const optionsAndArgs = Array.getSomes([
        depth,
        repository,
        subcommandConfig.directory,
      ]);
      const configs = Option.match(parentConfig.configs, {
        onNone: () =>
          '',
        onSome: (map) =>
          Array.fromIterable(map).map(([key, value]) => `${key}=${value}`).join(
            ', ',
          ),
      });
      return Console.log(
        "Running 'minigit clone' with the following options and arguments: " +
          `'${Array.join(optionsAndArgs, ', ')}'\n` +
          `and the following configuration parameters: ${configs}`,
      );
    }),
);

const command = minigit.pipe(
  Command.withSubcommands([minigitAdd, minigitClone]),
);

const cli = Command.run(command, {
  name: 'Minigit Distributed Version Control',
  version: 'v1.0.0',
});

Effect.suspend(() => cli(process.argv)).pipe(
  Effect.withConfigProvider(
    ConfigProvider.nested(ConfigProvider.fromEnv(), 'GIT'),
  ),
  Effect.provide(NodeContext.layer),
  NodeRuntime.runMain,
);
```

# examples Examples

## examples

### schema.ts

```typescript
import * as Rpc from '@effect/rpc/Rpc';
import * as S from '@effect/schema/Schema';
import { pipe } from 'effect/Function';

export const UserId = pipe(S.Number, S.int(), S.brand('UserId'));
export type UserId = S.Schema.Type<typeof UserId>;

export class User extends S.Class<User>('User')({
  id: UserId,
  name: S.String,
}) {}

export class GetUserIds
  extends Rpc.StreamRequest<GetUserIds>()('GetUserIds', S.Never, UserId, {}) {}
export class GetUser
  extends S.TaggedRequest<GetUser>()('GetUser', S.Never, User, {
    id: UserId,
  }) {}
```

### router.ts

```typescript
import { NodeHttpServer, NodeRuntime } from '@effect/platform-node';
import * as Http from '@effect/platform/HttpServer';
import { Router, Rpc } from '@effect/rpc';
import { HttpRouter } from '@effect/rpc-http';
import { Array, Effect, Layer, Stream } from 'effect';
import { createServer } from 'http';
import { GetUser, GetUserIds, User, UserId } from './schema.js';

// Implement the RPC server router
const router = Router.make(
  Rpc.stream(
    GetUserIds,
    () => Stream.fromIterable(Array.makeBy(1000, UserId.make)),
  ),
  Rpc.effect(
    GetUser,
    ({ id }) => Effect.succeed(new User({ id, name: 'John Doe' })),
  ),
);

export type UserRouter = typeof router;

// Create the http server
const HttpLive = Http.router.empty.pipe(
  Http.router.post('/rpc', HttpRouter.toHttpApp(router)),
  Http.server.serve(Http.middleware.logger),
  Http.server.withLogAddress,
  Layer.provide(NodeHttpServer.server.layer(createServer, { port: 3000 })),
);

Layer.launch(HttpLive).pipe(
  NodeRuntime.runMain,
);
```

### client.ts

```typescript
import * as Http from '@effect/platform/HttpClient';
import { Resolver } from '@effect/rpc';
import { HttpResolver } from '@effect/rpc-http';
import { Console, Effect, Stream } from 'effect';
import type { UserRouter } from './router.js';
import { GetUser, GetUserIds } from './schema.js';

// Create the client
const client = HttpResolver.make<UserRouter>(
  Http.client.fetchOk.pipe(
    Http.client.mapRequest(
      Http.request.prependUrl('http://localhost:3000/rpc'),
    ),
  ),
).pipe(Resolver.toClient);

// Use the client
client(new GetUserIds()).pipe(
  Stream.runCollect,
  Effect.flatMap(
    Effect.forEach((id) => client(new GetUser({ id })), { batching: true }),
  ),
  Effect.tap(Console.log),
  Effect.runFork,
);
```

# examples Examples

## examples

### http-router.ts

```typescript
import { BunHttpServer, BunRuntime } from '@effect/platform-bun';
import * as Http from '@effect/platform/HttpServer';
import { Schema } from '@effect/schema';
import { Effect, Layer, Schedule, Stream } from 'effect';

const ServerLive = BunHttpServer.server.layer({ port: 3000 });

const HttpLive = Http.router.empty.pipe(
  Http.router.get(
    '/',
    Effect.map(
      Http.request.ServerRequest,
      (req) => Http.response.text(req.url),
    ),
  ),
  Http.router.get('/package', Http.response.file('./package.json')),
  Http.router.get(
    '/sleep',
    Effect.as(Effect.sleep('10 seconds'), Http.response.empty()),
  ),
  Http.router.post(
    '/upload',
    Effect.gen(function* (_) {
      const data = yield* _(Http.request.schemaBodyForm(Schema.Struct({
        files: Http.multipart.FilesSchema,
      })));
      console.log('got files', data.files);
      return Http.response.empty();
    }),
  ),
  Http.router.get(
    '/ws',
    Stream.fromSchedule(Schedule.spaced(1000)).pipe(
      Stream.map(JSON.stringify),
      Stream.pipeThroughChannel(Http.request.upgradeChannel()),
      Stream.decodeText(),
      Stream.runForEach((_) => Effect.log(_)),
      Effect.annotateLogs('ws', 'recv'),
      Effect.as(Http.response.empty()),
    ),
  ),
  Http.server.serve(Http.middleware.logger),
  Http.server.withLogAddress,
  Layer.provide(ServerLive),
);

BunRuntime.runMain(Layer.launch(HttpLive));
```

### http-server.ts

```typescript
import { BunHttpServer, BunRuntime } from '@effect/platform-bun';
import * as Http from '@effect/platform/HttpServer';
import { Effect, Layer } from 'effect';

const HttpLive = Http.server.serve(
  Effect.succeed(Http.response.text('Hello World')),
).pipe(
  Layer.provide(BunHttpServer.server.layer({ port: 3000 })),
);

BunRuntime.runMain(Layer.launch(HttpLive));
```

### range.ts

```typescript
import { BunRuntime, BunWorkerRunner } from '@effect/platform-bun';
import * as Runner from '@effect/platform/WorkerRunner';
import { Effect, Layer, Stream } from 'effect';

const WorkerLive = Effect.gen(function* (_) {
  yield* _(Runner.make((n: number) => Stream.range(0, n)));
  yield* _(Effect.log('worker started'));
  yield* _(Effect.addFinalizer(() => Effect.log('worker closed')));
}).pipe(Layer.scopedDiscard, Layer.provide(BunWorkerRunner.layer));

BunRuntime.runMain(Layer.launch(WorkerLive));
```

### http-client.ts

```typescript
import { BunRuntime } from '@effect/platform-bun';
import * as Http from '@effect/platform/HttpClient';
import type * as ParseResult from '@effect/schema/ParseResult';
import * as Schema from '@effect/schema/Schema';
import { Context, Effect, Layer } from 'effect';

class Todo extends Schema.Class<Todo>('Todo')({
  userId: Schema.Number,
  id: Schema.Number,
  title: Schema.String,
  completed: Schema.Boolean,
}) {}

const TodoWithoutId = Schema.Struct(Todo.fields).pipe(Schema.omit('id'));
type TodoWithoutId = Schema.Schema.Type<typeof TodoWithoutId>;

interface TodoService {
  readonly create: (
    _: TodoWithoutId,
  ) => Effect.Effect<
    Todo,
    Http.error.HttpClientError | Http.body.BodyError | ParseResult.ParseError
  >;
}
const TodoService = Context.GenericTag<TodoService>(
  '@effect/platform-bun/examples/TodoService',
);

const makeTodoService = Effect.gen(function* (_) {
  const defaultClient = yield* _(Http.client.Client);
  const clientWithBaseUrl = defaultClient.pipe(
    Http.client.filterStatusOk,
    Http.client.mapRequest(
      Http.request.prependUrl('https://jsonplaceholder.typicode.com'),
    ),
  );

  const addTodoWithoutIdBody = Http.request.schemaBody(TodoWithoutId);
  const create = (todo: TodoWithoutId) =>
    addTodoWithoutIdBody(
      Http.request.post('/todos'),
      todo,
    ).pipe(
      Effect.flatMap(clientWithBaseUrl),
      Http.response.schemaBodyJsonScoped(Todo),
    );

  return TodoService.of({ create });
});

const TodoServiceLive = Layer.effect(TodoService, makeTodoService).pipe(
  Layer.provide(Http.client.layer),
);

Effect.flatMap(
  TodoService,
  (todos) => todos.create({ userId: 1, title: 'test', completed: false }),
).pipe(
  Effect.tap(Effect.log),
  Effect.provide(TodoServiceLive),
  BunRuntime.runMain,
);
```

### worker.ts

```typescript
import { Worker } from '@effect/platform';
import { BunRuntime, BunWorker } from '@effect/platform-bun';
import { Console, Context, Effect, Layer, Stream } from 'effect';
import * as OS from 'node:os';

class MyWorkerPool extends Context.Tag('@app/MyWorkerPool')<
  MyWorkerPool,
  Worker.WorkerPool<number, never, number>
>() {}

const PoolLive = Worker.makePoolLayer(MyWorkerPool, {
  size: OS.availableParallelism(),
}).pipe(
  Layer.provide(
    BunWorker.layer(() =>
      new globalThis.Worker(`${__dirname}/worker/range.ts`)
    ),
  ),
);

Effect.gen(function* () {
  const pool = yield* MyWorkerPool;
  yield* Effect.all([
    pool.execute(5).pipe(
      Stream.runForEach((_) => Console.log('worker 1', _)),
    ),
    pool.execute(10).pipe(
      Stream.runForEach((_) => Console.log('worker 2', _)),
    ),
    pool.execute(15).pipe(
      Stream.runForEach((_) => Console.log('worker 3', _)),
    ),
  ], { concurrency: 'inherit' });
}).pipe(Effect.provide(PoolLive), BunRuntime.runMain);
```

# examples Examples

## examples

### sqlite.ts

```typescript
import * as Sql from '@effect/sql';
import * as SqliteDrizzle from '@effect/sql-drizzle/Sqlite';
import * as Sqlite from '@effect/sql-sqlite-node';
import * as D from 'drizzle-orm/sqlite-core';
import { Config, Effect, Layer } from 'effect';

// setup

const SqlLive = Sqlite.client.layer({
  filename: Config.succeed('test.db'),
});
const DrizzleLive = SqliteDrizzle.layer.pipe(
  Layer.provide(SqlLive),
);
const DatabaseLive = Layer.mergeAll(SqlLive, DrizzleLive);

// usage

const users = D.sqliteTable('users', {
  id: D.integer('id').primaryKey(),
  name: D.text('name'),
});

Effect.gen(function* () {
  const sql = yield* Sql.client.Client;
  const db = yield* SqliteDrizzle.SqliteDrizzle;
  yield* sql`CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT)`;
  yield* db.delete(users);
  yield* db.insert(users).values({ id: 1, name: 'Alice' });
  const results = yield* db.select().from(users);
  console.log(results);
}).pipe(
  Effect.provide(DatabaseLive),
  Effect.runPromise,
);
```

# examples Examples

## examples

### main.ts

```typescript
import * as Ansi from '@effect/printer-ansi/Ansi';
import * as Doc from '@effect/printer-ansi/AnsiDoc';

const doc = Doc.hsep([
  Doc.text('red'),
  Doc.align(Doc.vsep([
    Doc.hsep([
      Doc.text('blue+u'),
      Doc.text('bold').pipe(Doc.annotate(Ansi.bold)),
      Doc.text('blue+u'),
    ]).pipe(Doc.annotate(Ansi.combine(Ansi.blue, Ansi.underlined))),
    Doc.text('red'),
  ])),
]).pipe(Doc.annotate(Ansi.red));

console.log(Doc.render(doc, { style: 'pretty' }));
```

# examples Examples

## examples

### statement-transform.ts

```typescript
import * as DevTools from '@effect/experimental/DevTools';
import * as Sql from '@effect/sql';
import * as Mysql from '@effect/sql-mysql2';
import {
  Config,
  Effect,
  FiberRef,
  FiberRefs,
  Layer,
  Option,
  Redacted,
  String,
} from 'effect';

const currentResourceName = FiberRef.unsafeMake('');

const SqlTracingLive = Sql.statement.setTransformer((prev, sql, refs, span) => {
  const [query, params] = prev.compile();
  return sql.unsafe(
    `/* ${
      JSON.stringify({
        trace_id: span.traceId,
        span_id: span.spanId,
        resource_name: Option.getOrUndefined(
          FiberRefs.get(refs, currentResourceName),
        ),
      })
    } */ ${query}`,
    params,
  );
});

const EnvLive = Mysql.client.layer({
  database: Config.succeed('effect_dev'),
  username: Config.succeed('effect'),
  password: Config.succeed(Redacted.make('password')),
  transformQueryNames: Config.succeed(String.camelToSnake),
  transformResultNames: Config.succeed(String.snakeToCamel),
}).pipe(
  Layer.provide(SqlTracingLive),
  Layer.provide(DevTools.layer()),
);

const program = Effect.gen(function* (_) {
  const sql = yield* _(Sql.client.Client);
  yield* _(
    sql`SELECT * FROM people`,
    Effect.replicateEffect(50),
    sql.withTransaction,
    Effect.locally(currentResourceName, 'GET /people'),
  );
});

program.pipe(
  Effect.provide(EnvLive),
  Effect.tapErrorCause(Effect.logError),
  Effect.runFork,
);
```

# examples Examples

## examples

### Client.test.ts

```typescript
import { BunFileSystem } from '@effect/platform-bun';
import { FileSystem } from '@effect/platform/FileSystem';
import * as Sqlite from '@effect/sql-sqlite-bun';
import { describe, expect, test } from 'bun:test';
import { Effect } from 'effect';

const makeClient = Effect.gen(function* (_) {
  const fs = yield* _(FileSystem);
  const dir = yield* _(fs.makeTempDirectoryScoped());
  return yield* _(Sqlite.client.make({
    filename: dir + '/test.db',
  }));
}).pipe(Effect.provide(BunFileSystem.layer));

describe('Client', () => {
  test('works', () =>
    Effect.gen(function* (_) {
      const sql = yield* _(makeClient);
      yield* _(sql`CREATE TABLE test (id INTEGER PRIMARY KEY, name TEXT)`);
      yield* _(sql`INSERT INTO test (name) VALUES ('hello')`);
      let rows = yield* _(sql`SELECT * FROM test`);
      expect(rows).toEqual([{ id: 1, name: 'hello' }]);
      yield* _(
        sql`INSERT INTO test (name) VALUES ('world')`,
        sql.withTransaction,
      );
      rows = yield* _(sql`SELECT * FROM test`);
      expect(rows).toEqual([
        { id: 1, name: 'hello' },
        { id: 2, name: 'world' },
      ]);
    }).pipe(Effect.scoped, Effect.runPromise));
});
```

# examples Examples

## examples

### keyValueStore.ts

```typescript
import * as KeyValueStore from '@effect/platform/KeyValueStore';
import * as Effect from 'effect/Effect';

const program = KeyValueStore.KeyValueStore.pipe(
  Effect.flatMap((kv) => kv.set('foo', 'bar')),
  Effect.provide(KeyValueStore.layerMemory),
);

Effect.runPromise(program);
```

# effect-http

# examples Examples

## examples

### example.ts

```typescript
console.log('WIP');
```

# examples Examples

## examples

### _utils.ts

```typescript
import * as fs from 'node:fs';

import { Data, Effect, Layer, Logger, LogLevel, pipe } from 'effect';
import { PrettyLogger } from 'effect-log';

export class FileNotFoundError extends Data.TaggedError('FileNotFoundError')<{
  filename: string;
}> {}

export const readFile = (filename: string) =>
  Effect.async<string, FileNotFoundError>((cb) =>
    fs.readFile(filename, { encoding: 'utf8' }, (error, content) => {
      if (error !== null) {
        cb(Effect.fail(new FileNotFoundError({ filename })));
      } else {
        cb(Effect.succeed(content));
      }
    })
  );

export const debugLogger = pipe(
  PrettyLogger.layer(),
  Layer.merge(Logger.minimumLogLevel(LogLevel.All)),
);
```

### example-server.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, ExampleServer, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const Response = Schema.Struct({
  name: Schema.String,
  value: Schema.Number,
});

const api = pipe(
  Api.make({
    servers: ['http://localhost:3000', { description: 'hello', url: '/api/' }],
  }),
  Api.addEndpoint(
    Api.get('test', '/test').pipe(Api.setResponseBody(Response)),
  ),
);

pipe(
  ExampleServer.make(api),
  RouterBuilder.build,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### pattern-example.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make({ title: 'My awesome pets API', version: '1.0.0' }),
  Api.addEndpoint(
    Api.get('test', '/test').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestQuery(Schema.Struct({ value: Schema.String })),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'test',
    ({ query }) => Effect.succeed(`test ${query.value}`),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 4000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### scoped-resources.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Context, Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

interface Resource {
  value: number;
}

const ResourceService = Context.GenericTag<Resource>(
  '@services/ResourceService',
);

const resource = Effect.acquireRelease(
  pipe(
    Effect.log('Acquried resource'),
    Effect.as({ value: 2 } satisfies Resource),
  ),
  () => Effect.log('Released resource'),
);

const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.get('test', '/test').pipe(Api.setResponseBody(Schema.String)),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'test',
    () => Effect.map(ResourceService, ({ value }) => `There you go: ${value}`),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provideServiceEffect(ResourceService, resource),
  Effect.scoped,
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### handle-raw.ts

```typescript
import { HttpServer } from '@effect/platform';
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { Api, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { PrettyLogger } from 'effect-log';

export const api = Api.make({ title: 'Example API' }).pipe(
  Api.addEndpoint(
    Api.get('root', '/').pipe(
      Api.setResponseBody(Schema.String),
      Api.setResponseHeaders(Schema.Struct({ 'Content-Type': Schema.String })),
    ),
  ),
);

export const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handleRaw(
    'root',
    HttpServer.response.text('Hello World!', {
      status: 200 as const,
      headers: HttpServer.headers.fromInput({ 'content-type': 'text/plain' }),
    }),
  ),
  RouterBuilder.build,
);

const program = app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(PrettyLogger.layer()),
);

NodeRuntime.runMain(program);
```

### conflict-error-example.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Context, Effect, pipe } from 'effect';
import { Api, HttpError, Middlewares, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make({ title: 'Users API' }),
  Api.addEndpoint(
    Api.post('storeUser', '/users').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestBody(Schema.Struct({ name: Schema.String })),
    ),
  ),
);

interface UserRepository {
  userExistsByName: (name: string) => Effect.Effect<boolean>;
  storeUser: (user: string) => Effect.Effect<void>;
}

const UserRepository = Context.GenericTag<UserRepository>('UserRepository');

const mockUserRepository = UserRepository.of({
  userExistsByName: () => Effect.succeed(true),
  storeUser: () => Effect.void,
});

const { storeUser, userExistsByName } = Effect.serviceFunctions(UserRepository);

const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle('storeUser', ({ body }) =>
    pipe(
      userExistsByName(body.name),
      Effect.filterOrFail(
        (alreadyExists) => !alreadyExists,
        () => HttpError.conflictError(`User "${body.name}" already exists.`),
      ),
      Effect.andThen(storeUser(body.name)),
      Effect.map(() => `User "${body.name}" stored.`),
    )),
  RouterBuilder.build,
  Middlewares.errorLog,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provideService(UserRepository, mockUserRepository),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### readme-security.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, Option } from 'effect';
import { Api, Middlewares, RouterBuilder, Security } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const mySecurity = Security.or(
  Security.asSome(Security.basic()),
  Security.as(Security.unit, Option.none()),
);

const mySecuredEnpoint = Api.post('security', '/testSecurity').pipe(
  Api.setResponseBody(Schema.String),
  Api.setSecurity(mySecurity),
);

const api = Api.make().pipe(
  Api.addEndpoint(mySecuredEnpoint),
);

const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle('security', (_, security) =>
    Effect.succeed(
      Option.match(security, {
        onSome: (creds) => `logged as ${creds.user}`,
        onNone: () => 'not logged',
      }),
    )),
  RouterBuilder.build,
  Middlewares.errorLog,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### headers.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Array, Context, Effect, pipe, Ref } from 'effect';
import { Api, HttpError, Middlewares, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

interface Clients {
  hasAccess: (clientId: string) => Effect.Effect<boolean>;
  getRemainingUsage: (clientId: string) => Effect.Effect<number, never, Usages>;
  recordUsage: (aipKey: string) => Effect.Effect<void, never, Usages>;
}

const ClientsService = Context.GenericTag<Clients>('@services/ClientsService');

type ClientUsage = {
  clientId: string;
  timestamp: number;
};

const RATE_WINDOW = 1000 * 30; // 30s
const ALLOWED_USAGES_PER_WINDOW = 5;

const clients = ClientsService.of({
  hasAccess: (clientId) => Effect.succeed(clientId === 'abc'),
  getRemainingUsage: (clientId) =>
    pipe(
      Effect.all(
        [
          Effect.flatMap(UsagesService, Ref.get),
          Effect.clockWith((clock) => clock.currentTimeMillis),
        ] as const,
      ),
      Effect.map(([usages, timestamp]) =>
        pipe(
          usages,
          Array.filter(
            (usage) =>
              usage.clientId === clientId &&
              usage.timestamp > timestamp - RATE_WINDOW,
          ),
          Array.length,
          (usagesPerWindow) => ALLOWED_USAGES_PER_WINDOW - usagesPerWindow,
        )
      ),
    ),
  recordUsage: (clientId) =>
    pipe(
      Effect.all(
        [
          UsagesService,
          Effect.clockWith((clock) => clock.currentTimeMillis),
        ] as const,
      ),
      Effect.flatMap(([usages, timestamp]) =>
        Ref.update(usages, (usages) => [...usages, { clientId, timestamp }])
      ),
    ),
});

type Usages = Ref.Ref<Array<ClientUsage>>;

const UsagesService = Context.GenericTag<Usages>('@services/UsagesService');

export const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.post('hello', '/hello').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestBody(Schema.Struct({ value: Schema.Number })),
      Api.setRequestHeaders(Schema.Struct({ 'x-client-id': Schema.String })),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'hello',
    ({ headers: { 'x-client-id': clientId } }) =>
      pipe(
        Effect.filterOrFail(
          Effect.flatMap(
            ClientsService,
            (clients) => clients.hasAccess(clientId),
          ),
          (hasAccess) => hasAccess,
          () => HttpError.unauthorizedError('Wrong api key'),
        ),
        Effect.flatMap(() =>
          Effect.flatMap(
            ClientsService,
            (client) => client.getRemainingUsage(clientId),
          )
        ),
        Effect.tap((remainingUsages) =>
          Effect.log(`Remaining ${remainingUsages} usages.`)
        ),
        Effect.filterOrFail(
          (remainingUsages) => remainingUsages > 0,
          () => HttpError.tooManyRequestsError('Rate limit exceeded'),
        ),
        Effect.flatMap(() =>
          Effect.flatMap(
            ClientsService,
            (client) => client.recordUsage(clientId),
          )
        ),
        Effect.as('hello there'),
      ),
  ),
  RouterBuilder.build,
  Middlewares.errorLog,
  Middlewares.accessLog('Debug'),
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provideService(ClientsService, clients),
  Effect.provideServiceEffect(
    UsagesService,
    Ref.make([] as Array<ClientUsage>),
  ),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### readme-security-basic.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { Api, RouterBuilder, Security } from 'effect-http';
import { NodeServer } from 'effect-http-node';

const api = Api.make().pipe(
  Api.addEndpoint(
    Api.post('mySecuredEndpoint', '/my-secured-endpoint').pipe(
      Api.setResponseBody(Schema.String),
      Api.setSecurity(Security.basic()),
    ),
  ),
);

const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle(
    'mySecuredEndpoint',
    (_, security) => Effect.succeed(`Accessed as ${security.user}`),
  ),
  RouterBuilder.build,
);

app.pipe(NodeServer.listen({ port: 3000 }), NodeRuntime.runMain);
```

### 100-299_success-channel.ts

```typescript
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { Api, ApiResponse, Client } from 'effect-http';

export const api = Api.make().pipe(
  Api.addEndpoint(
    Api.post('test', '/test').pipe(
      Api.setResponseBody(Schema.String),
      Api.addResponse(ApiResponse.make(400)),
    ),
  ),
);

const client = Client.make(api);

const log200 = (body: string) => Effect.log(body);

Effect.tap(client.test({}), log200);
```

### readme-quickstart.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, Client, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';

const UserResponse = Schema.Struct({
  name: Schema.String,
  id: pipe(Schema.Number, Schema.int(), Schema.positive()),
});
const GetUserQuery = Schema.Struct({ id: Schema.NumberFromString });

const api = pipe(
  Api.make({ title: 'Users API' }),
  Api.addEndpoint(
    pipe(
      Api.get('getUser', '/user'),
      Api.setResponseBody(UserResponse),
      Api.setRequestQuery(GetUserQuery),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'getUser',
    ({ query }) => Effect.succeed({ name: 'milan', id: query.id }),
  ),
  RouterBuilder.build,
);

app.pipe(NodeServer.listen({ port: 3000 }), NodeRuntime.runMain);

// Another file

const client = Client.make(api, { baseUrl: 'http://localhost:3000' });

const program = pipe(
  client.getUser({ query: { id: 12 } }),
  Effect.flatMap((user) => Effect.log(`Got ${user.name}, nice!`)),
  Effect.scoped,
);

Effect.runPromise(program);
```

### headers-client.ts

```typescript
import { Schema } from '@effect/schema';
import { Array, Effect, pipe } from 'effect';
import { Api, Client } from 'effect-http';

// Example client triggering the API from `examples/headers.ts`
// Running the script call the `/hello` endpoint 1000k times

export const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.post('hello', '/hello').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestBody(Schema.Struct({ value: Schema.Number })),
      Api.setRequestHeaders(Schema.Struct({ 'x-client-id': Schema.String })),
    ),
  ),
);

const client = Client.make(api, { baseUrl: 'http://localhost:3000' });

Effect.all(
  client.hello({ body: { value: 1 }, headers: { 'x-client-id': 'abc' } }).pipe(
    Effect.flatMap((r) => Effect.logInfo(`Success ${r}`)),
    Effect.catchAll((e) => Effect.logInfo(`Error ${JSON.stringify(e)}`)),
    Array.replicate(1000000),
  ),
).pipe(Effect.scoped, Effect.runPromise);
```

### repository.ts

```typescript
import { Array, Context, Effect, Layer, Option, Ref } from 'effect';

import type {
  CreateItemRequest,
  GetItemsQuery,
  Item,
  Items,
} from './schemas.js';

export interface ItemRepository {
  getItems: (query: GetItemsQuery) => Effect.Effect<Items>;
  createItem: (item: CreateItemRequest) => Effect.Effect<Item>;
}

export const ItemRepository = Context.GenericTag<ItemRepository>(
  '@services/ItemRepository',
);

export const getItems = (...args: Parameters<ItemRepository['getItems']>) =>
  Effect.flatMap(ItemRepository, ({ getItems }) => getItems(...args));

export const createItem = (...args: Parameters<ItemRepository['createItem']>) =>
  Effect.flatMap(ItemRepository, ({ createItem }) => createItem(...args));

export const ItemRepositoryInMemory = Ref.make([] as Items).pipe(
  Effect.map((memory) =>
    ItemRepository.of({
      getItems: (query) =>
        Ref.get(memory).pipe(
          Effect.map(
            Array.filter((item) => {
              const matchesId = query.id === undefined
                ? true
                : item.id === query.id;
              const matchesTitle = query.title === undefined
                ? true
                : item.title.includes(query.title);
              const matchesContent = query.content === undefined
                ? true
                : item.content.includes(query.content);

              return matchesId && matchesTitle && matchesContent;
            }),
          ),
        ),
      createItem: (item) =>
        Effect.gen(function* () {
          const items = yield* Ref.get(memory);

          const newItem = {
            ...item,
            id: items.length + 1,
            createdAt: new Date(),
            updatedAt: Option.none(),
          };

          yield* Ref.update(memory, Array.append(newItem));
          return newItem;
        }),
    })
  ),
  Layer.effect(ItemRepository),
);
```

### main.ts

```typescript
import { Effect } from 'effect';
import { NodeServer } from 'effect-http-node';
import { PrettyLogger } from 'effect-log';

import { NodeRuntime } from '@effect/platform-node';
import { ItemRepositoryInMemory } from './repository.js';
import { app } from './server.js';

const program = app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(PrettyLogger.layer()),
  Effect.provide(ItemRepositoryInMemory),
);

NodeRuntime.runMain(program);
```

### schemas.ts

```typescript
import * as Schema from '@effect/schema/Schema';

const Integer = Schema.Number.pipe(Schema.int());
const IntegerFromString = Schema.NumberFromString.pipe(Schema.int());

export const Item = Schema.Struct({
  id: Integer,
  title: Schema.String,
  content: Schema.String,
  createdAt: Schema.Date,
  updatedAt: Schema.OptionFromNullOr(Schema.Date),
});
export type Item = Schema.Schema.Type<typeof Item>;

export const Items = Schema.Array(Item);
export type Items = Schema.Schema.Type<typeof Items>;

export const CreateItemRequest = Item.pipe(
  Schema.omit('id', 'createdAt', 'updatedAt'),
);
export type CreateItemRequest = Schema.Schema.Type<typeof CreateItemRequest>;

export const CreateItemResponse = Item.pipe(Schema.pick('id', 'createdAt'));

export const GetItemsQuery = Item.pipe(
  Schema.pick('title', 'content'),
  Schema.extend(Schema.Struct({ id: IntegerFromString })),
  (schema) => Schema.partial(schema),
);
export type GetItemsQuery = Schema.Schema.Type<typeof GetItemsQuery>;
```

### api.ts

```typescript
import { Api } from 'effect-http';

import {
  CreateItemRequest,
  CreateItemResponse,
  GetItemsQuery,
  Items,
} from './schemas.js';

const createItem = Api.post('createItem', '/item').pipe(
  Api.setRequestBody(CreateItemRequest),
  Api.setResponseStatus(201),
  Api.setResponseBody(CreateItemResponse),
);

const getItems = Api.get('getItems', '/items').pipe(
  Api.setRequestQuery(GetItemsQuery),
  Api.setResponseBody(Items),
);

export const api = Api.make({ title: 'Example TODO list API' }).pipe(
  Api.addEndpoint(createItem),
  Api.addEndpoint(getItems),
);
```

### server.ts

```typescript
import { Effect } from 'effect';
import { RouterBuilder } from 'effect-http';

import { api } from './api.js';
import { createItem, getItems } from './repository.js';

export const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle('getItems', ({ query }) =>
    getItems(query).pipe(
      Effect.tap((items) => Effect.log(`Found ${items.length} items`)),
    )),
  RouterBuilder.handle('createItem', ({ body }) => createItem(body)),
  RouterBuilder.build,
);
```

### example.ts

```typescript
import { Schema } from '@effect/schema';
import { Context, Effect, Layer, pipe } from 'effect';
import { Api, RouterBuilder, Security } from 'effect-http';

import { NodeRuntime } from '@effect/platform-node';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

// Schemas

const HumanSchema = Schema.Struct({
  height: Schema.Number,
  name: Schema.String,
});
const Lesnek = Schema.Struct({ name: Schema.String });
const Standa = Schema.Record(
  Schema.String,
  Schema.Union(Schema.String, Schema.Number),
);

interface StuffService {
  value: number;
}
const StuffService = Context.GenericTag<StuffService>('@services/StuffService');

const dummyStuff = pipe(
  Effect.succeed({ value: 42 }),
  Layer.effect(StuffService),
);

// Api

const getLesnek = Api.get('getLesnek', '/lesnek').pipe(
  Api.setResponseBody(Schema.String),
  Api.setRequestQuery(Lesnek),
  Api.setSecurity(
    Security.bearer({ name: 'myAwesomeBearerAuth', bearerFormat: 'JWT' }),
  ),
);

const api = pipe(
  Api.make({ title: 'My awesome pets API', version: '1.0.0' }),
  Api.addEndpoint(getLesnek),
  Api.addEndpoint(
    Api.get('getMilan', '/milan').pipe(Api.setResponseBody(Schema.String)),
  ),
  Api.addEndpoint(
    Api.get('test', '/test').pipe(
      Api.setResponseBody(Standa),
      Api.setRequestQuery(Lesnek),
    ),
  ),
  Api.addEndpoint(
    Api.post('standa', '/standa').pipe(
      Api.setResponseBody(Standa),
      Api.setRequestBody(Standa),
    ),
  ),
  Api.addEndpoint(
    Api.post('handleMilan', '/petr').pipe(
      Api.setResponseBody(HumanSchema),
      Api.setRequestBody(HumanSchema),
    ),
  ),
  Api.addEndpoint(
    Api.put('callStanda', '/api/zdar').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestBody(Schema.Struct({ zdar: Schema.Literal('zdar') })),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api, { parseOptions: { errors: 'all' } }),
  RouterBuilder.handle('getLesnek', ({ query }) =>
    pipe(
      Effect.succeed(`hello ${query.name}`),
      Effect.tap(() => Effect.logDebug('hello world')),
    )),
  RouterBuilder.handle(
    'handleMilan',
    ({ body }) =>
      Effect.map(StuffService, ({ value }) => ({
        ...body,
        randomValue: body.height + value,
      })),
  ),
  RouterBuilder.handle('getMilan', () => Effect.succeed('test')),
  RouterBuilder.handle(
    'test',
    ({ query: { name } }) => Effect.succeed({ name }),
  ),
  RouterBuilder.handle(
    'standa',
    ({ body }) => Effect.succeed({ ...body, standa: 'je borec' }),
  ),
  RouterBuilder.handle('callStanda', () => Effect.succeed('zdar')),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 4000 }),
  Effect.provide(dummyStuff),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### bun-server.ts

```typescript
import { HttpServer } from '@effect/platform';
import { BunContext, BunHttpServer } from '@effect/platform-bun';
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, Layer, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';
import { NodeSwaggerFiles } from 'effect-http-node';

const Response = Schema.Struct({
  name: Schema.String,
  id: pipe(Schema.Number, Schema.int(), Schema.positive()),
});
const Query = Schema.Struct({ id: Schema.NumberFromString });

const api = pipe(
  Api.make({ title: 'Users API' }),
  Api.addEndpoint(
    Api.get('getUser', '/user').pipe(
      Api.setResponseBody(Response),
      Api.setRequestQuery(Query),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'getUser',
    ({ query }) => Effect.succeed({ name: 'milan', id: query.id }),
  ),
  RouterBuilder.build,
);

const server = pipe(
  HttpServer.server.serve(app),
  Layer.provide(NodeSwaggerFiles.SwaggerFilesLive),
  Layer.provide(BunHttpServer.server.layer({ port: 3000 })),
  Layer.provide(BunContext.layer),
  Layer.launch,
  Effect.scoped,
);

NodeRuntime.runMain(server);
```

### extensions.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, Metric, pipe } from 'effect';
import { Api, Middlewares, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make({ title: 'Users API' }),
  Api.addEndpoint(
    Api.get('getUser', '/user', { description: 'Returns a User by id' }).pipe(
      Api.setResponseBody(Schema.String),
    ),
  ),
  Api.addEndpoint(
    Api.get('metrics', '/metrics').pipe(
      Api.setResponseBody(Schema.Unknown),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'getUser',
    () => Effect.succeed('Hello').pipe(Effect.tap(() => Effect.log('hello'))),
  ),
  RouterBuilder.handle('metrics', () => Metric.snapshot),
  RouterBuilder.build,
  Middlewares.accessLog(),
  Middlewares.endpointCallsMetric(),
  Middlewares.uuidLogAnnotation(),
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### form-data.ts

```typescript
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, HttpError, Representation, RouterBuilder } from 'effect-http';

import { FileSystem, HttpServer } from '@effect/platform';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.post('upload', '/upload').pipe(
      Api.setRequestBody(Api.FormData),
      Api.setResponseBody(Schema.String),
      Api.setResponseRepresentations([Representation.plainText]),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle('upload', () =>
    Effect.gen(function* () {
      const request = yield* HttpServer.request.ServerRequest;
      const formData = yield* request.multipart;

      const file = formData['file'];

      if (typeof file === 'string') {
        return yield* HttpError.badRequest('File not found');
      }

      const fs = yield* FileSystem.FileSystem;
      return yield* fs.readFileString(file[0].path);
    }).pipe(Effect.scoped)),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  Effect.provide(NodeContext.layer),
  NodeRuntime.runMain,
);
```

### optional-query-parameter.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const SchemaBooleanFromString = Schema.transformLiterals(['true', true], [
  'false',
  false,
]);

export const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.get('userById', '/api/users/:userId').pipe(
      Api.setResponseBody(Schema.Struct({ name: Schema.String })),
      Api.setRequestPath(Schema.Struct({ userId: Schema.String })),
      Api.setRequestQuery(
        Schema.Struct({
          include_deleted: Schema.optional(SchemaBooleanFromString),
        }),
      ),
      Api.setRequestHeaders(Schema.Struct({ authorization: Schema.String })),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'userById',
    ({ query: { include_deleted } }) =>
      Effect.succeed({
        name: `include_deleted = ${include_deleted ?? '[not set]'}`,
      }),
  ),
  RouterBuilder.build,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### schema-with-optional-field.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, Option, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const Response = Schema.Struct({
  foo: Schema.optional(Schema.String, { as: 'Option' }),
  bar: Schema.Option(Schema.String),
});

const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.get('hello', '/hello').pipe(Api.setResponseBody(Response)),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'hello',
    () => Effect.succeed({ foo: Option.none(), bar: Option.none() }),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 4000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### input-example.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, HttpError, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make({ title: 'My api' }),
  Api.addEndpoint(
    Api.get('stuff', '/stuff').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestQuery(Schema.Struct({ value: Schema.String })),
    ),
  ),
);

const stuffHandler = RouterBuilder.handler(api, 'stuff', ({ query }) =>
  pipe(
    Effect.fail(HttpError.notFoundError('I didnt find it')),
    Effect.tap(() => Effect.log(`Received ${query.value}`)),
  ));

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(stuffHandler),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### plain-text.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect } from 'effect';
import { Api, Representation, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { PrettyLogger } from 'effect-log';

export const api = Api.make({ title: 'Example API' }).pipe(
  Api.addEndpoint(
    Api.get('root', '/').pipe(
      Api.setResponseBody(Schema.Unknown),
      Api.setResponseRepresentations([
        Representation.plainText,
        Representation.json,
      ]),
    ),
  ),
);

export const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle(
    'root',
    () => Effect.succeed({ content: { hello: 'world' }, status: 200 as const }),
  ),
  RouterBuilder.build,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(PrettyLogger.layer()),
  NodeRuntime.runMain,
);
```

### groups.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, ApiGroup, ExampleServer, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const Response = Schema.Struct({ name: Schema.String });

const testApi = pipe(
  ApiGroup.make('test', {
    description: 'Test description',
    externalDocs: {
      description: 'Test external doc',
      url: 'https://www.google.com/search?q=effect-http',
    },
  }),
  ApiGroup.addEndpoint(
    ApiGroup.get('test', '/test').pipe(Api.setResponseBody(Response)),
  ),
);

const userApi = pipe(
  ApiGroup.make('Users', {
    description: 'All about users',
    externalDocs: {
      url: 'https://www.google.com/search?q=effect-http',
    },
  }),
  ApiGroup.addEndpoint(
    ApiGroup.get('getUser', '/user').pipe(Api.setResponseBody(Response)),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.post('storeUser', '/user').pipe(Api.setResponseBody(Response)),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.put('updateUser', '/user').pipe(Api.setResponseBody(Response)),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.delete('deleteUser', '/user').pipe(Api.setResponseBody(Response)),
  ),
);

const categoriesApi = ApiGroup.make('Categories').pipe(
  ApiGroup.addEndpoint(
    ApiGroup.get('getCategory', '/category').pipe(
      Api.setResponseBody(Response),
    ),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.post('storeCategory', '/category').pipe(
      Api.setResponseBody(Response),
    ),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.put('updateCategory', '/category').pipe(
      Api.setResponseBody(Response),
    ),
  ),
  ApiGroup.addEndpoint(
    ApiGroup.delete('deleteCategory', '/category').pipe(
      Api.setResponseBody(Response),
    ),
  ),
);

const api = Api.make().pipe(
  Api.addGroup(testApi),
  Api.addGroup(userApi),
  Api.addGroup(categoriesApi),
);

ExampleServer.make(api).pipe(
  RouterBuilder.build,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### new-api.ts

```typescript
import { Schema } from '@effect/schema';
import { pipe } from 'effect';
import { Api, ApiGroup, ApiResponse, Security } from 'effect-http';

interface MyRequirement {}
interface AnotherDep {}

const schema1: Schema.Schema<number, string, MyRequirement> =
  Schema.NumberFromString;
const schema2: Schema.Schema<number, string, AnotherDep> =
  Schema.NumberFromString;

class MyRequest extends Schema.Class<MyRequest>('Schema1')({
  name: schema1,
}) {}

class TestPathParams extends Schema.Class<TestPathParams>('TestPathParams')({
  path: schema2,
}) {}

const group1 = pipe(
  ApiGroup.make('my group'),
  ApiGroup.addEndpoint(
    pipe(
      ApiGroup.get('groupTest', '/test', { description: 'test description' }),
      ApiGroup.setRequestBody(MyRequest),
      ApiGroup.setRequestPath(TestPathParams),
    ),
  ),
);

const test = pipe(
  Api.get('test', '/test'),
  Api.setRequestBody(MyRequest),
  Api.setRequestPath(TestPathParams),
  Api.setSecurity(
    Security.bearer({ name: 'mySecurity', description: 'test' }),
  ),
  Api.setResponseBody(MyRequest),
  Api.addResponse(ApiResponse.make(201, TestPathParams, MyRequest)),
);

export const api = pipe(
  Api.make({ title: 'my api' }),
  Api.addEndpoint(test),
  Api.addEndpoint(
    pipe(
      Api.get('another', '/hello-there'),
      Api.setRequestBody(MyRequest),
      Api.setRequestPath(TestPathParams),
    ),
  ),
  Api.addGroup(group1),
);
```

### multiple-responses.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, ApiResponse, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const helloEndpoint = Api.post('hello', '/hello').pipe(
  Api.setResponseBody(Schema.Number),
  Api.setResponseHeaders(Schema.Struct({
    'my-header': pipe(
      Schema.NumberFromString,
      Schema.annotations({ description: 'My header' }),
    ),
  })),
  Api.addResponse(ApiResponse.make(201, Schema.Number)),
  Api.addResponse({
    status: 204,
    headers: Schema.Struct({ 'x-another': Schema.NumberFromString }),
  }),
);

const api = pipe(
  Api.make(),
  Api.addEndpoint(helloEndpoint),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'hello',
    () =>
      Effect.succeed({
        body: 12,
        headers: { 'my-header': 69 },
        status: 201 as const,
      }),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### readme-security-custom.ts

```typescript
import { HttpServer } from '@effect/platform';
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import {
  Api,
  HttpError,
  Middlewares,
  RouterBuilder,
  Security,
} from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const customSecurity = Security.make(
  pipe(
    HttpServer.request.schemaHeaders(
      Schema.Struct({ 'x-api-key': Schema.String }),
    ),
    Effect.mapError(() =>
      HttpError.unauthorizedError('Expected valid X-API-KEY header')
    ),
    Effect.map((headers) => headers['x-api-key']),
  ),
  {
    'myApiKey': {
      name: 'X-API-KEY',
      type: 'apiKey',
      in: 'header',
      description: 'My API key',
    },
  },
);

const api = Api.make().pipe(
  Api.addEndpoint(
    Api.post('myRoute', '/my-route').pipe(
      Api.setResponseBody(Schema.String),
      Api.setSecurity(customSecurity),
    ),
  ),
);

const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle(
    'myRoute',
    (_, apiKey) => Effect.succeed(`Logged as ${apiKey}`),
  ),
  RouterBuilder.build,
  Middlewares.errorLog,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### readme-headers.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { pipe } from 'effect';
import { Api, ExampleServer, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';

const api = Api.make().pipe(
  Api.addEndpoint(
    Api.get('hello', '/hello').pipe(
      Api.setResponseBody(Schema.String),
      Api.setRequestHeaders(Schema.Struct({ 'x-client-id': Schema.String })),
    ),
  ),
);

pipe(
  ExampleServer.make(api),
  RouterBuilder.build,
  NodeServer.listen({ port: 3000 }),
  NodeRuntime.runMain,
);
```

### request-validation-optional-parameter.ts

```typescript
import { Schema } from '@effect/schema';
import { pipe } from 'effect';
import { Api } from 'effect-http';

const Stuff = Schema.Struct({ value: Schema.Number });
const StuffParams = Schema.Struct({
  param: Schema.String,
  another: Schema.optional(Schema.String),
});

export const api = pipe(
  Api.make({ title: 'My api' }),
  Api.addEndpoint(
    pipe(
      Api.get('stuff', '/stuff/:param/:another?'),
      Api.setResponseBody(Stuff),
      Api.setRequestPath(StuffParams),
    ),
  ),
);
```

### readme-security-complex.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, Fiber, Layer, pipe, Schedule } from 'effect';
import { Api, Client, Middlewares, RouterBuilder, Security } from 'effect-http';
import { NodeServer } from 'effect-http-node';

interface UserInfo {
  email: string;
}

class UserStorage extends Effect.Tag('UserStorage')<
  UserStorage,
  { getInfo: (user: string) => Effect.Effect<UserInfo> }
>() {
  static dummy = Layer.succeed(
    this,
    { getInfo: (_: string) => Effect.succeed({ email: 'email@gmail.com' }) },
  );
}

const mySecurity = pipe(
  Security.basic({ description: 'My basic auth' }),
  Security.map((creds) => creds.user),
  Security.mapEffect((user) => UserStorage.getInfo(user)),
);

const api = Api.make().pipe(
  Api.addEndpoint(
    pipe(
      Api.post('endpoint', '/endpoint'),
      Api.setResponseBody(Schema.String),
      Api.setSecurity(mySecurity),
    ),
  ),
);

const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle(
    'endpoint',
    (_, security) => Effect.succeed(`Logged as ${security.email}`),
  ),
  RouterBuilder.build,
  Middlewares.errorLog,
);

Effect.gen(function* (_) {
  const fiber = yield* pipe(
    app,
    NodeServer.listen({ port: 3000 }),
    Effect.fork,
  );

  const client = Client.make(api, { baseUrl: 'http://localhost:3000' });

  yield* pipe(
    client.endpoint({}, Client.setBasic('patrik', 'slepice')),
    Effect.catchAllDefect(Effect.fail),
    Effect.onError((e) => Effect.logWarning(`Api call failed with ${e}`)),
    Effect.retry({ schedule: Schedule.spaced('1 second') }),
    Effect.flatMap((response) =>
      Effect.log(`Api call succeeded with ${response}`)
    ),
  );

  yield* Fiber.join(fiber);
}).pipe(
  Effect.provide(UserStorage.dummy),
  NodeRuntime.runMain,
);
```

### request-example.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import {
  Array,
  Context,
  Duration,
  Effect,
  pipe,
  Request,
  RequestResolver,
} from 'effect';
import { Api, HttpError, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import type { FileNotFoundError } from './_utils.js';
import { debugLogger, readFile } from './_utils.js';

interface GetValue extends Request.Request<string, FileNotFoundError> {
  readonly _tag: 'GetValue';
}
const GetValue = Request.tagged<GetValue>('GetValue');

const GetValueCache = Context.GenericTag<Request.Cache>(
  '@services/GetValueCache',
);

const GetValueResolver = RequestResolver.fromEffect((_: GetValue) =>
  pipe(
    readFile('test-file'),
    Effect.tap(() => Effect.logDebug('Value read from file')),
  )
);

const requestMyValue = Effect.flatMap(GetValueCache, (getValueCache) =>
  pipe(
    Effect.request(GetValue({}), GetValueResolver),
    Effect.withRequestCache(getValueCache),
    Effect.withRequestCaching(true),
  ));

const api = pipe(
  Api.make(),
  Api.addEndpoint(
    Api.get('getValue', '/value').pipe(Api.setResponseBody(Schema.String)),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'getValue',
    () =>
      Effect.flatMap(GetValueCache, (getValueCache) =>
        pipe(
          Effect.all(Array.replicate(requestMyValue, 10), {
            concurrency: 10,
          }),
          Effect.mapError(() => HttpError.notFoundError('File not found')),
          Effect.withRequestCache(getValueCache),
          Effect.withRequestCaching(true),
          Effect.map((values) => values.join(', ')),
        )),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provideServiceEffect(
    GetValueCache,
    Request.makeCache({ capacity: 100, timeToLive: Duration.seconds(5) }),
  ),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### request-validation.ts

```typescript
import { Schema } from '@effect/schema';
import { Api } from 'effect-http';

const Stuff = Schema.Struct({ value: Schema.Number });
const StuffRequest = Schema.Struct({ field: Schema.Array(Schema.String) });
const StuffQuery = Schema.Struct({ value: Schema.String });
const StuffPath = Schema.Struct({ param: Schema.String });

export const api = Api.make({ title: 'My api' }).pipe(
  Api.addEndpoint(
    Api.post('stuff', '/stuff/:param').pipe(
      Api.setRequestBody(StuffRequest),
      Api.setRequestQuery(StuffQuery),
      Api.setRequestPath(StuffPath),
      Api.setResponseBody(Stuff),
    ),
  ),
);
```

### unexpected-error.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Data, Effect } from 'effect';
import { Api, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { PrettyLogger } from 'effect-log';

export const api = Api.make({ title: 'Example API' }).pipe(
  Api.addEndpoint(
    Api.get('root', '/').pipe(Api.setResponseBody(Schema.String)),
  ),
);

class MyError extends Data.TaggedError('MyError')<{}> {}

export const app = RouterBuilder.make(api).pipe(
  RouterBuilder.handle(
    'root',
    () => Effect.fail(new MyError()),
  ),
  RouterBuilder.build,
);

const program = app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(PrettyLogger.layer()),
);

NodeRuntime.runMain(program);
```

### mock-client.ts

```typescript
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, MockClient } from 'effect-http';

export const exampleApiGet = Api.make().pipe(
  Api.addEndpoint(
    Api.get('getValue', '/get-value').pipe(
      Api.setResponseBody(Schema.Number),
    ),
  ),
);

const client = MockClient.make(exampleApiGet);

const program = pipe(
  client.getValue({}),
  Effect.tap(Effect.log),
  Effect.scoped,
);

Effect.runPromise(program);
```

### description.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const Response = pipe(
  Schema.Struct({
    name: Schema.String,
    id: pipe(Schema.Number, Schema.int(), Schema.positive()),
  }),
  Schema.annotations({ description: 'User' }),
);
const Query = Schema.Struct({
  id: pipe(
    Schema.NumberFromString,
    Schema.annotations({ description: 'User id' }),
  ),
});

const api = pipe(
  Api.make({ title: 'Users API' }),
  Api.addEndpoint(
    Api.get('getUser', '/user', { description: 'Returns a User by id' }).pipe(
      Api.setResponseBody(Response),
      Api.setRequestQuery(Query),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'getUser',
    ({ query }) => Effect.succeed({ name: 'mike', id: query.id }),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### resource-example.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import {
  Array,
  Context,
  Duration,
  Effect,
  pipe,
  Resource,
  Schedule,
} from 'effect';
import { Api, HttpError, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import type { FileNotFoundError } from './_utils.js';
import { debugLogger, readFile } from './_utils.js';

const MyValue = Context.GenericTag<
  Resource.Resource<string, FileNotFoundError>
>('@services/MyValue');

const readMyValue = Effect.flatMap(MyValue, Resource.get);

const api = Api.make().pipe(
  Api.addEndpoint(
    Api.get('getValue', '/value').pipe(
      Api.setResponseBody(Schema.String),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle('getValue', () =>
    pipe(
      Effect.all(Array.replicate(readMyValue, 10), { concurrency: 10 }),
      Effect.mapError(() => HttpError.notFoundError('File not found')),
      Effect.map((values) => values.join(', ')),
    )),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provideServiceEffect(
    MyValue,
    Resource.auto(
      pipe(
        readFile('test-file'),
        Effect.tap(() => Effect.logDebug('MyValue refreshed from file')),
      ),
      Schedule.fixed(Duration.seconds(5)),
    ),
  ),
  Effect.scoped,
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### custom-response.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = pipe(
  Api.make(),
  Api.addEndpoint(
    pipe(
      Api.get('hello', '/hello'),
      Api.setResponseStatus(201),
      Api.setResponseBody(Schema.Number),
      Api.setResponseHeaders(Schema.Struct({ 'x-hello-world': Schema.String })),
    ),
  ),
);

const app = pipe(
  RouterBuilder.make(api),
  RouterBuilder.handle(
    'hello',
    () =>
      Effect.succeed({
        body: 12,
        headers: { 'x-hello-world': 'test' },
        status: 201 as const,
      }),
  ),
  RouterBuilder.build,
);

pipe(
  app,
  NodeServer.listen({ port: 3000 }),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### static-files-from-root.ts

```typescript
import { NodeContext, NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Effect, pipe } from 'effect';
import { Api, RouterBuilder } from 'effect-http';

import { HttpServer } from '@effect/platform';
import { NodeServer } from 'effect-http-node';
import { debugLogger } from './_utils.js';

const api = Api.make().pipe(
  Api.addEndpoint(
    Api.get('handle', '/api/handle').pipe(Api.setResponseBody(Schema.String)),
  ),
);

const StaticFilesMiddleware = HttpServer.middleware.make((app) =>
  Effect.gen(function* () {
    const request = yield* HttpServer.request.ServerRequest;

    if (request.url.startsWith('/api')) {
      return yield* app;
    }

    return yield* pipe(
      HttpServer.response.file(request.url.replace('/', '')),
      Effect.orElse(() =>
        HttpServer.response.text('Not found', { status: 404 })
      ),
    );
  })
);

const app = RouterBuilder.make(api, { enableDocs: true }).pipe(
  RouterBuilder.handle('handle', () => Effect.succeed('Hello World')),
  RouterBuilder.build,
  StaticFilesMiddleware,
);

app.pipe(
  NodeServer.listen({ port: 3000 }),
  Effect.provide(NodeContext.layer),
  Effect.provide(debugLogger),
  NodeRuntime.runMain,
);
```

### no-content.ts

```typescript
import { NodeRuntime } from '@effect/platform-node';
import { Schema } from '@effect/schema';
import { Api, ExampleServer, RouterBuilder } from 'effect-http';
import { NodeServer } from 'effect-http-node';

export const api = Api.make().pipe(
  Api.addEndpoint(
    Api.post('test', '/test').pipe(Api.setRequestBody(Schema.String)),
  ),
);

const app = ExampleServer.make(api).pipe(
  RouterBuilder.build,
);

app.pipe(NodeServer.listen({ port: 3000 }), NodeRuntime.runMain);
```

# examples Examples

## examples

### example.ts

```typescript
console.log('WIP');
```
